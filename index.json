[{"authors":null,"categories":null,"content":"I am an ambitious data professional with a background in computational biology and experience applying data technology to the domains of biotech, supply chain, and manufacturing. I have a strong focus on applying data, ML, statistics, and modern data tools to solve real-world problems.\nDownload my CV  or visit my about page.\n","date":1621123200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1621123200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/anders-e.-nielsen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/anders-e.-nielsen/","section":"authors","summary":"I am an ambitious data professional with a background in computational biology and experience applying data technology to the domains of biotech, supply chain, and manufacturing. I have a strong focus on applying data, ML, statistics, and modern data tools to solve real-world problems.","tags":null,"title":"Anders E. Nielsen","type":"authors"},{"authors":null,"categories":null,"content":"  index  code{white-space: pre-wrap;} span.smallcaps{font-variant: small-caps;} span.underline{text-decoration: underline;} div.column{display: inline-block; vertical-align: top; width: 50%;} div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;} ul.task-list{list-style: none;} pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ff0000; font-weight: bold; } /* Alert */ code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #7d9029; } /* Attribute */ code span.bn { color: #40a070; } /* BaseN */ code span.bu { } /* BuiltIn */ code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4070a0; } /* Char */ code span.cn { color: #880000; } /* Constant */ code span.co { color: #60a0b0; font-style: italic; } /* Comment */ code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #ba2121; font-style: italic; } /* Documentation */ code span.dt { color: #902000; } /* DataType */ code span.dv { color: #40a070; } /* DecVal */ code span.er { color: #ff0000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #40a070; } /* Float */ code span.fu { color: #06287e; } /* Function */ code span.im { } /* Import */ code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #007020; font-weight: bold; } /* Keyword */ code span.op { color: #666666; } /* Operator */ code span.ot { color: #007020; } /* Other */ code span.pp { color: #bc7a00; } /* Preprocessor */ code span.sc { color: #4070a0; } /* SpecialChar */ code span.ss { color: #bb6688; } /* SpecialString */ code span.st { color: #4070a0; } /* String */ code span.va { color: #19177c; } /* Variable */ code span.vs { color: #4070a0; } /* VerbatimString */ code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */ div.csl-bib-body { } div.csl-entry { clear: both; } .hanging div.csl-entry { margin-left:2em; text-indent:-2em; } div.csl-left-margin { min-width:2em; float:left; } div.csl-right-inline { margin-left:2em; padding-left:1em; } div.csl-indent { margin-left: 2em; }   document.addEventListener(\"DOMContentLoaded\", function () { var mathElements = document.getElementsByClassName(\"math\"); var macros = []; for (var i = 0; i          Bayesian optimisation is a powerful optimisation technique for black-box functions and processes with expensive evaluations. It is popular for hyperparameter tuning and model selection in machine learning, but has many real-world applications as well. One of the key components of Bayesian optimisation is the acquisition function, which guides the search process by balancing exploration and exploitation of the search space. In this post, we will dive into the role of acquisition functions in Bayesian optimisation and discuss some popular examples.\nAlong with the discussion are implementations of each acquisition function in R, using only base R and the Tidyverse.\nlibrary(ggplot2) library(magrittr) set.seed(4444)  Acquisition Functions in Bayesian Optimisation Bayesian optimisation is an iterative process. It combines a probabilistic surrogate model, often a Gaussian Process (GP), with an acquisition function to select the next point to evaluate in an expensive objective function or process, f. The surrogate model captures our current understanding and uncertainty of the objective function, while the acquisition function helps balance the trade-off between exploring new regions of input space and exploiting regions with high predicted performance.\nMathematically, the acquisition function, a(\\mathbf{x}), assigns a value to each point in the search space \\mathbf{x} \\in \\mathcal{X}. The next point to evaluate, \\mathbf{x}_{t+1}, is chosen by maximising or minimising the acquisition function, depending on the optimisation task and acquisition function at hand, i.e.\n\\mathbf{x}_{t+1} = \\arg\\min_{\\mathbf{x} \\in \\mathcal{X}} a(\\mathbf{x})\nor\n\\mathbf{x}_{t+1} = \\arg\\max_{\\mathbf{x} \\in \\mathcal{X}} a(\\mathbf{x})\nThe acquisition function takes into account both the mean \\mu(\\mathbf{x}) and the variance \\sigma^2(\\mathbf{x}) of the surrogate model’s prediction, to balance exploration and exploitation. Roughly speaking, areas with extreme values of \\mu(\\mathbf{x}) correspond to areas we might exploit to get good performing samples, while areas with high values of \\sigma^2(\\mathbf{x}) correspond to with high uncertainty that we might consider for exploration.\nNotation The notation used in this post is as follows\na(\\mathbf{x}) is an acquisition function of a point \\mathbf{x} in the search space \\mathcal{X}. While the search space often contains multiple feature dimensions \\mathcal{X} \\in \\mathbb{R}^n, here the example will be in one dimension.\nf(\\mathbf{x}) is the value of true objective function, f, at \\mathbf{x}. It is this function that we aim to optimise. However, the function is not directly available and it is expensive to evaluate so we use a surrogate model to approximate it.\nIn most applications, the observations of the objective function are noisy, y = f(\\mathbf{x}) + \\epsilon, where \\epsilon is Gaussian noise. So we will use \\mathbf{y} to indicate observations.\nf(\\mathbf{x}^+), f_{\\min}, and f_{\\max} all represent the best observed value of the objective function so far. If the observations are noisy, the corresponding notation is y^+, y_{\\min}, and y_{\\max}. For most examples of acquisition functions, this post focuses on minimisation problems, where the best observed value is y_{\\min}.\n\\mathcal{D} is a set of training observations (\\mathbf{X}_{train}, \\mathbf{y}_{train}).\n\\mu(\\mathbf{x}) represents the mean prediction of the surrogate model at point \\mathbf{x}.\n\\sigma(\\mathbf{x}) represents the standard deviation (uncertainty) of the surrogate model’s prediction at point \\mathbf{x}. For a GP, this is an entry in the diagonal of the posterior covariance matrix.\nAn Example Problem For the demonstration of acquisition functions, we need a toy problem. We will use a simple objective function without noise and a single dimension.\nobjective_function \u0026lt;- function(x) {  sin(12 * x) * x + 0.5 * x^2 } X_pred \u0026lt;- matrix(seq(0, 1, length.out = 100), 100, 1) y_pred \u0026lt;- objective_function(X_pred)  This function has two minima and two maxima in the search space \\mathcal{X} = [0,1], so it will not be too easy to maximise or minimise.\n\n Show the code\nggplot(data = tibble::tibble(x = X_pred, y = y_pred)) +  geom_line(aes(x = x, y = y)) +  theme_minimal() +  labs(x = \"x\", y = \"f(x)\", title = \"Objective Function\")    We will approximate the the objective function with a Gaussian process surrogate model that utilises the RBF kernel. See the Bayesian optimisation post for details.\n\n Show the code\n#' RBF Kernel #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param l length scale #' @param sigma_f scale parameter  #' #' @return matrix of dimensions (n, m) rbf_kernel \u0026lt;- function(X1, X2, l = 1.0, sigma_f = 1.0) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  sqdist \u0026lt;- (- 2*(X1 %*% t(X2))) %\u0026gt;%  add(rowSums(X1**2, dims = 1)) %\u0026gt;%  sweep(2, rowSums(X2**2, dims = 1), `+`)  sigma_f**2 * exp(-0.5 / l**2 * sqdist) }  #' Random Samples from a Multivariate Gaussian #'  #' This implementation is similar to MASS::mvrnorm, but uses chlosky #' decomposition instead. This should be more stable but is less efficient than #' the MASS implementation, which recycles the eigen decomposition for the #' sampling part. #' #' @param n number of samples to sample #' @param mu the mean of each input dimension #' @param sigma the covariance matrix #' @param epsilon numerical tolerance added to the diagonal of the covariance #' matrix. This is necessary for the Cholesky decomposition, in some cases. #' #' @return numerical vector of n samples rmvnorm \u0026lt;- function(n = 1, mu, sigma, epsilon = 1e-6) {  p \u0026lt;- length(mu)  if(!all(dim(sigma) == c(p, p))) stop(\"incompatible dimensions of arguments\")  ev \u0026lt;- eigen(sigma, symmetric = TRUE)$values  if(!all(ev \u0026gt;= -epsilon*abs(ev[1L]))) {  stop(\"The covariance matrix (sigma) is not positive definite\")  }  cholesky \u0026lt;- chol(sigma + diag(p)*epsilon)  sample \u0026lt;- rnorm(p*n, 0, 1)  dim(sample) \u0026lt;- c(n, p)  sweep(sample %*% cholesky, 2, mu, FUN = `+`) }  #' Get Parameters of the Posterior Gaussian Process #' #' @param kernel kernel function used for the Gaussian process #' @param X_pred matrix (m, d) of prediction points #' @param X_train matrix (n, d) of training points #' @param y_train column vector (n, d) of training observations #' @param noise scalar of observation noise #' @param ... named parameters for the kernel function #' #' @return list of mean (mu) and covariance (sigma) for the Gaussian posterior \u0026lt;- function(kernel, X_pred, X_train, y_train, noise = 1e-8, ...) {  if (is.null(dim(X_pred))) dim(X_pred) \u0026lt;- c(length(X_pred), 1)  if (is.null(dim(X_train))) dim(X_train) \u0026lt;- c(length(X_train), 1)  if (is.null(dim(y_train))) dim(y_train) \u0026lt;- c(length(y_train), 1)  K \u0026lt;- kernel(X_train, X_train, ...) + noise**2 * diag(dim(X_train)[[1]])  K_s \u0026lt;- kernel(X_train, X_pred, ...)  K_ss \u0026lt;- kernel(X_pred, X_pred, ...) + 1e-8 * diag(dim(X_pred)[[1]])  K_inv \u0026lt;- solve(K)  mu \u0026lt;- (t(K_s) %*% K_inv) %*% y_train  sigma \u0026lt;- K_ss - (t(K_s) %*% K_inv) %*% K_s  list(mu = mu, sigma = sigma) }  #' Negative log-Likelihood of a Kernel #' #' @param kernel kernel function #' @param X_train matrix (n, d) of training points #' @param y_train column vector (n, d) of training observations #' @param noise scalar of observation noise #' #' @return function with kernel parameters as input and negative log likelihood #' as output nll \u0026lt;- function(kernel, X_train, y_train, noise) {  function(params) {  n \u0026lt;- dim(X_train)[[1]]  K \u0026lt;- rlang::exec(kernel, X1 = X_train, X2 = X_train, !!!params)  L \u0026lt;- chol(K + noise**2 * diag(n))  a \u0026lt;- backsolve(r = L, x = forwardsolve(l = t(L), x = y_train))  0.5*t(y_train)%*%a + sum(log(diag(L))) + 0.5*n*log(2*pi)  } }  #' Gaussian Process Regression #' #' @param kernel kernel function #' @param X_train matrix (n, d) of training points #' @param y_train column vector (n, d) of training observations #' @param noise scalar of observation noise #' @param ... parameters of the kernel function with initial guesses. Due to the #' optimiser used, all parameters must be given and the order unfortunately #' matters #' #' @return function that takes a matrix of prediction points as input and #' returns the posterior predictive distribution for the output gpr \u0026lt;- function(kernel, X_train, y_train, noise = 1e-8, ...) {  kernel_nll \u0026lt;- nll(kernel, X_train, y_train, noise)  param \u0026lt;- list(...)  opt \u0026lt;- optim(par = rep(1, length(param)), fn = kernel_nll)  opt_param \u0026lt;- opt$par  function(X_pred) {  post \u0026lt;- rlang::exec(  posterior,  kernel = kernel,  X_pred = X_pred,  X_train = X_train,  y_train = y_train,  noise = noise,  !!!opt_param  )  list(  mu = post$mu,  sigma = diag(post$sigma),  Sigma = post$sigma,  parameters = set_names(opt_param, names(param))  )  } }   The model will receive four training points. We perform Gaussian process regression and condition the Gaussian process on our training data before drawing from the posterior predictive distribution on a grid of \\mathbf{x} \\in \\mathcal{X}. The \\mu(\\mathbf{x}) and \\sigma(\\mathbf{x}) of the posterior predictive distribution are needed to calculate some acquisition functions.\nX_train \u0026lt;- matrix(c(0.1, 0.2, 0.7, 0.75), 4, 1) y_train \u0026lt;- objective_function(X_train) gp \u0026lt;- gpr(rbf_kernel, X_train, y_train, noise = 1e-8, l = 1, sigma_f = 1) y_min \u0026lt;- min(y_train) y_max \u0026lt;- max(y_train) post_pred \u0026lt;- gp(X_pred) mu \u0026lt;- post_pred$mu sigma \u0026lt;- post_pred$sigma  Here is what the Gaussian process looks like so far.\n\n Show the code\ngp_plot \u0026lt;- tibble::tibble(  mu = mu,  uncertainty = 1.96*sqrt(sigma),  upper = mu + uncertainty,  lower = mu - uncertainty,  x = X_pred,  f = y_pred  ) %\u0026gt;%  ggplot(aes(x = x)) +  geom_line(aes(y = mu, colour = \"Mean\")) +  geom_ribbon(  aes(ymin = lower, ymax = upper, fill = \"89% interval\"),  alpha = 0.2  ) +  geom_point(  data = tibble::tibble(x = X_train, y = y_train),  aes(x = x, y = y, shape = \"Training point\"),  colour = \"#fb8500\",  size = 4  ) +  geom_line(mapping = aes(y = f, colour = \"True function\")) +  scale_shape_manual(values = c(\"Training point\" = \"+\")) +  scale_fill_manual(values = c(\"89% interval\" = \"#219ebc\")) +  labs(shape = \"\") +  theme_minimal() +  labs(  y = \"y\",  x = \"\",  colour = \"\",  fill = \"\"  ) +  theme(panel.grid = element_blank(), axis.text.x = element_blank()) gp_plot    Before getting started, we also define a plot to visualise the acquisition function along with the GP.\n\n Show the code\nacquisition_plot \u0026lt;- function(X_pred,  acquisition_function,  gp_plot,  xt1,  label = \"EI\",  title = \"\") {  p1 \u0026lt;- tibble::tibble(  x = X_pred,  a = acquisition_function  ) %\u0026gt;%  ggplot() +  geom_line(aes(x = x, y = a, colour = label)) +  geom_vline(xintercept = xt1, linetype = 2) +  theme_minimal() +  labs(x = \"\", y = label, colour = \"\") +  theme(panel.grid = element_blank())  p2 \u0026lt;- gp_plot +  geom_vline(xintercept = xt1, linetype = 2) +  labs(title = title)  aligned_plots \u0026lt;- cowplot::align_plots(p2, p1 , align = \"v\")  cowplot::plot_grid(aligned_plots[[1]], aligned_plots[[2]], ncol = 1) }   Now we are ready to apply different acquisition functions to help recommend the next point to sample.\nExpected Improvement The idea behind Expected Improvement (EI) is to search for the point in the search space that has the highest probability of improving the current best solution. EI is defined as the expected value of the improvement over the current best solution, where the improvement is defined as the difference between the function value at the candidate point and the current best value. In other words, EI measures how much better the objective function is expected to be at the candidate point compared to the current best value, weighted by the probability of achieving that improvement.\nFormally, the expected improvement acquisition function for a minimisation problem is defined as:\na_{EI}(\\mathbf{x}) = \\mathbb{E}\\left[\\max(0, f_{\\min} - f(\\mathbf{x}))\\right]\nwhere \\mathbf{x} is the candidate point and f_{\\min} is the current best function value observed so far.\nWhen using a GP surrogate model conditioned on noisy observations in place of f, EI can be calculated using the following formula [1]\na_{EI}(\\mathbf{x}) = (y_{min} - \\mu(\\mathbf{x}) - \\xi) \\Phi(Z) + \\sigma(\\mathbf{x}) \\phi(Z)\nwith\nZ = \\frac{y_{min} - \\mu(\\mathbf{x}) - \\xi}{\\sigma(\\mathbf{x})}\nwhere \\mu(\\mathbf{x}) and \\sigma(\\mathbf{x}) are the mean and standard deviation of the Gaussian process at \\mathbf{x}. \\Phi and \\phi are the standard normal cumulative distribution function and probability density function, respectively, and \\xi is a trade-off parameter that balances exploration and exploitation. Higher values of \\xi lead to more exploration and smaller values to exploitation. a_{EI}(\\mathbf{x}) = 0 when \\sigma(\\mathbf{x}) = 0.\nThe formulas can be implemented directly.\n#' Expected Improvement Acquisition Function #'  #' @mu vector of length m. Mean of a Gaussian process at m points. #' @sigma vector of length m. The diagonal of the covariance matrix of a #' Gaussian process evaluated at m points. #' @param y_best scalar. Best mean prediction so far on observed points #' @param xi scalar, exploration/exploitation trade off #' @task one of \"max\" or \"min\", indicating the optimisation problem #' #' @return EI, vector of length m expected_improvement \u0026lt;- function(mu, sigma, y_best, xi = 0.01, task = \"min\") {  if (task == \"min\") imp \u0026lt;- y_best - mu - xi  if (task == \"max\") imp \u0026lt;- mu - y_best - xi  if (is.null(imp)) stop('task must be \"min\" or \"max\"')  Z \u0026lt;- imp / sigma  ei \u0026lt;- imp * pnorm(Z) + sigma * dnorm(Z)  ei[sigma == 0.0] \u0026lt;- 0.0  ei }  Let’s see it in action. We calculate EI along a grid and draw it below the GP.\nei \u0026lt;- expected_improvement(mu, sigma, y_min, xi = 0.05) xt1 \u0026lt;- X_pred[which.max(ei)] acquisition_plot(  X_pred,  ei,  gp_plot,  xt1,  \"EI\",  \"Expected Improvement (Minimisation)\" )   The next sampling point, \\mathbf{x}_{t+1}, is the one that maximises the acquisition function, here EI. As marked by the dashed line, this point is close to the right edge, where there is a high mean prediction but also high uncertainty, so it satisfies our need for both exploration and exploitation.\nEI works for maximisation problems as well, by replacing y_{min} - \\mu(\\mathbf{x}) with \\mu(\\mathbf{x}) - y_{max} in the expressions above.\nei \u0026lt;- expected_improvement(mu, sigma, y_max, xi = 0.05, task = \"max\") xt1 \u0026lt;- X_pred[which.max(ei)] acquisition_plot(  X_pred,  ei,  gp_plot,  xt1,  \"EI\",  \"Expected Improvement (Maximisation)\" )   The next sampling point, \\mathbf{x}_{t+1}, is still the one that maximises EI. As marked by the dashed line, this point is close to two sampled points, where we are quite certain that there is improvement to be found.\nProbability of Improvement Probability of improvement (PI) aims to select the point that has the highest probability of improving the current best solution. Like expected improvement, the PI function balances exploration and exploitation by taking into account both the mean and the variance of the surrogate model. A point with a high mean and low variance is likely to be a good candidate for exploitation, while a point with a high variance but lower mean may be more suitable for exploration.\nThe PI acquisition function is defined as\na_{PI}(\\mathbf{x}) = P(f(\\mathbf{x}) \\lt f_{\\min} + \\xi)\nWhen using a GP surrogate model conditioned on noisy observations in place of f, EI can be calculated using the formula\na_{\\text{PI}}(\\mathbf{x}) = \\Phi\\left(\\frac{y_{min} - \\mu(\\mathbf{x}) - \\xi}{\\sigma(\\mathbf{x})}\\right)\nwhere \\mu(\\mathbf{x}) and \\sigma(\\mathbf{x}) are the mean and standard deviation of the Gaussian process at \\mathbf{x}, \\Phi is the standard normal cumulative distribution function, and \\xi is a trade-off parameter that balances exploration and exploitation [2]. Higher values of \\xi lead to more exploration and smaller values to exploitation.\nThe formula can be implemented directly\n#' Probability of Improvement Acquisition Function #'  #' @mu vector of length m. Mean of a Gaussian process at m points. #' @sigma vector of length m. The diagonal of the covariance matrix of a #' Gaussian process evaluated at m points. #' @param y_best scalar. Best mean prediction so far on observed points #' @param xi scalar, exploration/exploitation trade off #' @task one of \"max\" or \"min\", indicating the optimisation problem #' #' @return PI, vector of length m probability_of_improvement \u0026lt;- function(mu,  sigma,  y_best,  xi = 0.01,  task = \"min\") {  if (task == \"min\") imp \u0026lt;- y_best - mu - xi  if (task == \"max\") imp \u0026lt;- mu - y_best - xi  pnorm(imp / sigma) }  Let’s see it in action. We calculate PI along a grid and draw it below the GP.\npi \u0026lt;- probability_of_improvement(mu, sigma, y_min, xi = 0.1) xt1 \u0026lt;- X_pred[which.max(pi)] acquisition_plot(  X_pred,  pi,  gp_plot,  xt1,  \"PI\",  \"Probability of Improvement (Minimisation)\" )   The next sampling point, \\mathbf{x}_{t+1}, is the one that maximises the acquisition function, here PI. As marked by the dashed line, this is close to the right edge, where there is a low mean prediction but also high uncertainty, so it satisfies our need for both exploration and exploitation. There are a few other good contenders in the spaces between training points though.\nPI works for maximisation problems as well, by replacing y_{min} - \\mu(\\mathbf{x}) with \\mu(\\mathbf{x}) - y_{max} in the expression above.\npi \u0026lt;- probability_of_improvement(mu, sigma, y_max, xi = 1, task = \"max\") xt1 \u0026lt;- X_pred[which.max(pi)] acquisition_plot(  X_pred,  pi,  gp_plot,  xt1,  \"PI\",  \"Probability of Improvement (Maximisation)\" )   The next sampling point, \\mathbf{x}_{t+1}, is still the one that maximises PI. As marked by the dashed line, this is in an area of high uncertainty.\nLower \u0026amp; Upper Confidence Bound The Lower Confidence Bound (LCB) and Upper Confidence Bound (UCB) acquisition functions are fairly simple acquisition functions. They balance exploration and exploitation by combining the mean and the weighted standard deviation predictions of the surrogate model. LCB is used for minimisation problems and UCP is applied for maximisation problems.\nThe LCB function is defined as\na_{LCB}(\\mathbf{x}) = \\mu(\\mathbf{x}) - \\kappa \\sigma(\\mathbf{x})\nand UCB as\na_{UCB}(\\mathbf{x}) = \\mu(\\mathbf{x}) + \\kappa \\sigma(\\mathbf{x})\nwhere \\mu(\\mathbf{x}) and \\sigma(\\mathbf{x}) are the mean and standard deviation of the Gaussian process at \\mathbf{x} and \\kappa is a tunable parameter that controls the balance between exploration and exploitation. Higher values of \\kappa promote more exploration, while lower values emphasise exploitation.\nWith the mean term explicitly controlling exploitation and the weighed standard deviation term explicitly controlling exploration, UCB and LCB arguably represent the simplest acquisition function one could implement. This does not mean that UCB or LCB are worse than EI or PI, however. When the surrogate model is a GP, this simpler acquisition function might have similar performance to EI, for appropriate choices of \\kappa [3] [2].\nThe acquisition functions are straightforward to implement, given \\mu and \\sigma:\n#' Upper and Lower Confidence Bound Acquisition Function #'  #' @mu vector of length m. Mean of a Gaussian process at m points. #' @sigma vector of length m. The diagonal of the covariance matrix of a #' Gaussian process evaluated at m points. #' @param kappa scalar, exploration/exploitation trade off #' @task one of \"max\" or \"min\", indicating the optimisation problem #' #' @return CB, vector of length m confidence_bound \u0026lt;- function(mu, sigma, kappa, task = \"min\") {  if (task == \"min\") return(mu - kappa * sigma)  if (task == \"max\") return(mu + kappa * sigma) }  Let’s see it in action. We calculate LCB along a grid and draw it below the GP.\nlcb \u0026lt;- confidence_bound(mu, sigma, kappa = 2, \"min\") xt1 \u0026lt;- X_pred[which.min(lcb)] acquisition_plot(X_pred, lcb, gp_plot, xt1, \"LCB\", \"Lower Confidence Bound\")   As marked by the dashed line, LCB tells us that the next point to sample, \\mathbf{x}_{t+1}, is all the way at the right edge of search space.\nWe can do the same for UCB\nucb \u0026lt;- confidence_bound(mu, sigma, kappa = 2, \"max\") xt1 \u0026lt;- X_pred[which.max(ucb)] acquisition_plot(X_pred, ucb, gp_plot, xt1, \"UCB\", \"Upper Confidence Bound\")   As marked by the dashed line, UCB tells us that the next point to sample, \\mathbf{x}_{t+1}, is close to two known points, where we are fairly certain that there is improvement to be found.\nThompson Sampling A Gaussian process represents a distribution over functions. At this point in Bayesian optimisation, the GP has been conditioned on training data, \\mathcal{D}, and it acts as a surrogate for the objective function. This means that we have a distribution of functions which summarise our knowledge and uncertainty about the objective function.\nWe can take that a step further and consider the posterior distribution, p(\\mathbf{x}'|\\mathcal{D}), of points, \\mathbf{x}', that optimise the the functions drawn from the GP. A point drawn from that distribution would be a good candidate for our next evaluation of the objective function\n\\mathbf{x}_{t+1} \\sim p(\\mathbf{x}'|\\mathcal{D})\nThis is the core idea of Thompson Sampling. Thompson sampling addresses the exploration versus exploitation dilemma by directly making use of our posterior beliefs and the fact that the GP is just a distribution of functions [2]. Notice also that no additional parameters are needed for this method.\nTo do Thompson sampling in practice, we sample a function from the GP\na_{ts}(\\mathbf{x}) \\sim p(y | \\mathcal{D})\nThis is not an acquisition function in the same way that Expected Improvement or Confidence Bound are, but we can use it in exactly the same way to suggest the next point\n\\mathbf{x}_{t+1} \\in \\arg\\min\\limits_{\\mathbf{x} = \\mathcal{X}}(a_{ts}(\\mathbf{x}))\nfor a minimisation problem, or\n\\mathbf{x}_{t+1} \\in \\arg\\max\\limits_{\\mathbf{x} = \\mathcal{X}}(a_{ts}(\\mathbf{x}))\nfor a maximisation problem.\nGiven the posterior predictive distribution, Thompson sampling is straightforward to implement. Let’s see it in action!\nWe draw a random sample function and find its minimum and maximum\nts \u0026lt;- as.vector(rmvnorm(1, post_pred$mu, post_pred$Sigma)) xt1 \u0026lt;- X_pred[which.min(ts)] acquisition_plot(  X_pred,  ts,  gp_plot,  xt1,  \"Sample\",  \"Thompson Sampling (Minimisation)\" )   xt1 \u0026lt;- X_pred[which.max(ts)] acquisition_plot(  X_pred,  ts,  gp_plot,  xt1,  \"Sample\",  \"Thompson Sampling (Maximisation)\" )   The dashed line indicates the next sampling point, \\mathbf{x}_{t+1}, for a minimisation and maximisation task, respectively. For the minimisation problem, we are suggested a point that corresponds to exploitation and for the maximisation problem we are suggested a point that corresponds to exploration. It is this stochastic behaviour that, over a sequence of experiments, will give us a natural balance between exploration and exploitation.\nKnowledge Gradient The Knowledge Gradient (KG) is an acquisition function that makes extensive use of the posterior distribution to suggest a sampling point. KG is simulated rather than calculated and the rationale behind it takes a bit of set up.\nImagine that we are at the end of our sequential experimentation. We have collected a set of observations \\mathcal{D} = (\\mathbf{X},\\mathbf{y}) and we are about to recommend our final set point, \\mathbf{x}^*, which hopefully is close the global optimum of the objective function.\nIn most real world cases, we are risk averse and would opt to select a point that we have already tested, i.e.\u0026nbsp;\\mathbf{x}^* \\in \\mathbf{X}. Imagine, however, that we were not risk averse and just wanted to report the point in search space with the best expected outcome given the data so far, then we might recommend\n\\mathbf{x}^* = \\arg\\min\\limits_{\\mathbf{x} \\in \\mathcal{X}}\\mu(\\mathbf{x})\nWe also define \\mu^* = \\mu(\\mathbf{x}^*).\nAt this point, imagine that we are suddenly allowed to test just one more point. Given that we have decided to recommend the point that optimises the posterior mean at the end of our experimental sequence, the next point, \\mathbf{x}_{t+1}, we choose to evaluate in the the objective function should be the point that maximises the increase in the optimum posterior mean.\nLet’s say we pick any point, \\mathbf{x}_{t+1} \\in \\mathcal{X}, to be our next point. That would result in the observation y_{t+1} and eventually a recommended final point, \\mathbf{x}^*_{t+1} with mean \\mu^*_{t+1}. The decrease in posterior mean, \\mu^* - \\mu^*_{t+1}, would be an excellent estimator of improvement in choosing \\mathbf{x}_{t+1} as the next sampling point.\nHowever, we cannot calculate \\mu^* - \\mu^*_{t+1} without actually collecting the sample y_{t+1}. Instead we could estimate the expected value, given just the observations so far:\na_{KG}(\\mathbf{x}) = \\mathbb{E}_{p(y|\\mathcal{D})}[\\mu^* - \\mu^*_{t+1}]\nThis is the definition of the Knowledge Gradient for a minimisation problem [1].\nFor a maximisation problem, the definition is\na_{KG}(\\mathbf{x}) = \\mathbb{E}_{p(y|\\mathcal{D})}[\\mu^*_{t+1} - \\mu^*]\nwhere \\mu^* = \\max(\\mu(\\mathbf{x})).\nTo calculate KG in practice, we need a way to estimate \\mu^*_{t+1} as a function of existing observations and we need a way to integrate over p(y|\\mathcal{D}).\nTo address the latter for a proposed point, \\mathbf{x}_{sim}, we take the following steps\n We draw a sample y_{sim} \\sim p(y|\\mathbf{x}_{sim},\\mathcal{D})-\n We then create an augmented dataset \\mathcal{D}^+ = (\\{\\mathbf{X},\\mathbf{x}_{sim}\\}, \\{\\mathbf{y},y_{sim}\\}).\n We condition the surrogate model on the augmented dataset.\n Finally, we compute the optimum of the new posterior mean. This is an estimate of \\mu^*_{t+1}.\n  We cannot integrate this estimate over p(y_{sim}|\\mathcal{D}), but we can draw M samples, compute \\mu^*_{t+1} for each of them and calculate the mean difference:\na_{KG}(\\mathbf{x}) \\approx \\frac{1}{M}\\sum_{j=1}^M \\mu^* - \\mu^*_{t+1,j}\nAs M approaches infinity, the estimate should converge to the true KG. Since we need a large amount of samples and need to repeat the process for each candidate \\mathbf{x}, a good sampler is needed to estimate KG.\nFor our simple one-dimensional example, we can brute force it without worrying too much about optimising the calculation. For an example with more dimensions or for a smoother estimate of KG, a proper MCMC sampling would be needed.\nmu_min \u0026lt;- min(mu) mu_max \u0026lt;- max(mu) # for each candidate point kg \u0026lt;- tibble::tibble(x_sim = X_pred) %\u0026gt;%  dplyr::mutate(  # Calculate the posterior predictive distribution for y at x_sim  post = purrr::map(x_sim, gp),  # Draw M = 100 samples of y_sim from the posterior predictive distribution  y_sim = purrr::map(post, function(p) {  rlang::exec(rmvnorm, n = 100, mu = p$mu, sigma = p$Sigma)  })  ) %\u0026gt;%  tidyr::unnest_longer(y_sim) %\u0026gt;%  dplyr::mutate(  # For each pair of (x_sim, y_sim)  # augment dataset with x_sim, y_sim and get the posterior mean  mu_sim = purrr::map2(x_sim, y_sim, function(xs, ys) {  rlang::exec(  posterior,  kernel = rbf_kernel,  X_pred = X_pred,  X_train = rbind(X_train, xs),  y_train = rbind(y_train, ys),  !!!post_pred$parameters  )$mu  }),  # Calculate the estimator  mu_min_sim = purrr::map_dbl(mu_sim, min),  mu_max_sim = purrr::map_dbl(mu_sim, max),  mu_diff_min = mu_min - mu_min_sim,  mu_diff_max = mu_max_sim - mu_max  ) %\u0026gt;%  dplyr::group_by(x_sim) %\u0026gt;%  dplyr::summarise(kg_min = mean(mu_diff_min), kg_max = mean(mu_diff_max)) %\u0026gt;%  dplyr::arrange(x_sim)  Here is KG for the minimisation case. Notice that the estimate is very rough. More samples would have made the estimate smoother. The dashed line shows where we would sample next, according to KG.\nacquisition_plot(  X_pred,  kg$kg_min,  gp_plot,  X_pred[which.max(kg$kg_min)],  \"KG\",  \"Knowledge Gradient (minimisation)\" )   Here is KG for the maximisation case. Notice that the estimate is very rough. The dashed line shows where we would sample next, according to KG.\nacquisition_plot(  X_pred,  kg$kg_max,  gp_plot,  X_pred[which.max(kg$kg_max)],  \"KG\",  \"Knowledge Gradient (maximisation)\" )   References [1] Frazier, P. I. (2018). A tutorial on bayesian optimization. Available at https://arxiv.org/abs/1807.02811.  [2] Garnett, R. (2023). Bayesian Optimization. Cambridge University Press.  [3] Srinivas, N., Krause, A., Kakade, S. M. and Seeger, M. W. (2012). Information-theoretic regret bounds for gaussian process optimization in the bandit setting. IEEE Transactions on Information Theory 58 3250–65 Available at https://doi.org/10.1109%2Ftit.2011.2182033.   License The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license, and the underlying code is licensed under the GNU General Public License v3.0 license.\nwindow.document.addEventListener(\"DOMContentLoaded\", function (event) { const tabsets = window.document.querySelectorAll(\".panel-tabset-tabby\") tabsets.forEach(function(tabset) { const tabby = new Tabby('#' + tabset.id); }); const icon = \"\"; const anchorJS = new window.AnchorJS(); anchorJS.options = { placement: 'right', icon: icon }; anchorJS.add('.anchored'); const clipboard = new window.ClipboardJS('.code-copy-button', { target: function(trigger) { return trigger.previousElementSibling; } }); clipboard.on('success', function(e) { // button target const button = e.trigger; // don't keep focus button.blur(); // flash \"checked\" button.classList.add('code-copy-button-checked'); setTimeout(function() { button.classList.remove('code-copy-button-checked'); }, 1000); // clear code selection e.clearSelection(); }); function tippyHover(el, contentFn) { const config = { allowHTML: true, content: contentFn, maxWidth: 500, delay: 100, arrow: false, appendTo: function(el) { return el.parentElement; }, interactive: true, interactiveBorder: 10, theme: 'light-border', placement: 'bottom-start' }; window.tippy(el, config); } const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]'); for (var i=0; i","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682965298,"objectID":"9d5012860ecb2b8a0293970ba3bdb912","permalink":"/post/acquisition-functions-r/","publishdate":"2023-05-01T00:00:00Z","relpermalink":"/post/acquisition-functions-r/","section":"post","summary":"A comprehensive overview of acquisition functions for Gaussian processes and Bayesian optimisation. Implementation in R.","tags":["Modelling","Bayesian statistics","Bayesian optimisation","R"],"title":"Acquisition Functions for Bayesian Optimisation","type":"post"},{"authors":null,"categories":null,"content":" index  code{white-space: pre-wrap;} span.smallcaps{font-variant: small-caps;} span.underline{text-decoration: underline;} div.column{display: inline-block; vertical-align: top; width: 50%;} div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;} ul.task-list{list-style: none;} pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ff0000; font-weight: bold; } /* Alert */ code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #7d9029; } /* Attribute */ code span.bn { color: #40a070; } /* BaseN */ code span.bu { } /* BuiltIn */ code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4070a0; } /* Char */ code span.cn { color: #880000; } /* Constant */ code span.co { color: #60a0b0; font-style: italic; } /* Comment */ code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #ba2121; font-style: italic; } /* Documentation */ code span.dt { color: #902000; } /* DataType */ code span.dv { color: #40a070; } /* DecVal */ code span.er { color: #ff0000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #40a070; } /* Float */ code span.fu { color: #06287e; } /* Function */ code span.im { } /* Import */ code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #007020; font-weight: bold; } /* Keyword */ code span.op { color: #666666; } /* Operator */ code span.ot { color: #007020; } /* Other */ code span.pp { color: #bc7a00; } /* Preprocessor */ code span.sc { color: #4070a0; } /* SpecialChar */ code span.ss { color: #bb6688; } /* SpecialString */ code span.st { color: #4070a0; } /* String */ code span.va { color: #19177c; } /* Variable */ code span.vs { color: #4070a0; } /* VerbatimString */ code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */ div.csl-bib-body { } div.csl-entry { clear: both; } .hanging div.csl-entry { margin-left:2em; text-indent:-2em; } div.csl-left-margin { min-width:2em; float:left; } div.csl-right-inline { margin-left:2em; padding-left:1em; } div.csl-indent { margin-left: 2em; }   document.addEventListener(\"DOMContentLoaded\", function () { var mathElements = document.getElementsByClassName(\"math\"); var macros = []; for (var i = 0; i          This post takes an extensive look at kernels and discusses the rationales, utility, and limitations of some popular kernels, focusing primarily on their application in Gaussian processes and Bayesian optimisation. Along with the discussion are implementations of the kernels in base R.\nlibrary(ggplot2) library(magrittr) set.seed(4444)  Kernels, also known as covariance functions, are central to Gaussian processes and other machine learning methods where they provide the main means of implementing prior knowledge about the modelled process.\nIntuitively, kernels quantify how similar two points are, given just their position in input space. The kernel function determines the smoothness and complexity of the resulting Gaussian process model, and it controls how much weight is given to different regions of the input space. Different types of kernel functions can be used to model different types of data, such as periodic or spatial data.\nBayesian optimisation extensively employs Gaussian processes, so kernels provide the means to define a bespoke prior distribution over the objective function or process being optimised. There are a plethora of kernels available, and for successful implementations of Bayesian optimisation, selecting the right one is essential but difficult.\nApplying Kernels in Gaussian Processes Formally, a kernel function k(\\mathbf{x},\\mathbf{x'}) takes two input vectors, \\mathbf{x} and \\mathbf{x'}, and returns a real-valued scalar that represents a similarity measure between the inputs.\nA kernel function must be positive semi-definite (PSD). This means that the kernel matrix, \\mathbf{\\Sigma}, constructed from any set of n input row vectors {\\mathbf{x}_1, \\ldots, \\mathbf{x}_n}, must be PSD. The entries of the kernel matrix are defined as \\mathbf{\\Sigma}_{i,j} = k(\\mathbf{x}_i, \\mathbf{x}_j), for all combinations of i, j \\in (1, \\ldots, n). The PSD property ensures that the kernel matrix can be applied as the covariance matrix in a Gaussian process.\nIn the context of a Gaussian process that should approximate an objective function, a good kernel function should be flexible enough to capture the underlying structure of the data, but not so flexible that it overfits the data. The choice of kernel function and its hyperparameters can have a significant impact on the performance of the Gaussian process and its application in Bayesian optimisation, so it is important to choose carefully and experiment with different options.\nHowever, without knowing the virtues, pitfalls, and assumptions of a kernel, it is difficult to assess its quality for a given problem. In the following sections, a selection of kernels and their virtues are discussed.\nTo demonstrate the kernels, two plots are defined. The first plot simply draws the kernel function as a function of Euclidean distance.\n\n Show the code\nplot_kernel_value \u0026lt;- function(kernel, ...) {  tibble::tibble(  X1 = seq(0, 5, by = 0.05),  X2 = rep(0, length(X1)),  kv = purrr::map2_dbl(X1, X2, kernel, ...)  ) %\u0026gt;%  ggplot(aes(x = X1, y = kv)) +  geom_line() +  labs(x = \"Euclidean distance\", y = \"kernel value\") +  theme_minimal() }   The next plot samples from the Gaussian process that uses the kernel function to calculate its covariance matrix. This essentially translates to sampling random functions from the Gaussian process. See the post on Bayesian optimisation for details.\n\n Show the code\n#' Random Samples from a Multivariate Gaussian #'  #' This implementation is similar to MASS::mvrnorm, but uses chlosky #' decomposition instead. This should be more stable but is less efficient than #' the MASS implementation, which recycles the eigen decomposition for the #' sampling part. #' #' @param n number of samples to sample #' @param mu the mean of each input dimension #' @param sigma the covariance matrix #' @param epsilon numerical tolerance added to the diagonal of the covariance #' matrix. This is necessary for the Cholesky decomposition, in some cases. #' #' @return numerical vector of n samples rmvnorm \u0026lt;- function(n = 1, mu, sigma, epsilon = 1e-6) {  p \u0026lt;- length(mu)  if(!all(dim(sigma) == c(p, p))) stop(\"incompatible dimensions of arguments\")  ev \u0026lt;- eigen(sigma, symmetric = TRUE)$values  if(!all(ev \u0026gt;= -epsilon * abs(ev[1L]))) {  stop(\"The covariance matrix (sigma) is not positive definite\")  }  cholesky \u0026lt;- chol(sigma + diag(p) * epsilon)  sample \u0026lt;- rnorm(p*n, 0, 1)  dim(sample) \u0026lt;- c(n, p)  sweep(sample %*% cholesky, 2, mu, FUN = `+`) }  plot_gp \u0026lt;- function(kernel, ...) {  n_samples \u0026lt;- 5  X_predict \u0026lt;- matrix(seq(-5, 5, length.out = 100), 100, 1)  mu \u0026lt;- rep(0, times = length(X_predict))  sigma \u0026lt;- rlang::exec(kernel, X1 = X_predict, X2 = X_predict, ...)  samples \u0026lt;- rmvnorm(n = n_samples, mu, sigma)  p \u0026lt;- tibble::as_tibble(  t(samples),  .name_repair = ~ paste(\"sample\", seq(1, n_samples))  ) %\u0026gt;%  dplyr::mutate(  x = X_predict,  uncertainty = 1.6*sqrt(diag(sigma)),  mu = mu,  lower = mu - uncertainty,  upper = mu + uncertainty  ) %\u0026gt;%  ggplot(aes(x = x)) +  geom_ribbon(  aes(ymin = lower, ymax = upper, fill = \"89% interval\"),  alpha = 0.2  ) +  geom_line(aes(y = mu, colour = \"Mean\")) +  theme_minimal() +  labs(  y = \"y\",  x = \"x\",  colour = \"\",  fill = \"\"  ) +  theme(panel.grid = element_blank())  Reduce(  `+`,  init = p,  x = lapply(paste(\"sample\", seq(1, n_samples)), function(s) {  geom_line(aes(y = .data[[s]], colour = s), linetype = 2)  })  ) +  scale_colour_brewer(palette = \"YlGnBu\") +  scale_fill_manual(values = list(\"89% interval\" = \"#219ebc\")) }   Stationary Kernels Stationary kernels are a class of kernel functions that are invariant to translations in input space. Mathematically, a kernel function is stationary if it depends only on the difference between its arguments, \\mathbf{x}-\\mathbf{x'}, and not on their absolute values. Formally, a kernel function k(\\mathbf{x}, \\mathbf{x'}) is stationary if and only if:\nk(\\mathbf{x}, \\mathbf{x'}) = k(\\mathbf{x} + a, \\mathbf{x'} + a)\nfor all inputs \\mathbf{x} and \\mathbf{x'} and all a.\nRBF Kernel The Radial Basis Function (RBF) kernel is also known as the Squared Exponential kernel or the Gaussian kernel. It is a popular choice in Gaussian processes because of its simplicity and interpretability. The RBF kernel is defined as\nk(\\mathbf{x}, \\mathbf{x'}) = \\sigma^2 \\exp\\left(-\\frac{\\lVert \\mathbf{x} - \\mathbf{x'}\\rVert^2}{2l^2}\\right)\nwhere \\lVert \\mathbf{x} - \\mathbf{x'}\\rVert^2 is the squared Euclidean distance between the two vectors. \\sigma^2 is a variance parameter that simply scales the kernel. More interestingly, the length scale parameter, l, controls the smoothness and the range of influence of the kernel. It determines how quickly the similarity between two input points decreases as their distance increases.\nIntuitively, small length scales mean that two points have to be very close to have any correlation. This results in very flexible functions that do not expect much correlation between data points. For a large length scale, however, points that are far apart are still expected to behave in a similar way. This results in very smooth functions that expect similar output values across the entire feature space.\nThe flexibility and interpretability of the length scale parameter makes the RBF kernel a good starting point, when exploring Gaussian processes.\n#' RBF Kernel #' #' Isotropic RBF kernel function generalised to two sets of n and m observations #' of d features. #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param sigma scale parameter, scalar #' @param l length scale, scalar #' #' @return kernel matrix of dimensions (n, m) rbf_kernel \u0026lt;- function(X1, X2, sigma = 1.0, l = 1.0) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  sqdist \u0026lt;- (- 2*(X1 %*% t(X2))) %\u0026gt;%  add(rowSums(X1**2, dims = 1)) %\u0026gt;%  sweep(2, rowSums(X2**2, dims = 1), `+`)  sigma**2 * exp(-0.5 / l**2 * sqdist) }  Here is an example of how the covariance between two vectors tapers off, as their Euclidean distance increases.\nplot_kernel_value(rbf_kernel)   Random functions pulled from a Gaussian process that employs the RBF kernel are quite flexible.\nplot_gp(rbf_kernel)   RQ Kernel The Rational Quadratic (RQ) kernel is a generalisation of the RBF kernel in the sense that it can be interpreted as an infinite sum of RBF kernels with different length scales. The RQ kernel is defined as:\nk(\\mathbf{x}, \\mathbf{x'}) = \\sigma^2\\left(1 + \\frac{\\Vert x - x'\\Vert^2}{2\\alpha \\ell^2}\\right)^{-\\alpha}\nwhere \\lVert \\mathbf{x} - \\mathbf{x'}\\rVert^2 is the squared Euclidean distance between the two vectors. \\sigma^2 is a variance parameter that simply scales the kernel. The length scale parameter, l, determines how quickly the similarity between two input points decreases as their distance increases, just like for the RBF kernel. The mixture parameter, \\alpha, can be viewed as controlling how much local variation the kernel allows. When drawing functions from a Gaussian process that employs the RQ kernel, small values of \\alpha will yield functions with more local variation while still displaying the overall length scaling defined by l. On the other hand, larger values of \\alpha will yield functions with less local variation. In fact as \\alpha \\to \\infty the RQ kernel converges to the RBF kernel with the same l.\nSince the RQ Kernel can model functions with a mixture of different length scales, it is useful for problems where the function may have both local and global variations. However, the RQ kernel needs tuning of two hyperparameters, \\alpha and l, which in turn requires more data. The addition of \\alpha also arguably decreases the interpretability of l.\nThe added flexibility compared to the RBF kernel without too much added complexity, makes the RQ kernel a good alternative, when exploring Gaussian processes.\n#' RQ Kernel #' #' Isotropic RQ kernel function generalised to two sets of n and m observations #' of d features. #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param sigma scale parameter, scalar #' @param l length scale, scalar #' @param alpha mixture parameter, positive scalar #' #' @return kernel matrix of dimensions (n, m) rq_kernel \u0026lt;- function(X1, X2, sigma = 1, l = 1, alpha = 1) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  sqdist \u0026lt;- (- 2*(X1 %*% t(X2))) %\u0026gt;%  add(rowSums(X1**2, dims = 1)) %\u0026gt;%  sweep(2, rowSums(X2**2, dims = 1), `+`)  sigma^2 * (1 + sqdist / (2 * alpha * l^2))^(-alpha) }  Here is an example of how the covariance between two vectors tapers off, as their Euclidean distance increases.\nplot_kernel_value(rq_kernel, alpha = 0.5, l = 0.5)   The emphasis on local variation yields functions which are much more flexible.\nplot_gp(rq_kernel, alpha = 0.5, l = 0.5)   Exponential Kernel The RBF and RQ kernels represent smooth kernels, i.e.\u0026nbsp;kernels that are differentiable and, when applied in Gaussian processes, yield functions that are less prone to abrupt changes. The exponential kernel, on the other hand, is not differentiable. The exponential kernel is defined as\nk(\\mathbf{x}, \\mathbf{x'}) = \\sigma^2 \\exp\\left(-\\frac{\\lVert \\mathbf{x} - \\mathbf{x'}\\rVert}{l}\\right)\nwhere \\lVert \\mathbf{x} - \\mathbf{x'}\\rVert is the Euclidean distance between the two vectors. \\sigma^2 is a variance parameter that simply scales the kernel. The length scale parameter, l, determines how quickly the similarity between two input points decreases as their distance increases, just like for the RBF kernel.\nWhen applied in Gaussian processes, the exponential kernel yields functions that are much less smooth compared to the RBF kernel. This is useful when trying to model functions that exhibit abrupt changes.\n#' Exponential Kernel #' #' Isotropic exponential kernel function generalised to two sets of n and m #' observations of d features. #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param sigma scale parameter, scalar #' @param l length scale, scalar #' #' @return kernel matrix of dimensions (n, m) exponential_kernel \u0026lt;- function(X1, X2, sigma = 1, l = 1) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  distance \u0026lt;- (- 2*(X1 %*% t(X2))) %\u0026gt;%  add(rowSums(X1**2, dims = 1)) %\u0026gt;%  sweep(2, rowSums(X2**2, dims = 1), `+`) %\u0026gt;%  sqrt()  sigma^2 * exp(-distance / l) }  Here is an example of of the covariance tapers off between two vectors, as their Euclidean distance increases. Notice the abrupt decline in covariance.\nplot_kernel_value(exponential_kernel, l = 1)   The Gaussian process yields functions which are prone to abrupt changes and thus look very rough.\nplot_gp(exponential_kernel, l = 5)   Matérn Kernel The Matérn kernel is a flexible and versatile stationary kernel that can model a wide range of functions. The Matérn kernel is given by:\nk(\\mathbf{x},\\mathbf{x'}) = \\sigma^2\\frac{2^{1-\\nu}}{\\Gamma(\\nu)}\\left(\\frac{\\sqrt{2\\nu}\\lVert\\mathbf{x}-\\mathbf{x'}\\rVert}{l}\\right)^{\\nu} K_{\\nu}\\left(\\frac{\\sqrt{2\\nu}\\lVert\\mathbf{x}-\\mathbf{x'}\\rVert}{l}\\right)\nwhere \\sigma^2 is a variance parameter that scales the kernel, l is the length scale parameter, \\nu is the smoothness parameter, \\lVert\\mathbf{x}-\\mathbf{x'}\\rVert is the Euclidean distance between the two vectors, \\Gamma(\\cdot) is the gamma function, and K_{\\nu}(\\cdot) is a modified Bessel function of the second kind with order \\nu.\nThe RBF kernel yields smooth functions when applied in a Gaussian process, and the exponential kernel yields rugged functions. The Matérn kernel is a generalisation of the RBF kernel, where the parameter \\nu controls the differentiability, and thus smoothness, of the kernel. In fact, setting \\nu = 0.5 results in the exponential kernel and, as \\nu \\to \\infty, the Matérn kernel converges to the RBF kernel.\nThe Matérn kernel is a popular choice for Gaussian processes, as it only makes very weak assumptions about the function being modelled. The length scale and smoothness parameters allow for modelling smooth functions with long-range covariance as well as functions with abrupt changes. The downside is that the kernel is very flexible and it takes data and effort to avoid overfitting.\nBase R includes functions for the gamma function as well as a Bessel function of the second kind with given order, so it can be implemented without the need for additional libraries.\n#' Matérn Kernel #' #' Isotropic Matérn kernel function generalised to two sets of n and m #' observations of d features. #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param sigma scale parameter, scalar #' @param l length scale, scalar #' @param nu smoothness parameter, positive scalar #' #' @return kernel matrix of dimensions (n, m) matern_kernel \u0026lt;- function(X1, X2, sigma = 1, l = 1, nu = 2.5) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  distance \u0026lt;- (- 2*(X1 %*% t(X2))) %\u0026gt;%  add(rowSums(X1**2, dims = 1)) %\u0026gt;%  sweep(2, rowSums(X2**2, dims = 1), `+`) %\u0026gt;%  sqrt()  term \u0026lt;- sqrt(2 * nu) * distance / l  K \u0026lt;- sigma * (2^(1 - nu) / gamma(nu)) * (term^nu) * besselK(term, nu)  K[distance == 0] \u0026lt;- 1  K }  The kernel value looks like the RBF kernel or the exponential kernel, depending on the smoothness parameter\nplot_kernel_value(matern_kernel, nu = 100)   The Matérn kernel can yield functions that strike a balance between smoothness and flexibility\nplot_gp(matern_kernel, nu = 1.5)   Periodic Kernels Periodic kernels are a class of kernel functions that exhibit periodicity. Formally, a periodic kernel function k(\\mathbf{x}, \\mathbf{x'}) is periodic if and only if:\nk(\\mathbf{x}, \\mathbf{x'}) = k(\\mathbf{x}, \\mathbf{x'}+n\\omega)\nfor all inputs \\mathbf{x} and \\mathbf{x'} and all integers n, where \\omega is the period of the kernel.\nThe Basic Periodic Kernel The basic periodic kernel is a simple periodic kernel that can be used to model functions that exhibit periodic behaviour, i.e., functions that repeat their values in regular intervals. This is especially useful when dealing with time series data or spatial data that exhibit cyclical patterns. The kernel is derived from the RBF kernel with a transformation of the input to a periodic domain [1]. Consequently, the basic periodic kernel resembles the RBF kernel but with an additional trigonometric term that introduces periodicity. The definition is:\nk(\\mathbf{x}, \\mathbf{x'}) = \\exp \\left( -\\frac{2 \\sin^2\\left(\\pi \\frac{\\lVert\\mathbf{x}-\\mathbf{x'}\\rVert}{\\omega}\\right)}{l^2} \\right)\nWhere \\lVert\\mathbf{x}-\\mathbf{x'}\\rVert is the Euclidean distance between the two vectors, \\omega is the period, and l is the length scale.\n#' Basic Periodic Kernel #' #' Isotropic basic periodic kernel function generalised to two sets of n and m #' observations of d features. #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param sigma scale parameter, scalar #' @param l length scale, scalar #' @param omega period parameter, scalar #' #' @return kernel matrix of dimensions (n, m) periodic_kernel \u0026lt;- function(X1, X2, sigma = 1, l = 1, omega = 1) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  distance \u0026lt;- (- 2*(X1 %*% t(X2))) %\u0026gt;%  add(rowSums(X1**2, dims = 1)) %\u0026gt;%  sweep(2, rowSums(X2**2, dims = 1), `+`) %\u0026gt;%  sqrt()  sigma * exp(-2 * sin(pi * distance / omega)^2 / l^2) }  Plotting the basic periodic kernel function results in a periodic pattern with peaks and valleys, where the peaks occur when the inputs are multiples of the period, \\omega apart. The covariance between input points is highest when the points are separated by multiples of the period length and decreases as the distance between the points deviates from multiples of the period.\nplot_kernel_value(periodic_kernel, l = 0.5, omega = 1.5)   Sampled functions from a Gaussian process that utilises the basic periodic kernel exhibit periodic behaviour. Such functions, when plotted, appear as smooth, oscillating curves that repeat their patterns over regular intervals.\nThe properties of the basic periodic kernel, i.e.\u0026nbsp;the period \\omega and the length scale l, determine the characteristics of the sampled functions.\nThe period, \\omega controls the distance between repetitions of the pattern in the sampled functions. A smaller period length will result in more frequent repetitions, while a larger period length will cause the repetitions to be spaced further apart.\nThe length scale, l, determines how smooth or wiggly the sampled functions are, just like it does for the RBF kernel. A smaller length scale will produce more wiggly functions, while a larger length scale will yield smoother functions with fewer oscillations within each period.\nplot_gp(periodic_kernel, l = 1, omega = 2)   The basic periodic kernel alone cannot capture trends or non-periodic variations in the data, but can be combined with other kernels to create a very powerful model for objective functions with periodicity.\nHowever, compared to simpler kernels, the basic periodic kernel has an additional hyperparameter, the period parameter \\omega, that needs to be tuned. The choice of period can have a significant impact on the model performance, and finding an appropriate value can be challenging. As with any periodic kernel, applying the basic periodic kernel comes with the assumption that the underlying objective function being modelled exhibits periodic behaviour. If the assumption does not hold true, applying this kernel could be detrimental.\nLocally Periodic Kernel An example of the basic periodic kernel working in tandem with a non-periodic kernel is the locally periodic kernel, which is the product of the basic periodic kernel and the RBF kernel.\nk(\\mathbf{x}, \\mathbf{x'}) = \\sigma^2\\exp \\left( -\\frac{2 \\sin^2\\left(\\pi \\frac{\\lVert\\mathbf{x}-\\mathbf{x'}\\rVert}{\\omega}\\right)}{l_p^2} \\right) \\exp \\left( -\\frac{\\lVert\\mathbf{x}-\\mathbf{x'}\\rVert^2}{2 l_v^2} \\right)\n#' Locally Periodic Kernel #' #' Isotropic locally periodic kernel function generalised to two sets of n and m #' observations of d features. #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param sigma scale parameter, scalar #' @param l_period length scale for periodicity, scalar #' @param l_var length scale for stationary variance, scalar #' @param omega period parameter, scalar #' #' @return kernel matrix of dimensions (n, m) locally_periodic_kernel \u0026lt;- function(X1,  X2,  sigma = 1,  l_period = 1,  l_var = 1,  omega = 1) {  periodic_kernel(X1, X2, l = l_period, omega = omega, sigma = sigma) *  rbf_kernel(X1, X2, l = l_period, sigma = 1) }  Plotting the locally periodic kernel results a series of peaks, reflecting the periodic behaviour captured by the periodic kernel. The peaks are highest when the Euclidean distance between the input vectors is a multiple of the period length. The periodic effect is dampened over longer distances due to the length scaling of the RBF kernel.\nplot_kernel_value(locally_periodic_kernel, omega = 0.5)   Sample functions from a Gaussian process that utilises the locally periodic kernel exhibit both periodic behaviour and local variations. The functions appear as smooth, oscillating curves that repeat their patterns over regular intervals, but with varying amplitude and local changes.\nplot_gp(locally_periodic_kernel, omega = 0.5)   The locally periodic kernel could be combined with other non-periodic kernels like the Matérn kernel to create even more complex dynamics. However, applying a periodic kernel comes with the assumption that the underlying objective function being modelled exhibits periodic behaviour. If the assumption does not hold true, applying a periodic kernel could be detrimental.\nNon-stationary Kernels Unlike stationary kernels, non-stationary kernels can depend on the absolute values of their inputs.\nNon-stationary kernels are often used when the underlying function being modelled exhibits varying behaviour or has different characteristics in different regions of feature space. For example, if the function being modelled changes rapidly in some regions and slowly in others, a non-stationary kernel may be more appropriate than a stationary kernel.\nLinear Kernel The linear kernel, also known as the dot product kernel, is a simple non-stationary kernel function. It is defined as\nk(\\mathbf{x}, \\mathbf{x'}) = \\mathbf{x}^T \\mathbf{x'} + \\sigma^2 \nWhere \\sigma is a constant. When sigma = 0 the kernel is called homogeneous and inhomogeneous otherwise.\nThe linear kernel can be applied in cases when linear behaviour is expected. If the value of the modelled function is expected to grow as a function of the distance from an origin, a linear kernel might be appropriate.\n#' Linear Kernel #' #' Linear kernel function generalised to two sets of n and m observations of d #' features. #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param sigma homogeneity parameter, scalar #' #' @return kernel matrix of dimensions (n, m) linear_kernel \u0026lt;- function(X1, X2, sigma = 0) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  sigma^2 + X1 %*% t(X2) }  Sampled functions from a Gaussian process that utilises the linear kernel exhibit linear behaviour. These sampled functions, appear as straight lines with varying slopes and intercepts. Indeed, applying a Gaussian process with a linear kernel to data is equivalent to doing Bayesian linear regression.\nplot_gp(linear_kernel)   Since this kernel captures linear patterns in the data, the sampled functions will always be straight lines and will not be able to model other types of variation. However, it can be combined with other kernels to increase its utility.\nPolynomial Kernel The polynomial kernel is a generalisation of the linear kernel and is defined as\nK(\\mathbf{x}, \\mathbf{x'}) = (\\mathbf{x}^T \\mathbf{x'} + \\sigma^2)^{\\nu} \nWhere \\sigma is a constant that determines the shape of the kernel function and \\nu, a positive integer, is the degree of the polynomial. When sigma = 0 the kernel is called homogeneous and inhomogeneous otherwise.\n#' Polynomial Kernel #' #' Polynomial kernel function generalised to two sets of n and m observations of #' d features. #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param sigma homogeneity parameter, scalar #' @param nu degree parameter, positive integer #' #' @return kernel matrix of dimensions (n, m) polynomial_kernel \u0026lt;- function(X1, X2, sigma = 0, nu = 2) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  (sigma + X1 %*% t(X2))^nu }  Sampled functions from a Gaussian process that utilises the polynomial kernel will exhibit polynomial behaviour. The functions appear as smooth curves with varying shapes, depending on the degree and the parameters of the polynomial kernel. When \\nu = 2, the functions are parabolas.\nplot_gp(polynomial_kernel, sigma = 1, nu = 2)   Applying a Gaussian process with the polynomial kernel corresponds to doing Bayesian polynomial regression. This means that the kernel can be applied to model non-linear relationships, but it will also be subject to the same constraints and overfitting challenges of regular polynomial regression.\nOther Kernels Constant Kernel The constant kernel, also known as the bias kernel, is a simple kernel defined as\nk(\\mathbf{x}, \\mathbf{x'}) = c\nwhere c is a constant value.\nThe constant kernel is characterised by its simplicity, as it assumes a constant value, meaning the output is the same for all input points. The constant kernel can be combined with other kernels to model more complex relationships between data points. In Gaussian process regression, this kernel can capture constant offsets in the function being modelled.\n#' Constant Kernel #' #' Constant kernel function generalised to two sets of n and m observations of d #' features. #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param c kernel value, scalar #' #' @return kernel matrix of dimensions (n, m) constant_kernel \u0026lt;- function(X1, X2, c = 1) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  matrix(c, dim(X1)[[1]], dim(X2)[[1]]) }  The constant kernel function is just a flat, two-dimensional surface parallel to the input space. The height of the surface is equal to the constant value c.\nplot_kernel_value(constant_kernel)   Sampled functions from a Gaussian process that utilises the constant kernel are just constant functions. The functions are flat, horizontal lines parallel to the x-axis. There is still variance - each function has a different constant value, determined by the variance specified by the kernel. If the Gaussian process has a zero mean function, the sampled functions will be horizontal lines with y-values centred around zero, and their heights will be determined by the constant kernel value according to y = \\beta where \\beta \\sim \\mathcal{N}(0, c^2).\nplot_gp(constant_kernel)   White Noise Kernel The white noise kernel is also known as the Kronecker Delta Kernel because its definition utilises the Kronecker delta function:\nk(\\mathbf{x}, \\mathbf{x'}) = \\sigma^2\\delta_{\\mathbf{x}, \\mathbf{x'}}\nIn other words, when the input vectors are exactly the same there is noise, \\sigma, otherwise the kernel is zero.\n#' White Noise Kernel #' #' White noise kernel function generalised to two sets of n and m observations #' of d features. #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param sigma noise parameter, positive scalar #' #' @return kernel matrix of dimensions (n, m) white_noise_kernel \u0026lt;- function(X1, X2, sigma = 1) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  k \u0026lt;- matrix(0, dim(X1)[[1]], dim(X2)[[1]])  diag(k) \u0026lt;- 1  k * sigma^2 }  Samples pulled from a Gaussian processes that utilises just the white noise kernel are nothing but white noise.\nplot_gp(white_noise_kernel)   The white noise kernel alone cannot capture the underlying signal of the function being modelled. However, it can be used in combination with other kernels. Specifically, the white noise kernel models the case where observations have white, i.e.\u0026nbsp;Gaussian, noise but the magnitude of the noise is unknown.\nAnisotropic Kernels Anisotropic kernels allow for different length scales in different dimensions of feature space. This is in opposition to the isotropic kernels described above, with a single length scale across all dimensions. Intuitively, the anisotropic kernel is stretched or compressed in certain directions compared to its isotropic counterpart. This property can be useful when the input variables have different units or scales.\nThe anisotropy of a kernel is controlled by several length scale parameters, which specify the length scaling along each dimension in feature space. The use of anisotropic kernels can improve the predictive accuracy of Gaussian process models when the input variables have different levels of variability or when the correlations between variables vary in different directions. However, anisotropic kernels also increase the complexity of the model because of the added parameters.\nFormally, an anisotropic kernel can be constructed from an isotropic stationary kernel by substituting the distance part of the definition, i.e.\u0026nbsp;\\lVert\\mathbf{x}-\\mathbf{x'}\\rVert^2/l^2, with (\\mathbf{x}-\\mathbf{x'})\\mathbf{M}(\\mathbf{x}-\\mathbf{x'})^T where \\mathbf{M} is a (D×D) matrix. There are different options for constructing \\mathbf{M}. A diagonal matrix \\mathbf{M} = l^{-2}\\mathbf{I} where l is a scalar, would correspond to the isotropic kernel. A diagonal matrix \\mathbf{M} = \\mathrm{diag}(\\mathbf{l})^{-2}, where \\mathbf{l} is a vector of length D of length scales, would correspond to different length scales for each dimension. There are other options for \\mathbf{M} as well. See chapter 5 of [2].\nAnisotropic RBF Kernel The anisotropic RBF kernel expands the isotropic RBF kernel to allow for individual length scaling of input dimensions. It is defined by\nk(\\mathbf{x}, \\mathbf{x'}) = \\sigma^2 \\exp\\left(-\\frac{1}{2}(\\mathbf{x}-\\mathbf{x'})\\mathbf{M}(\\mathbf{x}-\\mathbf{x'})^T\\right)\nWhere \\sigma^2 is a variance parameter that simply scales the kernel and \\mathbf{M} is a (D×D) matrix that controls the length scaling of the D input dimensions. \\mathbf{M} is often constructed from a length scale scalar, l, or length scale vector \\mathbf{l}, see examples below.\n#' Anisotropic RBF Kernel #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param sigma scale parameter  #' @param l length scale.  #' A vector of size 1 yields the isotropic kernel. #' A vector of size d yields the anisotropic kernel with individual length #' scales for each dimension. #' A matrix of size (d, d) allows for fine-grained control of length scaling. #' #' @return matrix of dimensions (n, m) anisotropic_rbf_kernel \u0026lt;- function(X1, X2, sigma = 1.0, l = 1.0) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  d \u0026lt;- dim(X1)[[2]]  if (is.null(dim(l)) \u0026amp;\u0026amp; length(l) == 1) M \u0026lt;- diag(d) * l^(-2)  if (is.null(dim(l)) \u0026amp;\u0026amp; length(l) == d) M \u0026lt;- diag(l^(-2))  if (length(dim(l)) == 2 \u0026amp;\u0026amp; dim(l)[[1]] == d \u0026amp;\u0026amp; dim(l)[[2]] == d) M \u0026lt;- l  if (is.null(M)) stop(\"Dimensions of length scale are not compatible.\")  lX1 \u0026lt;- X1 %*% M  lX2 \u0026lt;- X2 %*% M  sqdist \u0026lt;- (- 2*(lX1 %*% t(lX2))) %\u0026gt;%  add(rowSums(lX1**2, dims = 1)) %\u0026gt;%  sweep(2, rowSums(lX2**2, dims = 1), `+`)  sigma**2 * exp(-0.5 * sqdist) }  When \\mathbf{M} is a diagonal matrix\n\\mathbf{M} = l^{-2}\\mathbf{I}\nWhere l is a length scale scalar, the kernel is isotropic and the kernel response is exactly identical to the one described above for the RBF kernel.\n# A scalar l actually yields the isotropic RBF kernel plot_kernel_value(anisotropic_rbf_kernel, l = 1.0)   The scaling is the same in all dimensions. Here is an example in 2D\n# Prepare a 2D grid X1 \u0026lt;- as.matrix(expand.grid(d1 = seq(-5, 5, 0.1), d2 = seq(-5, 5, 0.1))) X2 \u0026lt;- matrix(0, 1, dim(X1)[[2]])  K \u0026lt;- anisotropic_rbf_kernel(X1, X2, l = 1.0) tibble::as_tibble(X1) %\u0026gt;%   dplyr::mutate(k = K) %\u0026gt;%  ggplot() +  geom_contour_filled(aes(x = d1, y = d2, z = k), alpha = 0.8) +  labs(  x = \"Distance in 1st dimension\",  y = \"Distance in 2nd dimension\",  fill = \"Kernel value\"  ) +  theme_minimal()   When \\mathbf{M} is a diagonal matrix\n\\mathbf{M} = \\mathrm{diag}(\\mathbf{l})^{-2}\nwhere \\mathbf{l} is a length scale vector, the kernel is anisotropic and has a separate length scale for each dimension. This effectively stretches or compresses each dimension. Here is an example in 2D of differing length scales\nK \u0026lt;- anisotropic_rbf_kernel(X1, X2, l = c(2.5, 1)) tibble::as_tibble(X1) %\u0026gt;%   dplyr::mutate(k = K) %\u0026gt;%  ggplot() +  geom_contour_filled(aes(x = d1, y = d2, z = k), alpha = 0.8) +  labs(  x = \"Distance in 1st dimension\",  y = \"Distance in 2nd dimension\",  fill = \"Kernel value\"  ) +  theme_minimal()   Since the first dimension has a larger length scale than the second dimension, the kernel value gets stretched in the first dimension.\nWhen the length scales of the anisotropic kernel are fitted rather than given, they can sometimes be used for determining feature relevance. An infinitely large length scale corresponds to a dimension with no variation and thus an irrelevant feature. On the other hand, a smaller length scale could indicate a feature with large variation and influence on the model. The inverse of the length scale is thus sometimes used to indicate feature relevance and the process is known as Automatic Relevance Determination (ARD). However, context is important for proper interpretation of fitted length scales. Specifically, the length scales also depend on the unit of each feature and tend to be biased towards non-linear features [3].\nWhen \\mathbf{M} has non-zero values outside the diagonal, the kernel is stretched and rotated. Here is an example of a rotated kernel\nK \u0026lt;- anisotropic_rbf_kernel(X1, X2, l = matrix(c(1, 1, 1, 2), 2, 2)) tibble::as_tibble(X1) %\u0026gt;%   dplyr::mutate(k = K) %\u0026gt;%  ggplot() +  geom_contour_filled(aes(x = d1, y = d2, z = k), alpha = 0.8) +  labs(  x = \"Distance in 1st dimension\",  y = \"Distance in 2nd dimension\",  fill = \"Kernel value\"  ) +  theme_minimal()   This property can be used to create a rotation that effectively reduces the dimensionality of the input features.\nCombining Kernels Kernels can be combined to create new kernels with more flexibility or sophisticated dynamics. The successful application of Gaussian processes relies on choosing a kernel that can model the target function and combining different types of kernels provides a major means of creating a good kernel for the Gaussian process.\nThere are two main ways kernels are combined: combining multiple kernels on each feature or using different kernels for different features.\nCreating new kernels from existing kernels A new kernel can be created from existing kernels in multiple ways.\nSummation Two or more kernels can be added together to create a new kernel that captures the features of both. Two kernels k_1(\\mathbf{x},\\mathbf{x'}) and k_2(\\mathbf{x},\\mathbf{x'}), can be combined as\nk_{sum}(\\mathbf{x},\\mathbf{x'}) = k_1(\\mathbf{x},\\mathbf{x'}) + k_2(\\mathbf{x},\\mathbf{x'})\nThe resulting kernel will assign high covariance to pairs of points that are similar in either k_1 or k_2. I.e. the inputs \\mathbf{x} and \\mathbf{x'} only need to have a high covariance according to one kernel to return a high covariance for the combined kernel, when the kernels are added together.\nProduct Two or more kernels can be multiplied together to create a new kernel that captures the features of both. Two kernels K_1(\\mathbf{x},\\mathbf{x'}) and K_2(\\mathbf{x},\\mathbf{x'}), can be combined as\nK_{sum}(\\mathbf{x},\\mathbf{x'}) = K_1(\\mathbf{x},\\mathbf{x'})K_2(\\mathbf{x},\\mathbf{x'}) The resulting kernel will assign high values to pairs of points that are similar in both k_1 and k_2. I.e. the inputs \\mathbf{x} and \\mathbf{x'} need to have a high covariance according to both kernels to return a high covariance for the combined kernel, when the kernels are multiplied. The locally periodic kernel, as described above, is an example of a periodic kernel combined with a stationary kernel by multiplication.\nAs a consequence of this rule, any kernel can also be raised to a power of a positive integer and still be a valid kernel. For instance, the polynomial kernel can be viewed as the product of \\nu linear kernels.\nOther Methods The sum and product rules can also be combined. Along with the fact that the constant kernel is a valid kernel, one can effectively create a weighed sum of kernels.\nk_{sum}(\\mathbf{x},\\mathbf{x'}) = w_1k_1(\\mathbf{x},\\mathbf{x'}) + w_2k_2(\\mathbf{x},\\mathbf{x'})\nWhere w_1 and w_2 are weights.\nTwo or more kernels can also be combined through convolution and yield a valid kernel [2].\nDifferent Kernels for Different Dimensions Using different kernels across different dimensions is often the right thing to, as it allows for a more accurate representation of prior knowledge of the modelled process.\nSpecifically, when the input features have different properties or units, different kernels might be appropriate. For example, a dimension representing time might benefit from a periodic kernel and another another representing temperature might best be represented with a stationary kernel. Using a separate kernel for each dimension can help capture the distinct behaviours and scales of the two features. It is also easy to imagine a real-world problem where the gathered data includes a mix of different data types, such as continuous, discrete, or categorical. By applying the right type of kernel to each type of feature, all features can be included in the same Gaussian process.\nImagine the situation where there are two different types of features, \\mathbf{x}_a and \\mathbf{x}_b. These could be a set of continuous features and a set of categorical features. On the first set of features, one kernel is applied, i.e., k_a(\\mathbf{x}_a,\\mathbf{x'}_a). On the other set of features another kernel is applied, i.e., k_b(\\mathbf{x}_b,\\mathbf{x'}_b). The two kernel values can be combined by multiplication\nk(\\mathbf{x}_a, \\mathbf{x}_b, \\mathbf{x'}_a, \\mathbf{x'}_b) = k_a(\\mathbf{x}_b,\\mathbf{x'}_b)k_b(\\mathbf{x}_b,\\mathbf{x'}_b)\nThis scales to many feature sets, so it is possible to have a separate kernel for each feature.\nReferences [1] MacKay, D. J. C. (1998). Introduction to gaussian processes. Available at http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.1927\u0026amp;rep=rep1\u0026amp;type=pdf.  [2] Rasmussen, C. E. and Williams, C. K. I. (2006). Gaussian processes for machine learning, chapters 4 \u0026amp; 5. MIT Press.  [3] Piironen, J. and Vehtari, A. (2016). Projection predictive model selection for gaussian processes. In 2016 IEEE 26th international workshop on machine learning for signal processing (MLSP). IEEE Available at https://doi.org/10.1109%2Fmlsp.2016.7738829.   License The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license, and the underlying code is licensed under the GNU General Public License v3.0 license.\nwindow.document.addEventListener(\"DOMContentLoaded\", function (event) { const tabsets = window.document.querySelectorAll(\".panel-tabset-tabby\") tabsets.forEach(function(tabset) { const tabby = new Tabby('#' + tabset.id); }); const icon = \"\"; const anchorJS = new window.AnchorJS(); anchorJS.options = { placement: 'right', icon: icon }; anchorJS.add('.anchored'); const clipboard = new window.ClipboardJS('.code-copy-button', { target: function(trigger) { return trigger.previousElementSibling; } }); clipboard.on('success', function(e) { // button target const button = e.trigger; // don't keep focus button.blur(); // flash \"checked\" button.classList.add('code-copy-button-checked'); setTimeout(function() { button.classList.remove('code-copy-button-checked'); }, 1000); // clear code selection e.clearSelection(); }); function tippyHover(el, contentFn) { const config = { allowHTML: true, content: contentFn, maxWidth: 500, delay: 100, arrow: false, appendTo: function(el) { return el.parentElement; }, interactive: true, interactiveBorder: 10, theme: 'light-border', placement: 'bottom-start' }; window.tippy(el, config); } const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]'); for (var i=0; i","date":1681603200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681635720,"objectID":"f54f3ca427ebff5d3ad24ae6312fb420","permalink":"/post/kernels-r/","publishdate":"2023-04-16T00:00:00Z","relpermalink":"/post/kernels-r/","section":"post","summary":"A comprehensive overview of kernels, or covariance functions, for Gaussian processes and Bayesian optimisation. Implementation in R.","tags":["Modelling","Bayesian statistics","Bayesian optimisation","R"],"title":"Kernels for Gaussian Processes","type":"post"},{"authors":null,"categories":[],"content":" batch-effects  code{white-space: pre-wrap;} span.smallcaps{font-variant: small-caps;} span.underline{text-decoration: underline;} div.column{display: inline-block; vertical-align: top; width: 50%;} div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;} ul.task-list{list-style: none;} pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ff0000; font-weight: bold; } /* Alert */ code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #7d9029; } /* Attribute */ code span.bn { color: #40a070; } /* BaseN */ code span.bu { } /* BuiltIn */ code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4070a0; } /* Char */ code span.cn { color: #880000; } /* Constant */ code span.co { color: #60a0b0; font-style: italic; } /* Comment */ code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #ba2121; font-style: italic; } /* Documentation */ code span.dt { color: #902000; } /* DataType */ code span.dv { color: #40a070; } /* DecVal */ code span.er { color: #ff0000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #40a070; } /* Float */ code span.fu { color: #06287e; } /* Function */ code span.im { } /* Import */ code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #007020; font-weight: bold; } /* Keyword */ code span.op { color: #666666; } /* Operator */ code span.ot { color: #007020; } /* Other */ code span.pp { color: #bc7a00; } /* Preprocessor */ code span.sc { color: #4070a0; } /* SpecialChar */ code span.ss { color: #bb6688; } /* SpecialString */ code span.st { color: #4070a0; } /* String */ code span.va { color: #19177c; } /* Variable */ code span.vs { color: #4070a0; } /* VerbatimString */ code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */ .display.math{display: block; text-align: center; margin: 0.5rem auto;}           In previous studies, we built bespoke Bayesian models to fit observations from a biochemical assay with kinetics that could be represented by the Hill equation. Then we scaled that up to a screening experiment. In those studies, our main goal was to achieve good fits for kinetic parameters.\nIn this study, we extend the screening experiment to account for variance outside the kinetics of the tissue response. This can be used to account for batch variation, as is demonstrated here, but could also be used to account for other covariates of interest.\nlibrary(ggplot2) library(magrittr)  colour \u0026lt;- list(  orange_dark = \"#fb8500\",  orange_light = \"#ffb703\",  blue_dark = \"#023047\",  azure = \"#219ebc\",  blue_light = \"#8ecae6\" ) seed \u0026lt;- 4444 set.seed(seed)  Generative Model As as always the case in a Bayesian modelling workflow, we start by considering the process that generated the data. Along the way, we will generate simulations from the generative process.\nThe process in this case is going to be similar to the screening experiment of the previous post, but we are imagining a scenario where we perform the screening experiment in four batches. We want to combine and compare results from the four batches, but we also realise that the conditions might vary slightly between each batch, so we need some way to account for that.\nEach tested compound is expected to follow a dose-response curve as described by the Hill equation.\nhill_function \u0026lt;- function(log_conc, bottom, top, log_IC50, nH) {  top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH)) }  In our assay, we test each compound at different concentrations and observe the corresponding response. We expect that this response is noisy\nassay_response \u0026lt;- function(log_conc, bottom, top, log_IC50, nH, sigma) {  noise \u0026lt;- rnorm(length(log_conc), 0, sigma)  hill_function(log_conc, bottom, top, log_IC50, nH) + noise }  screening_experiment \u0026lt;- function(parameters, log_conc) {  parameters %\u0026gt;%   tidyr::expand_grid(log_conc = log_conc) %\u0026gt;%  dplyr::mutate(  response = assay_response(log_conc, bottom, top, log_IC50, nH, sigma)  ) }  Now we can define some parameters for the experiment. It is these parameters that we should be able to recover with the Bayesian model later.\nWe imagine an experiment of four batches with 50 compounds each. The compounds are randomly assigned to batches, so there is no correlation between batch and compound parameters. However, the batches are expected to have different levels of noise in the observations.\nn_batch_size \u0026lt;- 50 n_batches \u0026lt;- 4 n_compounds \u0026lt;- n_batches * n_batch_size  true_parameters \u0026lt;- tibble::tibble(  compound = seq(1, n_compounds),  batch = rep(1:n_batches, each = n_batch_size),  bottom = 1 - rlnorm(n_compounds, -0.25, 0.125),  log_IC50 = rnorm(n_compounds, -5, 1.5) + rexp(n_compounds, 3),  top = 1.02,  nH = 0.99,  sigma = rep(seq(0.05, 0.4, length.out = n_batches), each = n_batch_size) )  Let’s plot a few curves just to make sure that we have got the generative process right.\ntrue_curves \u0026lt;- purrr::pmap(  dplyr::sample_n(true_parameters, size = 10),  ~ geom_function(  fun = hill_function,  args = list(  top = ..5,  bottom = ..3,  nH = ..6,  log_IC50 = ..4  ),  colour = colour$blue_dark,  alpha = 0.5  ) )  p \u0026lt;- ggplot() +  xlim(-9, -1) +  theme_minimal() +  labs(  x = \"Ligand concentration [M]\",  y = \"True tissue response\",  title = \"Sample True Tissue Responses\"  )  Reduce(`+`, true_curves, init = p)   Bespoke Bayesian Model Now that we understand the generative process and we have functions to simulate data, we can start considering a Bayesian model. We need to specify two things; a set of relations that describe the generative process and priors for any parameters. If this seems similar to what we did in the previous post, it is because it is. The Bayesian model should reflect the process that generated the data, and the process is only slightly different to what we did before. So let’s get started.\nLikelihood Model In our screening assay, we will consider Ncompound compounds j = 1, ..., Ncompound. For each compound, we measure an assay response, yij, for a number, i = 1, ..., Nmeasurement, of ligand concentrations [Aij]. We also know that the assay response averages to the tissue response, μij, but that observations are noisy. Previously, we assumed that all observations were made in the same batch, such that they had identically distributed noise. In this study, we imagine that we had to do our screening experiment in batches, k = 1, ..., Nbatch, under slightly different conditions.\n$$y_{ijk} \\sim {\\sf Normal}(\\mu_{ij}, \\sigma_k)$$\nNote that the noise parameter, σk, is the same for some, but not all, compounds.\nThe dose-response is the same as always\n$$\\mu_{ij} = top - \\frac{bottom_j - top}{1 + 10^{(\\log_{10}(IC_{50,j}) - \\log_{10}([A_{ij}]))^{n_H}}}$$\nPriors For our priors, we employ the same as in the previous post\n$$top \\sim {\\sf Normal}(1, 0.01)$$\n$$n_H \\sim {\\sf LogNormal}(0, 0.5)$$\n$$bottom_j \\sim {\\sf Normal}(0.25, 0.25)$$\n$$\\log_{10}(IC_{50,j}) \\sim {\\sf Normal}(-6, 1.5)$$\nThe only prior that is a little different is the batch noise, which is now four parameters. We expect the four parameters to be different but sampled from the same distribution.\n$$\\sigma_k \\sim {\\sf Exp}(10)$$\nLet’s define a function that we can use to sample compounds from the assumed prior distributions.\nprior_parameters \u0026lt;- function(n_compounds = NULL,  bottom_mean = NULL,  bottom_sd = NULL,  top_mean = NULL,  top_sd = NULL,  log_IC50_mean = NULL,  log_IC50_sd = NULL,  nH_meanlog = NULL,  nH_sdlog = NULL,  sigma_rate = NULL) {  tibble::tibble(  compound = seq(1, n_compounds),  bottom = rnorm(n_compounds, bottom_mean, bottom_sd),  log_IC50 = rnorm(n_compounds, log_IC50_mean, log_IC50_sd),  top = rnorm(1, top_mean, top_sd),  nH = rlnorm(1, nH_meanlog, nH_sdlog),  sigma = rexp(1, sigma_rate)  ) }  Let’s also sample some dose-response curves from our assumed joint prior distribution. Hopefully the curves will be similar to those simulated from the generative model, but with a bit of noise.\npriors \u0026lt;- list(  bottom_mean \u0026lt;- 0.25,  bottom_sd \u0026lt;- 0.25,  top_mean \u0026lt;- 1,  top_sd \u0026lt;- 0.01,  log_IC50_mean \u0026lt;- -6,  log_IC50_sd \u0026lt;- 1.5,  nH_meanlog \u0026lt;- 0,  nH_sdlog \u0026lt;- 0.5,  sigma_rate \u0026lt;- 10 )  replicate(  10,  rlang::exec(  prior_parameters,  n_compounds = 5,  !!!priors  ),  simplify = FALSE ) %\u0026gt;%  dplyr::bind_rows(.id = \"rep\") %\u0026gt;%  dplyr::mutate(rep = paste0(rep, \"-\", compound)) %\u0026gt;%  screening_experiment(log_conc = seq(-10, -2, length.out = 100)) %\u0026gt;%  ggplot(aes(x = log_conc, y = response, group = rep)) +  geom_line(colour = colour$blue_dark, alpha = 0.5) +  theme_minimal() +  labs(  x = \"log ligand concentration\",  y = \"response\",  title = \"Prior Samples\"  )   The sampled dose-responses look reasonable.\nStan Implementation The likelihood and priors are relatively straightforward to implement in Stan. Each observation now has two indexes, one linking it to a compound and one linking it to a specific batch.\nwriteLines(readLines(\"hill_equation_batch_effects.stan\")) data { int\u0026lt;lower=0\u0026gt; N; int\u0026lt;lower=0\u0026gt; N_comp; int\u0026lt;lower=0\u0026gt; N_batch; int\u0026lt;lower=0\u0026gt; comp[N]; int\u0026lt;lower=0\u0026gt; batch[N]; vector[N] log_conc; vector[N] y; } parameters { real top; vector\u0026lt;upper=top\u0026gt;[N_comp] bottom; vector[N_comp] log_IC50; real\u0026lt;lower=0\u0026gt; nH; real\u0026lt;lower=0\u0026gt; sigma[N_batch]; } model { vector[N] mu; bottom ~ normal(0.25, 0.25); top ~ normal(1, 0.01); log_IC50 ~ normal(-6, 1.5); nH ~ normal(1, 0.01); sigma ~ exponential(10); for ( i in 1:N ) { mu[i] = top + (bottom[comp[i]] - top) / (1 + 10^((log_IC50[comp[i]] - log_conc[i])*nH)); y[i] ~ normal(mu[i], sigma[batch[i]]); } } generated quantities { vector[N] mu; vector[N] y_sampled; for ( i in 1:N ) { mu[i] = top + (bottom[comp[i]] - top) / (1 + 10^((log_IC50[comp[i]] - log_conc[i])*nH)); y_sampled[i] = normal_rng(mu[i], sigma[batch[i]]); } }   Now we can condition the model on some training data. We simulate some data, compile an input for the Stan model, and sample from the posterior\nassay_window \u0026lt;- seq(-8, -2, length.out = 6)  observations \u0026lt;- screening_experiment(  parameters = true_parameters,  log_conc = assay_window )  data \u0026lt;- list(  N = nrow(observations),  N_comp = n_compounds,  N_batch = n_batches,  comp = observations$compound,  batch = observations$batch,  log_conc = observations$log_conc,  y = observations$response )  post \u0026lt;- rstan::stan_model(\"hill_equation_batch_effects.stan\") %\u0026gt;%  rstan::sampling(  data = data,  chains = 4,  cores = 4,  iter = 4000,  seed = seed  )  # Extract samples from the posterior distribution posterior_samples \u0026lt;- tibble::as_tibble(rstan::extract(post))  Model Evaluation Before diving into the posterior distribution, we should check to see that we have good quality samples for each parameter\npost_summaries \u0026lt;- rstan::summary(  post,  probs = NULL )$summary  tibble::as_tibble(post_summaries) %\u0026gt;%  dplyr::select(-c(mean, se_mean, sd)) %\u0026gt;%  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %\u0026gt;%  dplyr::mutate(dplyr::across(-parameter, round, digits = 3)) %\u0026gt;%  dplyr::arrange(desc(Rhat)) %\u0026gt;%  dplyr::slice_head(n = 10) %\u0026gt;%  knitr::kable()   parameter n_eff Rhat    bottom[25] 308.722 1.009  log_IC50[25] 389.533 1.006  mu[1178] 718.568 1.005  mu[1179] 907.454 1.005  log_IC50[197] 1025.443 1.004  mu[542] 1471.156 1.004  mu[543] 2084.679 1.004  mu[1177] 851.739 1.004  mu[129] 2058.746 1.003  mu[149] 668.907 1.003      R̂ \u0026lt; 1.01 for all parameters and it looks like we have at least a couple hundred effective samples, so we should be ready to look at the posterior distribution.\nShared Parameters Let’s start with a look at nH and top which are shared parameters among all compounds\n# True parameters of the simulation. truth \u0026lt;- true_parameters %\u0026gt;%  dplyr::slice_head(n = 1) %\u0026gt;%  tidyr::pivot_longer(  dplyr::everything(),  names_to = \"parameter\",  values_to = \"truth\"  )  # A number of draws from our priors to match the number of draws we have from # the posterior prior_samples \u0026lt;- replicate(  nrow(posterior_samples),  rlang::exec(  prior_parameters,  n_compounds = 1,  !!!priors  ),  simplify = FALSE ) %\u0026gt;%   dplyr::bind_rows() %\u0026gt;%  dplyr::select(top, nH) %\u0026gt;%   tidyr::pivot_longer(  dplyr::everything(),  names_to = \"parameter\",  values_to = \"sample\"  )   # Plot each of the marginal distributions, comparing prior, posterior, and true # simulation parameters posterior_samples %\u0026gt;%  dplyr::select(top, nH) %\u0026gt;%  tidyr::pivot_longer(  dplyr::everything(),  names_to = \"parameter\",  values_to = \"sample\"  ) %\u0026gt;%  dplyr::left_join(truth, by = \"parameter\") %\u0026gt;%  ggplot() +  geom_histogram(  data = prior_samples,  mapping = aes(x = sample, fill = \"Prior\"),  bins = 50,  alpha = 0.5  ) +  geom_histogram(aes(x = sample, fill = \"Posterior\"), bins = 50, alpha = 0.5) +  geom_vline(aes(xintercept = truth, colour = \"truth\"), alpha = 0.5) +  facet_wrap(~ parameter, scales = \"free\") +  theme_minimal() +  scale_colour_manual(values = c(\"truth\" = colour$orange_light)) +  scale_fill_manual(values = c(  \"Prior\" = colour$azure,  \"Posterior\" = colour$blue_dark  )) +  labs(  y = \"Posterior sample count\",  x = \"\",  colour = \"\",  fill = \"\",  title = \"Marginal Posterior and Prior Distributions\"  )   We seem to have recovered the true underlying parameters nicely.\nNext up is the batch noise. We had four batches so there are four noise parameters, and hopefully they look different\n# True parameters of the simulation. truth \u0026lt;- true_parameters %\u0026gt;%  dplyr::select(batch, sigma) %\u0026gt;%  dplyr::distinct() %\u0026gt;%  tidyr::pivot_longer(  -batch,  names_to = \"parameter\",  values_to = \"truth\"  )  unpack_matrix \u0026lt;- function(data, cols) {  for (col in cols) {  mat \u0026lt;- data[[col]]  for (i in 1:dim(mat)[[2]]) {  cname \u0026lt;- paste0(col, i)  data \u0026lt;- dplyr::mutate(data, \"{cname}\" := mat[,i])  }  }  dplyr::select(data, -dplyr::all_of(cols)) }  # A number of draws from our priors to match the number of draws we have from # the posterior prior_samples \u0026lt;- replicate(  nrow(posterior_samples),  rlang::exec(  prior_parameters,  n_compounds = 1,  !!!priors  ),  simplify = FALSE ) %\u0026gt;%   dplyr::bind_rows() %\u0026gt;%  dplyr::select(sigma) %\u0026gt;%   tidyr::pivot_longer(  dplyr::everything(),  names_to = \"parameter\",  values_to = \"sample\"  )  # Plot each of the marginal distributions, comparing prior, posterior, and true # simulation parameters lapply(1:n_batches, function(i) {  tibble::tibble(  sigma = posterior_samples$sigma[,i],  batch = i  ) }) %\u0026gt;%  dplyr::bind_rows() %\u0026gt;%  tidyr::pivot_longer(  -batch,  names_to = \"parameter\",  values_to = \"sample\"  ) %\u0026gt;%  dplyr::left_join(truth, by = c(\"parameter\", \"batch\")) %\u0026gt;%  ggplot() +  geom_histogram(  data = prior_samples,  mapping = aes(x = sample, fill = \"Prior\"),  bins = 50,  alpha = 0.5  ) +  geom_histogram(aes(x = sample, fill = \"Posterior\"), bins = 50, alpha = 0.5) +  geom_vline(aes(xintercept = truth, colour = \"truth\"), alpha = 0.5) +  facet_grid(rows = vars(batch), cols = vars(parameter), scales = \"free\") +  theme_minimal() +  theme(strip.text.y = element_text(angle = 0)) +  scale_colour_manual(values = c(\"truth\" = colour$orange_light)) +  scale_fill_manual(values = c(  \"Prior\" = colour$azure,  \"Posterior\" = colour$blue_dark  )) +  labs(  y = \"Posterior sample count\",  x = \"\",  colour = \"\",  fill = \"\",  title = \"Marginal Posterior and Prior Distributions\"  )   Our model has successfully recovered the noise parameter for each batch, even though they are different.\nPosterior Curves It is cool that we are able to recover different noise levels for each batch. However, it is important that this does not come at the cost of worse dose-response curve fits. So let’s check that we are still able to determine good curve parameters.\nI have deliberately chosen one easy and one challenging curve.\nexample_curves \u0026lt;- tibble::tibble(curve = c(3, 180)) example_curves$post_pred \u0026lt;- purrr::map(example_curves$curve, function(i) {  posterior_samples %\u0026gt;%  dplyr::sample_n(4000) %\u0026gt;% # Ran out of RAM...  dplyr::mutate(  log_IC50 = log_IC50[, i],  bottom = bottom[, i]  ) %\u0026gt;%  tidyr::expand_grid(log_conc = seq(-2, -9, length.out = 50)) %\u0026gt;%   dplyr::mutate(tissue_response = purrr::pmap_dbl(  list(log_conc, bottom, top, log_IC50, nH),  hill_function  )) %\u0026gt;%  dplyr::group_by(log_conc) %\u0026gt;%  dplyr::summarise(  response_mean = mean(tissue_response),  response_upper = quantile(tissue_response, probs = 0.945),  response_lower = quantile(tissue_response, probs = 0.055)  ) %\u0026gt;%  ggplot() +  geom_ribbon(  aes(  x = log_conc,  ymin = response_lower,  ymax = response_upper,  fill = \"89% interval\"  ),  alpha = 0.5  ) +  geom_line(aes(  x = log_conc,  y = response_mean,  colour = \"Posterior mean\"  )) +  geom_point(  data = dplyr::filter(observations, compound == i),  aes(x = log_conc, y = response, colour = \"Observations\")  ) +  geom_function(  fun = hill_function,  args = true_parameters[i, -c(1,2,7)],  mapping = aes(colour = \"True tissue response\")  ) +  labs(  y = \"Tissue response\",  x = \"Log ligand concentration [M]\",  colour = \"\",  fill = \"\",  title = paste(\"Posterior Predictive for Compound\", i)  ) +  scale_fill_manual(values = c(\"89% interval\" = colour$azure)) +  theme_minimal() }) example_curves$post_pred_coloured \u0026lt;- purrr::map(  example_curves$post_pred,  function(p) {  p + scale_colour_manual(values = c(  \"Posterior mean\" = colour$blue_dark,  \"Observations\" = colour$orange_light,  \"True tissue response\" = colour$orange_dark  ))  } )  For the well-behaved curve, all looks good and the uncertainty around the key parameters is fairly small.\nexample_curves$post_pred_coloured[[1]]   Even in the difficult case, we get a decent fit, demonstrating that we can still get good curves even with the addition of additional parameters to account for batch effects.\nexample_curves$post_pred_coloured[[2]]   Perspective In this post, we extended our model for the dose-response screening experiment to also include batch effects. We demonstrated that batch effects can be recovered without compromising on curve parameter quality.\nAccounting for batch effects is already very useful, but the approach can be expanded to even more useful situations. Imagine, for instance, a case where the model includes expressions that relate either efficacy or potency to known variations among compounds. That way we combine the power of screening assays with the structure of experiments and possibly derive much more information from our hard earned data.\nwindow.document.addEventListener(\"DOMContentLoaded\", function (event) { const tabsets = window.document.querySelectorAll(\".panel-tabset-tabby\") tabsets.forEach(function(tabset) { const tabby = new Tabby('#' + tabset.id); }); const icon = \"\"; const anchorJS = new window.AnchorJS(); anchorJS.options = { placement: 'right', icon: icon }; anchorJS.add('.anchored'); const clipboard = new window.ClipboardJS('.code-copy-button', { target: function(trigger) { return trigger.previousElementSibling; } }); clipboard.on('success', function(e) { // button target const button = e.trigger; // don't keep focus button.blur(); // flash \"checked\" button.classList.add('code-copy-button-checked'); setTimeout(function() { button.classList.remove('code-copy-button-checked'); }, 1000); // clear code selection e.clearSelection(); }); function tippyHover(el, contentFn) { const config = { allowHTML: true, content: contentFn, maxWidth: 500, delay: 100, arrow: false, appendTo: function(el) { return el.parentElement; }, interactive: true, interactiveBorder: 10, theme: 'light-border', placement: 'bottom-start' }; window.tippy(el, config); } const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]'); for (var i=0; i","date":1679184000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679251080,"objectID":"4bc0fd1694143d0ae393ed7654a9a6fd","permalink":"/post/bespoke-biochem-three/","publishdate":"2023-03-19T00:00:00Z","relpermalink":"/post/bespoke-biochem-three/","section":"post","summary":"Developing a bespoke Bayesian model for dose-response screening assays with batch effects","tags":["Bayesian data analysis","Bayesian statistics","R","Stan","Statistics","Modelling","Biochemistry"],"title":"Bespoke Bayesian Model for Batch Effects in High Throughput Biochemical Assays","type":"post"},{"authors":null,"categories":null,"content":"I am on a quest to improve the model fitting I do on biochemical assays. For some time, I have had this feeling that I should be able to extract more information from the data gathered in biochemical assays, in particular assays with a high throughput. I have been using classical machine learning techniques and generic fitting and optimisation functions to interpret data from such assays. While this approach works, it also neglects much of the available domain expertise. Many of the underlying biochemical mechanisms are known and I would like my models to take that into account so I get results that are more directly interpretable in the context of the hypothesis that required the assay in the first place. In other words, I want a bespoke model.\nThrough three incremental iterations, I have built a bespoke Bayesian Model for biochemical assays that seek to quantify a dose-response. These are common assays in drug development and provide the foundation for screening as well as optimisation experiments.\nPosts in the Series Bespoke Bayesian Model for Biochemical Assays\nIn this, I build a Bayesian model for a single dose-response curve, representing a single experiment.\nBespoke Bayesian Model for High Throughput Biochemical Assays\nIn this, I build a Bayesian model for a screening experiment with multiple variations of a compound.\nBespoke Bayesian Model for High Throughput Biochemical Assays with Batch Effects\nPost coming soon. In this, I add upon the screening experiment, by showing how to account for batch effects and include covariates in the Bayesian model.\nLicense The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license, and the underlying code is licensed under the GNU General Public License v3.0 license.\n","date":1678838400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1678905444,"objectID":"012c0ab528db8eab2407a9c60ec845c9","permalink":"/project/bayesian-biochemistry/","publishdate":"2023-03-15T00:00:00Z","relpermalink":"/project/bayesian-biochemistry/","section":"project","summary":"Building bespoke Bayesian models for for dose-response curves in biochemical assays.","tags":["AI","Bayesian statistics","Machine learning","Biotech"],"title":"Bayesian Biochemistry","type":"project"},{"authors":null,"categories":null,"content":"When trying to optimise valuable industrial processes, like manufacturing, drug development, or supply chains, I often encounter the same challenge. There is little relevant historical data available and it is extremely expensive to conduct experiments on the process.\nMy go-to tool in these cases is Bayesian optimisation.\nBayesian optimisation is a powerful tool to perform optimisation of opaque, complex processes. Bayesian optimisation uses a probabilistic model as a surrogate for the opaque process. This model is updated with sequential experiments that the model itself helps design. With relatively few experiments, Bayesian optimisation can find good maxima or minima.\nThe probabilistic model allows us to incorporate our prior knowledge about the process at hand and gives us a head start in the optimisation. However, for the same reason, Bayesian optimisation is sensitive to initial assumptions, and there are a lot of moving parts.\nWith this project, I aim to introduce and discuss the components of Bayesian optimisation. However, I will focus less on the mathematical intricacies and put more emphasis on the assumptions and implementation of each component.\nPosts on Bayesian Optimisation Bayesian Optimisation from Scratch in R\nThis post introduces and demonstrates all the core components of Bayesian optimisation and implements them from scratch in R. This is a great place to start.\nKernel Functions\nThis post contains a comprehensive list and discussion of kernels to use in the Gaussian processes surrogate model, when doing Bayesian optimisation. Accompanying the discussion, are implementations in R. The kernel is the main way to incorporate prior information into a surrogate model, making it an important choice, when setting up Bayesian optimisation.\nAcquisition Functions\nThis post discusses acquisition functions, which are used to recommend the next point to sample in the experiment sequence. Acquisition functions are the main means of balancing exploration and exploitation during optimisation. The post lists a number of acquisition functions and implements them in R.\nNeural Networks as Surrogate Models\nThis post is coming soon.\nLatin Hypercube Sampling and other Initial Designs for Bayesian Optimisation\nThis post is coming soon.\nBenchmarking Bayesian Optimisation\nThis post is coming soon.\nLicense The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license, and the underlying code is licensed under the GNU General Public License v3.0 license.\n","date":1678838400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679088084,"objectID":"12b70b607e086be5dcfa8302a9227c51","permalink":"/project/bayesian-optimisation/","publishdate":"2023-03-15T00:00:00Z","relpermalink":"/project/bayesian-optimisation/","section":"project","summary":"Tools and tutorials for Baysian optimisation.","tags":["AI","Bayesian statistics","Machine learning"],"title":"Bayesian Optimisation Tools and Tutorials","type":"project"},{"authors":null,"categories":null,"content":" index  code{white-space: pre-wrap;} span.smallcaps{font-variant: small-caps;} span.underline{text-decoration: underline;} div.column{display: inline-block; vertical-align: top; width: 50%;} div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;} ul.task-list{list-style: none;} pre  code.sourceCode { white-space: pre; position: relative; } pre  code.sourceCode  span { display: inline-block; line-height: 1.25; } pre  code.sourceCode  span:empty { height: 1.2em; } .sourceCode { overflow: visible; } code.sourceCode  span { color: inherit; text-decoration: inherit; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { pre  code.sourceCode { white-space: pre-wrap; } pre  code.sourceCode  span { text-indent: -5em; padding-left: 5em; } } pre.numberSource code { counter-reset: source-line 0; } pre.numberSource code  span { position: relative; left: -4em; counter-increment: source-line; } pre.numberSource code  span  a:first-child::before { content: counter(source-line); position: relative; left: -1em; text-align: right; vertical-align: baseline; border: none; display: inline-block; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { } @media screen { pre  code.sourceCode  span  a:first-child::before { text-decoration: underline; } } code span.al { color: #ff0000; font-weight: bold; } /* Alert */ code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #7d9029; } /* Attribute */ code span.bn { color: #40a070; } /* BaseN */ code span.bu { } /* BuiltIn */ code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4070a0; } /* Char */ code span.cn { color: #880000; } /* Constant */ code span.co { color: #60a0b0; font-style: italic; } /* Comment */ code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #ba2121; font-style: italic; } /* Documentation */ code span.dt { color: #902000; } /* DataType */ code span.dv { color: #40a070; } /* DecVal */ code span.er { color: #ff0000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #40a070; } /* Float */ code span.fu { color: #06287e; } /* Function */ code span.im { } /* Import */ code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #007020; font-weight: bold; } /* Keyword */ code span.op { color: #666666; } /* Operator */ code span.ot { color: #007020; } /* Other */ code span.pp { color: #bc7a00; } /* Preprocessor */ code span.sc { color: #4070a0; } /* SpecialChar */ code span.ss { color: #bb6688; } /* SpecialString */ code span.st { color: #4070a0; } /* String */ code span.va { color: #19177c; } /* Variable */ code span.vs { color: #4070a0; } /* VerbatimString */ code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */ div.csl-bib-body { } div.csl-entry { clear: both; } .hanging div.csl-entry { margin-left:2em; text-indent:-2em; } div.csl-left-margin { min-width:2em; float:left; } div.csl-right-inline { margin-left:2em; padding-left:1em; } div.csl-indent { margin-left: 2em; }   document.addEventListener(\"DOMContentLoaded\", function () { var mathElements = document.getElementsByClassName(\"math\"); var macros = []; for (var i = 0; i          Bayesian optimisation is a powerful technique for optimising expensive functions or processes. In many applications, such as drug discovery, manufacturing, machine learning, or scientific experimentation, the function or process to be optimised may be time consuming or costly to evaluate. Bayesian optimisation provides a framework for sequential experimentation and for finding optima with as few evaluations as possible.\nThis post seeks to introduce the core ideas and components of Bayesian optimisation. Along with the introduction are implementations of all the core components of Bayesian optimisation in R. The implementations only use base R and Tidyverse - they are designed to be simple and not necessarily efficient.\nlibrary(ggplot2) library(magrittr) set.seed(4444)  The core idea behind Bayesian optimisation is to use a surrogate model to approximate a true objective function or process, and then use this approximation to determine the next experiment to perform. Typically, Gaussian processes or other similar probabilistic models are used as surrogate models.\nThe surrogate model is initialised with a few points and an acquisition function is then used to determine the next point to evaluate. The acquisition function balances exploration, ie. searching the regions of covariate space where the uncertainty is high, and exploitation ie. searching the regions where the surrogate model predicts a high value.\nAfter the next point is evaluated, it is added to the existing data and the surrogate model is updated. The process of selecting the next point to evaluate and updating the surrogate model is repeated until a stopping criterion is met. This could be when subsequent experiments stop yielding significantly different or better results. In real-world applications, a budget might only allow for limited number of experiments.\nBayesian optimisation has several advantages over other optimisation methods, including its ability to handle expensive functions and processes with a small number of evaluations. It also performs well in cases with noisy or uncertain data. However, while it can be considered a machine learning model, the surrogate model obtained through Bayesian optimisation is not a universally good approximation of the objective function and is not necessarily suitable for cases where extensive inference or interpretation is needed.\nCore Components of Bayesian Optimisation There are five main components to Bayesian optimisation\nObjective Function The objective function is the function or process that needs to be optimised, but which is expensive or time consuming to evaluate. The objective function is typically a black box, meaning that its mathematical form is unknown, and only its inputs and outputs can be observed.\nSurrogate Model The surrogate is a regression model that is used to approximate the objective function. The most commonly used surrogate model in Bayesian optimisation is a Gaussian process, which is a flexible, non-parametric model that can capture complex, non-linear relationships between the inputs and outputs of the objective function.\nAcquisition Function The acquisition function is used to determine the next point to evaluate in the search space. The acquisition function balances exploration and exploitation.\nInitial Training Data Bayesian optimisation requires some initial data to construct the surrogate model. This data can be obtained by evaluating the objective function at a few points in the search space. Given that the total experiment budget is often limited, much consideration often goes into deciding these initial training points.\nStopping Criterion Bayesian optimisation might require a stopping criterion to determine when to stop the search. This could be some measure of convergence, but often the number of experiments or deadlines set the constraints.\nIn the following sections, each component is discussed in greater detail, accompanied by implementations in R.\nObjective Function Bayesian optimisation can be applied to optimise any function or process that can be thought of as a black box function, f, that takes as input a set of covariates, \\mathbf{x}, and returns a scalar, y. Sometimes the actual readings from such function are noisy, i.e.\ny = f(\\mathbf{x}) + \\epsilon\nwhere \\epsilon is the noise, often assumed to be Gaussian \\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2).\nSome common examples of real world objective functions include\nML Hyperparameters. Machine learning model hyperparameters such as learning rate or regularisation strength are expensive to optimise, since they require retraining the model for each iteration. In the context of Bayesian optimisation, the model hyperparameters would be the input \\mathbf{x} and the model output would be the scalar objective y.\nDesign of experiments. Optimising the parameters of chemical or biological experiments can save both time and money, or even accelerate the discovery of new drugs or products.\nManufacturing. A manufacturing process can often be thought of as have a set of defined inputs (material, flow, settings, etc.) and measurable outputs that should be maximised (eg. product output or yield) or minimised (eg. waste).\nBenchmarking Functions This implementation of Bayesian optimisation mainly explores each component at a high level so there will not be an actual black box process to optimise. Instead, a benchmark function is used to demonstrate the implementation.\nThere are many good benchmark functions. One such is the Ackley function. It is defined as:\nf(\\mathbf{x}) = -a\\exp\\left(-b\\sqrt{\\frac{1}{d}\\sum_{i=1}^dx_i^2}\\right) - \\exp\\left(\\frac{1}{d}\\sum_{i=1}^d \\cos(c x_i)\\right) \\\\ + a + \\exp(1)\nwhere d is the number of dimensions and a, b, and c are constants. The global minimum of the Ackley function is f(\\mathbf{x})=0 at \\mathbf{x}=(0,0,...,0).\nFor this implementation the constants are set at a = 20, b = 0.2 and c = 2\\pi, and the function can be applied to a matrix of observations, \\mathbf{X}, rather than just a single vector of covariates.\nackley \u0026lt;- function(X) {  if (is.null(dim(X))) dim(X) \u0026lt;- c(1, length(X))  d \u0026lt;- ncol(X)  part1 \u0026lt;- -20*exp(-0.2*sqrt(1/d*rowSums(X^2)))  part2 \u0026lt;- -exp(1/d*rowSums(cos(2*pi*X)))  part1 + part2 + 20 + exp(1) }  Surrogate Model: Gaussian Process Regression This section explores the virtues Gaussian processes and how they can be applied as surrogate models for Bayesian optimisation. This is the largest and most complex part of Bayesian optimisation, and the discussions and implementations will only take a brief glance at some of the considerations.\nA Gaussian process (GP) is a probabilistic model that defines a distribution over functions. A GP model assumes that a function can be represented as a collection of random variables with a multivariate Gaussian distribution. Intuitively, the GP assumes that data points with high correlation among the covariates have similar values of the output variable(s).\nFormally, a GP is defined by a mean function and a covariance function, also called a kernel function.\np(f | \\mathbf{X}) = \\mathcal{N}(f | \\mathbf{\\mu}, \\mathbf{\\Sigma})\nf is the objective function and \\mathbf{X} is a set of observations for the covariates of f. The mean function, \\mathbf{\\mu}, specifies the expected value of the function at each point in the covariate space, while the covariance matrix, \\mathbf{\\Sigma}, specifies how the function values at any two points in the covariate space are correlated. The covariance matrix is calculated using a kernel function and, in practice, the choice of kernel function is important for obtaining good and interpretable results with Bayesian optimisation. The mean function is of much lesser consequence and is often set to \\mathbf{\\mu} = \\mathbf{0}.\nKernels The choice of kernel function reflects prior beliefs about smoothness, periodicity, and other properties of the objective function. Intuitively, the kernel is a function that specifies the similarity between pairs of vectors of covariates. In other words, the kernel should quantify how similar two data points are, given just the input.\nFormally, a kernel function k(\\mathbf{x}, \\mathbf{x'}) takes two input vectors \\mathbf{x} and \\mathbf{x'} and produces a scalar value that quantifies the similarity or covariance between the two vectors.\nThe kernel function can be applied to the covariates, \\mathbf{X}, of a set of observed data points to create a covariance matrix, \\mathbf{\\Sigma}\n\\Sigma_{ij} = k(\\mathbf{x}_i, \\mathbf{x}_j)\nfor all combinations of observations i and j.\nKernels themselves are an entire subject, see the kernel post for a thorough discussion of kernels for Gaussian processes and Bayesian optimisation.\nImplementing the RBF kernel An example of a commonly used kernel is the Radial Basis Function (RBF) kernel. The RBF kernel is defined as\nk(\\mathbf{x}_i, \\mathbf{x}_j) = \\sigma_f^2 \\exp\\left(-\\frac{1}{2}\\frac{\\lVert \\mathbf{x}_i - \\mathbf{x}_j\\rVert^2}{l^2}\\right)\nwhere \\sigma_f and l are parameters and \\lVert \\rVert is the euclidean distance of the two vectors.\nThis implementation can take two vectors or two matrices. For a vector input, it returns the kernel function value. For a matrix inputs, the covariance matrix, \\mathbf{\\Sigma}, is returned.\n#' RBF Kernel #' #' @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d). #' @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d). #' @param l length scale #' @param sigma_f scale parameter  #' #' @return matrix of dimensions (n, m) rbf_kernel \u0026lt;- function(X1, X2, l = 1.0, sigma_f = 1.0) {  if (is.null(dim(X1))) dim(X1) \u0026lt;- c(1, length(X1))  if (is.null(dim(X2))) dim(X2) \u0026lt;- c(1, length(X2))  sqdist \u0026lt;- (- 2*(X1 %*% t(X2))) %\u0026gt;%  add(rowSums(X1**2, dims = 1)) %\u0026gt;%  sweep(2, rowSums(X2**2, dims = 1), `+`)  sigma_f**2 * exp(-0.5 / l**2 * sqdist) }  \\sigma_f^2 is a variance parameter that simply scales the functions to the magnitude of f. More interestingly, the length scale parameter, l of the RBF kernel affects the smoothness and flexibility of the functions modelled with a GP that uses this kernel. For a small value of the length scale, the kernel results in very flexible functions, whereas a larger length scale yields very smooth functions.\ntibble::tibble(l = c(0.25, 0.5, 1, 2, 5)) %\u0026gt;%  tidyr::expand_grid(x1 = seq(0, 10, length.out = 100)) %\u0026gt;%  dplyr::mutate(k = purrr::map2_dbl(x1, l, ~ rbf_kernel(.x, 0, .y))) %\u0026gt;%  ggplot(aes(x = x1, y = k, colour = factor(l))) +  geom_line() +  theme_minimal() +  labs(  x = \"Euclidian distance of points\",  y = \"Covariance\",  colour = \"Length scale\",  title = \"RBF kernel\"  )   The intuition here is that for small length scales two points have to be very close to have any correlation. This results in very flexible functions that do not expect much correlation between data points. For a large length scale, however, points that are far apart are still expected to behave in a similar way. This results in very smooth functions that expect similar output values across the entire covariate space.\nThe RBF kernel is a popular choice for Gaussian processes in part because of this interpretability. There are other advantages to the RBF kernel, but it is not necessarily a good default choice for every problem.\nGaussian processes as a distribution over functions If the Gaussian process is a distribution over functions, it should be possible to sample random functions from it. And indeed it is! The only thing needed in order to sample from a Gaussian is a function for pulling random numbers from, well, a Gaussian.\nIn practice, this amounts to plugging the mean and the covariance (kernel) into a multivariate Gaussian and sampling from it. Of course, a set of points, \\mathbf{x}, is required to compute \\mathbf{\\Sigma}. Note, however, that no outputs, \\mathbf{y} are needed yet, so a grid for \\mathbf{x} will suffice.\n#' Random Samples from a Multivariate Gaussian #'  #' This implementation is similar to MASS::mvrnorm, but uses chlosky #' decomposition instead. This should be more stable but is less efficient than #' the MASS implementation, which recycles the eigen decomposition for the #' sampling part. #' #' @param n number of samples to sample #' @param mu the mean of each input dimension #' @param sigma the covariance matrix #' @param epsilon numerical tolerance added to the diagonal of the covariance #' matrix. This is necessary for the Cholesky decomposition, in some cases. #' #' @return numerical vector of n samples rmvnorm \u0026lt;- function(n = 1, mu, sigma, epsilon = 1e-6) {  p \u0026lt;- length(mu)  if(!all(dim(sigma) == c(p, p))) stop(\"incompatible dimensions of arguments\")  ev \u0026lt;- eigen(sigma, symmetric = TRUE)$values  if(!all(ev \u0026gt;= -epsilon*abs(ev[1L]))) {  stop(\"The covariance matrix (sigma) is not positive definite\")  }  cholesky \u0026lt;- chol(sigma + diag(p)*epsilon)  sample \u0026lt;- rnorm(p*n, 0, 1)  dim(sample) \u0026lt;- c(n, p)  sweep(sample %*% cholesky, 2, mu, FUN = `+`) }  To assist the visualisation, here is a plot for the mean, uncertainty, and some samples of a Gaussian process for the case where there is only one covariate, i.e.\u0026nbsp;\\mathbf{X} is of shape (n,1) where n is the number of observations.\ngpr_plot \u0026lt;- function(samples,  mu,  sigma,  X_pred,  X_train = NULL,  y_train = NULL,  true_function = NULL) {  n_samples \u0026lt;- dim(samples)[[1]]  p \u0026lt;- tibble::as_tibble(  t(samples),  .name_repair = ~ paste(\"sample\", seq(1, n_samples))  ) %\u0026gt;%  dplyr::mutate(  x = X_pred,  uncertainty = 1.6*sqrt(diag(sigma)),  mu = mu,  lower = mu - uncertainty,  upper = mu + uncertainty,  f = if (!is.null(true_function)) true_function(X_pred)  ) %\u0026gt;%  ggplot(aes(x = x)) +  geom_ribbon(  aes(ymin = lower, ymax = upper, fill = \"89% interval\"),  alpha = 0.2  ) +  geom_line(aes(y = mu, colour = \"Mean\")) +  theme_minimal() +  labs(  y = \"y\",  x = \"x\",  colour = \"\",  fill = \"\"  ) +  theme(panel.grid = element_blank())  p \u0026lt;- Reduce(  `+`,  init = p,  x = lapply(paste(\"sample\", seq(1, n_samples)), function(s) {  geom_line(aes(y = .data[[s]], colour = s), linetype = 2)  })  ) +  scale_colour_brewer(palette = \"YlGnBu\") +  scale_fill_manual(values = list(\"89% interval\" = \"#219ebc\"))  if (!is.null(X_train) \u0026amp;\u0026amp; !is.null(y_train)) {  p \u0026lt;- p +   geom_point(  data = tibble::tibble(x = X_train, y = y_train),  aes(x = x, y = y, shape = \"Training point\"),  colour = \"#fb8500\",  size = 4  ) +  scale_shape_manual(values = c(\"Training point\" = \"+\")) +  labs(shape = \"\")  }  if (!is.null(true_function)) {  p \u0026lt;- p +   geom_line(mapping = aes(y = f, colour = \"True function\"))  }  return(p) }  This bit is at the core of Gaussian processes. Given a set of points, the corresponding \\mathbf{\\Sigma} is calculated. Then this are plugged into a multivariate Gaussian to obtain predicted function values. In this case, \\mathbf{\\mu} has just been set to \\mathbf{0}.\nn_samples \u0026lt;- 5 X_predict \u0026lt;- matrix(seq(-5, 5, length.out = 100), 100, 1) mu \u0026lt;- rep(0, times = length(X_predict)) sigma \u0026lt;- rbf_kernel(X_predict, X_predict, l = 1, sigma_f = 1) samples \u0026lt;- rmvnorm(n = n_samples, mu, sigma) gpr_plot(samples, mu, sigma, X_predict)   Conditioning the Gaussian process Until now, the GP has just represented a prior belief for the surrogate functions that might model the objective function. It is not a surrogate model yet.\nIn order for the GP to be a useful surrogate model, it should provide posterior predictions for proposed points, given the available training data. I.e. for a set of training data, \\mathbf{X}_t and \\mathbf{y}_t, as well as a set of proposed points \\mathbf{X}_p, the GP should yield a posterior predictive distribution for the proposed/predicted outputs \\mathbf{y}_p. For a GP, the joint distribution of training points and new proposed points is itself a GP. Consequently, it is possible to compute the joint distribution of training data and posterior prediction points directly.\nThe mean and covariance of this joint distribution have well defined expressions. Given a set of training data, \\mathbf{X}_t, \\mathbf{y}_t, and set of points on which to make predictions, \\mathbf{X}_p, the mean of the posterior predictive distribution is\n\\mathbf{\\mu}_{p|t} = \\mathbf{\\mu}_p + \\mathbf{\\Sigma}_{tp}^T \\mathbf{\\Sigma}_{tt}^{-1} (\\mathbf{y}_t - \\mathbf{\\mu}_t)\nWhere \\mathbf{\\Sigma}_{tp} is the covariance matrix between training and prediction points and \\mathbf{\\Sigma}_{tt} is the covariance matrix between training points.\nRecall though that often \\mathbf{\\mu} = \\mathbf{0}, so the equation will often show up as\n\\mathbf{\\mu}_{p|t} = \\mathbf{\\Sigma}_{tp} \\mathbf{\\Sigma}_{tt}^{-1} \\mathbf{y}_t\nThis is also what is implemented below.\nThe covariance matrix of the posterior predictive distribution is\n\\mathbf{\\Sigma}_{p|t} = \\mathbf{\\Sigma}_{pp} - \\mathbf{\\Sigma}_{tp}^T \\mathbf{\\Sigma}_{tt}^{-1} \\mathbf{\\Sigma}_{tp}\nWhere \\mathbf{\\Sigma}_{pp} is the covariance matrix between prediction points.\nThese formulas are straightforward linear algebra and could be implemented directly as such. However, they are somewhat numerically unstable. For greater stability, the implementation below calculates the posterior using the algorithm described in chapter 2 of [1].\n#' Get Parameters of the Posterior Gaussian Process #' #' @param kernel kernel function used for the Gaussian process #' @param X_pred matrix (m, d) of prediction points #' @param X_train matrix (n, d) of training points #' @param y_train column vector (n, d) of training observations #' @param noise scalar of observation noise #' @param ... named parameters for the kernel function #' #' @return list of mean (mu) and covariance (sigma) for the Gaussian posterior \u0026lt;- function(kernel, X_pred, X_train, y_train, noise = 1e-8, ...) {  if (is.null(dim(X_pred))) dim(X_pred) \u0026lt;- c(length(X_pred), 1)  if (is.null(dim(X_train))) dim(X_train) \u0026lt;- c(length(X_train), 1)  if (is.null(dim(y_train))) dim(y_train) \u0026lt;- c(length(y_train), 1)  K \u0026lt;- kernel(X_train, X_train, ...) + noise**2 * diag(dim(X_train)[[1]])  K_s \u0026lt;- kernel(X_train, X_pred, ...)  K_ss \u0026lt;- kernel(X_pred, X_pred, ...) + 1e-8 * diag(dim(X_pred)[[1]])  K_inv \u0026lt;- solve(K)  mu \u0026lt;- (t(K_s) %*% K_inv) %*% y_train  sigma \u0026lt;- K_ss - (t(K_s) %*% K_inv) %*% K_s  list(mu = mu, sigma = sigma) }  With a way to calculate the posterior, it is possible to condition a Gaussian process on some training data.\nHere is a bit of of training data for a one dimensional example.\nX_train \u0026lt;- matrix(c(-4.33, -2.1, 2.1), 3, 1) y_train \u0026lt;- ackley(X_train)  The Gaussian process is then conditioned on training data and applied to new proposed points in a single step\nX_predict \u0026lt;- matrix(seq(-5, 5, length.out = 100), 100, 1) post \u0026lt;- posterior(rbf_kernel, X_predict, X_train, y_train)  Just like the prior distribution, it is possible to sample random functions from the posterior distribution\nmu \u0026lt;- c(post$mu) sigma \u0026lt;- post$sigma n_samples \u0026lt;- 3 samples \u0026lt;- rmvnorm(n = n_samples, mu, sigma) gpr_plot(samples, mu, sigma, X_predict, X_train, y_train, ackley)   At this point, the fit is not too great and the sampled functions look nothing like the true function. However, this is only based on three data points and an arbitrary choice of kernel parameters.\nBoth things will be handled in due time, but it gets worse before it gets better.\nA Quick Note on Noise Recall that training data might be noisy, i.e.\u0026nbsp;y = f(\\mathbf{x}) + \\epsilon.\nNoise, too, is a subject all on its own. The key thing to remember is that noise can be accounted for by adding it to the diagonal of \\mathbf{\\Sigma}_{tt}. This is already implemented in the function for the posterior above.\nThe effect of noisy training data on the posterior is, unsurprisingly, more uncertainty.\nHere a bit of known noise is added to the observations.\nnoise \u0026lt;- 1 y_train \u0026lt;- ackley(X_train) + noise * rnorm(length(X_train))  When recreating the plot from above, now using the noisy observations, the most noticeable difference is that the distribution mean no longer passes though each observation.\npost \u0026lt;- posterior(rbf_kernel, X_predict, X_train, y_train, noise = noise) mu \u0026lt;- post$mu sigma \u0026lt;- post$sigma n_samples \u0026lt;- 3 samples \u0026lt;- rmvnorm(n = n_samples, mu, sigma) gpr_plot(samples, mu, sigma, X_predict, X_train, y_train, ackley)   Gaussian Process Regression Until now, the kernel parameters have been set at fixed, arbitrary values. This is a waste of good parameters, and it is possible to do something better. The core idea of Gaussian process regression (GPR) is that the kernel parameters can be adapted to fit the training data.\nA common approach to estimating the parameters of a kernel function in GPR is Maximum Likelihood Estimation (MLE).\nThe likelihood function for a Gaussian process is given by\np(\\mathbf{y}_t \\mid \\mathbf{X}_t, \\theta) = \\mathcal{N}(\\mathbf{y}_t \\mid \\mathbf{\\mu}, \\mathbf{\\Sigma}_{tt} + \\sigma_{\\epsilon}^2 \\mathbf{I})\nwhere \\mathbf{\\Sigma}_{tt} is the covariance matrix computed on training data using some kernel with parameters \\theta. In the case of the RBF kernel, the parameters to estimate are \\theta = (\\sigma_f, l). Notice that the noise has been added to the diagonal of the covariance matrix to account for noisy training data.\nThe corresponding log likelihood function is\n\\log p(\\mathbf{y}_t \\mid \\mathbf{X}_t, \\theta) = -\\frac{1}{2} \\left( \\log \\det (\\mathbf{\\Sigma}_{tt} + \\sigma_{\\epsilon}^2 \\mathbf{I}) + \\mathbf{y}_t^T (\\mathbf{\\Sigma}_{tt} + \\sigma_{\\epsilon}^2 \\mathbf{I})^{-1} \\mathbf{y}_t + n \\log(2\\pi) \\right)\nwhere n is the number of data points.\nThe optimal values of the kernel parameters are the values that maximise the log likelihood or, equivalently, minimise the negative log likelihood.\nTo implement Gaussian process regression, two components are needed: the likelihood and an optimiser. Here is an implementation of a negative log likelihood function, for any kernel. The implementation follows Algorithm 2.1 from chapter 2 of [1].\n#' Negative log-Likelihood of a Kernel #' #' @param kernel kernel function #' @param X_train matrix (n, d) of training points #' @param y_train column vector (n, d) of training observations #' @param noise scalar of observation noise #' #' @return function with kernel parameters as input and negative log likelihood #' as output nll \u0026lt;- function(kernel, X_train, y_train, noise) {  function(params) {  n \u0026lt;- dim(X_train)[[1]]  K \u0026lt;- rlang::exec(kernel, X1 = X_train, X2 = X_train, !!!params)  L \u0026lt;- chol(K + noise**2 * diag(n))  a \u0026lt;- backsolve(r = L, x = forwardsolve(l = t(L), x = y_train))  0.5*t(y_train)%*%a + sum(log(diag(L))) + 0.5*n*log(2*pi)  } }  There are many ways to minimise the function. Since there are only two parameters for the RBF kernel, the built in optimiser will do just fine.\nrbf_nll \u0026lt;- nll(rbf_kernel, X_train, y_train, noise) opt \u0026lt;- optim(par = c(1, 1), fn = rbf_nll)  The optimised kernel parameters should improve the GP.\npost \u0026lt;- posterior(  rbf_kernel,  X_predict,  X_train,  y_train,  noise = noise,  l = opt$par[[1]],  sigma_f = opt$par[[2]] ) mu \u0026lt;- post$mu sigma \u0026lt;- post$sigma n_samples \u0026lt;- 3 samples \u0026lt;- rmvnorm(n = n_samples, mu, sigma) gpr_plot(samples, mu, sigma, X_predict, X_train, y_train, ackley)   With that, all the components for creating a GP surrogate model are in place. For future use, they are collected in a single function that performs GPR.\n#' Gaussian Process Regression #' #' @param kernel kernel function #' @param X_train matrix (n, d) of training points #' @param y_train column vector (n, d) of training observations #' @param noise scalar of observation noise #' @param ... parameters of the kernel function with initial guesses. Due to the #' optimiser used, all parameters must be given and the order unfortunately #' matters #' #' @return function that takes a matrix of prediction points as input and #' returns the posterior predictive distribution for the output gpr \u0026lt;- function(kernel, X_train, y_train, noise = 1e-8, ...) {  kernel_nll \u0026lt;- nll(kernel, X_train, y_train, noise)  param \u0026lt;- list(...)  opt \u0026lt;- optim(par = rep(1, length(param)), fn = kernel_nll)  opt_param \u0026lt;- opt$par  function(X_pred) {  post \u0026lt;- rlang::exec(  posterior,  kernel = kernel,  X_pred = X_pred,  X_train = X_train,  y_train = y_train,  noise = noise,  !!!opt_param  )  list(  mu = post$mu,  sigma = diag(post$sigma),  parameters = set_names(opt_param, names(param))  )  } }  Applying GP in more Dimensions A GP surrogate model is great for problems with many dimensions and relatively few observations. Here is an example in 2D with just 10 training points.\nnoise_2d \u0026lt;- 1 X_train_2d \u0026lt;- matrix(runif(20, -5, 5), 10, 2) y_train_2d \u0026lt;- ackley(X_train_2d) + noise_2d * rnorm(2) gpr_2d \u0026lt;- gpr(rbf_kernel, X_train_2d, y_train_2d, noise_2d, l = 1, sigma_f = 1) X_predict_2d \u0026lt;- as.matrix(expand.grid(  seq(-5,5, length.out = 50),  seq(-5,5, length.out = 50) )) post \u0026lt;- gpr_2d(X_predict_2d) tibble::as_tibble(X_predict_2d, .name_repair = ~ c(\"x1\", \"x2\")) %\u0026gt;%  dplyr::mutate(y = post$mu) %\u0026gt;%  ggplot(aes(x = x1, y = x2)) +  geom_contour_filled(aes(z = y), bins = 8) +  geom_point(  data = tibble::as_tibble(X_train_2d, .name_repair = ~ c(\"x1\", \"x2\"))  ) +  theme_minimal() +  labs(fill = \"\")   Even with just a few training points, some general tendencies of the objective function have been captured and the surrogate model should be useful for Bayesian optimisation.\nAcquisition Function An acquisition function is used to determine the next point at which to evaluate the objective function. The goal of the acquisition function is to balance exploration, i.e.\u0026nbsp;sampling points in unexplored regions, and exploitation, i.e.\u0026nbsp;sampling points that are likely to be optimal. The acquisition function takes into account the posterior predictive distribution of the surrogate model and provides a quantitative measure of the value of evaluating the objective function at a given point. Some common acquisition functions used in Bayesian optimisation include expected improvement, probability of improvement, and upper confidence bound.\nImplementing Expected Improvement The basic idea behind Expected Improvement (EI) is to search for the point in the search space that has the highest probability of improving the current best solution. EI is defined as the expected value of the improvement over the current best solution, where the improvement is defined as the difference between the function value at the candidate point and the current best value. In other words, EI measures how much better the objective function is expected to be at the candidate point compared to the current best value, weighted by the probability of achieving that improvement.\nFormally, the expected improvement acquisition function for a minimisation problem is defined as:\n\\mathrm{EI}(\\mathbf{x}) = \\mathbb{E}\\left[\\max(0, f_{\\min} - f(\\mathbf{x}))\\right]\nwhere \\mathbf{x} is the candidate point f_{\\min} is the current best function value observed so far.\nWhen using a GP surrogate model in place of f, EI can be calculated using the formula\nEI(\\mathbf{x}) = (\\mu(\\mathbf{x}) - y_{best} - \\xi) \\Phi(Z) + \\sigma(\\mathbf{x}) \\phi(Z) with\nZ = \\frac{\\mu(\\mathbf{x}) - y_{best} - \\xi}{\\sigma(\\mathbf{x})}\n\\mu(\\mathbf{x}) and \\sigma(\\mathbf{x}) are the mean and standard deviation of the Gaussian process at \\mathbf{x}. \\Phi and \\phi are the standard normal cumulative distribution function and probability density function, respectively, and \\xi is a trade-off parameter that balances exploration and exploitation. Higher values of \\xi leads to more exploration and smaller values to exploitation. EI(\\mathbf{x}) = 0 when \\sigma(\\mathbf{x}) = 0.\nThe formulas can be implemented directly.\n#' Expected Improvement #' #' @param gp a conditioned Gaussian process #' @param X matrix (m, d) of points where EI should be evaluated #' @param X_train matrix (n, d) of training points #' @param xi scalar, exploration/exploitation trade off #' #' @return EI, vector of length m expected_improvement \u0026lt;- function(gp, X, X_train, xi = 0.01) {  post_pred \u0026lt;- gp(X)  post_train \u0026lt;- gp(X_train)  min_train \u0026lt;- min(post_train$mu)  sigma \u0026lt;- post_pred$sigma  dim(sigma) \u0026lt;- c(length(post_pred$sigma), 1)  imp \u0026lt;- min_train - post_pred$mu - xi  Z \u0026lt;- imp / sigma  ei \u0026lt;- imp * pnorm(Z) + sigma * dnorm(Z)  ei[sigma == 0.0] \u0026lt;- 0.0  ei }  When there is only a single input dimension, EI can be plotted next to the GP.\nei_plot \u0026lt;- function(mu,  sigma,  X_pred,  X_train,  y_train,  ei,  true_function = NULL,  title = \"\") {  p1 \u0026lt;- tibble::tibble(  mu = mu,  uncertainty = 1.96*sqrt(sigma),  upper = mu + uncertainty,  lower = mu - uncertainty,  x = X_pred,  f = if (!is.null(true_function)) true_function(X_pred)  ) %\u0026gt;%  ggplot(aes(x = x)) +  geom_line(aes(y = mu, colour = \"Mean\")) +  geom_ribbon(  aes(ymin = lower, ymax = upper),  fill = \"#219ebc\",  alpha = 0.2  ) +  geom_point(  data = tibble::tibble(x = X_train, y = y_train),  aes(x = x, y = y, shape = \"Training point\"),  colour = \"#fb8500\",  size = 4  ) +  scale_shape_manual(values = c(\"Training point\" = \"+\")) +  labs(shape = \"\") +  theme_minimal() +  labs(  y = \"y\",  x = \"\",  colour = \"\",  title = title  ) +  theme(panel.grid = element_blank(), axis.text.x = element_blank())  if (!is.null(true_function)) {  p1 \u0026lt;- p1 +   geom_line(mapping = aes(y = f, colour = \"True function\"))  }  p2 \u0026lt;- tibble::tibble(  x = X_pred,  ei = ei  ) %\u0026gt;%  ggplot() +  geom_line(aes(x = x, y = ei, colour = \"EI\")) +  theme_minimal() +  labs(x = \"\", y = \"Expected improvement\", colour = \"\") +  theme(panel.grid = element_blank())  aligned_plots \u0026lt;- cowplot::align_plots(p2, p1, align = \"v\")  cowplot::plot_grid(aligned_plots[[2]], aligned_plots[[1]], ncol = 1) } mygpr \u0026lt;- gpr(rbf_kernel, X_train, y_train, noise, l = 1, sigma_f = 1) ei \u0026lt;- expected_improvement(mygpr, X_predict, X_train, xi = 0.1) post \u0026lt;- mygpr(X_predict) ei_plot(post$mu, post$sigma, X_predict, X_train, y_train, ei, ackley)   In this example, there is some expected improvement near the middle of the input range, but the point expected to bring about the highest improvement is at the right edge of the range.\nInitial Training Data Before applying GPR and EI, a few initial training data are needed. Considering that it is expensive to evaluate the objective function, the number of initial training observations should be limited. However, considering that the GP is not great for extrapolation, the number of initial observation should not be too small either.\nIn general, the initial training data should be chosen to provide a good representation of the objective function. This means that the data should be chosen to cover the range of each input dimension. The data should also include inputs that are expected to be both good and bad performers.\nThere are a few ways to create a set of initial training inputs. One approach is to use a set of random inputs. This is easy to implement, but it risks testing redundant points and it neglects any prior information of the objective function. In place of a completely random design, Latin Hypercube Sampling (LHS) is often used.\nAnother approach is to use domain knowledge to select an initial set of inputs. For example, if the function being optimised is a manufacturing process there might be a fixed range of feasible settings and skilled operators might have good ideas for which settings would perform well.\nFor the demonstration of Bayesian optimisation with the Ackley function in just a few dimensions, a few random or linearly spaced points will do fine.\nStopping Criterion The final component of Bayesian optimisation is a stopping criterion. Depending on the application, a good stopping criterion might be more or less obvious. In settings where a real life process is optimised, time and money are common constraints. In ML or other theoretical applications, a mathematically defined criterion might be preferred.\nExamples of stopping criteria include\n Maximum number of objective function evaluations. When the improvement in objective function value falls below a threshold. Project time limits or deadlines. Accuracy of the surrogate model.  Bayesian Optimisation in Action With all the components of Bayesian optimisation in place, a demonstration is due.\nExample in 1D The initial training data is just two points.\nn_initial \u0026lt;- 2 X_initial \u0026lt;- matrix(c(-2.5, 2.1), n_initial, 1) noise \u0026lt;- 1 y_initial \u0026lt;- ackley(X_initial) + noise * rnorm(n_initial)  A GP is conditioned on the initial training data and expected improvement is calculated along a grid.\ngp \u0026lt;- gpr(rbf_kernel, X_initial, y_initial, noise, l = 1, sigma_f = 1) X_predict \u0026lt;- matrix(seq(-5, 5, length.out = 100), 100, 1) ei \u0026lt;- expected_improvement(gp, X_predict, X_initial, xi = 0.01)  Here is what it looks like so far.\npost \u0026lt;- gp(X_predict) ei_plot(post$mu, post$sigma, X_predict, X_initial, y_initial, ei, ackley)   It looks like the point that will yield the most improvement is all the way at the right edge of input space.\nNow this point is added to the training data.\nx \u0026lt;- X_predict[[which.max(ei)]] y \u0026lt;- ackley(x) + noise * rnorm(1) X_train \u0026lt;- rbind(X_initial, matrix(x)) y_train \u0026lt;- c(y_initial, matrix(y))  Now it is time for the optimisation part. The stopping criterion will be five additional evaluations.\nn_rounds \u0026lt;- 5  In each round, the GP is conditioned on the training data, the point that maximises EI is found, and that point is evaluated in the objective function.\nplots \u0026lt;- lapply(seq_len(n_rounds), function(i) {  gp \u0026lt;- gpr(rbf_kernel, X_train, y_train, noise, l = 1, sigma_f = 1)  ei \u0026lt;- expected_improvement(gp, X_predict, X_train, xi = 0.01)  post \u0026lt;- gp(X_predict)  p \u0026lt;- ei_plot(  post$mu,  post$sigma,  X_predict,  X_train,  y_train,  ei,  ackley,  title = paste(\"Round\", i)  )  x \u0026lt;- X_predict[[which.max(ei)]]  y \u0026lt;- ackley(x) + noise * rnorm(1)  X_train \u0026lt;\u0026lt;- rbind(X_train, matrix(x))  y_train \u0026lt;\u0026lt;- c(y_train, matrix(y))  p })  A closer look at each iteration reveals that the global optimum was found in the fourth evaluation of the objective function.\n         Example in 2D With two input dimensions the optimisation is a bit harder.\nThe initial training data will be four points.\nn_initial \u0026lt;- 4 X_initial \u0026lt;- c(5, -5, 2.1, -2.1, 4.7, -4.7, -2.5, -2.5) %\u0026gt;%  matrix(n_initial, 2) noise \u0026lt;- 1 y_initial \u0026lt;- ackley(X_initial) + noise * rnorm(n_initial)  A GP is conditioned on the initial training data and expected improvement is calculated along a grid.\ngp \u0026lt;- gpr(rbf_kernel, X_initial, y_initial, noise, l = 1, sigma_f = 1) X_predict \u0026lt;- seq(-5, 5, length.out = 50) %\u0026gt;%  expand.grid(.,.) %\u0026gt;%  as.matrix() ei \u0026lt;- expected_improvement(gp, X_predict, X_initial, xi = 0.01)  Here is what it looks like so far.\npost \u0026lt;- gp(X_predict) tibble::as_tibble(X_predict, .name_repair = ~ c(\"x1\", \"x2\")) %\u0026gt;%  dplyr::mutate(y = post$mu) %\u0026gt;%  ggplot(aes(x = x1, y = x2)) +  geom_contour_filled(aes(z = y), bins = 8) +  geom_point(  data = tibble::as_tibble(X_initial, .name_repair = ~ c(\"x1\", \"x2\"))  ) +  geom_point(  data = tibble::as_tibble(  t(X_predict[which.max(ei), ]),  .name_repair = ~ c(\"x1\", \"x2\")  ),  mapping = aes(colour = \"max EI\")  ) +  theme_minimal() +  labs(fill = \"\", colour = \"\")   It looks like the point that will yield the most improvement is all the way at the corner of input space.\nNow this point is added to the training data.\nx \u0026lt;- X_predict[which.max(ei), ] y \u0026lt;- ackley(x) + noise * rnorm(1) X_train \u0026lt;- rbind(X_initial, x) y_train \u0026lt;- c(y_initial, matrix(y))  Now it is time for the optimisation part. The stopping criterion will be eigth additional evaluations.\nn_rounds \u0026lt;- 8  In each round, the GP is conditioned on the training data, the point that maximises EI is found, and that point is evaluated in the objective function.\nplots \u0026lt;- lapply(seq_len(n_rounds), function(i) {  gp \u0026lt;- gpr(rbf_kernel, X_train, y_train, noise, l = 1, sigma_f = 1)  ei \u0026lt;- expected_improvement(gp, X_predict, X_train, xi = 0.01)  post \u0026lt;- gp(X_predict)  x \u0026lt;- X_predict[which.max(ei), ]  p \u0026lt;- tibble::as_tibble(X_predict, .name_repair = ~ c(\"x1\", \"x2\")) %\u0026gt;%  dplyr::mutate(y = post$mu) %\u0026gt;%  ggplot(aes(x = x1, y = x2)) +  geom_contour_filled(aes(z = y), bins = 8) +  geom_point(  data = tibble::as_tibble(X_train, .name_repair = ~ c(\"x1\", \"x2\"))  ) +  geom_point(  data = tibble::as_tibble(t(x), .name_repair = ~ c(\"x1\", \"x2\")),  mapping = aes(colour = \"max EI\")  ) +  theme_minimal() +  labs(fill = \"\", colour = \"\", title = paste(\"Round\", i))  y \u0026lt;- ackley(x) + noise * rnorm(1)  X_train \u0026lt;\u0026lt;- rbind(X_train, x)  y_train \u0026lt;\u0026lt;- c(y_train, matrix(y))  p })  Looking at the last four iterations reveals that, while close, the global optimum has not been found and that many iterations were spent exploring the edges of input space. A few more iterations might have revealed the global optimum. On the other hand, the small budget did reveal a relatively good set of input parameters.\n       References [1] Rasmussen, C. E. and Williams, C. K. I. (2006). Gaussian processes for machine learning. MIT Press.   License The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license, and the underlying code is licensed under the GNU General Public License v3.0 license.\nwindow.document.addEventListener(\"DOMContentLoaded\", function (event) { const tabsets = window.document.querySelectorAll(\".panel-tabset-tabby\") tabsets.forEach(function(tabset) { const tabby = new Tabby('#' + tabset.id); }); const icon = \"\"; const anchorJS = new window.AnchorJS(); anchorJS.options = { placement: 'right', icon: icon }; anchorJS.add('.anchored'); const clipboard = new window.ClipboardJS('.code-copy-button', { target: function(trigger) { return trigger.previousElementSibling; } }); clipboard.on('success', function(e) { // button target const button = e.trigger; // don't keep focus button.blur(); // flash \"checked\" button.classList.add('code-copy-button-checked'); setTimeout(function() { button.classList.remove('code-copy-button-checked'); }, 1000); // clear code selection e.clearSelection(); }); function tippyHover(el, contentFn) { const config = { allowHTML: true, content: contentFn, maxWidth: 500, delay: 100, arrow: false, appendTo: function(el) { return el.parentElement; }, interactive: true, interactiveBorder: 10, theme: 'light-border', placement: 'bottom-start' }; window.tippy(el, config); } const noterefs = window.document.querySelectorAll('a[role=\"doc-noteref\"]'); for (var i=0; i","date":1678579200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1678626300,"objectID":"11faf5839e97d7db6614218145102f23","permalink":"/post/bayesian-opt-r/","publishdate":"2023-03-12T00:00:00Z","relpermalink":"/post/bayesian-opt-r/","section":"post","summary":"All the basic components of Bayesian optimisation introduced and implemented in R","tags":["Modelling","Bayesian statistics","Bayesian optimisation","R"],"title":"Bayesian Optimisation from Scratch in R","type":"post"},{"authors":null,"categories":[],"content":"  I am on a quest to improve the model fitting I do on biochemical assays. For some time, I have had this feeling that I should be able to extract more information from the data gathered in biochemical assays, in particular assays with a high throughput. I have been using classical machine learning techniques and generic fitting and optimisation functions to interpret data from such assays. While this approach works, it also neglects much of the available domain expertise. Many of the underlying biochemical mechanisms are known and I would like my models to take that into account so I get results that are more directly interpretable in the context of the hypothesis that required the assay in the first place. In other words, I want a bespoke model.\nI will be developing the bespoke model one minimally viable step at a time. In this study, I am building a Bayesian model for biochemical assays where the underlying data generating process is the Hill equation for tissue responses [1]. I will then test the model in two simulated example studies.\nI was inspired to write this study after reading the chapter “Generalized Linear Madness” in the book Statistical Rethinking by R. McElreath [2] and the writings of M. Betancourt [3]. For an introduction to bespoke Bayesian models, I highly recommend these resources.\nIf you are following along, we will build the Bayesian models in Stan and make use of the Rstan interface to extract posterior samples. For data wrangling and visualisation, we will use the Tidyverse.\nlibrary(ggplot2) library(magrittr) options(mc.cores = parallel::detectCores()) colour \u0026lt;- list( orange_dark = \u0026quot;#fb8500\u0026quot;, orange_light = \u0026quot;#ffb703\u0026quot;, blue_dark = \u0026quot;#023047\u0026quot;, azure = \u0026quot;#219ebc\u0026quot;, blue_light = \u0026quot;#8ecae6\u0026quot; ) set.seed(4444) Contents  Contents Domain Expertise  Hill Equation From Domain Expertise to Probabilistic Model  A prior for the Hill coefficient A prior for the maximum tissue response A prior for the minimum tissue response A prior for potency A prior for experiment noise   Example Studies  Example Study 1 - Exploring Kinetics  A model for study 1 Prior predictive check in Tidyverse Building a Stan model for study 1 Fitting study 1  Example Study 2 - New Drug  A model for study 2 Prior predictive check with Stan Building a Stan model for study 2 Fitting study 2  Assessing posterior quality Comparing to another fitting method  Next Steps References License   Domain Expertise Before we start coding a model or even looking at any data, let’s formally discuss the biochemical domain experitise.\nHill Equation When a ligand, e.g. a drug, is an antagonist to a receptor that causes some tissue response, the strength of that response, \\(\\mu_i\\), declines with increased concentration of that ligand, \\([A_i]\\). The response is known to follow the Hill Equation [1].\n\\[\\mu_i = top - \\frac{bottom - top}{1 + 10^{(\\log_{10}(IC_{50}) - \\log_{10}([A_i]))^{n_H}}}\\]\nWhen tissue response is plotted against log ligand concentration, the Hill equation is a downwards sloping S-curve where \\(top\\) is the maximum response and \\(bottom\\) is the minimum response. \\(IC_{50}\\) is the concentration at which the response is halfway between \\(top\\) and \\(bottom\\). The final parameter, the Hill coefficient \\(n_H\\), affects the steepness of the curve and is determined by the underlying kinetics. At \\(n_H = 1\\), a ligand binding is independent of previously bound ligands. At \\(n_H \u0026lt; 1\\) binding has diminishing returns and at \\(n_H \u0026gt; 1\\) ligands cooperatively bind for increasing returns on tissue response.\nThe Hill Equation appears in various forms in literature. Notably, when the ligand is an agonist, the curve has a positive slope and the halfway point is then often named \\(EC_{50}\\). The logarithm base used could also be any other, but base 10 is a common choice, as 10 times dilutions or other whole-number dilutions are easier to make.\nLet’s plot an example curve\nhill_function \u0026lt;- function(log_conc, bottom, top, log_IC50, nH) { top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH)) } bottom \u0026lt;- 0 top \u0026lt;- 1 log_IC50 \u0026lt;- -3 nH \u0026lt;- 1 ggplot() + xlim(log_IC50 - 3, log_IC50 + 3) + geom_function( fun = hill_function, args = list(bottom = bottom, top = top, log_IC50 = log_IC50, nH = nH), aes(colour = \u0026quot;Tissue response\u0026quot;) ) + labs( x = \u0026quot;log ligand concentration\u0026quot;, y = \u0026quot;response\u0026quot;, title = \u0026quot;Hill Equation Example\u0026quot; ) + scale_colour_manual(values = c(\u0026quot;Tissue response\u0026quot; = colour$azure)) + theme_minimal() + theme(legend.title = element_blank()) In the real world, we cannot sample the true tissue response exactly. As a proxy for the tissue response, we employ assays that are performed in vitro. Such assays are sensitive to environmental conditions and, even in the most strictly controlled settings, yield noisy responses. Baring any systematic bias, the assay response, \\(y_i\\) should average to the true tissue response though.\nassay_response \u0026lt;- function(log_conc, bottom, top, log_IC50, nH, sigma) { noise \u0026lt;- rnorm(length(log_conc), 0, sigma) hill_function(log_conc, bottom, top, log_IC50, nH) + noise } tibble::tibble( log_conc = seq(log_IC50 -3, log_IC50 + 3, length.out = 5), y = assay_response(log_conc, bottom, top, log_IC50, nH, (top - bottom)/20) ) %\u0026gt;% ggplot(aes(log_conc, y)) + geom_point(aes(colour = \u0026quot;Noisy assay response\u0026quot;)) + geom_function( fun = hill_function, args = list(bottom = bottom, top = top, log_IC50 = log_IC50, nH = nH), aes(colour = \u0026quot;Tissue response\u0026quot;) ) + scale_colour_manual(values = c( \u0026quot;Tissue response\u0026quot; = colour$azure, \u0026quot;Noisy assay response\u0026quot; = colour$orange_light )) + labs( x = \u0026quot;log ligand concentration\u0026quot;, y = \u0026quot;response\u0026quot;, colour = \u0026quot;\u0026quot; ) + theme_minimal()  From Domain Expertise to Probabilistic Model With the basic domain knowledge in place, we are ready to start thinking about the assay in terms of probability distributions.\nThe first expression relates our observed assay responses, \\(y_i\\), to the true underlying tissue response, \\(\\mu_i\\). Given repeat observations, the assay response should average to the tissue response and the variance should be small and finite, so it is not too far a stretch to think of the assay response as a sample from a normal distribution.\n\\[y_i \\sim {\\sf Normal}(\\mu_i, \\sigma)\\]\nWhere \\(\\sigma\\) is a parameter that is shared among all observations.\nWe already know how the tissue response relates to the ligand concentration, \\([A_i]\\), the variable of our assay; it is the Hill equation.\n\\[\\mu_i = top - \\frac{bottom - top}{1 + 10^{(\\log_{10}(IC_{50}) - \\log_{10}([A_i]))^{n_H}}}\\]\nThese two expressions define our observational model or likelihood function. Next, we need to specify our prior model, and this is where domain expertise comes in handy.\nThe prior model needs to have prior assumptions and corresponding distributions for each parameter in the model. The parameters that need priors are \\(IC_{50}\\), \\(bottom\\), \\(top\\), \\(n_H\\), and \\(\\sigma\\).\n\\(\\mu_i\\) is an unobserved variable - it is a deterministic function of the model parameters and our variable, \\([A_i]\\), so it does not need a prior.\nThe priors will always have to be specific to the assay at hand. In this study, we are not considering a real assay, but will be simulating instead. Even so, we can still discuss general prior strategies for parameters of the model, in the light of our general knowledge about the biochemical processes. Later, when we start simulating, we can lock in specific priors.\nLet’s consider each parameter in turn, starting with \\(n_H\\).\nA prior for the Hill coefficient The Hill coefficient will in many cases be well known. For instance, if the receptor that causes the tissue response is known to have only one binding site for the ligand, it extremely unlikely that we will observe any cooperative or competitive kinetics.\nWhen each ligand binds an individual receptor, the binding should be independent, regardless of the nature of the ligand. Hence, in theory, \\(n_H = 1\\) and we can assign a narrow prior, say \\(n_H \\sim {\\sf Normal}(1, 0.1)\\). This prior puts 95% of the probability between 0.8 and 1.2. If we were very sure, we could go for an even narrower prior.\nIn case we encountered a response with cooperative binding, we would just move the prior distribution a bit above 1. For instance, if we were studying hemoglobin, we could put the prior at \\({\\sf Normal}(2.5, 0.5)\\) or thereabouts.\nWe know one more thing though. The Hill coefficient cannot be less than zero, as that would change the kinetics of the system. With the narrow prior around \\(n_H = 1\\) it is not really an issue, as there is virtually no probability mass below 0, but for kinetics with diminishing returns, an exponential prior or a half-normal distribution may be preferable.\n A prior for the maximum tissue response When discussing the \\(top\\) and \\(bottom\\) parameters, it is worth discussing assay technique. Even though the assay is performed in vitro, the subject, e.g. tissue, receptor, or enzyme, is often a biological construct and thus likely to exhibit batch variation. Furthermore, the raw assay reading carries no particular meaning. Instead, we employ controls to get a normalised response. For instance, we might use a bit of buffer as a negative control and assign the corresponding response to 1 and, at the other end, we might use a known strongly binding ligand as a positive control and assign the corresponding response to 0. The raw readings are then normalised between these two controls to yield the assay response, \\(y_i\\).\nBack to the maximum response. In most contexts, the maximum response is not all that interesting compared to the other parameters. We expect the maximum response to be in the vicinity of the negative control, and if we were doing regular curve fitting, we might just fix the maximum response at 1.\nIn terms of probabilities, it means that we have very strong prior knowledge about the maximum response. We could allow it to vary a bit, but I assert that is would not offer much utility.\n A prior for the minimum tissue response The minimum response, \\(bottom\\), is much more interesting, as it represents the greatest effect a ligand can have on a tissue response. Analogous to the negative control, we set the response of a positive control to 0. However, we cannot necessarily fix the minimum response at this point.\nImagine an assay where we are testing a chemical compound in the hopes of identifying a new antagonist for the tissue response of interest. If the compound is not a ligand for the receptor, there is no response and \\(bottom = top\\). On the other hand, if we come across a ligand, then it might elicit a stronger or weaker response than the positive control.\nWhat does this mean in terms of a prior? It means that screening experiments require a relatively wide prior for the \\(bottom\\) parameter; we only know that it should be less than \\(top\\) and that it is unlikely to be much smaller than 0. However, if we are studying the kinetics of the system and we have a known strong ligand as positive control, we can choose a much narrower prior around 0.\n A prior for potency Deciding on a prior for \\(IC_{50}\\) is difficult for two reasons. If we are screening new compounds, we might have no idea about the potency of the compound or whether it even has potency at all. Secondly, \\(IC_{50}\\) is a concentration and the tissue response depends on the ligand concentration relative to this concentration. In other words, it is the magnitude of the potency that matters.\nThe way to handle this is by thinking of a prior for \\(\\log_{10}(IC_{50})\\) instead. Units matter, but if we use Molar concentration then \\(\\log_{10}(IC_{50}) = -9\\) would correspond to an extremely potent ligand and \\(\\log_{10}(IC_{50}) = 0\\) would correspond to extremely low potency.\n A prior for experiment noise Hopefully, the experiment noise is minimal. Consider \\(\\sigma = 0.1\\). Since we expect most readings to fall in the range \\([0, 1]\\), this noise level translates to 95% of assay responses being within +-20% of the tissue response. This might be a lot or it might be what is expected from a biological assay, but the point is that, as long as we normalise the assay responses, this parameter should be easy to reason about. For instance, \\(\\sigma\\) can never be less than zero, and if it is higher than 0.5, then the assay is more noise than signal.\n   Example Studies Let’s move on to some simulated studies\nExample Study 1 - Exploring Kinetics In this study we are imagining a situation where we are trying to learn more about the kinetics of a tissue response. We are investigating a receptor for which we have a known strongly binding antagonist. We suspect that the receptor has multiple binding sites and that ligand binding is not independent. We also do not know the potency, \\(IC_{50}\\), of the antagonist, but we know that maximum tissue response is observed at \\([A_i] \u0026gt; 10^{-3}\\).\nLet’s set some ‘secret’ values for the system and simulate assay readings. Later, we will try to recover these values.\nstudy_1_params \u0026lt;- list( bottom = 0, top = 1, log_IC50 = -5.6, nH = 1.4, sigma = 0.05 ) A model for study 1 Before performing the experiment, i.e. simulating observations, we should take some time to reflect on our domain expertise and translate it into a bespoke probabilistic model for this particular scenario.\nWe know that we will measure an assay response, \\(y_i\\), for a number of ligand concentrations \\([A_i]\\). We also know that the assay response averages to the tissue response, \\(\\mu_i\\), but that observations are noisy:\n\\[y_i \\sim {\\sf Normal}(\\mu_i, \\sigma)\\]\nThe tissue response is a deterministic function of four kinetic parameters, as described by the Hill equation:\n\\[\\mu_i = top - \\frac{bottom - top}{1 + 10^{(\\log_{10}(IC_{50}) - \\log_{10}([A_i]))^{n_H}}}\\]\nThe \\(top\\) parameter should, on average, be equal to our negative control, which we fix at 1. Our negative control is just water or buffer, and we have no reason to believe that the maximum tissue response when ligand concentration is infinitely small is any different from the buffer. Thus, our domain expertise tells us to put a very narrow prior on this parameter:\n\\[top \\sim {\\sf Normal}(1, 0.01)\\]\nThe \\(bottom\\) parameter should, on average, be equal to our positive control, which we fix at 0. Our positive control is an extreme concentration of the ligand to be sure that it elicits the minimum tissue response. We have no reason to believe that the minimum tissue response when ligand concentration is infinitely large is any different from the extreme concentration. Thus, our domain expertise tells us to put a very narrow prior on this parameter too:\n\\[bottom \\sim {\\sf Normal}(0, 0.01)\\]\nWe do not know much about the Hill coefficient, \\(n_H\\), as we have limited experience with the underlying kinetics. We do, however, know that the Hill coefficient should not be less than 0. While \\(n_H\\) may be more or less than 1, we also know that it is very unlikely that it is orders of magnitude smaller or larger. We can place a wide log-normal prior on this parameter to keep it positive and we can choose distribution parameters such that there is equal probability above and below 1:\n\\[n_H \\sim {\\sf LogNormal}(0, 1)\\]\nWe also do not know much about \\(\\log_{10}(IC_{50})\\), but we consider -9 and -3 fairly extreme values, so we can just use a wide normal prior that keeps the parameter mostly in that range:\n\\[\\log_{10}(IC_{50}) \\sim {\\sf Normal}(-6, 1.5)\\]\nFinally, we should consider how noisy our observations might be. We have little experience with this assay, so we expect a lot of noise. Let’s say that we expect the assay response to be within 20% above or below the tissue response, in most cases. This roughly translates to an expectation of \\(\\sigma = 0.1\\). We also know that \\(\\sigma \u0026gt; 0\\), so we can use an exponential prior with an expectation of 0.1, i.e. a rate of 10:\n\\[\\sigma \\sim {\\sf Exp}(10)\\]\n Prior predictive check in Tidyverse With the model specified, my hands are itching to start fitting. That would be a poor idea, though. Before fitting, we should verify that the model as a whole conforms to our domain knowledge. Even though we have chosen what we think are reasonable priors, it it difficult to get an intuition about how all those priors interact. However, since the model is probabilistic and generative, we can sample predictions from it without fitting anything first. If the distribution of those prior predictions agree with our expectations, then we are good to go.\nFor a simple model like this, it is fairly easy to perform such a prior predictive check with Tidyverse and basic R functionality. First we sample parameters from the prior distributions, then we calculate the deterministic variables, and finally draw out the curves.\nn_samples \u0026lt;- 50 # A function to easily sample prior parameters study_1_priors \u0026lt;- function(n) { tibble::tibble( top = rnorm(n, 1, 0.01), bottom = rnorm(n, 0, 0.01), nH = rlnorm(n, 0, 1), log_IC50 = rnorm(n, -6, 1.5), sigma = rexp(n, 10) ) } # Draw each corresponding assay response study_1_prior_pred_samples \u0026lt;- study_1_priors(n_samples) %\u0026gt;% dplyr::filter(top \u0026gt; bottom) %\u0026gt;% # This is very unlikely to happen though dplyr::mutate( tissue_response = purrr::pmap( list(top, bottom, nH, log_IC50, sigma), ~ geom_function( fun = assay_response, args = list( top = ..1, bottom = ..2, nH = ..3, log_IC50 = ..4, sigma = ..5 ), colour = colour$blue_dark, alpha = 0.5 ) ) ) p \u0026lt;- ggplot() + xlim(-9, -3) + theme_minimal() + labs(x = \u0026quot;Ligand concentration [M]\u0026quot; , y = \u0026quot;Prior assay response\u0026quot;) Reduce(`+`, study_1_prior_pred_samples$tissue_response, init = p) This looks much like the curves we would expect from a real assay. Extreme concentrations have extreme responses and the s-shaped part of the curve is somewhere in between. In some cases, the noise is extreme but that is probably to be expected from an assay where we have little or no experience.\nI initially set the prior for \\(n_H\\) way too wide, resulting in many extreme responses. That does not comply with domain knowledge, so I shrunk the prior.\n Building a Stan model for study 1 Now we are almost ready to fit the model. To do so, I have implemented it in Stan. There are other excellent introductions to Stan, see the Stan User Guide or some of the references below.\nHere is the Stan model that corresponds to the model described above.\nwriteLines(readLines(\u0026quot;hill_equation_study_1.stan\u0026quot;)) data { int\u0026lt;lower=0\u0026gt; N; // Number of observations vector[N] log_conc; // Tested concentration on log10 scale vector[N] y; // Normalised assay responses } parameters { real bottom; real\u0026lt;lower=bottom\u0026gt; top; real log_IC50; real\u0026lt;lower=0\u0026gt; nH; real\u0026lt;lower=0\u0026gt; sigma; } model { vector[N] mu; bottom ~ normal(0, 0.01); top ~ normal(1, 0.01); log_IC50 ~ normal(-6, 1.5); nH ~ lognormal(0, 1); sigma ~ exponential(10); for ( i in 1:N) { mu[i] = top + (bottom - top)/(1 + 10^((log_IC50 - log_conc[i])*nH)); } y ~ normal(mu, sigma); }  Fitting study 1 Now we can simulate some observations and fit the model. To make the simulation realistic, we generate observations in a wide space of ligand concentration, from \\(\\log_{10}([A_i]) = -9\\) to \\(\\log_{10}([A_i]) = -3\\). To make it a challenge, we will generate just 6 observations.\nFitting our bespoke Bayesian model amounts to sampling from the posterior distribution. Here I am drawing 1000 samples per chain from the posterior. This is not a large model, so we could easily sample a lot more if we wanted.\nn_observations \u0026lt;- 6 n_posterior_samples \u0026lt;- 1e3 # Determine the log concentrations at which to simulate study_1_concentrations \u0026lt;- seq(-9, -3, length.out = n_observations) # Simulate observations using our \u0026#39;secret\u0026#39; parameters study_1_observations \u0026lt;- rlang::exec( assay_response, study_1_concentrations, !!!study_1_params ) # Everything the model needs to know study_1_data_list \u0026lt;- list( N = n_observations, log_conc = study_1_concentrations, y = study_1_observations ) # This compiles the model and samples from the posterior study_1_post \u0026lt;- rstan::stan( \u0026quot;hill_equation_study_1.stan\u0026quot;, data = study_1_data_list, chains = 4, iter = n_posterior_samples * 2, warmup = n_posterior_samples, seed = 4444 ) Now we have samples from the posterior distribution. Let’s put them to work!\nRecall that the underlying research question was the kinetics of the tissue response. So more than the actual tissue response, we are interested in the posterior marginal distributions for the Hill coefficient, \\(n_H\\), and the potency, \\(\\log_{10}(IC_{50})\\). We can extract samples for the marginal distribution of each of our model parameters.\n# Extract samples from the posterior distribution posterior_samples \u0026lt;- rstan::extract(study_1_post) %\u0026gt;% tibble::as_tibble() %\u0026gt;% dplyr::select(bottom, top, log_IC50, nH, sigma) # True parameters of the simulation. parameter_tibble \u0026lt;- study_1_params %\u0026gt;% tibble::as_tibble() %\u0026gt;% tidyr::pivot_longer( dplyr::everything(), names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;truth\u0026quot; ) # Plot each of the marginal distributions, comparing prior, posterior, and true # simulation parameters posterior_samples %\u0026gt;% tidyr::pivot_longer( dplyr::everything(), names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;sample\u0026quot; ) %\u0026gt;% dplyr::left_join(parameter_tibble, by = \u0026quot;parameter\u0026quot;) %\u0026gt;% ggplot() + geom_histogram( data = tidyr::pivot_longer( study_1_priors(nrow(posterior_samples)), dplyr::everything(), names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;sample\u0026quot; ), mapping = aes(x = sample, fill = \u0026quot;Prior\u0026quot;), bins = 50, alpha = 0.5 ) + geom_histogram(aes(x = sample, fill = \u0026quot;Posterior\u0026quot;), bins = 50, alpha = 0.5) + geom_vline(aes(xintercept = truth, colour = \u0026quot;truth\u0026quot;), alpha = 0.5) + facet_wrap(~ parameter, scales = \u0026quot;free\u0026quot;) + theme_minimal() + scale_colour_manual(values = c(\u0026quot;truth\u0026quot; = colour$orange_light)) + scale_fill_manual(values = c( \u0026quot;Prior\u0026quot; = colour$azure, \u0026quot;Posterior\u0026quot; = colour$blue_dark )) + labs( y = \u0026quot;Posterior sample count\u0026quot;, x = \u0026quot;\u0026quot;, colour = \u0026quot;\u0026quot;, fill = \u0026quot;\u0026quot;, title = \u0026quot;Marginal Posterior and Prior Distributions\u0026quot; ) There are so many exciting things to discuss here. I have opted to plot samples from both the posterior and prior distributions, so we can appreciate how the data worked to update our prior beliefs to posterior distributions.\nThe first thing to notice is that the parameters for which we selected very narrow priors, i.e. \\(top\\) and \\(bottom\\), nothing has changed. The data is not enough to overwhelm the strong priors and the posterior is mostly informed by the prior.\nOn the other hand, the data has provided enough information to concentrate the probability density to a much narrower interval for the three remaining parameters. The posterior median for \\(\\log_{10}(IC_{50})\\) is very close to the truth. \\(nH\\) is a bit more uncertain, but most of the probability is concentrated well above one, which correctly suggests cooperatively binding ligands.\npost_summaries \u0026lt;- rstan::summary( study_1_post, pars = c(\u0026quot;bottom\u0026quot;, \u0026quot;top\u0026quot;, \u0026quot;log_IC50\u0026quot;, \u0026quot;nH\u0026quot;, \u0026quot;sigma\u0026quot;), probs = c(0.055, 0.5, 0.945) )$summary tibble::as_tibble(post_summaries) %\u0026gt;% dplyr::select(c(\u0026quot;5.5%\u0026quot;, \u0026quot;50%\u0026quot;, \u0026quot;94.5%\u0026quot;)) %\u0026gt;% dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %\u0026gt;% knitr::kable()   parameter 5.5% 50% 94.5%    bottom -0.0170975 -0.0010557 0.0144481  top 0.9861742 1.0016366 1.0170142  log_IC50 -5.7516723 -5.5360470 -5.4050335  nH 0.9012444 1.6121050 4.1663929  sigma 0.0434627 0.0712316 0.1351734    At this point, we can draw a conclusion for our experiment: Given our model assumptions, data strongly suggests cooperatively binding kinetics with a 89% compatibility interval for \\(\\log_{10}(IC_{50})\\) at about \\([-5.75, -5.41]\\).\nTo improve the result, we could run another experiment using this much narrower range for \\(\\log_{10}(IC_{50})\\) as a prior and for determining ligand concentrations to test, as that interval is likely to contain the s-shaped part of the Hill curve.\nSpeaking of the Hill curve, let’s see what our posterior predictions look like for the tissue response as a function of log ligand concentration.\nstudy_1_post_pred \u0026lt;- posterior_samples %\u0026gt;% tidyr::expand_grid(log_conc = seq(-3, -9, length.out = 50)) %\u0026gt;% dplyr::mutate(tissue_response = purrr::pmap_dbl( list(log_conc, bottom, top, log_IC50, nH), hill_function )) %\u0026gt;% dplyr::group_by(log_conc) %\u0026gt;% dplyr::summarise( response_mean = mean(tissue_response), response_upper = quantile(tissue_response, probs = 0.945), response_lower = quantile(tissue_response, probs = 0.055) ) %\u0026gt;% ggplot() + geom_ribbon( aes( x = log_conc, ymin = response_lower, ymax = response_upper, fill = \u0026quot;89% interval\u0026quot; ), alpha = 0.5 ) + geom_line(aes(x = log_conc, y = response_mean, colour = \u0026quot;Posterior mean\u0026quot;)) + geom_point( data = tibble::tibble( log_conc = study_1_concentrations, observations = study_1_observations ), aes(x = log_conc, y = observations, colour = \u0026quot;Observations\u0026quot;) ) + geom_function( fun = hill_function, args = study_1_params[-5], mapping = aes(colour = \u0026quot;True tissue response\u0026quot;) ) + labs( y = \u0026quot;Tissue response\u0026quot;, x = \u0026quot;Log ligand concentration [M]\u0026quot;, colour = \u0026quot;\u0026quot;, fill = \u0026quot;\u0026quot; ) + scale_fill_manual(values = c(\u0026quot;89% interval\u0026quot; = colour$azure)) + theme_minimal() study_1_post_pred + scale_colour_manual(values = c( \u0026quot;Posterior mean\u0026quot; = colour$blue_dark, \u0026quot;Observations\u0026quot; = colour$orange_light, \u0026quot;True tissue response\u0026quot; = colour$orange_dark )) The true tissue response is all contained in the 89% interval for the posterior predicted response, despite noisy observations and despite the fact that 5 out of 6 observations lie outside the s-shaped part of the curve.\nHowever, it also seems that we got lucky and had an observation very close to the true \\(\\log_{10}(IC_{50})\\). This point quite clearly provides an anchor for the entire model. We might not always be this lucky. In that case, however, the posterior marginal distributions for the kinetic parameters would just be much more informed by the priors, in turn telling us that we should perform more experiments.\n  Example Study 2 - New Drug In this study, we imagine that we are developing a new potential drug candidate. As a part of the development process, we have produced a modified version of an endogenous ligand and we are looking to assess its potency, \\(\\log_{10}(IC_{50})\\), and efficacy, which is defined in terms of \\(bottom\\).\nWe are able to approximate the tissue response in vitro, but it involves complex biochemistry, so noisy measurements are to be expected.\nThe tissue response to the endogenous ligand is well characterised, so we know that the ligands bind independently, i.e. \\(n_H = 1\\), and we know that for the endogenous ligand \\(\\log_{10}(IC_{50}) = -7.2\\).\nLet’s set some ‘secret’ values for the system and simulate assay readings. Later, we will try to recover these values.\nstudy_2_params \u0026lt;- list( bottom = 0.2, top = 1, log_IC50 = -7.6, nH = 1, sigma = 0.1 ) A model for study 2 We are still assuming the same kinetics for the tissue response as in study 1.\n\\[y_i \\sim {\\sf Normal}(\\mu_i, \\sigma)\\]\n\\[\\mu_i = top - \\frac{bottom - top}{1 + 10^{(\\log_{10}(IC_{50}) - \\log_{10}([A_i]))^{n_H}}}\\]\nOur assumptions about the \\(top\\) parameter are the same as in study 1.\n\\[top \\sim {\\sf Normal}(1, 0.01)\\]\nIn this case, we have produced a variant of the endogenous ligand. The most likely scenario is that our modification causes the ligand to lose efficacy such that the minimum tissue response is somewhere between 0 and 1. However, there is a small chance that our superior design yields a ligand that is more efficacious than the endogenous ligand and thus has a minimum response below 0. Our prior for the \\(bottom\\) parameter should thus be concentrated between 0 and 1 but with some probability below 0. I have opted for a normal prior.\nNote that this prior puts some probability in the scenario where the \\(bottom\\) parameter is larger than the \\(top\\) parameter. This is not consistent with our domain knowledge and it is a challenge that we will handle in a moment.\n\\[bottom \\sim {\\sf Normal}(0.25, 0.25)\\]\nChanging the ligand will not change the receptor, so it is extremely unlikely that the Hill coefficient changes.\n\\[n_H \\sim {\\sf Normal}(1, 0.01)\\]\nThe modified ligand is likely to lose potency, i.e. have a higher \\(\\log_{10}(IC_{50})\\), compared to the endogenous ligand which has \\(\\log_{10}(IC_{50}) = -7.2\\), but we might get lucky and see an increase. This is not much to go on, but it should still allow us to use a narrower prior than in study 1.\n\\[\\log_{10}(IC_{50}) \\sim {\\sf Normal}(-6, 0.7)\\]\nNoise is expected to be quite severe.\n\\[\\sigma \\sim {\\sf Exp}(10)\\]\n Prior predictive check with Stan As in the previous study, we should check that the prior predictive distribution conforms to expectations as given by our domain expertise.\nThis time I have opted to utilise Stan to sample from the priors. It is a bit of extra work, but it scales well for larger and more complex models.\nOne challenge we have, is the constraint that \\(top \\ge bottom\\). A way to handle this could be to discard any samples that violates the constraint and replace them with new samples until the desired number of samples are obtained. I would like something a bit more elegant.\nIn Stan, constraints can be set on parameters and, during Monte Carlo sampling from the posterior, those constraints are enforced. However, when we want to use random number generators to sample from the prior distributions, we have to enforce it ourselves. I have implemented a small Stan program to sample from the priors in study 2:\nwriteLines(readLines(\u0026quot;hill_equation_study_2_prior.stan\u0026quot;)) functions { // A lower-bounded normal distribution random number generator real normal_lower_rng(real mu, real sigma, real lower_bound) { // Locate the lower bound real p_lower_bound = normal_cdf(lower_bound, mu, sigma); // Uniformly sample probabilities in the bounded range real u = uniform_rng(p_lower_bound, 1); // Transform back to a normal distribution real y = mu + sigma * inv_Phi(u); return y; } // An upper-bounded normal distribution random number generator real normal_upper_rng(real mu, real sigma, real upper_bound) { // Locate the upper bound real p_upper_bound = normal_cdf(upper_bound, mu, sigma); // Uniformly sample probabilities in the bounded range real u = uniform_rng(0, p_upper_bound); // Transform back to a normal distribution real y = mu + sigma * inv_Phi(u); return y; } } data { int\u0026lt;lower=0\u0026gt; N; // Number of samples vector[N] log_conc; // Tested concentration on log10 scale } generated quantities{ real\u0026lt;lower = 0\u0026gt; nH = normal_lower_rng(1, 0.01, 0); real top = normal_rng(1, 0.01); real bottom = normal_upper_rng(0.25, 0.25, top); real log_IC50 = normal_rng(-6, 0.7); real sigma = exponential_rng(10); vector[N] mu; vector[N] y; for ( i in 1:N) { mu[i] = top + (bottom - top)/(1 + 10^((log_IC50 - log_conc[i])*nH)); y[i] = normal_rng(mu[i], sigma); } } Note that there is no model block in the code. This program should not run a Monte Carlo simulation. Rather, it should just pull samples from the prior distributions. This can be accomplished with Stan’s Fixed Parameter mode.\nn_prior_samples \u0026lt;- 50 log_conc \u0026lt;- seq(-9, -3, length.out = n_prior_samples) prior \u0026lt;- rstan::stan( \u0026quot;hill_equation_study_2_prior.stan\u0026quot;, data = list(N = n_prior_samples, log_conc = log_conc), algorithm = \u0026quot;Fixed_param\u0026quot;, chains = 1, iter = 100, warmup = 0, seed = 4444 ) samples \u0026lt;- rstan::extract(prior) sample_readings \u0026lt;- lapply(1:100, function(i) { tibble::tibble( y = samples$y[i,], x = log_conc ) %\u0026gt;% geom_line(mapping = aes(x, y), colour = colour$blue_dark, alpha = 0.5) }) p \u0026lt;- ggplot() + theme_minimal() + labs(x = \u0026quot;Ligand concentration [M]\u0026quot; , y = \u0026quot;Prior assay response\u0026quot;) Reduce(`+`, sample_readings, init = p) We expect most potential curves to reach 50% of their minimum response well above -7.2, corresponding to lost potency. There is, however, still a small chance of increased potency, i.e. a value smaller than -7.2. Likewise for the minimum response, we find it most likely that a modification will cause the minimum response to be somewhere between 0 and 1, yet there is a chance that the minimum response is less than zero.\nAll in all, these seem like suitable priors, but we also note that the amount of noise could severely impact conclusions.\n Building a Stan model for study 2 Here is the Stan model that corresponds to the model described above. Note that we do not need to specify our own distribution functions to satisfy constraints. When running the simulation, Stan keeps track of constraints and makes sure that they are satisfied.\nwriteLines(readLines(\u0026quot;hill_equation_study_2_post.stan\u0026quot;)) data { int\u0026lt;lower=0\u0026gt; N; vector[N] log_conc; vector[N] y; } parameters { real bottom; real\u0026lt;lower=bottom\u0026gt; top; real log_IC50; real\u0026lt;lower=0\u0026gt; nH; real\u0026lt;lower=0\u0026gt; sigma; } model { vector[N] mu; bottom ~ normal(0.25, 0.25); top ~ normal(1, 0.01); log_IC50 ~ normal(-6, 0.7); nH ~ normal(1, 0.01); sigma ~ exponential(10); for ( i in 1:N) { mu[i] = top + (bottom - top)/(1 + 10^((log_IC50 - log_conc[i])*nH)); } y ~ normal(mu, sigma); }  Fitting study 2 Now we can simulate some observations and fit the model. As we do not expect our modified ligand to stray too far from the curve of the endogenous ligand, we generate observations in a narrow space of ligand concentration, from \\(\\log_{10}([A_i]) = -7.5\\) to \\(\\log_{10}([A_i]) = -4.5\\). To make it a challenge, we will generate just 6 observations.\nAs for study 1, I am drawing 1000 samples per chain from the posterior.\nn_observations \u0026lt;- 6 n_posterior_samples \u0026lt;- 1e3 # Determine the log concentrations at which to simulate study_2_concentrations \u0026lt;- seq(-7.5, -4.5, length.out = n_observations) # Simulate observations using our \u0026#39;secret\u0026#39; parameters study_2_observations \u0026lt;- rlang::exec( assay_response, study_2_concentrations, !!!study_2_params ) # Everything the model needs to know data_list \u0026lt;- list( N = n_observations, log_conc = study_2_concentrations, y = study_2_observations ) # This compiles the model and samples from the posterior study_2_post \u0026lt;- rstan::stan( \u0026quot;hill_equation_study_2_post.stan\u0026quot;, data = data_list, chains = 4, iter = n_posterior_samples * 2, warmup = n_posterior_samples, seed = 4444 ) The underlying research question for this study was primarily concerned with the \\(\\log_{10}(IC_{50})\\) and \\(bottom\\) parameters. So more than the actual tissue response, we are interested in the marginal posterior distributions for these two parameters. Let’s start by summarising the marginal posterior distributions.\nstudy_2_priors \u0026lt;- function(n) { tibble::tibble( top = rnorm(n, 1, 0.01), bottom = rnorm(n, 0.25, 0.25), nH = rnorm(n, 1, 0.01), log_IC50 = rnorm(n, -6, 0.7), sigma = rexp(n, 10) ) } # Extract samples from the posterior distribution posterior_samples \u0026lt;- rstan::extract(study_2_post) %\u0026gt;% tibble::as_tibble() %\u0026gt;% dplyr::select(bottom, top, log_IC50, nH, sigma) # True parameters of the simulation. parameter_tibble \u0026lt;- study_2_params %\u0026gt;% tibble::as_tibble() %\u0026gt;% tidyr::pivot_longer( dplyr::everything(), names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;truth\u0026quot; ) # Plot each of the marginal distributions, comparing prior, posterior, and true # simulation parameters posterior_samples %\u0026gt;% tidyr::pivot_longer( dplyr::everything(), names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;sample\u0026quot; ) %\u0026gt;% dplyr::left_join(parameter_tibble, by = \u0026quot;parameter\u0026quot;) %\u0026gt;% ggplot() + geom_histogram( data = tidyr::pivot_longer( study_2_priors(nrow(posterior_samples)), dplyr::everything(), names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;sample\u0026quot; ), mapping = aes(x = sample, fill = \u0026quot;Prior\u0026quot;), bins = 50, alpha = 0.5 ) + geom_histogram(aes(x = sample, fill = \u0026quot;Posterior\u0026quot;), bins = 50, alpha = 0.5) + geom_vline(aes(xintercept = truth, colour = \u0026quot;truth\u0026quot;), alpha = 0.5) + facet_wrap(~ parameter, scales = \u0026quot;free\u0026quot;) + theme_minimal() + scale_colour_manual(values = c(\u0026quot;truth\u0026quot; = colour$orange_light)) + scale_fill_manual( values = c(\u0026quot;Prior\u0026quot; = colour$azure, \u0026quot;Posterior\u0026quot; = colour$blue_dark) ) + labs( y = \u0026quot;Posterior sample count\u0026quot;, x = \u0026quot;\u0026quot;, colour = \u0026quot;\u0026quot;, fill = \u0026quot;\u0026quot;, title = \u0026quot;Marginal Posterior and Prior Distributions\u0026quot; ) The first thing to notice here is that the posterior probability mass is more concentrated than the prior. However, the marginal posterior distributions for \\(\\log_{10}(IC_{50})\\) and \\(bottom\\) are still relatively wide. Recall that a difference of one in \\(\\log_{10}(IC_{50})\\) is an order of magnitude in terms of concentration. Small changes in potency matter a lot if we have to manufacture the compound at one point. So our data did not tell us much about the precise potency and efficacy of this modified ligand.\nOn the other hand, the posterior probability mass is mostly at \\(\\log_{10}(IC_{50}) \u0026lt; -7.2\\) and \\(bottom \u0026gt; 0\\), i.e. we are quite certain that our modified ligand has higher potency than the endogenous ligand but elicits a smaller response. With well defined priors and a small amount of data, we have a perfectly good screening experiment.\nIf we were interested in gaining a better understanding of the modified ligand, we could perform more experiments and get those posterior probability masses even more concentrated. We also see that the true noise of the assay is quite high; reducing it might help to better learn the underlying tissue response.\npost_summaries \u0026lt;- rstan::summary( study_2_post, pars = c(\u0026quot;bottom\u0026quot;, \u0026quot;top\u0026quot;, \u0026quot;log_IC50\u0026quot;, \u0026quot;nH\u0026quot;, \u0026quot;sigma\u0026quot;), probs = c(0.055, 0.5, 0.945) )$summary tibble::as_tibble(post_summaries) %\u0026gt;% dplyr::select(c(\u0026quot;5.5%\u0026quot;, \u0026quot;50%\u0026quot;, \u0026quot;94.5%\u0026quot;)) %\u0026gt;% dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %\u0026gt;% knitr::kable()   parameter 5.5% 50% 94.5%    bottom 0.0848792 0.1544085 0.2183073  top 0.9831631 0.9995818 1.0156166  log_IC50 -7.7146376 -7.4971292 -7.2296555  nH 0.9842731 0.9999304 1.0161020  sigma 0.0405449 0.0680069 0.1388871    At this point, we can draw a conclusion for our experiment: Given our model assumptions, data strongly suggests that the modified ligand has higher potency than the endogenous ligand with a 89% credibility interval for \\(\\log_{10}(IC_{50})\\) at about \\([-8.08, -7.22]\\). We also conclude that the modified ligand has less efficacy than the endogenous ligand with a 89% credibility interval for \\(bottom\\) at about \\([0.12, 0.30]\\)\nBefore accepting the conclusion, it is a good idea to look at the posterior predictions and compare them to the data.\nposterior_samples %\u0026gt;% tidyr::expand_grid(log_conc = seq(-3, -9, length.out = 50)) %\u0026gt;% dplyr::mutate(tissue_response = purrr::pmap_dbl( list(log_conc, bottom, top, log_IC50, nH), hill_function )) %\u0026gt;% dplyr::group_by(log_conc) %\u0026gt;% dplyr::summarise( response_mean = mean(tissue_response), response_upper = quantile(tissue_response, probs = 0.945), response_lower = quantile(tissue_response, probs = 0.055) ) %\u0026gt;% ggplot() + geom_ribbon( aes( x = log_conc, ymin = response_lower, ymax = response_upper, fill = \u0026quot;89% interval\u0026quot; ), alpha = 0.5 ) + geom_line(aes(x = log_conc, y = response_mean, colour = \u0026quot;Posterior mean\u0026quot;)) + geom_point( data = tibble::tibble( log_conc = study_2_concentrations, observations = study_2_observations ), aes(x = log_conc, y = observations, colour = \u0026quot;Observations\u0026quot;) ) + geom_function( fun = hill_function, args = study_2_params[-5], mapping = aes(colour = \u0026quot;True tissue response\u0026quot;) ) + scale_colour_manual(values = c( \u0026quot;Posterior mean\u0026quot; = colour$blue_dark, \u0026quot;Observations\u0026quot; = colour$orange_light, \u0026quot;True tissue response\u0026quot; = colour$orange_dark )) + labs( y = \u0026quot;Tissue response\u0026quot;, x = \u0026quot;Log ligand concentration [M]\u0026quot;, colour = \u0026quot;\u0026quot;, fill = \u0026quot;\u0026quot; ) + scale_fill_manual(values = c(\u0026quot;89% interval\u0026quot; = colour$azure)) + theme_minimal() The true tissue response is all contained in the 89% interval for the posterior predicted response, despite noisy observations and despite the fact that 4 out of 6 observations lie outside the s-shaped part of the curve.\n  Assessing posterior quality During the two studies, I avoided a rather important subject, namely assessing the quality of our posterior estimate. The algorithm that explores and samples from the posterior, Hamiltonian Monte Carlo (HMC), is as much a part of the Bayesian model as priors and as such should enjoy the same deliberate consideration.\nWe have observed that the posterior predictive distribution yields reasonable predictions, which gives us a lot of confidence in the model as a whole. In these studies, we could also compare the predictions to the true underlying parameters of the simulations, so we know that the model is at least somewhat right.\nAll is not perfectly well, however. In study one, Stan complains that during the HMC run there were divergent transitions:\nrstan::check_divergences(study_1_post) 5 of 4000 iterations ended with a divergence (0.125%). Try increasing \u0026#39;adapt_delta\u0026#39; to remove the divergences. Stan is noisy and will complain when something seems wrong in the HMC sampler.\nIn this case, it is divergent transitions which usually happens when an iteration ends up in a part of parameter space where the probabilities have large gradients.\nIncreasing adapt_delta as suggested by Stan will help avoid the divergent transitions, but why were they there in the first place? Let’s look at some diagnostic parameters for the posterior in the first study:\npost_summaries \u0026lt;- rstan::summary( study_1_post, pars = c(\u0026quot;bottom\u0026quot;, \u0026quot;top\u0026quot;, \u0026quot;log_IC50\u0026quot;, \u0026quot;nH\u0026quot;, \u0026quot;sigma\u0026quot;), probs = c(0.055, 0.5, 0.945) )$summary tibble::as_tibble(post_summaries) %\u0026gt;% dplyr::select(c(\u0026quot;n_eff\u0026quot;, \u0026quot;Rhat\u0026quot;)) %\u0026gt;% dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %\u0026gt;% knitr::kable()   parameter n_eff Rhat    bottom 1610.7382 1.002482  top 3738.8936 1.000015  log_IC50 1401.6208 1.002600  nH 523.3805 1.012667  sigma 1414.4814 1.000310    n_eff is an estimate of the number of independent samples from the posterior. Rhat is a measure of convergence. Values \\(\\hat{R} \u0026gt; 1.01\\) indicate that convergence has not entirely been reached.\nAccording to the diagnostics, the marginal posterior for \\(n_H\\) has been challenging to estimate. This is not altogether surprising, considering that we only have one good point on the s-shaped part of the curve. There are many combinations of \\(\\log_{10}(IC_{50})\\) and \\(n_H\\) that would pass though the point equally well and some of them have extreme probability gradients.\nSo why does increasing adapt_delta work? Intuitively, it causes Stan to pick a smaller step size for the HMC sampler. This reduces the chance that the sample ends up in a far off part of parameter space where gradients are extreme. The trade-off is that the posterior might be less efficiently sampled, so for larger models, one might have to do more samples to fully explore the posterior.\nLet’s try running study one with an increased adapt_delta.\nstudy_1_post_improved \u0026lt;- rstan::stan( \u0026quot;hill_equation_study_1.stan\u0026quot;, data = study_1_data_list, chains = 4, iter = n_posterior_samples * 2, warmup = n_posterior_samples, seed = 4444, control = list(adapt_delta = 0.95) ) That should improve the situation.\nrstan::check_divergences(study_1_post_improved) 0 of 4000 iterations ended with a divergence. Indeed it did!. Let’s also have a look at the diagnostics.\npost_summaries \u0026lt;- rstan::summary( study_1_post_improved, pars = c(\u0026quot;bottom\u0026quot;, \u0026quot;top\u0026quot;, \u0026quot;log_IC50\u0026quot;, \u0026quot;nH\u0026quot;, \u0026quot;sigma\u0026quot;), probs = c(0.055, 0.5, 0.945) )$summary tibble::as_tibble(post_summaries) %\u0026gt;% dplyr::select(c(\u0026quot;n_eff\u0026quot;, \u0026quot;Rhat\u0026quot;)) %\u0026gt;% dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %\u0026gt;% knitr::kable()   parameter n_eff Rhat    bottom 2103.743 0.9995628  top 3942.552 1.0001219  log_IC50 1152.528 1.0010730  nH 1380.143 1.0016422  sigma 1375.529 1.0041702    The numbers have improved and we have more faith in the posterior samples. Remember though that having good diagnostics alone does not imply a good model. The diagnostic check should be combined with prior and posterior predictive checks to ensure that the model is reasonable.\nThere is so much more to discuss about diagnosing HMC - we have barely scratched the surface here. ?rstan::check_hmc_diagnostics is a great place to start, if you want to learn more.\n Comparing to another fitting method Before wrapping up, I’d like to return to my initial goal, which was to squeeze more information out of the data I get from biochemical assays.\nAt this point, all we have done is fit a model to two experiments of six data points each and, despite the assistance from Stan, it has taken more code and more computation than a ‘classic’ fit would have. So was it worth it? Let’s compare.\nHere I am fitting the data from study one using non-linear least squares. To make it fair, I have put in as much information as the optimisation algorithm allows: the initial guess is at the median of the priors we set for study one and the parameters are roughly constrained to the 95% prior interval.\nmod \u0026lt;- nls( y ~ top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH)), data = study_1_data_list, algorithm = \u0026quot;port\u0026quot;, start = list(bottom = 0, top = 1, log_IC50 = -6, nH = 1), lower = list(bottom = -0.02, top = 0.98, log_IC50 = -9, nH = 0), upper = list(bottom = 0.02, top = 1.02, log_IC50 = -3, nH = 100) ) study_1_post_pred + geom_function( fun = hill_function, args = mod$m$getPars(), mapping = aes(colour = \u0026quot;NLS fit\u0026quot;) ) + scale_colour_manual(values = c( \u0026quot;Posterior mean\u0026quot; = colour$blue_dark, \u0026quot;Observations\u0026quot; = colour$orange_light, \u0026quot;True tissue response\u0026quot; = colour$orange_dark, \u0026quot;NLS fit\u0026quot; = \u0026quot;black\u0026quot; )) The NLS fit is obviously close to the true tissue response and it took much less code and time to fit. Compared to our Bayesian model, the NLS fit is not bad. In fact, it will be useful in many cases, but there are a few notable differences.\nWith the Bayesian model, we get an estimate of the amount of noise in the experiment, in addition to the parameters of the Hill equation. Such an estimate can be very useful for understanding and continuous improvement of the biochemical assays.\nWith the Bayesian model, we also get marginal posterior distributions. With a regular fit, we only get a point estimate for each parameter and any uncertainty is lost. We do not always need anything but a point estimate to answer our hypotheses, but the marginal posterior distributions can be useful in future experimental design and as priors for the next experiment.\nFinally there is an added robustness. Biological data has all sorts of weird behaviour. In a situation where the data points are all over the place, due to some unknown external factor, the resulting Bayesian model would show little or no change from the prior model, whereas the NLS model would fail altogether. So with a Bayesian model, we can rely on probabilities to tell us when an experiment is an outlier.\nAt the end of the day, the chosen method depends on the downstream application of the parameters and the hypotheses that we are trying to answer with the data. For now, I am keeping both in my toolbox, but I am seeing increased usefulness for the Bayesian approach, especially in screening experiments.\n  Next Steps In the preceding two study examples, we spent a lot of time fuzzing over just a few data points. In real applications, however, data is often more abundant and more diverse. In particular, I am thinking of screening experiments. In screening experiments, one might test a large number of potential ligands at once, meaning that there is more data but also more behaviour to be captured.\nIn my next study, I will be discussing development of a bespoke Bayesian model for high-throughput biochemical screening assays. Stay tuned!\n References [1] Neubig, R. R., Spedding, M., Kenakin, T. and Christopoulos, A. (2003). International union of pharmacology committee on receptor nomenclature and drug classification. XXXVIII. Update on terms and symbols in quantitative pharmacology. Pharmacological Reviews 55 597–606 Available at https://pharmrev.aspetjournals.org/content/55/4/597.  [2] McElreath, R. (2020). Statistical rethinking: A bayesian course with examples in r and stan. CRC Press.  [3] Betancourt, M. (2019). Probabilistic modeling and statistical inference. Available at https://github.com/betanalpha/knitr_case_studies/tree/master/modeling_and_inference.    License The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license, and the underlying code is licensed under the GNU General Public License v3.0 license.\n ","date":1637366400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639939080,"objectID":"276377dec00f42fc3d0d8bab4e1feb70","permalink":"/post/bespoke-biochem-one/","publishdate":"2021-11-20T00:00:00Z","relpermalink":"/post/bespoke-biochem-one/","section":"post","summary":"Developing a bespoke Bayesian model for fitting the Hill equation in biochemical assays","tags":["Bayesian data analysis","Bayesian statistics","R","Stan","Statistics","Modelling","Biochemistry"],"title":"Bespoke Bayesian Model for Biochemical Assays","type":"post"},{"authors":[],"categories":[],"content":"  It is the Olympics and thus the perfect time to look at some Olympic data. This set of data is part of the data provided for Tidy Tuesday 2021-07-27 and was originally scraped by GitHub user rgriff23. It is a really cool set of data and I thought it would be the perfect stage to show off how I like to use R and the Tidyverse for numeric calculations in exploratory Bayesian data analysis.\nLet’s get right into it and load in the data.\nData Preparation tt_data \u0026lt;- tidytuesdayR::tt_load(\u0026quot;2021-07-27\u0026quot;) head(tt_data$olympics) ## # A tibble: 6 × 15 ## id name sex age height weight team noc games year season city ## \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 1 A Diji… M 24 180 80 China CHN 1992 … 1992 Summer Barc… ## 2 2 A Lamu… M 23 170 60 China CHN 2012 … 2012 Summer Lond… ## 3 3 Gunnar… M 24 NA NA Denma… DEN 1920 … 1920 Summer Antw… ## 4 4 Edgar … M 34 NA NA Denma… DEN 1900 … 1900 Summer Paris ## 5 5 Christ… F 21 185 82 Nethe… NED 1988 … 1988 Winter Calg… ## 6 5 Christ… F 21 185 82 Nethe… NED 1988 … 1988 Winter Calg… ## # … with 3 more variables: sport \u0026lt;chr\u0026gt;, event \u0026lt;chr\u0026gt;, medal \u0026lt;chr\u0026gt; The data holds statistics about athletes that participated in Olympic Games, both summer and winter, from 1896 to 2016. There are so many great stories to be told with such an extensive set of data, but here I have chosen to focus on the height data, as it offers a great opportunity to do some simple exploratory Bayesian data analysis and to do so within the great structure of Tidyverse.\nIn order to have a goal to work towards, let’s decide to explore the difference in the height of athletes before and after the 1940s. I’ll clean the data a bit and split it into into those two groups.\nolympics_data \u0026lt;- tt_data$olympics %\u0026gt;% dplyr::filter(!is.na(height), !is.na(weight), season == \u0026quot;Summer\u0026quot;) %\u0026gt;% dplyr::distinct(id, .keep_all = TRUE) %\u0026gt;% dplyr::mutate( div = dplyr::case_when( year \u0026lt; 1940 ~ \u0026quot;before\u0026quot;, year \u0026gt; 1950 ~ \u0026quot;after\u0026quot;, TRUE ~ NA_character_ ) ) %\u0026gt;% dplyr::filter(!is.na(div))  Data Model and Priors I am assuming that athlete height is normally distributed with mean and standard deviation parameters that can be estimated:\n\\[h_i \\sim {\\sf Normal}(\\mu, \\sigma)\\]\nBefore looking at the data, we should determine some sensible priors. I think that the mean athlete height should be somewhere in the range of 150 to 190 cm, and I think that it is possible, but quite unlikely, to fall outside of this range. This translates to a normal prior centered at 170 cm and a 10 cm standard deviation. That way approximately 95% of the probability falls within the 150 to 190 cm range.\n\\[\\mu \\sim {\\sf Normal}(170, 10)\\]\nI expect quite a large standard deviation on athlete height. The Olympic games has sports that favour tall athletes and sports that favour short athletes. I am, however, fairly confident that the majority of heights will fall within 60 cm on either side of the mean height. I’ll go for a flat, uniform, prior. Often it makes sense to use a log-normal prior for the standard deviation but, in this case, I would like to allow less regularisation on larger standard deviations.\n\\[\\sigma \\sim {\\sf Uniform}(0, 30)\\]\nLet’s simulate some prior samples, to ensure that the priors we have chosen are realistic.\nn_prior_samples \u0026lt;- 1e5 tibble::tibble( sample_mu = rnorm(n_prior_samples, 170, 10), sample_sigma = runif(n_prior_samples, 0, 30), prior_pred = rnorm(n_prior_samples, sample_mu, sample_sigma) ) %\u0026gt;% ggplot(aes(x = prior_pred)) + geom_density(fill = \u0026quot;#219ebc\u0026quot;, alpha = 0.5, colour = FALSE) + labs(x = \u0026quot;Athlete height\u0026quot;, y = \u0026quot;Prior density\u0026quot;) Our prior belief of athlete height puts almost all probability in the range 100 to 250 cm. The priors might be a bit on the weak side, but we should have enough data that this is not too consequential.\n Bayesian Data Analysis Since we only have two parameters, we can simulate the posterior distribution using grid approximation. We will estimate the posterior at 1000 values of mu and sigma, so a total of 10e6 parameter combinations.\nI am going to sample 500 athletes from each group. The grid approximation becomes much slower with more data, but 500 examples from each group should be plenty for the question we are exploring.\nOnce the parameter grid is generated, the grid approximation proceeds in four steps that we repeat for each of our two sets of data 1. The likelihood of data given the two parameters is calculated for each point in the parameter grid 2. The prior probability of each parameter is calculated for each point in the grid 3. We find the product of likelihood and prior (the numerator of Bayes’ Theorem) 4. We estimate the posterior probabilities at every point on the grid\nSince we have quite a lot of data, the probabilities are going to be extremely small. In fact, if we try to estimate them directly, we cross the precision boundary of R and everything will just evaluate to 0. Instead we will calculate the log probabilities. This also means that probability products instead become sums.\nThis is where I find the Tidyverse tools very useful. Instead of keeping simulations in separate vectors, I can build the grid approximation directly in the data frame (tibble) and keep track of the relationship between the elements of the simulation.\nn_data \u0026lt;- 500 n_per_param \u0026lt;- 1e3 # Sample data heights_before \u0026lt;- olympics_data %\u0026gt;% dplyr::filter(div == \u0026quot;before\u0026quot;) %\u0026gt;% dplyr::slice_sample(n = n_data) %\u0026gt;% dplyr::pull(height) heights_after \u0026lt;- olympics_data %\u0026gt;% dplyr::filter(div == \u0026quot;after\u0026quot;) %\u0026gt;% dplyr::slice_sample(n = n_data) %\u0026gt;% dplyr::pull(height) # Build grid approximation grid \u0026lt;- tibble::tibble( # These are the grid, not the priors mu = seq(from = 160, to = 190, length.out = n_per_param), sigma = seq(from = 5, to = 25, length.out = n_per_param) ) %\u0026gt;% tidyr::expand(mu, sigma) %\u0026gt;% dplyr::mutate( # Log-likelihoods loglikelihood_before = purrr::map2_dbl( mu, sigma, ~ sum(dnorm(mean = .x, sd = .y, x = heights_before, log = TRUE)) ), loglikelihood_after = purrr::map2_dbl( mu, sigma, ~ sum(dnorm(mean = .x, sd = .y, x = heights_after, log = TRUE)) ), # Prior probabilities prior_p_mu = dnorm(mu, mean = 170, sd = 10, log = TRUE), prior_p_sigma = dunif(sigma, min = 0, max = 30, log = TRUE), # Numerator of Bayes\u0026#39; theorem logproduct_before = loglikelihood_before + prior_p_mu + prior_p_sigma, logproduct_after = loglikelihood_after + prior_p_mu + prior_p_sigma, # Posterior probabilities posterior_before = exp(logproduct_before - max(logproduct_before)), posterior_after = exp(logproduct_after - max(logproduct_after)) ) In the posterior calculation, I have chosen to subtract the max log-product from the log-product vector before exponentiating and thus moving from log-probabilities to probabilities. To get samples from the true posterior, we would have had to exponentiate the log-products and then divide each product by the sum of the products (the denominator of Bayes’ Theorem). The log-products are very small (large negative numbers), however, and exponentiating them would cause all of them to evaluate to zero. Instead, I opted to subtract the max log-product, which will bring the log-products much closer to zero and yield a number that can be exponentiated. This does mean that the estimated posterior is not the true posterior, but rather proportional to it. We could try to fix it, but this will work fine for what I intend to do.\nLet’s have a look at the posterior parameter distributions. Since we only have two parameters and since we have everything on a neat grid, we can use ggplot2’s geom_tile to draw a nice contour plot of the joint distribution of the parameters.\nggplot(grid, aes(x = mu, y = sigma, fill = posterior_before)) + geom_tile() + labs( x = \u0026quot;Mean athelete height, mu (cm)\u0026quot;, y = \u0026quot;Standard deviation of athlete height, sigma (cm)\u0026quot;, fill = \u0026quot;\u0026quot;, title = \u0026quot;Posterior parameter distribution for athlete heights before 1940\u0026quot; ) ggplot(grid, aes(x = mu, y = sigma, fill = posterior_after)) + geom_tile() + labs( x = \u0026quot;Mean athelete height, mu (cm)\u0026quot;, y = \u0026quot;Standard deviation of athlete height, sigma (cm)\u0026quot;, fill = \u0026quot;\u0026quot;, title = \u0026quot;Posterior parameter distribution for athlete heights after 1950\u0026quot; ) There is not much going on in these plots, but this is actually great. It means that the data has overwhelmed our relatively weak priors and produced a narrow posterior distribution.\nIt looks like there is some difference between the two distributions, but this does not necessarily translate to a difference in athlete height. For that, we need to explore the posterior predictive distributions.\nTo produce the posterior predictive distributions, we sample mus and sigmas from the grid with replacement and weighted by the posterior probabilities. Using these sampled parameters, we can simulate samples from the posterior predictive distribution using the random normal generator. We can estimate parameter differences by taking the difference between posterior predictive samples. Again, I like to keep everything aligned in a tibble.\nn_post_pred_samples \u0026lt;- 1e6 post_pred \u0026lt;- tibble::tibble( # Samples of mu post_samples_mu_before = grid %\u0026gt;% dplyr::slice_sample( n = n_post_pred_samples, weight_by = posterior_before, replace = TRUE ) %\u0026gt;% dplyr::pull(mu), post_samples_mu_after = grid %\u0026gt;% dplyr::slice_sample( n = n_post_pred_samples, weight_by = posterior_after, replace = TRUE ) %\u0026gt;% dplyr::pull(mu), # Samples of sigma post_samples_sigma_before = grid %\u0026gt;% dplyr::slice_sample( n = n_post_pred_samples, weight_by = posterior_before, replace = TRUE ) %\u0026gt;% dplyr::pull(sigma), post_samples_sigma_after = grid %\u0026gt;% dplyr::slice_sample( n = n_post_pred_samples, weight_by = posterior_after, replace = TRUE ) %\u0026gt;% dplyr::pull(sigma), # Posterior predictive samples post_pred_before = rnorm( n = n_post_pred_samples, mean = post_samples_mu_before, sd = post_samples_sigma_before ), post_pred_after = rnorm( n = n_post_pred_samples, mean = post_samples_mu_after, sd = post_samples_sigma_after ), # Posterior predictive samples for the difference post_pred_diff = post_pred_after - post_pred_before, ) Let’s go ahead and plot the distributions of mean height and the posterior predictive distribution for the difference in height.\nggplot(post_pred) + geom_density( aes(x = post_samples_mu_before, fill = \u0026quot;Before 1940\u0026quot;), alpha = 0.5, colour = FALSE ) + geom_density( aes(x = post_samples_mu_after, fill = \u0026quot;After 1950\u0026quot;), alpha = 0.5, colour = FALSE ) + scale_fill_manual( name = \u0026quot;\u0026quot;, values = c(\u0026quot;Before 1940\u0026quot; = \u0026quot;#219ebc\u0026quot;, \u0026quot;After 1950\u0026quot; = \u0026quot;#ffb703\u0026quot;) ) + labs(x = \u0026quot;Mean athlete height (cm)\u0026quot;) ggplot(post_pred, aes(x = post_pred_diff)) + geom_density(fill = \u0026quot;#023047\u0026quot;, alpha = 0.5, colour = FALSE) + labs(x = \u0026quot;Difference in athlete height before 1940 and after 1950 (cm)\u0026quot;) While it seems that there are some differences in the distribution of heights before and after the 1940s, the posterior predictive distribution for the difference in heights places the most probability in a broad interval that includes 0. So it does not seem reasonable to conclude that there is a difference. For good measure, let’s calculate the highest probability density interval that includes 89% of the probability:\ncoda::HPDinterval(coda::as.mcmc(post_pred$post_pred_diff), prob = 0.89) ## lower upper ## var1 -21.48762 21.55056 ## attr(,\u0026quot;Probability\u0026quot;) ## [1] 0.89 We did not find a difference, but we got to estimate some cool distributions. In practice, grid approximated almost never makes sense to do, but it is a really good example of how I use Tidyverse to alleviate some of the organisational headache when doing numeric calculations for Bayesian statistics and other applications.\n ","date":1627603200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631447436,"objectID":"dec578af38942a29d70930b6a1ec14a2","permalink":"/post/bayesian-olympics/","publishdate":"2021-07-30T00:00:00Z","relpermalink":"/post/bayesian-olympics/","section":"post","summary":"Exploring a dataset of Olympic athletes over time using Bayesian data analysis and the Tidyverse","tags":["Bayesian data analysis","Bayesian statistics","Tidyverse","Tidy Tuesday","Exploratory data analysis","R","Statistics"],"title":"Olympic Athletes over Time - A Tidy Bayesian Data Exploration","type":"post"},{"authors":[],"categories":null,"content":"  Ever since I realised that I could host static websites in an S3 bucket, I have wanted to build a website-based portfolio for myself.\nRecently, as I was getting back into R, I learned about the Rmarkdown as an easy way to generate html that includes math and code. Further down the rabbit hole, I came across Hugo and Hugo themes, and I figured that the time had come to finally build the site.\nIn this short post, I am outlining how I have built this site. I will not elaborate too much on how I am hosting the site, but I will put in a few pointers.\nRmarkdown While perusing the excellent R for Data Science book, I learned of Rmarkdown and knitr. Rmarkdown are essentially notebooks like Jupyter notebooks and they facilitate writing code (and not just R), math, and markdown text in one text file. knitr is an R library that knits .Rmd files into html. This means that I can write whatever I want, including stuff with math and plots, in plain text files and then generate static html at the press of a button. Ideal for building a data themed website. Yay!\nSo the most essential part of my workflow involves writing posts or projects in Rmarkdown and knitting them into html with knitr.\n Blogdown html pages alone do not create a website, and I immediately started looking for a way to turn my individual pages into a coherent site. The R package blogdown does just that or, more precisely, it is an interface to the static website generator Huge, which does just that. blogdown simply automates the process of converting Rmarkdown to markdown or html so that Hugo can pick them up and generate the site. With blogdown, I never have to leave the comfort of RStudio to build my entire website.\n Hugo and Themes Hugo is a standalone tool for generating static websites, and there there are many ways to work with it. I like working through blogdown because it gets me stated easily and I can install (and update) Hugo with a single line of R:\ninstall.packages(\u0026quot;blogdown\u0026quot;) library(blogdown) blogdown::install_hugo() Once Hugo is installed, we can get to building a site. Rather than building everything from scratch, we can take advantage of premade themes. There are lots of themes to choose from. I went with the starter-academic theme from Wowchemy because it is well-maintained, documented, and very customisable.\nblogdown::new_site(theme = \u0026quot;wowchemy/starter-academic\u0026quot;) That sets up a site that we can start adding to. For instance, I created this post like this:\nblogdown::new_post(title = \u0026quot;Create a website with Wowchemy and Hugo\u0026quot;, ext = \u0026#39;.Rmd\u0026#39;, subdir = \u0026quot;post\u0026quot;)  Wowchemy and Configuring the Site Out of the box, the theme comes with a lot of examples and superfluous elements that do not need to be on every site, so a bit of pruning and tuning is in order. With the starter-academic theme from Wowchemy most things can be managed through the config files and elements can be deleted by just removing the corresponding folder. The Wowchemy site offers great documentation, suggestions, and an overview of what can be safely deleted.\nIn addition to configuring the theme, I also added a bit of custom scss, which can be easily done by writing it into a file at /assets/scss/custom.scss. I removed the box-shadow of the navbar in the light theme and I also wanted to add both a linear gradient and a texture image to the background of my widgets - something that is not possible through the regular configs. I spent a long time configuring the site to look just like I wanted it to - and I’ll probably keep making tweaks. The best part about building the website with Hugo and Blogdown is that I do not need to rebuild the whole site just to see how a small change looks. While working on the site, I let Hugo serve the site:\nblogdown::serve_site() I like to open the site in a browser window and get a real-time view of changes to the site. ## My Workflow Viewing the site like this also works great, even if I am just writing content. If I am working in Rmarkdown and serving the site through Blogdown, then every time I save changes to to my file, Blogdown will invoke knitr to generate html (or markdown) and Hugo will pick it up and serve it.\nWhen writing content, my workflow looks like this: I open my project and add a new post or project\nlibrary(blogdown) blogdown::new_post(title = \u0026quot;New Project\u0026quot;, ext = \u0026#39;.Rmd\u0026#39;, subdir = \u0026quot;project\u0026quot;) I then let Hugo serve the site\nblogdown::serve_site() I edit my post in Rmarkdown and let Blogdown and knitr worry about converting it to html. Once I am done, I build the site\nblogdown::build_site(build_rmd = TRUE) build_rmd will re-knit Rmd files to html. The final output appears in the public/ folder, ready to deploy. I just upload the entire content to the S3 bucket where I am hosting the website. Besides AWS S3, there are other options, such as Netlify and GitHub Pages, for hosting static content. I keep the content and configurations under version control in repo on GitHub.\n ","date":1621209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621274780,"objectID":"13727834f10e9a17a41c8054d1a3d37a","permalink":"/post/create-a-website-with-wowchemy-and-hugo/","publishdate":"2021-05-17T00:00:00Z","relpermalink":"/post/create-a-website-with-wowchemy-and-hugo/","section":"post","summary":"How I built this website using R Blogdown and the Wowchemy theme for Hugo.","tags":null,"title":"Create a website with Wowchemy and Hugo","type":"post"},{"authors":["Anders E. Nielsen"],"categories":[],"content":"Bayesian Optimisation The Full Walkthrough  Libraries  SciKit GPyOpt  from sklearn.gaussian_process import GaussianProcessRegressor from sklearn.gaussian_process.kernels import Matern   $$ f\\left( x \\right) = \\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n One  **Two**  Three   A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS)\n weight: sets the order in which a fragment appears   Speaker Notes Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  hello ","date":1621123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621123200,"objectID":"014540f91356850cf9d4d4b31d266c05","permalink":"/slides/bayesian-optimisation/","publishdate":"2021-05-16T00:00:00Z","relpermalink":"/slides/bayesian-optimisation/","section":"slides","summary":"Bayesian optimisation deck.","tags":[],"title":"Bayesian Optimisation","type":"slides"},{"authors":null,"categories":[],"content":"  I am on a quest to improve the model fitting I do on biochemical assays. For some time, I have had this feeling that I should be able to extract more information from the data gathered in biochemical assays, in particular assays with a high throughput.\nIn two previous studies we built bespoke Bayesian models to fit observations from a biochemical assay with kinetics that could be represented by the Hill equation. In those studies, we fit a single curves one at a time. In this study, we extend the model to capture the additional information available when screening a large number of compounds in parallel.\nWe start by setting a seed and some nice colours for plotting.\nlibrary(ggplot2) library(magrittr) colour \u0026lt;- list( orange_dark = \u0026quot;#fb8500\u0026quot;, orange_light = \u0026quot;#ffb703\u0026quot;, blue_dark = \u0026quot;#023047\u0026quot;, azure = \u0026quot;#219ebc\u0026quot;, blue_light = \u0026quot;#8ecae6\u0026quot; ) set.seed(4444) High Troughput Biochemical Experiments With Bayesian models, we can take advantage of our domain expertise to produce clear answers to our scientific hypotheses and to quantify uncertainty in data and hypotheses. It does, however, require that we are able to represent our expertise as probabilistic models. So before we dive into the Bayesian engine, let’s discuss our biochemistry knowledge and the data we might get from a high throughput experiment.\nWe are considering compounds that are potential ligands to receptors and cause a tissue response according to the Hill equation\n\\[\\mu_{ij} = top - \\frac{bottom_j - top}{1 + 10^{(\\log_{10}(IC_{50,j}) - \\log_{10}([A_i]))^{n_H}}}\\]\nWhere \\(\\mu_{ij}\\) is the tissue response of the \\(j\\)’th compound at concentration \\([A_i]\\).\nThe equation looks slightly different from the previous studies because we now have multiple compounds in a screening study. The equation also encodes a few assumptions about such an assay. First of all, we are assuming that the tissue response in the absence of ligand, \\(top\\), is the same for all tested compounds. Similarly, we are assuming that the kinetics of the tissue response, as represented by the Hill number, \\(n_H\\), stays the same for all compounds. For the maximum tissue response, \\(bottom_j\\), and the concentration at half response, \\(\\log_{10}(IC_{50,j})\\), however, we are assuming that each compound has its own parameter.\nThese assumptions might not hold true for every experiment, but if we imagine that we are screening compounds for a good drug candidate and we are looking at the same tissue response for each of them, these assumptions should hold.\nAs in previous studies, I opt for synthetic data. This has two advantages; we are forced to consider the underlying process that generates our experiment data and, after we have applied a model, we can compare the output to our known truth. We can code the first part of the generative process with a simple function\nhill_function \u0026lt;- function(log_conc, bottom, top, log_IC50, nH) { top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH)) } Now, our observations are not perfect and will be subject to some noise. For this study, we are going to assume that all observations were made in the same batch, under the same conditions, and at the same time such that they have identically distributed noise. Specifically, we will give the observations some Gaussian noise.\nassay_response \u0026lt;- function(log_conc, bottom, top, log_IC50, nH, sigma) { noise \u0026lt;- rnorm(length(log_conc), 0, sigma) hill_function(log_conc, bottom, top, log_IC50, nH) + noise } Next we should consider what type of screening we are doing. There are a couple of different options. We could screen a lot of random compounds for activity. While this is a common scenario, it is not too interesting to model, as we expect that the vast majority of tested compounds will have no activity. In this study, as in the previous, we instead imagine the case where we produce a large number of variations on an endogenous ligand, in the hopes that we stumble upon something with more desirable properties like higher potency.\nSo we produce 100 modifications to an endogenous ligand which has known parameters \\(\\log_{10}(IC_{50}) = -7.2\\) and \\(bottom = 0\\). We expect that the modifications might cause us to lose potency, i.e. increase \\(\\log_{10}(IC_{50})\\), and efficacy, i.e. increase \\(bottom\\), most of the time. To add a little extra challenge, I am adding compounds that have extremely low \\(\\log_{10}(IC_{50})\\) corresponding to the case where our modification almost or completely removes potency.\nWith this, we have the final part of the generative model:\nn_compounds \u0026lt;- 100 true_parameters \u0026lt;- tibble::tibble( compound = seq(1, n_compounds), bottom = 1 - rlnorm(n_compounds, -0.25, 0.125), log_IC50 = rnorm(n_compounds, -5, 1.5) + rexp(n_compounds, 3), top = 1.02, nH = 0.99, sigma = 0.15 ) With the generative model in place, we can draw a few of the true curves that we will sample from and estimate in our hypothetical screening experiment.\ntrue_curves \u0026lt;- purrr::pmap( true_parameters, ~ geom_function( fun = hill_function, args = list( top = ..4, bottom = ..2, nH = ..5, log_IC50 = ..3 ), colour = colour$blue_dark, alpha = 0.5 ) ) p \u0026lt;- ggplot() + xlim(-9, -1) + theme_minimal() + labs( x = \u0026quot;Ligand concentration [M]\u0026quot;, y = \u0026quot;True tissue response\u0026quot;, title = \u0026quot;Sample True Tissue Responses\u0026quot; ) Reduce(`+`, true_curves[1:10], init = p)  Bespoke Bayesian Model Now that we understand the generative process and we have some data, we can start considering a Bayesian model. We need to specify two things; a set of relations that describe the generative process and priors for any parameters. If this seems similar to what we just did in the previous section, it is because it is. The Baysian model should reflect the process that generated the data. So let’s get started.\nLikelihood Model In our screening assay, we will consider \\(M\\) compounds \\(j = 1, ..., M\\). For each compound, we measure an assay response, \\(y_{ij}\\), for a number, \\(i = 1, ..., N\\), of ligand concentrations \\([A_{ij}]\\). We also know that the assay response averages to the tissue response, \\(\\mu_{ij}\\), but that observations are noisy:\n\\[y_{ij} \\sim {\\sf Normal}(\\mu_{ij}, \\sigma)\\]\nNote that the noise parameter, \\(\\sigma\\), is the same for all \\(M\\) compounds.\nThe tissue response is a deterministic function of four kinetic parameters, as described by the Hill equation:\n\\[\\mu_{ij} = top - \\frac{bottom_j - top}{1 + 10^{(\\log_{10}(IC_{50,j}) - \\log_{10}([A_{ij}]))^{n_H}}}\\]\n Priors For the minimum response parameter, \\(top\\), we will specify a narrow prior, as we have no indication that it should be anything other than 1.\n\\[top \\sim {\\sf Normal}(1, 0.01)\\]\nIn a real scenario the Hill number, \\(n_H\\), will probably be well know before high throughput screening experiments are done. For the purpose of demonstration, however, we will give it a relatively wide prior and hope to learn the true number from our data, in this case.\n\\[n_H \\sim {\\sf LogNormal}(0, 0.5)\\]\nFor sigma \\(\\sigma\\), we put a prior that corresponds to a mean standard deviation that is 10% of the assay window. We also want very high noise to be very unlikely.\n\\[\\sigma \\sim {\\sf Exp}(10)\\]\nWe now have multiple \\(bottom_i\\) parameters to consider.\nWe know that the most likely scenario is where our modification causes the ligand to lose efficacy yielding a minimum tissue response somewhere between 0 and 1. However, there is a small chance that our superior design yields a ligand that is more efficacious than the endogenous ligand and thus has a minimum response below 0. Our prior for the \\(bottom\\) parameter should thus be concentrated between 0 and 1 but with some probability below 0. Let’s try a normal prior.\nThe question that remains is whether this argument is true for all \\(bottom_i\\). We are going to assume that it is and use the same prior for all \\(bottom_i\\).\n\\[bottom_i \\sim {\\sf Normal}(0.25, 0.25)\\]\nThe modified ligand is likely to lose potency, i.e. have a higher \\(\\log_{10}(IC_{50,i})\\), compared to the endogenous ligand which has \\(\\log_{10}(IC_{50,i}) = -7.2\\), but we might get lucky and see an increase. This is not much to go on, but it should still allow us to use a somewhat narrow prior. Again, we will use the same prior for all \\(\\log_{10}(IC_{50,i})\\).\nWe added a bit of an extra challenge, allowing for some compounds to have very high \\(\\log_{10}(IC_{50,i})\\). For now, we are going to pretend that we do not have that knowledge and see what this prior will do for us. In a real world scenario, we never know the true distributions. The best priors arise by applying our scientific experience and logic.\n\\[\\log_{10}(IC_{50}) \\sim {\\sf Normal}(-6, 1.5)\\]\n  Prior Predictive Simulation With the model and priors in place, we should control the sensibility of them with a prior predictive check. So let’s imagine that we perform the screening experiment, sampling the underlying parameters from our prior distributions, and have a look at the hypothetical observations that would arise.\nLet’s go ahead and define a function for sampling our priors and simulating a screening experiment.\nprior_parameters \u0026lt;- function(n_compounds = NULL, bottom_mean = NULL, bottom_sd = NULL, top_mean = NULL, top_sd = NULL, log_IC50_mean = NULL, log_IC50_sd = NULL, nH_meanlog = NULL, nH_sdlog = NULL, sigma_rate = NULL) { tibble::tibble( compound = seq(1, n_compounds), bottom = rnorm(n_compounds, bottom_mean, bottom_sd), log_IC50 = rnorm(n_compounds, log_IC50_mean, log_IC50_sd), top = rnorm(1, top_mean, top_sd), nH = rlnorm(1, nH_meanlog, nH_sdlog), sigma = rexp(1, sigma_rate) ) } screening_experiment \u0026lt;- function(parameters, log_conc) { parameters %\u0026gt;% tidyr::expand_grid(log_conc = log_conc) %\u0026gt;% dplyr::mutate( response = assay_response(log_conc, bottom, top, log_IC50, nH, sigma) ) } Now we can do our prior predictive check by performing a hypothetical experiment with our priors\npriors \u0026lt;- list( bottom_mean \u0026lt;- 0.25, bottom_sd \u0026lt;- 0.25, top_mean \u0026lt;- 1, top_sd \u0026lt;- 0.01, log_IC50_mean \u0026lt;- -6, log_IC50_sd \u0026lt;- 1.5, nH_meanlog \u0026lt;- 0, nH_sdlog \u0026lt;- 0.5, sigma_rate \u0026lt;- 10 ) replicate( 10, rlang::exec( prior_parameters, n_compounds = 5, !!!priors ), simplify = FALSE ) %\u0026gt;% dplyr::bind_rows(.id = \u0026quot;rep\u0026quot;) %\u0026gt;% dplyr::mutate(rep = paste0(rep, \u0026quot;-\u0026quot;, compound)) %\u0026gt;% screening_experiment(log_conc = seq(-10, -2, length.out = 100)) %\u0026gt;% ggplot(aes(x = log_conc, y = response, group = rep)) + geom_line(colour = colour$blue_dark, alpha = 0.5) + theme_minimal() + labs( x = \u0026quot;log ligand concentration\u0026quot;, y = \u0026quot;response\u0026quot;, title = \u0026quot;Prior Samples\u0026quot; ) Our prior understanding of the data generating process predicts a diverse set of curves. One of the things that often surprises me is the large number of seeming outliers, even with conservative estimates for noise. Given variance and enough samples, we are bound to see some weird behaviour.\nI think that these hypothetical samples seem like a fair representation of the samples I expect to get from the assay. If for some reason we thought that the hypothetical samples looked too extreme or did not represent the full range of possible observations, we would have to go back and adjust our priors.\n Bayesian Model Now it is time for the fun part. First we implement the complete Bayesian model, consisting of our observational model and prior distributions, in Stan.\nThe trick here is to define an index variable that keeps track of parameters for individual curves.\nwriteLines(readLines(\u0026quot;hill_equation_screening.stan\u0026quot;)) data { int\u0026lt;lower=0\u0026gt; N; int\u0026lt;lower=0\u0026gt; M; int\u0026lt;lower=0\u0026gt; curve_ind[N]; vector[N] log_conc; vector[N] y; } parameters { real top; vector\u0026lt;upper=top\u0026gt;[M] bottom; vector[M] log_IC50; real\u0026lt;lower=0\u0026gt; nH; real\u0026lt;lower=0\u0026gt; sigma; } model { vector[N] mu; bottom ~ normal(0.25, 0.25); top ~ normal(1, 0.01); log_IC50 ~ normal(-6, 1.5); nH ~ normal(1, 0.01); sigma ~ exponential(10); for ( i in 1:N ) { mu[i] = top + (bottom[curve_ind[i]] - top) / (1 + 10^((log_IC50[curve_ind[i]] - log_conc[i])*nH)); } y ~ normal(mu, sigma); } generated quantities { vector[N] mu; vector[N] y_sampled; for ( i in 1:N ) { mu[i] = top + (bottom[curve_ind[i]] - top) / (1 + 10^((log_IC50[curve_ind[i]] - log_conc[i])*nH)); y_sampled[i] = normal_rng(mu[i], sigma); } } Conditioning Next we need some data to condition our model on. So we perform a simulated screening experiment using our true parameters. Recall that we have 100 compounds. In the screening experiment we will sample the tissue response for each compound at 6 different concentrations.\nassay_window \u0026lt;- seq(-8, -2, length.out = 6) observations \u0026lt;- screening_experiment( parameters = true_parameters, log_conc = assay_window ) data \u0026lt;- list( N = nrow(observations), M = max(observations$compound), curve_ind = observations$compound, log_conc = observations$log_conc, y = observations$response ) post \u0026lt;- rstan::stan_model(\u0026quot;hill_equation_screening.stan\u0026quot;) %\u0026gt;% rstan::sampling( data = data, chains = 4, cores = 4, seed = 4444 ) # Extract samples from the posterior distribution posterior_samples \u0026lt;- rstan::extract(post) %\u0026gt;% tibble::as_tibble()   Examining the Posterior Before applying the model, we should do some quality assurance. Since we have simulated data, we can of course compare the posterior distributions to our known truth, and we will definitely do that, in a moment. In real problems, however, the truth is not known and we have to rely on other approaches.\nHere I have three approaches that rely only on the model and the data. None of the approaches will tell us whether the model is a good one, but they will often indicate any problems.\nQuality of the Monte Carlo Simulation The first thing we can do is do a quality check of the Monte Carlo sampling. Stan usually complains when something seems wrong, but we can also check some specific diagnostics.\nI often get divergent transitions when I build multilevel models and they are a signal that there are areas of the model space that are difficult to traverse. Often they can be fixed by increasing the adapt_delta parameter like we did in a previous study. When that does not work, it is a sign that maybe the model needs to be re-parametrised. For our model in this study, we should not have that problem, though.\nrstan::check_divergences(post) 0 of 4000 iterations ended with a divergence. When Stan complains about maximum tree depth it is because the Monte Carlo sampler was unable to fully explore some parts of the model space. It is really only an efficiency metric, but a common piece of advise when experiencing tree depth warnings is to use narrower priors. I also often find that I see this warning when I have forgotten to put an explicit prior on a parameter. In this case, we have put a lot of thought into our priors and they should be good.\nrstan::check_treedepth(post) 0 of 4000 iterations saturated the maximum tree depth of 10.  Convergence We should also check check whether each of our parameters have properly converged. Stan provides two metrics for us to review. \\(\\hat{R}\\) is a measure of convergence and when \\(\\hat{R} \u0026gt; 1.01\\) it is an indication that the posterior samples aren’t quite representative of the true posterior distribution.\n\\(n\\_eff\\) is an estimate of the number of true samples our chains represent. If the number of effective samples is low compared to the number of samples we chose to take after warm up, it indicates that it was difficult for the Monte Carlo sampler to figure out that parameter in the grand scheme of things. Sometimes it helps to increase adapt_delta and do more warm-up samples, but I find that it is also often indicative of data that is very incompatible with the model and its priors. In this study, we ran four chains with 1000 samples after warm-up, so we would like to see at least several hundred effective samples.\nLet’s just have a look at the parameters that proved to be most difficult.\npost_summaries \u0026lt;- rstan::summary( post, pars = c(\u0026quot;bottom\u0026quot;, \u0026quot;log_IC50\u0026quot;), probs = NULL )$summary tibble::as_tibble(post_summaries) %\u0026gt;% dplyr::select(-c(mean, se_mean, sd)) %\u0026gt;% dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %\u0026gt;% dplyr::mutate(dplyr::across(-parameter, round, digits = 3)) %\u0026gt;% dplyr::arrange(desc(Rhat)) %\u0026gt;% dplyr::slice_head(n = 10) %\u0026gt;% knitr::kable()   parameter n_eff Rhat    log_IC50[83] 1177.101 1.003  bottom[2] 4258.387 1.002  log_IC50[2] 4483.525 1.002  log_IC50[37] 1349.972 1.002  log_IC50[71] 2269.627 1.002  bottom[26] 3953.336 1.001  bottom[32] 6086.841 1.001  bottom[37] 1252.062 1.001  bottom[44] 4487.325 1.001  bottom[71] 4270.506 1.001    It looks like our parameters have converged nicely.\nNote that some parameters have \\(n\\_eff\\) that are quite a bit below the 4000 samples after warm-up. This is not necessarily a cause for concern, but in case it is very low and we want to use the distribution for predictive purposes, it might be a good idea to increase the number of samples after warm-up a bit.\n Data Replication Check A great sanity check for a model is whether it is able to replicate the data. Our model is fully generative, meaning we can generate hypothetical samples. For a good model, when we generate a number of samples corresponding to the number of data points, the qualitative properties those samples should be similar to those of the original data. Parameters like mean and variance will be very similar, as those are basically the parameters we conditioned on the data, but more qualitative aspects like minimum data point, maximum, or general shape are not a given.\nIn the Stan script, I included some generated quantities that are essentially sample observations, so we can compare. We will skip comparing maximum and minimum and just compare the overall shape.\nggplot() + geom_histogram( data = observations, mapping = aes(x = response, y = ..density.., fill = \u0026quot;Observed responses\u0026quot;), bins = 30, alpha = 0.5 ) + geom_histogram( data = tibble::tibble(y_sampled = as.vector(posterior_samples$y_sampled)), mapping = aes(x = y_sampled, y = ..density.., fill = \u0026quot;Posterior samples\u0026quot;), bins = 300, alpha = 0.5 ) + theme_minimal() + scale_fill_manual(values = list( \u0026quot;Observed responses\u0026quot; = colour$azure, \u0026quot;Posterior samples\u0026quot; = colour$blue_dark )) + labs( fill = \u0026quot;\u0026quot;, y = \u0026quot;Density\u0026quot;, x = \u0026quot;Response\u0026quot;, title = \u0026quot;Shape Check\u0026quot; ) It really looks like out model replicates the data quite nicely. Usually the concerns are whether the tails match; if the data has minimum points that are outside what the model yields or if the samples span a much wider range than the data, it might be cause to rethink the model.\n  Results Our model and the posterior samples seem to be of decent quality, so let’s put them to use.\nPosterior Marginal Distributions So our model has 203 parameters, 2 for each of the 100 compounds and 3 parameters that are shared between all of them. Let’s see what we have learned about the three shared parameters.\n# True parameters of the simulation. truth \u0026lt;- true_parameters %\u0026gt;% dplyr::slice_head(n = 1) %\u0026gt;% tidyr::pivot_longer( dplyr::everything(), names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;truth\u0026quot; ) # A number of draws from our priors to match the number of draws we have from # the posterior prior_samples \u0026lt;- replicate( nrow(posterior_samples), rlang::exec( prior_parameters, n_compounds = 1, !!!priors ), simplify = FALSE ) %\u0026gt;% dplyr::bind_rows() %\u0026gt;% dplyr::select(top, nH, sigma) %\u0026gt;% tidyr::pivot_longer( dplyr::everything(), names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;sample\u0026quot; ) # Plot each of the marginal distributions, comparing prior, posterior, and true # simulation parameters posterior_samples %\u0026gt;% dplyr::select(top, nH, sigma) %\u0026gt;% tidyr::pivot_longer( dplyr::everything(), names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;sample\u0026quot; ) %\u0026gt;% dplyr::left_join(truth, by = \u0026quot;parameter\u0026quot;) %\u0026gt;% ggplot() + geom_histogram( data = prior_samples, mapping = aes(x = sample, fill = \u0026quot;Prior\u0026quot;), bins = 50, alpha = 0.5 ) + geom_histogram(aes(x = sample, fill = \u0026quot;Posterior\u0026quot;), bins = 50, alpha = 0.5) + geom_vline(aes(xintercept = truth, colour = \u0026quot;truth\u0026quot;), alpha = 0.5) + facet_wrap(~ parameter, scales = \u0026quot;free\u0026quot;) + theme_minimal() + scale_colour_manual(values = c(\u0026quot;truth\u0026quot; = colour$orange_light)) + scale_fill_manual(values = c( \u0026quot;Prior\u0026quot; = colour$azure, \u0026quot;Posterior\u0026quot; = colour$blue_dark )) + labs( y = \u0026quot;Posterior sample count\u0026quot;, x = \u0026quot;\u0026quot;, colour = \u0026quot;\u0026quot;, fill = \u0026quot;\u0026quot;, title = \u0026quot;Marginal Posterior and Prior Distributions\u0026quot; ) And some summary statistics\npost_summaries \u0026lt;- rstan::summary( post, pars = c(\u0026quot;top\u0026quot;, \u0026quot;nH\u0026quot;, \u0026quot;sigma\u0026quot;), probs = c(0.055, 0.5, 0.945) )$summary tibble::as_tibble(post_summaries) %\u0026gt;% dplyr::select(-c(mean, se_mean, sd)) %\u0026gt;% dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %\u0026gt;% dplyr::mutate(dplyr::across(-parameter, round, digits = 2)) %\u0026gt;% knitr::kable()   parameter 5.5% 50% 94.5% n_eff Rhat    top 1.02 1.03 1.04 4667.23 1  nH 0.99 1.00 1.02 9232.87 1  sigma 0.15 0.15 0.16 2994.32 1    When we fitted the curve for each individual compound, we ended up with posteriors that were very similar to our priors, indicating that the data was insufficient to provide additional information. In this case, however, we share information about the curve shape, sample noise, and the minimum response among all compounds. The pooling of all that information causes us to get very exact estimates for the curve shape and the sample noise. The estimates are even essentially equal to the truth. For the minimum response, our prior is still very informative compared to the data, so the posterior distribution has barely changed.\nThese results are quite profound. Even with a relatively wide prior on \\(n_H\\), corresponding to little knowledge about the kinetics of the response, we were able to estimate those exact kinetics, despite the data being intended for a different purpose. In real problems, we would often be much more sure about that parameter. Similarly, we have a very exact estimate of the experiment noise. If we regularly run such screening experiments this would be a great metric to track over time.\nWe cannot look at parameters and curves for each of the compounds, so lets just pick a couple, including one that is difficult to fit. As with the shared parameters, we compare the posterior samples to the prior distribution and our known truth.\nexample_compounds \u0026lt;- c(1:5, 93) # True parameters of the simulation. truth \u0026lt;- true_parameters %\u0026gt;% dplyr::filter(compound %in% example_compounds) %\u0026gt;% tidyr::pivot_longer( -compound, names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;truth\u0026quot; ) # A number of draws from our priors to match the number of draws we have from # the posterior prior_samples \u0026lt;- replicate( nrow(posterior_samples), rlang::exec( prior_parameters, n_compounds = 1, !!!priors ), simplify = FALSE ) %\u0026gt;% dplyr::bind_rows() %\u0026gt;% dplyr::select(bottom, log_IC50) %\u0026gt;% tidyr::pivot_longer( dplyr::everything(), names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;sample\u0026quot; ) %\u0026gt;% tidyr::expand_grid(compound = example_compounds) # Plot each of the marginal distributions, comparing prior, posterior, and true # simulation parameters lapply(example_compounds, function(i) { tibble::tibble( bottom = posterior_samples$bottom[,i], log_IC50 = posterior_samples$log_IC50[,i], compound = i ) }) %\u0026gt;% dplyr::bind_rows() %\u0026gt;% tidyr::pivot_longer( -compound, names_to = \u0026quot;parameter\u0026quot;, values_to = \u0026quot;sample\u0026quot; ) %\u0026gt;% dplyr::left_join(truth, by = c(\u0026quot;parameter\u0026quot;, \u0026quot;compound\u0026quot;)) %\u0026gt;% ggplot() + geom_histogram( data = prior_samples, mapping = aes(x = sample, fill = \u0026quot;Prior\u0026quot;), bins = 50, alpha = 0.5 ) + geom_histogram(aes(x = sample, fill = \u0026quot;Posterior\u0026quot;), bins = 50, alpha = 0.5) + geom_vline(aes(xintercept = truth, colour = \u0026quot;truth\u0026quot;), alpha = 0.5) + facet_grid(rows = vars(compound), cols = vars(parameter), scales = \u0026quot;free\u0026quot;) + theme_minimal() + theme(strip.text.y = element_text(angle = 0)) + scale_colour_manual(values = c(\u0026quot;truth\u0026quot; = colour$orange_light)) + scale_fill_manual(values = c( \u0026quot;Prior\u0026quot; = colour$azure, \u0026quot;Posterior\u0026quot; = colour$blue_dark )) + labs( y = \u0026quot;Posterior sample count\u0026quot;, x = \u0026quot;\u0026quot;, colour = \u0026quot;\u0026quot;, fill = \u0026quot;\u0026quot;, title = \u0026quot;Marginal Posterior and Prior Distributions\u0026quot; ) And some summary statistics\npost_summaries \u0026lt;- rstan::summary( post, pars = c(\u0026quot;bottom\u0026quot;, \u0026quot;log_IC50\u0026quot;), probs = c(0.055, 0.5, 0.945) )$summary tibble::as_tibble(post_summaries) %\u0026gt;% dplyr::select(-c(mean, se_mean, sd)) %\u0026gt;% dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %\u0026gt;% dplyr::mutate(dplyr::across(-parameter, signif, digits = 4)) %\u0026gt;% dplyr::filter(stringr::str_detect( parameter, paste0(\u0026quot;(\\\\[\u0026quot;, example_compounds, \u0026quot;\\\\])\u0026quot;, collapse = \u0026quot;|\u0026quot;) )) %\u0026gt;% knitr::kable()   parameter 5.5% 50% 94.5% n_eff Rhat    bottom[1] -0.26640 0.02345 0.2899 6103.0 1.0000  bottom[2] -0.05292 0.30550 0.5976 4258.0 1.0020  bottom[3] 0.25210 0.42120 0.5831 5681.0 0.9995  bottom[4] 0.04298 0.18550 0.3221 6510.0 0.9996  bottom[5] -0.14800 0.07444 0.2785 5360.0 1.0000  bottom[93] 0.01054 0.22520 0.4813 1621.0 0.9996  log_IC50[1] -3.38700 -2.84400 -2.3980 4842.0 1.0000  log_IC50[2] -3.26300 -2.54000 -1.9200 4484.0 1.0020  log_IC50[3] -5.83300 -4.93800 -4.1330 6467.0 0.9993  log_IC50[4] -6.41500 -5.83600 -5.2860 7889.0 0.9995  log_IC50[5] -4.60200 -3.93300 -3.3400 5696.0 1.0000  log_IC50[93] -6.41600 -4.05500 -3.4590 801.6 1.0010    At first glance, these results may seem unimpressive. Even though the posterior has concentrated compared to our prior, it is still fairly wide. Even the compounds with the narrowest estimate of potency has a 89% interval for \\(\\log_{10}(IC_{50})\\) spanning more than a unit, corresponding to more than an order of magnitude difference in concentration. That is quite a bit.\nSeen from another perspective though, we only had six data points to estimate each of those two parameters. If we were extremely confident in the resulting estimates that would be very suspicious. The means of the marginal posterior distributions are close to the truth, so we have good estimates for any downstream analysis, but the relatively wide distributions are there to remind us that our estimate is uncertain.\n Posterior Predictive One way to understand how much, or how little, our model has learned from the data is to visualise the posterior predictions along with the original data. Here is a curve where things went rather well\nexample_curves \u0026lt;- tibble::tibble(curve = c(3, 93)) example_curves$post_pred \u0026lt;- purrr::map(example_curves$curve, function(i) { posterior_samples %\u0026gt;% dplyr::mutate( log_IC50 = log_IC50[, i], bottom = bottom[, i] ) %\u0026gt;% tidyr::expand_grid(log_conc = seq(-2, -9, length.out = 50)) %\u0026gt;% dplyr::mutate(tissue_response = purrr::pmap_dbl( list(log_conc, bottom, top, log_IC50, nH), hill_function )) %\u0026gt;% dplyr::group_by(log_conc) %\u0026gt;% dplyr::summarise( response_mean = mean(tissue_response), response_upper = quantile(tissue_response, probs = 0.945), response_lower = quantile(tissue_response, probs = 0.055) ) %\u0026gt;% ggplot() + geom_ribbon( aes( x = log_conc, ymin = response_lower, ymax = response_upper, fill = \u0026quot;89% interval\u0026quot; ), alpha = 0.5 ) + geom_line(aes(x = log_conc, y = response_mean, colour = \u0026quot;Posterior mean\u0026quot;)) + geom_point( data = dplyr::filter(observations, compound == i), aes(x = log_conc, y = response, colour = \u0026quot;Observations\u0026quot;) ) + geom_function( fun = hill_function, args = true_parameters[i, -c(1,6)], mapping = aes(colour = \u0026quot;True tissue response\u0026quot;) ) + labs( y = \u0026quot;Tissue response\u0026quot;, x = \u0026quot;Log ligand concentration [M]\u0026quot;, colour = \u0026quot;\u0026quot;, fill = \u0026quot;\u0026quot;, title = paste(\u0026quot;Posterior Predictive for Compound\u0026quot;, i) ) + scale_fill_manual(values = c(\u0026quot;89% interval\u0026quot; = colour$azure)) + theme_minimal() }) example_curves$post_pred_coloured \u0026lt;- purrr::map( example_curves$post_pred, function(p) { p + scale_colour_manual(values = c( \u0026quot;Posterior mean\u0026quot; = colour$blue_dark, \u0026quot;Observations\u0026quot; = colour$orange_light, \u0026quot;True tissue response\u0026quot; = colour$orange_dark )) } ) example_curves$post_pred_coloured[[1]] Our model is very open about its uncertainty. While the posterior mean is a great compromise between the data points, the model also knows that the assay is noisy, and it has used the pooled estimate of that noise across all curves to give us this nice interval for any point prediction. Not also how the model has confidently ruled out one of the points as an outlier. I think this is a lot of information gained from just a few points of data.\nNow let’s have a look at a more difficult case\nexample_curves$post_pred_coloured[[2]] This one is difficult because we did not get any good points on the curved part of the tissue response. This makes the estimate for \\(\\log_{10}(IC_{50})\\) very uncertain, resulting in the bulge in the middle. Despite all this, the 89% interval nicely contains the true tissue response.\n Model Comparison Before we wrap up, I want to highlight why I like this approach to modelling my screening assay data in this way by comparing it to a classic model fitting method.\nFor the comparison, we will use non-linear least squares to directly fit the Hill equation to the data points for a compound. We cannot put flexible priors on the parameters, but we can set constraints that limit the parameters to a range comparable to that of the priors in our Bayesian model.\nAgain let’s start by looking at the case where things go well.\nexample_curves$model_comp \u0026lt;- purrr::map2( example_curves$curve, example_curves$post_pred, function(curve, p) { mod \u0026lt;- nls( response ~ top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH)), data = dplyr::filter(observations, compound == curve), algorithm = \u0026quot;port\u0026quot;, start = list(bottom = 0.25, top = 1, log_IC50 = -6, nH = 1), lower = list(bottom = -0.3, top = 0.98, log_IC50 = -9, nH = 0), upper = list(bottom = 1.0, top = 1.02, log_IC50 = -3, nH = 2) ) p + geom_function( fun = hill_function, args = mod$m$getPars(), mapping = aes(colour = \u0026quot;NLS fit\u0026quot;) ) + scale_colour_manual(values = c( \u0026quot;Posterior mean\u0026quot; = colour$blue_dark, \u0026quot;Observations\u0026quot; = colour$orange_light, \u0026quot;True tissue response\u0026quot; = colour$orange_dark, \u0026quot;NLS fit\u0026quot; = \u0026quot;black\u0026quot; )) } ) example_curves$model_comp[[1]] The least squares model is almost identical to our posterior mean estimate and both are close to the truth. This is not altogether surprising, as we had great data points to fit the model curve on. However, only the Bayesian model comes with an estimate of the uncertainty. With the least squares model, we could easily grow overconfident in the fitted parameters.\nLet’s have a look at the more difficult case.\nexample_curves$model_comp[[2]] In this case, the least squares fit was not really able to find a good foothold in the data, yet it confidently reports the fitted parameters. Granted, our Bayesian model had its troubles too, but at least it reports the extreme uncertainty.\n  Conclusion In this study, we built and explored a Bayesian model for understanding large compound screening assays. We showed that we can use our prior knowledge to build a bespoke model and that such a model provides us with more useful information than a conventional least squares model. We experienced that it takes a bit more work to ensure the quality of a Bayesian model, but we tried out a few ways to do so.\n Next Steps In the preceding study, we assumed that the compounds were random perturbations on a known endogenous ligand. We also assumed that the observations arose under similar circumstances such that they shared a common noise parameter. These assumptions may hold in some cases, but often we know more about our data than that.\nMaybe the permutations could be described with categories or other labels.\nMaybe we performed our screening assay in batches across multiple days, resulting in a possible batch effect on observation data quality.\nEither of these cases add another layer of complexity, but batch effects and labels are both things we can handle with a bespoke Bayesian model. These are the subjects of a future study. Stay tuned!\n License The content of this project itself is licensed under the Creative Commons Attribution-ShareAlike 4.0 International license, and the underlying code is licensed under the GNU General Public License v3.0 license.\n ","date":1619136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650704040,"objectID":"e2827ca157657b4f14da423a60593a1a","permalink":"/post/bespoke-biochem-two/","publishdate":"2021-04-23T00:00:00Z","relpermalink":"/post/bespoke-biochem-two/","section":"post","summary":"Developing a bespoke Bayesian model for high throughput screening assays","tags":["Bayesian data analysis","Bayesian statistics","R","Stan","Statistics","Modelling","Biochemistry"],"title":"Bespoke Bayesian Model for High Throughput Biochemical Assays","type":"post"},{"authors":null,"categories":null,"content":"It is time to create an edge; to take advantage of the compute that is available right where the data is gathered. Even if we use the AWS IoT services, there are several ways and plenty of 3rd party software we could apply for device management and creating an edge. The AWS offering is Greengrass, a piece of software running on our gateway device and an accompanying cloud service. In this demonstration, we introduce key concepts in the context of an IoT edge using Greengrass.\nIn this demonstration we will\n Install AWS Greengrass Core on our Raspberry Pi Register the Pi as a Core Device in the AWS Greengrass console Connect a our sensor as a thing through Greengrass, sending data to AWS IoT Define a calculation in the cloud and deploy it onto the edge using a Lambda function in Greengrass   This is the architecture we are building in this demonstration.  Motivation When we walk through the demonstration, it might seem like a lot of hassle and extra steps to go through before data is flowing and we reach what is essentially the same state as in previous demonstrations, where we just published readings and subscribed directly in the script that also queried our sensor. Indeed, Greengrass is not intended for use with a single sensor. Imagine, however, that we are managing hundreds of sensors on a factory floor. The factory might be far away, or the gowning procedure might prohibit frequent visits, but even if our desk is right next to the manufacturing line, we still do not want to physically go there each time we deploy changes to sensor data streams, restart devices, define new signal processing, or update software. Greengrass allows us to define functionality in the cloud and deploy it to our device with a click.\nAnother important aspect of our IoT application to consider is cost. It is tempting to just send all raw data to storage in the cloud. Cloud storage is indeed inexpensive, but it is not free. What is worse, however, is the cost of compute. Cloud compute offers unprecedented flexibility, but it is expensive, so we generally want to use it to handle loads with varying intensity or low predictability, e.g. for hosting the application that uses data from the IoT setup. As an example of a case where we might quickly incur a large and unnecessary bill, imagine a set of vibration sensors. Vibration sensors are useful for predictive maintenance applications, since the patterns in vibrations from components like bearings and motors might be good predictors for the health of the component. An industrial grade vibration sensor might be able to sample acceleration thousands of times per second. If we were to store the data from just a few vibration sensors, we would quickly fill up enough storage to accomodate years worth of data from other sources like factory floor temperature and humidity. Furthermore, since it is not the acceleration itself but characteristics of the vibrations we are interested in, each time we use the data we would have to do signal processing and recalculate features. If we do that using cloud compute, we will work up quite a bill. The financially and environmentally responsible way to implement vibration sensors is to do the signal processing as close to the sampling point as possible and then only store the calculated features. We still want the flexibility of developing in the cloud and deploying to a remote device, however. While we will not work with signal processing in this demonstration, we will create an example of data transformation and deploy it from the cloud to the Raspberry Pi using Greengrass.\nConceptually, the setup for this demonstration is a bit different from that of the three previous demonstrations. The hardware is exactly the same but, in previous demonstrations, our Raspberry Pi acted the part of a microcontroller and essentially did not do a lot of work. In this demonstration, we will make use of the compute available on the Raspberry Pi, install Greengrass, and use it to manage the sensor. To demonstrate the concept of edge calculations, we will create a transformation that corrects for the fact that the temperature sensor is right next the CPU of our Pi.\nLet us get started!\nNotice that the BME680 air quality sensor is right next to the CPU of the Pi, which interferes with the temperature readings. The edge calculation example of this demonstration will attempt to correct the temperature reading from the BME680 by substracting an amount based on the current CPU temperature.  Install and Configure Greengrass The AWS Greengrass service consists of two main elements. The first, Greengrass Core, is a piece of software that is installed on our gateway device, in our case, the Raspberry Pi. Its main functionality is being an MQTT broker like IoT Core, but acting locally. However, it has other available functionality such as the ability to manage and run Lambda functions. We loosely refer to the gateway device and Greengrass Core as an \u0026lsquo;Edge\u0026rsquo;. The software is configured to communicate with Greengrass in AWS IoT, which constitutes the other element. We loosely refer to AWS IoT as the \u0026lsquo;Cloud\u0026rsquo; part.\nThe process of installing Greengrass Core depends a lot on our device and its operating system, but the docs contain a general guide. I used apt to install Greengrass on the Pi. When following this guide, you will\n Register the Greengrass Core in AWS IoT. Remember to download the package with certificates onto your device Download the packaged software for your specific device and operating system Set up the user group (ggc_group) and user (ggc_user) that Greengrass Core will assume on your device Unpack software and install certificates Download and install the root CA certificate  If it is not already available on the device, we might want to install the Java 8 runtime\nsudo apt install openjdk-8-jdk  For this demonstration we will use Python 3.7 for the functions we deploy into Greengrass Core. Therefore we also need to make sure that Python 3.7 is available to Greengrass core on the device.\nIn order for Greengrass to use these runtimes, the names of the binaries must be very specific. Python must be named Python3.7 and the Java runtime must be named Java8. If the versions installed are correct, but the binaries are not named the way Greengrass expects, e.g. Java 8 is just called Java, we can either rename them or create symlinks:\n# These are examples. Modify to your particular setup sudo ln -s /usr/bin/python3 /usr/bin/python3.7 sudo ln -s /usr/bin/java /usr/bin/java8  Once we have done all these steps, we might want to check that we have all the dependencies we need by running the Greengrass dependency checker:\nmkdir greengrass-dependency-checker-GGCv1.10.x cd greengrass-dependency-checker-GGCv1.10.x wget https://github.com/aws-samples/aws-greengrass-samples/raw/master/greengrass-dependency-checker-GGCv1.10.x.zip unzip greengrass-dependency-checker-GGCv1.10.x.zip cd greengrass-dependency-checker-GGCv1.10.x sudo ./check_ggc_dependencies | more  The dependency checker will also provide hints if it cannot locate Python or Java. Make sure these are available. We do not need the other optional dependencies.\nWhen all is set up and configured, we can start Greengrass by running\ncd /greengrass/ggc/core/ sudo ./greengrassd start  Greengrass Core will need to be running on our device in order to establish a connection between Core and the cloud. You can walk through the AWS hello world cases to familiarise yourself with Greengrass. We are going to do many of the same things in this demonstration but in a slightly different order and using our hardware setup instead of simulated devices.\nBuild a Greengrass Group During the setup, we created a Greengrass Group. The Group will eventually consist of one core device (in our case the Pi) and a variety of entities associated with the core. Our eventual goal is to have data sent from a thing that is associated with the core to the cloud. To reach that ambition we need to configure the thing, i.e. our sensor, a Lambda function that will move the data to the cloud, and subscriptions. We will go through each of these components in turn, starting with the thing.\nAssociate a Thing with a Greengrass Group To associate our thing, the sensor, with the core, we follow the guidelines, and go to AWS IoT \u0026gt; Greengrass \u0026gt; Groups, choose the group we just created, go to Devices, and click \u0026ldquo;Add Device\u0026rdquo;.\n The creation procedure is similar to the procedure for any other Thing registered in AWS IoT. Indeed, after registering the device, we will be able to find it under the AWS IoT \u0026gt; Manage tab and we are even able to associate existing devices with a core. I actually reused the device from the publishing demonstration for this demo.\nNote that before the device is fully associated with the core, the change needs to be deployed. We will go through how to do this after configuring a few more things.\nConnect a Device to Greengrass Core In this section, we will setup up a script that connects to the core with the eventual goal of publishing readings from the sensor to a topic. The messages will never reach the cloud, however. Instead, the messages are published into the core device on a topic that only lives within the the Greengrass group. The logic is something along the lines of\nsetup sensor connect to Greengrass core while true get sensor values publish to local topic  This logic is very similar to what we did in the case of simple publishing, and indeed the two cases are very similar. The main difference is that we will set up and configure a client that connects to the local MQTT broker in Greengrass Core rather than the cloud based broker in IoT Core.\nTo connect a device/thing to Greengrass core, we use the same MQTT client as always and, as usual, we will need a variety of resources to establish the right connection.\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId) myAWSIoTMQTTClient.configureCredentials(groupCA, privateKeyPath, certificatePath) myAWSIoTMQTTClient.configureEndpoint(coreHost, corePort)  Let us discuss each of these resources in turn.\n clientId could be anything allowed by the policy we created for our thing in the previous step. To keep down complexity, using the device ID is a prudent idea. privateKeyPath is the complete path to the key associated with the certificate created earlier for our thing. certificatePath is the complete path to the certificate for our thing that we created earlier. groupCA is the certificate authority for our Greengrass group and is used to authenticate that our thing is indeed connected to the intended Greengrass core when sending and receiving messages. In a moment we will walk through how to obtain this certificate. Note that this is not the root certificate authority used when communicating with AWS IoT Core. coreHost is the server running the Greengrass Core, i.e. our core device corePort is the port on which our thing will communicate with the core using the MQTT protocol. The default setting when generating a new Greengrass Core is 8883, but we could configure this, if we wanted to.  The three first elements are realtively straight forward; we know these from when we created the thing and its certificate in the first place. The three remaining resources, however, require a bit of additional work. The group certificate is managed by AWS and by default it is rotated every 7 days. This requires a little bit of effort on our part when connecting things to the core, but is worth it for the free added security. Since the the Greengrass Core is connected to AWS, AWS also knows the host and port, and so while we are querying AWS for the group certificate, we can also retrieve these two pieces of information. This process of retrieving connection information is called core discovery and is the only time our thing will connect to the cloud. Once connected to the core, all communication will be with it.\nCore Discovery To set up the discovery process, we need a special dicovery client that is also included in the AWS IoT SDK\nfrom AWSIoTPythonSDK.core.greengrass.discovery.providers import DiscoveryInfoProvider discoveryInfoProvider = DiscoveryInfoProvider() discoveryInfoProvider.configureEndpoint(host) discoveryInfoProvider.configureCredentials(rootCAPath, certificatePath, privateKeyPath) discoveryInfoProvider.configureTimeout(10)  The discovery client is set up using the usual materials; the AWS IoT custom endpoint for our account, the AWS root certificate authority, the private key, and certificate for our thing. We also tell the client to wait a maximum of 10 seconds before timing out a connection attempt.\nThe client can be used to send a discovery request to AWS and fetch connection information for the core. It works like this:\n# Returns list of AWSIoTPythonSDK.core.greengrass.discovery.models.DiscoveryInfo objects discoveryInfo = discoveryInfoProvider.discover(thingName)  We provide the thing name of the thing for which we are looking up connection information. In most of our applications this is probably the same as our client ID, but in this case it has to be the name of our thing as registered in AWS.\nIf the request is successful, discoveryInfo will hold information about Greengrass groups that the device belongs to (a device can belong to several groups, but each group has exactly one core). Of interest to us are the certificate authorities and the connection information, the lists of which can be accessed as such:\n# Returns list of AWSIoTPythonSDK.core.greengrass.discovery.models.CoreConnectivtyInfo objects caList = discoveryInfo.getAllCas() # Returns list of tuples (CA content, group ID) coreList = discoveryInfo.getAllCores()  These are lists with each entry representing a core. If our device only belongs to a single Greengrass core, this list will only have one entry. We can get the certificate authority for the first available core like this\ngroupId, ca = caList[0]  Each core might have several connection options so we might like to keep them in a list to loop over later\ncoreInfo = coreList[0] # Get a list of tuples (host, port) coreConnectivityInfoList = coreInfo.connectivityInfoList  Now we have everything we need to have out thing automatically discover and connect to the Greengrass core:\nfrom AWSIoTPythonSDK.core.greengrass.discovery.providers import DiscoveryInfoProvider from AWSIoTPythonSDK.core.protocol.connection.cores import ProgressiveBackOffCore from AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient # Configure client for gg core discovery discoveryInfoProvider = DiscoveryInfoProvider() discoveryInfoProvider.configureEndpoint(host) discoveryInfoProvider.configureCredentials(rootCAPath, certificatePath, privateKeyPath) discoveryInfoProvider.configureTimeout(10) # Discover gg cores for the thing discoveryInfo = discoveryInfoProvider.discover(thingName) # Get connection info caList = discoveryInfo.getAllCas() coreList = discoveryInfo.getAllCores() # Get info for the first core groupId, ca = caList[0] coreInfo = coreList[0] coreConnectivityInfoList = coreInfo.connectivityInfoList # Since the MQTT client expects a certificate file we have to # put the group certificate authority into a file and save # the path groupCA = GROUP_CA_PATH + groupId + \u0026quot;_CA_\u0026quot; + str(uuid.uuid4()) + \u0026quot;.crt\u0026quot; if not os.path.exists(GROUP_CA_PATH): os.makedirs(GROUP_CA_PATH) groupCAFile = open(groupCA, \u0026quot;w\u0026quot;) groupCAFile.write(ca) groupCAFile.close() # Initialise the MQTT client myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId) myAWSIoTMQTTClient.configureCredentials(groupCA, privateKeyPath, certificatePath) # Loop over and try connection with each set of host name and port connected = False for connectionInfo in coreConnectivityInfoList: coreHost = connectionInfo.host corePort = connectionInfo.port myAWSIoTMQTTClient.configureEndpoint(coreHost, corePort) try: myAWSIoTMQTTClient.connect() connected = True break except BaseException as e: pass  This is the most condensed code needed to implement discovery, but in production we will want to add much more logging, error handling, retries for discoveries, and other frills. See the section below on Greengrass in production for a further discussion on how to improve the thing script for a real world scenario.\nPublish inside the Greengrass Group Now that our thing is connected to the core in its Greengrass group we can start publishing data to a local topic. From the point of view of our thing, this works just like publishing to a topic on AWS IoT. Using the client we configured:\nmyAWSIoTMQTTClient.publish(topic, messageJson, 1)  With this, we have everything needed to run our thing running. The example script for this section summarises everything we have done so far but contains a bit more detail. It is based off of the example included with the AWS IoT SDK and was adapted to be used with our hardware setup. Note that the functionality in this script is running on the same Pi as the Greengrass software. In a real production setting, however, the two are likely to be seperate physical devices.\nOnce again, it is worth noting that if we have not deployed after associating the thing with the core, then our core device does not yet know that it is allowed to associate with the thing and the discovery process will fail. Specifically, we will get a DiscoveryDataNotFoundException. It happens to me all the time, but all we need to do is deploy the change. We will do so shortly.\nEven assuming that the Greengrass core is running and the thing script is publishing values, not much is happening yet. If we go to the AWS IoT test test client in the console and subscribe to the topic that the thing is publishing to, there should be no values flowing in, as nothing is being sent there. In order for us to see data flowing into the cloud, we have to grab the data in Greengrass Core and pass it on to a new topic that is published to the cloud.\nThe way this is done with Greengrass is by defining a Lambda function in AWS and deploying onto the core.\nWrite Lambda Functions for Greengrass Lambda functions are a huge subject on their own and, for the purposes of this demonstration, we will assume at least some fammiliarity with the concept. We will still walk through each step needed to writing a Lambda for the edge, but if you are new to AWS Lambda, you might want to read the getting started guide to get a feel for the terminology. Lambda is a pretty cool service, and chances are that you will find it useful for plenty of other applications.\nLambda Code The first Lambda we will write is very simple. It should take an incoming MQTT message, parse the message, and republish it on a new topic to AWS IoT. So something along the lines of\nget incoming message extract body of message republish body to new topic  Very linear, if we assume that the code is only run when there is an incoming message. This is exactly the power of Lambda. We can make a MQTT message, such as the ones we publish from the sensor, trigger a Lambda function. In the next section, we will go through how to set up the trigger. For now, just assume that the code we write is triggered each time there is a message.\nA Lambda always has a function handler that contains the details of whatever triggered the function:\ndef function_handler(event, context): # event holds the message body # context holds the incoming topic etc.  We can name the function whatever we want, just as long as we remember that name and give it the input objects event and context.\nThe event object holds the body of the MQTT message that triggered the Lambda. This is essentially the json we want to pass on to a new topic.\nThe context object holds all sorts of information on what triggered the Lambda, including the topic of the message. We do not really need any of this information now, so we can just ignore it.\nIn order to republish to AWS IoT, we are, as usual, going to need an MQTT client. Remember though that we went through all sorts of trouble to connect the core to AWS IoT and that the core is itself an MQTT broker, so there is no need to set up a new client and connection. Instead, we use one of the clients included in the Greengrass SDK:\nimport greengrasssdk client = greengrasssdk.client('iot-data')  We do not have to install the SDK on our device, but we will need to include it in our Lambda. There are multiple client types included in the SDK, and since we are doing IoT stuff, we need the iot-data client.\nNow we just need to decide on the topic to publish to. This needs to be a topic allowed in the policy for the core. With that, we have everything needed for the Lambda function:\nimport greengrasssdk REPUB_TOPIC = 'republish/reading' client = greengrasssdk.client('iot-data') def function_handler(event, context): client.publish(topic=REPUB_TOPIC, payload=event) return  This is all we need to republish. The full example with a few extra frills, such as adding the incoming topic to the output body, is here. Let us now look at creating the actual Lambda.\nCreate a Lambda Function To create a Lambda function, we navigate to the AWS Lambda console. Under \u0026lsquo;Functions\u0026rsquo; we click \u0026lsquo;Create Function\u0026rsquo;.\nIn the wizard, we choose \u0026lsquo;Author from scratch\u0026rsquo;, give our function a name, and choose our Python runtime. I named mine \u0026lsquo;repub_temp\u0026rsquo; and have been using Python 3.7 for the example. Then we click \u0026lsquo;Create Function\u0026rsquo;. This might take a moment.\n The next thing we need to do is to prepare our code for the Lambda function. So leave the console for a little while and locate the Python script we just created. Now download the Greengrass SDK folder. We only need the \u0026lsquo;greengrasssdk\u0026rsquo; folder, not the examples, docs, etc. Now package the Greengrass SDK and the Python script into a .zip.\n Now jump back to the console and scroll down to the \u0026lsquo;Function Code\u0026rsquo; window. In the \u0026lsquo;Code entry type\u0026rsquo; dropdown, select the \u0026lsquo;Upload a .zip file\u0026rsquo; option and upload the .zip file we just created. Also make sure to change the Handler to \u0026lt;function file\u0026gt;.\u0026lt;our handler function\u0026gt;, in the case of this example, it is greengrass_simple_lambda.function_handler. Click \u0026lsquo;Save\u0026rsquo; to save the changes.\n Now scroll up and, under the \u0026lsquo;Actions\u0026rsquo; dropdown, select \u0026lsquo;Publish new version\u0026rsquo;. We can optionally provide a version description.\n Now we go to \u0026lsquo;Actions\u0026rsquo; again and select \u0026lsquo;Create alias\u0026rsquo;. We give the alias a name and point it to the version we just created. Greengrass does not support pointers to the $latest version, so make sure to select a specific version.\n Now that our Lambda has been fully defined, we need to associate it with the Greengrass core.\nAttach a Lambda to Greengrass Navigate to the Greengrass console. Go to \u0026lsquo;Groups\u0026rsquo; and select the Greengrass group. Then go to the \u0026lsquo;Lambdas\u0026rsquo; menu and click \u0026lsquo;Add Lambda\u0026rsquo;.\n Choose \u0026lsquo;Use an existing Lambda function\u0026rsquo;. Select the Lambda function we just created and click \u0026lsquo;Next\u0026rsquo;. Select the alias we just created and click \u0026lsquo;Finish\u0026rsquo;.\nThat is it for the Lambda. Now the final piece of the puzzle is ensuring that data flows from the sensor to the Lambda function and then from the Lambda function to the cloud. This is done with subscriptions.\nConfigure Subscriptions in Greengrass Subscriptions are the way to configure where what data goes inside the Greengrass group. They specify the pubsub verticies between the things and Lambdas of the group and offer filtering capabilities.\nTo set up a subscription, go to the Greengrass console. Go to \u0026lsquo;Groups\u0026rsquo; and select our Greengrass group. Then go to the \u0026lsquo;Subscriptions\u0026rsquo; menu and click \u0026lsquo;Add Subscription\u0026rsquo;.\n When setting up at subscription we are asked to specify the source and the target. The source and target could be many things, including a specific device/thing, a Lambda function, the cloud, or a Shadow. Subscriptions are one-way, so a two-way communication between two entities within the group would require two subscriptions.\nFor this demonstration specifically, we want to set up a subscription from our thing which generates and publishes data locally to the Lambda function we created. The thing can be found under the \u0026lsquo;Devices\u0026rsquo; tab and the function under the \u0026lsquo;Lambdas\u0026rsquo; tab.\nClicking \u0026lsquo;Next\u0026rsquo; the first time will spawn a topic filter box. This is an optional filter we can specify to make data flows even more dynamic. I have given an example here, but it is not neccessary for the purposes of this demonstration. Click \u0026lsquo;Next\u0026rsquo; again and \u0026lsquo;Finish\u0026rsquo; to create the subscription.\n We need one more subscription, namely the one telling Greengrass that we are publishing data from the Lambda function to the Cloud. We set up another subscription; this time setting the Lambda function as the source and \u0026lsquo;IoT Cloud\u0026rsquo; as the target. Again we can specify an optional filter.\n Now all the pieces are in place. We are ready to deploy.\nDeploy a Greengrass Group Right now, nothing is running on our gateway device except for the Greengrass daemon. Unless we have deployed along the way, none of the device configurations, Lambda function, or subscriptions have made their way onto the core.\nBefore deploying, we should make sure that the Greengrass Daemon is actually running on our gateway device. From a shell on our device\nps aux | grep -E 'greengrass.*daemon'  If the output from this command includes a root entry for /greengrass/ggc/packages/1.10.1/bin/daemon, then the daemon is running. If the daemon is not running, recall that we can start it using:\ncd /greengrass/ggc/core/ sudo ./greengrassd start  Now we are ready to deploy. Fortunately it is very simple to deploy everything we have specified. From our group in the Greengrass console, we are always within sight of the \u0026lsquo;Action\u0026rsquo; dropdown menu which has a \u0026lsquo;Deploy\u0026rsquo; option that we will now click on and utilise. If all goes well the status of our device will go from \u0026lsquo;Is pending\u0026rsquo; to \u0026lsquo;In progress\u0026rsquo; to \u0026lsquo;Successfully completed\u0026rsquo;.\n Put Everything Together To get the example for this section to work, we need to do a few things in the correct order.\n Ensure that the device representing our sensor is associated with the core Ensure that the Lambda function is defined and associated with the core Ensure that there is a subscription from the device to the Lambda function and another subscription from the Lambda function to the cloud Ensure that the Greengrass daemon is running Deploy everything Run the discovery and publishing script for the sensor device  We can run the script like this:\npython3.7 greengrass_thing.py -e \u0026lt;AWS IoT custom endpoint\u0026gt; -r \u0026lt;root CA\u0026gt; -c \u0026lt;thing certificate\u0026gt; -k \u0026lt;private key\u0026gt; -id \u0026lt;client ID\u0026gt; -t \u0026lt;local topic\u0026gt;  And let us quickly look at whether it is working by going to the IoT test client. If we have done everythin correctly, we should not see any data published on the local topic from the sensor device. Rather, we should see data from the topic republish/reading topic that we defined in the Lambda script. Let us see.\n It is indeed working!\nCongratulations! You now know how to work with Greengrass and you have all the neccessary components to create your own Greengrass groups and create powerful IoTs with edges. However, if you are interested and want to know why we went through so much trouble to connect our device through Greengrass, I have another small example demonstrating the concept and power of \u0026lsquo;calculations on the edge\u0026rsquo;.\nDo Calculations on the Edge Compared to simple publishing, having a device publish its data through Greengrass might seem like a large unnecessary hassle. Indeed, sometimes it is, but as soon as our IoT starts to grow beyond a few devices, there will be headaches that are much more simple to solve when Greengrass and, in particular, Lambda is there.\nIn this example, we will demonstrate the utility of the setup through a simple example. I placed the BME680 air quality sensor quite close to the CPU of my Pi, meaning that the temperature of the CPU will interfere with what I really want to measure; the temperature of the air. If we were to obtain the temperature of the CPU, we might be able to calcualte a compensated temperature that is more representative of the air temperature. A quick disclaimer before we begin: there are a plethora of ways to avoid or compensate for this particular problem, including extending the sensor away from the Pi or including the compensation logic in the feeder script, but for the sake of this example assume that we have no flexibility in terms of the hardware and are aiming for a high degree of flexibility and maintainability in the software we create.\nSpecifically, we will create a Lambda function that performs the compensation for us. We will go for something simple like\ncompensated_temperature = 2 * temperature_reading - average_cpu_temperature  This is a very rough estimate, but it will get us going with a minimum viable solution.\nSince we are working with a Raspberry Pi, we can easily get the CPU temperature by reading the file /sys/class/thermal/thermal_zone0/temp like this:\ndef get_cpu_temperature(): f = open(\u0026quot;/sys/class/thermal/thermal_zone0/temp\u0026quot;) raw_temp = f.read() f.close() return float(raw_temp)/1000.0  CPU temperatures can be somewhat jittery, so let us read the temperature in an interval an get the average before we calculate the compensated temperature\nfor n in range(8): cpu_temps.append(get_cpu_temperature()) time.sleep(1) avg_cpu_temp = sum(cpu_temps)/float(len(cpu_temps)) # Compensated temperature comp_temp = 2*input_temperature - avg_cpu_temp  That is really all there is to it, and this is all we need to add to the previous example. The full Lambda function example has a few extra frills such as error handing and logging. The next step is to define this Lambda function and associate it with the Greengrass group. We could create a new Lambda function, but I opted to update the Lambda function we created in the previous section. To do so, open the function in the Lambda console, insert the code and publish a new version. Then, from the \u0026lsquo;Version\u0026rsquo; dropdown menu, select the alias we created earlier.\n Scroll down a bit, find the \u0026lsquo;Alias configuration\u0026rsquo;, and point the alias to the version of the Lambda we just created. Click \u0026lsquo;Save\u0026rsquo; to save changes.\nBefore we deploy, the Lambda will need some additional configuring. By default, any Lambda will timeout after 3 seconds, but ours will be running for at least 8 seconds to get an average CPU temperature. Furthermore, Lambda functions running in Greengrass to not have access to local resources under /sys. We will need to change these defaults.\nGo to the Greengrass console and select the group. Under the Lambda menu, click the three dots in the upper right of the Lambda function, we just modified and select \u0026lsquo;Edit configuration\u0026rsquo;.\n Set the timeout to 10 seconds and enable access to /sys.\n All that is left is to deploy the Greengrass group from the Greengrass console. The resulting output to the cloud should look exactly like before. This time around though, the temperature readings should look a bit more realistic.\nCongratulations! You are now doing calculations on the edge. It might not feel like much, but consider how we might have gone about solving the problem in other ways.\nWe could have published CPU temperature readings to the cloud and done the calcualtions using Lambda functions, SQL queries, or EC2 compute in the cloud. The cost of the additional storage and the cloud compute would make such a solution several times more expensive that what we just did.\nWe could have put the calculations directly in the feeder script. While this would cost slightly less than our solution, it increases the operational burden. Sensors and microcontrollers are generally less accessible, especially in a manufacturing context. With our solution, we can manage the calculations in the cloud from the comfort of our chair or even home. If we wanted to start recording the temperature in Kelvins, all we would have to do is add the calculation to our Lambda function and deploy the changes.\nThis was a very simple example of edge calculations managed from the cloud. Greengrass is, however, capable of handling much more complex setups than what we just built. Specifically, it is even possible to deploy machine learning models that are trained in the cloud onto the edge. These advanced features of Greengrass are the subject of the next demonstration.\nIn Production This section is not part of the demonstration as such. It is but a short discussion of some of the considerations we have to take when bringing Greengrass to production in a manufacturing environment and how to improve upon the examples to make them production ready. Considerations from previous demonstrations still apply.\nDefault vs Custom Core Config Note that in the demonstration we just went for the default options when setting up the Greengrass core. This creates a new ploicy for the certificate attached to the core. The policy is extremely permissive and, while it works great for demonstration purposes, it might not be what we want in a production setting.\nThe great thing about Greengrass is that we can define aggregations and handle the diversity of incoming data at the edge and then only publish to a set of neatly organised topics to the cloud. This means that we can manage a diverse set of topics and devices at the edge but still have a very restrictive policy for communication with the cloud.\nHandle Certificate Authority Rotation Per default, the CA for the local MQTT server run by Greengrass is rotated every 7 days. We can adjust this to be more or less frequent, but if the Greengrass core remains connected to the cloud it will eventually be rotated. This is a layer of free added security that we do not have to manage, but it requires a bit of extra development considerations for our devices.\nIn particular, our devices must be able to handle a situation where the CA obtained in the initial discovery process is no longer valid. Depending on our production architecture, we might have to call the discovery process again.\nMore details are available in the documentation in the section \u0026lsquo;Certificate Rotation on the Local MQTT Server\u0026rsquo;.\nManage the Greengrass Lifecycle Chances are that the device running Greengrass core will need to reboot at some point. Rather than starting the Greengrass daemon manually, we want it to start automatically on reboot. The documentation has information of how to do so but, for a Raspberry Pi, it is fairly straightforward to do using systemd.\nVerify that the Greengrass configuration option to use systemd is set to yes. The config file can be found on the Greengrass device at /greengrass/config/config.json. Ensure that \u0026quot;useSystemd\u0026quot; : \u0026quot;yes\u0026quot;, otherwise change it.\nMake service a service file at /etc/systemd/system/greengrass.service\n[Unit] Description=Greengrass Daemon [Service] Type=forking PIDFile=/var/run/greengrassd.pid Restart=on-failure ExecStart=/greengrass/ggc/core/greengrassd start ExecReload=/greengrass/ggc/core/greengrassd restart ExecStop=/greengrass/ggc/core/greengrassd stop [Install] WantedBy=multi-user.target  Make the service exeutable\nsudo chmod u+rwx /etc/systemd/system/greengrass.service  Add service to systemd\nsystemctl enable greengrass.service  Test the service by rebooting the device and confirming that the Greengrass daemon is running. We can check whether the daemon is running with\nps aux | grep -E 'greengrass.*daemon'  Connection Retries and Progressive Backoff Logic Imagine the following situation. We have a couple of hundred sensors that connect to one or a few Greengrass core devices, and all run off of the same power supply. At one point, the power supply is switched off, maybe it is maintenance maybe it is an error, but after a while power returns and our sensors and their controllers reboot. We set up the controllers such that they will automatically try to reconnect with the core. This is fine, but suddenly the core is getting hundreds of connection requests within a few seconds, so the controllers are receiving errors. Now, obviously there is nothing wrong with the core devices; they are just getting too many requests, so we will want the controllers to retry the connection before giving up. However, we do not want to have them all retry at the same time lest we repeat the story again.\nThe idea behind progressive backoff logic is to keep retrying but waiting progressively longer for each retry as well as throwing a bit of randomness into the wait time. One type of backoff logic, exponential backoff, waits exponentially longer before each retry. Here is a bit of Python style pseudocode showing the basics of it\nimport time retries = 0 wait_time = 2 while retries \u0026lt; max_retries: try: connect() break except connectionFailedException: time.sleep(wait_time) wait_time += wait_time*1.5 wait_time += random_number retries += 1  Each AWS SDK implements some sort of backoff logic and so does the AWS IoT SDK, so we do not have to do it ourselves. To increase clarity, I did not include the retry logic in the examples for this demonstration, but it is fairly straightforward to get started\nfrom AWSIoTPythonSDK.core.protocol.connection.cores import ProgressiveBackOffCore backOffCore = ProgressiveBackOffCore() retries = 0 while retries \u0026lt; max_retries: try: connect() break except connectionFailedException: backOffCore.backOff() retries += 1  The SDK also ships with an example very similiar to what we did in the previous sections and also implements this backoff method.\n","date":1592265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592265600,"objectID":"fbd359c087ee3e4f4440da08866cecde","permalink":"/post/iot-poc-greengrass/","publishdate":"2020-06-16T00:00:00Z","relpermalink":"/post/iot-poc-greengrass/","section":"post","summary":"In this tutorial, we build an IoT edge with Greengrass.","tags":["IoT","Data","Data Engineering"],"title":"Build an Edge with Greengrass","type":"post"},{"authors":null,"categories":null,"content":"This is an introduction to and a series of demonstrations of concepts in Industrial Internet of Things (iIoT). It is a port of my GitHub repository, where all code and materials are available.\nOn one hand, it is a simple introduction to how we might go about getting our sensor data from sensors to the cloud. On the other hand, we will dive into advanced IoT concepts. So if you are looking for demonstrations of concepts like edge inference, device fleet management, MQTT, and shadow records you have come to the right place.\nThere are many ways to do IoT and there is an ocean of offerings out there. This introduction focuses on AWS IoT services like IoT Core and Greengrass and uses the AWS IoT SDK for Python. The concepts are transferrable to other services, but we will write code specifically for AWS IoT and we will do so mostly in Python.\nAWS offers multiple ways to ingest and store data but, for industrial scale sensor data, it especially makes sense to look at the AWS IoT and streaming offerings. However, even here there are different ways to go about doing the same thing and the nuances can get confusing. This tutorial consists of a general introduction and five seperate demonstrations designed to exemplify increasingly complex IoT functionality. In each demonstration, We will work from scratch to the full setup, making it a full proof of concept for an AWS IoT architecture. I recommend starting at case 1 and working your way through each case before proceeding to the next. A full disclaimer before you get started though; the tutorial does reflect some subjective opinions and I am by no means an expert on the subject, but the tutorial arises from my work with IoT in a manufacturing setting.\nContents  Hardware Setup Cases  Simple Publishing Publish and Subscribe Utilise Thing Shadows Build an Edge with Greengrass Advanced Features and ML in Greengrass   Introduction to AWS IoT  The Hardware Setup It would not be IoT without at least one device. The demonstrations focus on the software layer but use actual hardware, not simulations, to prove concepts. I have been using a Raspberry Pi 3 Model B+ along with a Bosch BME680 sensor on a breakout. Any sensor would do, but I like this one and this particular breakout beacause it has a nice library which allows us to reduce the amount of code we need to query our sensor to a minimum. Furthermore, this particular sensor has four different components, allowing us to measure temperature, atmospheric pressure, relative humidity, and, with a bit of additional work, air quality. I will not elaborate too much on this particular sensor equipment for this demonstration and I will try to be clear about when you can replace my example code with code querying your particular sensor.\nIn IoT terms the sensor is the \u0026lsquo;Thing\u0026rsquo; or \u0026lsquo;Device\u0026rsquo;, and our Raspberry Pi is the \u0026lsquo;Edge\u0026rsquo; or \u0026lsquo;Gateway Device\u0026rsquo;. Names are not too important and, in real life, you would use different hardware for different situations.\nRaspberry Pi 3 Model B+ with the BME680 sensor. The sensor is intentionally placed quite close to the CPU, which will interfere with the temperature readings. In demonstration 4, we will deploy calculations from AWS onto the Pi to correct for this, as an example of edge calculations.  Hardware-wise everything will be the same throughout each demonstration; BME680 connected to the Pi which is connected to the internet. If you are using the same breakout, take a look at this tutorial to set it up.\nDemonstrations The five demonstrations are the main attraction of this tutorial, and if you are looking for examples and code snippets, then go ahead and dive right in. If you prefer a bit of theoretical background before you get started, then jump to the next section before starting the cases.\n1) Publish Industrial Data with AWS IoT The simplest way to do IoT with AWS. We will register our sensor as a thing in AWS IoT Core and will be using the AWS IoT Python SDK to publish sensor readings to a topic. We go through concepts such as things, topics, MQTT, and more.\nIn this case, the Raspberry Pi is simply simulating a microcontroller that will query the sensor and publish the result.\nGet started here. Here is the full example script.\nSchematic of the architecture we are building in the demonstration of publishing.  2) Publish and Subscribe In this case, we build upon the previous case and will construct a setup where our device will not just send data but also respond to messages sent to it.\nThe Raspberry Pi is still just simulating a microcontroller, but we start to see how having compute at the edge is useful and can be managed with AWS IoT.\nGet started here. Here is the full example script.\nSchematic of the architecture we are building in the demonstration of publishing and subscribing.  3) Utilise Thing Shadows Using the Thing Shadow feature of AWS IoT, we will create a twin/shadow of our device in the cloud and update it whenever a new reading is available. We could use this cool feature to build a digital twin of our process.\nThe Raspberry Pi is still simulating a microcontroller that will query the sensor, but instead of just publishing the result, it will update the Shadow document of the thing, our sensor.\nGet started here. Here is the full example script.\nSchematic of the architecture we are building in the demonstration of Shadow functionality.  4) Build an Edge with Greengrass Now our Pi will act the part of gateway device. The gateway device effectively represents an edge that is manageable from the cloud and where data transformations or calculations can happen. This could be signal processing, edge analytics, or even machine learning models. Greengrass is the AWS software offering for gateway devices. In this demonstration, we will set up Greengrass on the Pi, connect a thing, our sensor, to Greengrass, and deploy a calculation from the cloud to the edge using a Lambda function.\nGet started here. Here is the full example script for a local device and the Lambda function we will deploy into Greengrass Core.\nThis is the architecture we are building in the demonstration of Greengrass functionality.  5) Advanced Greengrass Features In this final demonstration, we will combine everything from the previous demonstrations to deploy a machine learning model from the cloud into Greengrass and do inference at the edge. This requires us to explore additional advanced features and configurations of Greengrass, but shows how, with a few means and a bit of engineering, we can achieve quite complex functionality.\nGet started here. This demonstration uses the same example script for a local device as the previous but has two new examples of Lambda functions, including one doing machine learning inference.\nThis is the architechture of the application we will build in the demonstration of advanced Greengrass Features.  IoT with AWS IoT This section has a bit of theoretical context for the demonstrations. We will try to understand some core concepts of internet of things in the context of an industrial setting and AWS IoT.\nThings Let us start with the Things in an internet of things. In an industrial setting, a thing is often anything that has a measurable state, is being actively measured, and is connected to a network. A simple example might be temperature at the factory floor. This is obviously a critical variable in many manufacturing processes and one can often find old school thermometers installed here and there. These are not things, however, until they are connected to a network either directly or indirectly through a gateway device. Other examples could be the airflow through a specific nozzle or the injection pressure for the plastic in an injection moulding process. The airflow could be measured using a flowmeter and the injection pressure with a pressure sensor. These could then be connected to a small computer that in turn connects to the internet.\nGiven this vague definition of things, an obvious question arises for those who have been in a manufacturing context for a while. Manufacturing processes are usually associated with process control loops. These include connecting key process parameters to a process logic controller (PLC) that in turn controls actuators to regulate the process. An example would be the flow of water through a pipe, measured by a flow sensor and regulated by the opening or closing of a valve. The question is: are these control loops also IoT?\nThe answer is that they could be. The process parameters and the state of the valve are all potential things that when connected to a network could become things in an internet of things. The key difference between IoT and a control loop would be all the other things and applications that might be on the network. The PLC is there to do process control, not neccessarily to send or store data, and connecting it to new networks could be a major risk for the manufacturing process, but also potentially unlocks the data for new valuable applications. In IoT, we use dedicated devices to buffer and send data to storage in the cloud or somewhere else.\nOne network that an IoT could take advantage of is a cloud. Cloud service providers like AWS and Azure have IoT-specific offerings that can help build new IoTs. AWS is our cloud of choice for this tutorial. In AWS IoT Core, we can register and manage our things. A thing is the highest level of granularity, and it makes sense to register each parameter we measure as a seperate thing. We can then aggregate and manage hierarchies of things using groups and types.\n The Edge and Gateway Devices We stumbled up the term gateway devices a few times. A gateway device is basically just a computer. It could be as small as a microcontroller and as large as a distributed compute system. In this tutorial we will use a Raspberry Pi to play the part of gateway device. In an industrial setting the gateway devices are there to do the things that a PLC should not do, like connecting to the internet, doing heavy calculations, and buffering data. It might be obvious at this point, but the gateway device is essentially what is referred to as the \u0026lsquo;edge\u0026rsquo;. Running machine learning at the edge essentially means having a machine learning algorithm do inference using the compute in our gateway device. A gateway device can be used for a bunch of other things though, such as signal processesing, data aggregation, or data transformation. Imagine for instance that our sensor reports the factory floor temperature in degrees Celcius. Maybe we want to convert that into Kelvins before sending and storing it in the cloud. Of course we could store the measurement in Celcius and then do the transformation later or directly in our application, but that would be more expensive (cloud compute is expensive, cloud storage is cheap) and less elegant. We run our computations at the edge whenever it makes sense and save money.\nThe edge device is where we will run the client that connects to AWS IoT, sends data, and maybe receives instructions. To do so we will use the AWS IoT Python SDK. AWS also provides software for managing and running our applications on gateway devices. These are called Greengrass and SiteWise (which is just additional software on top of Greengrass). Greengrass allows us to do cool things such as running Lambda functions and deploy machine learning models from the cloud to the edge. Greengrass and its functionality is covered in demonstrations 4 and 5.\nShadows We are doing IoT for a reason. Maybe we are building a dashboard for the operators of our manufacturing line, maybe we are developing a predictive maintenance model that uses measured parameters from the line to predict the remaining lifespan of a critical component. Whatever our application, we will need fresh data from our things. Unless we have gone all in on a massive synchronisation effort, our data points will not arrive at exactly matching timestamps, however. Factory floor humidity might be reported every 5 minutes while frequency and amplitude of a vibrating element might be reported every 15 seconds. Maybe the gateway device handling data from our flow sensors has been updating its software such that no values have been reported for the past 12 minutes. What does our application do when the refresh rate might be every 30 seconds? If all values are stored in a database, the application could just grab the latest values, but that might not be possible or introduce unwanted latency. There is another way, however.\nA Shadow record is a record of the latest process parameters, such that the currently most reliable view of reality is always available for applications. The notion is similar to a database, the key difference being that this record only ever keeps the latest entry. With such a record we can design our application to do what it needs to do and even dynamically correct for old data without ever worrying about not having available data or waiting for data to appear, thus effectively decoupling the IoT and our application.\nShadow records are a part of the AWS IoT offering. Each thing registered in AWS IoT automatically has a shadow, which is a json document containing the latest record for that thing, assuming we have set up our IoT to update it. In demonstration 3, we will explore how to interact with shadows in the cloud. Using Greengrass, we can also keep a shadow on the edge and even enable shadow synchronisation between the edge and the cloud. In this way our applications running at the edge can access shadow records with low latency, while cloud based applications have a copy available to them as well. We will explore the use of local shadows with Greengrass for a machine learning application in demonstration 5.\n SDK We will be using the Python SDK to configure the client that communicates with AWS. This means that our gateway device has to be able to run Python. This is no problem on a Raspberry Pi, but would not work for a microcontroller and probably would not be ideal for a web application. AWS IoT offers SDKs for a bunch of other languages, however.\nThis tutorial uses the first version of the Python SDK. A version two that uses a very different syntax was released, but will not be covered here.\nThe MQTT Protocol Communication with AWS is facilitated by the MQTT protocol. This is a protocol commonly used in manufacturing systems, and is documented online. The AWS flavour of MQTT is a slightly simpler implementation of the protocol. Communicating using HTTPS is also possible but is not covered in this tutorial.\nTo get started using the MQTT protocol with AWS IoT, we only need to know a few concepts: message, topic, quality of service (QoS), publishing, and subsribing. These concepts are summarised right here, but we will discuss them in detail when they show up in the demonstrations.\nMessages At the core of MQTT is the message, The message contains the actual data along with any metadata. It is structured as a json and we can put whatever we want in there, but we will want the reading from our thing, a timestamp for the time of sampling, and maybe an idication whether the reading was succesful or not.\nTopics Messages in AWS are distributed and filtered using topics. Topics are a kind of tag that we can use to identify the source of the message and distribute it accordingly. It is just a single string, generally in the format\nmain_tag/secondary_tag/tertiary_tag/etc  For instance, if we had several factories each with several manufacturing lines with several stations each eqipped with sensors, we might do something like\nfactoryA/line22/drying/temperature  and then have another sensor on the same line publish to\nfactoryA/line22/milling/torque  That way we can direct these messages to the store or dashboard for the same line but seperate Lambda functions, if that is needed for our application.\nThe topic system is quite flexible and we will have to rely on our own rigid naming conventions if we want to effectivly utilise topics in an application with many things. Some specific topics are reserved for specific purposes such as interacting with shadows. We will dive deeper into the use of topics and reserved topics in the demonstrations.\nPublishing and Subscribing Messages are transmitted using the publish subscribe model. A message always has a single publisher. The publisher client is the origin of the message and will publish that message to a given topic. A topic can have several publishes, meaning that several clients can publish messages to the same topic. Messages reach their destination through subscribers. Subscribers are clients that listen to a topic to get whatever messages are published there. A topic can also have multiple subscribers.\nServer/Broker The MQTT server is responsible for orchestrating the MQTT communication. It is the server that will authenticate MQTT clients and will route messages from publishers to subscribers using topic filters. AWS IoT Cores is essentially an infinitely scalable MQTT server. Greengrass is also an MQTT server that runs locally on a gateway device.\nClient The MQTT client is used to create an MQTT publisher or a subscriber. The core functionality of the AWS IoT SDKs is to abstract away the intricacies of setting up and authenticating an MQTT client.\nQuality of Service Quality of Service, abbreviated QoS, is a flag specifying what happens when messages get lost in the network. The AWS flavour of MQTT accepts two QoS flags. The flag 0 means that the message is delivered to subsrcibers \u0026lsquo;at most once\u0026rsquo;. The flag 1 means that the message is delivered to subsribers \u0026lsquo;at least once\u0026rsquo;. So for QoS = 0 the publisher will send the message once and then forget about it. If it does not get delivered, it is lost. For QoS = 1, however, the message is sent, and the publisher then waits for a reply from the subscriber before forgetting the message, and resends if neccessary. This ensures that the subscriber gets the message at least once.\n","date":1592265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592265600,"objectID":"e2f3228773d18d40a5599ecfdc14a288","permalink":"/project/iot-poc/","publishdate":"2020-06-16T00:00:00Z","relpermalink":"/project/iot-poc/","section":"project","summary":"Getting started with industial Internet of Things using AWS IoT and Greengrass. From the first sensor to machine learning at the edge.","tags":["IoT","Data","Data Engineering"],"title":"Industrial IoT with AWS and Python","type":"project"},{"authors":null,"categories":null,"content":"We are about to build something really cool. Machine learning inference managed from the cloud but performed at the edge might sound like a sequence of flimsy business colloquialisms and to some extent they might be. In this demonstration, however, we will dive into the actual technical substance behind these terms.\nSpecifically, we will discuss and apply advanced features of AWS Greengrass, including\n Creating and interacting with a local Shadow Shadow synchronisation with the cloud Decoupling data generation and application using a Shadow Long-lived Lambda functions Machine learning resources Machine learning inference in the Greengrass Group with a Tensorflow2 model The Greengrass service role  The target of the demonstration is to build a small IoT application that predicts whether it is raining or not, given the current temperature, relative humidity, and pressure. The weather data comes from our BME680 air quality sensor, and our Raspberry Pi 3B+ will play the role of gateway device but also runs the code querying the sensor.\nWe will be utilising expertise from the previous demonstrations of publishing, subscribing, Shadows, and general Greengrass features.\nSet Up To build the target demonstration, we will walk through three parts. First we will set up a local Shadow within our Greengrass group and use obtained sensor values to contiuously update the Shadow. Then we will enable synchronisation between the local Shadow and a cloud copy of the Shadow. Last, but not least, we will set up inference with a Tensorflow2 machine learning model.\nWe will not cover installing and setting up Greengrass Group with a device, as this was covered in the general introduction to Greengrass. Be sure to refer to previous demonstrations when in doubt.\nThis is the overall architechture of the application we will build in this demonstration.  Let us get started!\nPublish to Local Shadow In this section, we will set up a local Shadow and build a Lambda function that takes values published by our sensor and updates the Shadow.\nThis is the part of the architecture we will build in this section.  Prepare the Thing We register and add our Thing, the sensor, to our Greengrass group.\nWe already have a script that connects our Thing and publishes readings to our Greengrass Group on a local topic. There is no need to modify it in any way. We will just leave it running, continuously publishing values to a local topic. I went with the topic bme680/readings but any topic goes.\nThe Local Shadow Service Any Thing we include in our Greengrass Group lives only inside the Group and only connects to the cloud when first discovering the Group. This is great for reducing the number of devices connected to the cloud, but it also means that we cannot directly take advantage of the Shadow that is in the cloud.\nFortunately, Greengrass provides a Local Shadow Service inside Greengrass that we can use instead. The local Shadow service works in a very similar way to the Shadow in the cloud. The Shadow document follows the same schema, it is interacted with using the exact same topics, and it can be get, updated, and deleted. The Shadow lives inside the Greengrass Group and is only accessible to entities connected to the group.\nFor instance, assume we have a Thing called my_sensor and an MQTT client that is connected to our Greengrass Core, we can publish an update to the Shadow of our Thing like this:\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient import json client = AWSIoTMQTTClient('my_sensor') # Connect the client to Greengrass Core # ... left out for clarity # Build an update for the Shadow message = {} message[\u0026quot;state\u0026quot;] = { \u0026quot;reported\u0026quot; : {\u0026quot;temperature\u0026quot; : 12. } } # Publish the update to the Shadow client.publish('$aws/things/my_sensor/shadow/update', json.dumps(message))  The message goes to whichever MQTT server the client is connected to. Since we are connected to Greengrass Core and not AWS IoT, the message never reaches the cloud. So even though the topic is exactly the same as if we were updating the cloud based Shadow, the cloud based Shadow is not updated.\nAs a matter of fact, the message also does not reach the local Shadow. At least not yet. Since we are working with local topics, we need to set up subscriptions and deploy them to the Group before any messages are relayed.\n This is how it could look, but since there is a much easier way, this is not how we will do it.\nRepublish to Shadow We will build a Lambda function that will reside in the Greengrass Group. Its purpose is twofold: it will do a bit of transformation on the sensor readings and it will republish the readings as an update to the local Shadow.\nInteract with the local Shadow service from a Lambda function For a Greengrass MQTT client running in a Lambda function that is deployed into a Greengrass Group, interacting with the local Shadow service is very straight forward. We connect and then perform the action we desire:\nimport greengrasssdk import json # Hardcoding the thing name is not a good idea. We will look at an alternative # in a moment THING_NAME = 'my_sensor' # Define and connect the client client = greengrasssdk.client('iot-data') # Update the Shadow update = {\u0026quot;state\u0026quot; : { \u0026quot;reported\u0026quot; : {\u0026quot;value\u0026quot; : 3 }}} client.update_thing_shadow(thingName=THING_NAME, payload=json.dumps(message)) # Get the Shadow shadow = client.get_thing_shadow(thingName=THING_NAME) shadow = json.loads(shadow['payload']) # It takes a bit of unpacking... # Delete the Shadow client.delete_thing_shadow(thingName=THING_NAME)  There is no need to deal with callback functions - everthing is taken care of behind the scenes. Furthermore, there is no need to explicitly define the subscriptions in the Greengrass Group for these actions. As long as we use the Greengrass MQTT client, the messages find their way to the local Shadow service, which is just a set of hidden Lambda functions.\nWe now know everything we need to have our Lambda function perform the transformations we need and update the Shadow. There is just one small aesthetic detail to attend to before we can start building.\nSetting environment variables for Lambda functions in Greengrass In the snippet above, we hard coded the device ID, the Thing name into the Lambda function. This will work just fine, but it does make the Lambda function difficult to reuse. We do, however, have a better option. We can provide Lambda functions running in a Greengrass Group with environment variables. Environment variables are key-value pairs that are specified outside the running script but can be accessed at runtime. If you are already familiar with environment variables for Lambdas running in the cloud, they work in a very similar fashion, but are specified in a different place when used with Greengrass. Let us take it step by step.\nFirst we will need to decide on a key-value structure. We will go with the key being THING_NAME and the value being the ID of our device.\nThen we need to write our Lambda function to take advantage of the environment variable. This is fairly straight forward, in Python:\nimport os THING_NAME = os.environ('THING_NAME')  The last step we need is to actually provide the environment variable to the instance of our Lambda function in the Greengrass Group. We do this by locating our Greengrass Group in the console and configure the Lambda in question.\nNote that the name of your Greengrass Group and Lambdas may be different  At the bottom of the configuration options, we find a set of fields where we can provide key value pairs, and we just go ahead and provide ours.\n Now, when we deploy the Lambda function, the environment variable will be available for use. This means that if we have multiple sensors we we can use the same Lambda Alias to create multiple Lambda functions deployed to the Greengrass Group serving their exact device. Less code and less work for us.\nBuild the republishing Lambda function With a bit of additional logging and error handling, we have our Lambda function for transforming and republishing the weather data:\nimport greengrasssdk import logging import json import time import os THING_NAME = os.environ[\u0026quot;THING_NAME\u0026quot;] client = greengrasssdk.client('iot-data') def get_cpu_temperature(): ''' Gets the CPU temperature of a Raspberry Pi in deg. C ''' try: f = open(\u0026quot;/sys/class/thermal/thermal_zone0/temp\u0026quot;) raw_temp = f.read() f.close() cpu_temp = float(raw_temp)/1000.0 except Exception as e: logging.error('Unable to obtain CPU temperature. ' + repr(e)) return cpu_temp def get_topic(context): try: topic = context.client_context.custom['subject'] except Exception as e: logging.error('Unable to read a topic. ' + repr(e)) return topic def get_temperature(event): try: temperature = float(event[\u0026quot;temperature\u0026quot;]) except Exception as e: logging.error('Unable to parse message body. ' + repr(e)) return temperature def function_handler(event, context): try: input_temperature = get_temperature(event) cpu_temps = [] for _ in range(8): cpu_temps.append(get_cpu_temperature()) time.sleep(1) avg_cpu_temp = sum(cpu_temps)/float(len(cpu_temps)) # Compensated temperature comp_temp = 2*input_temperature - avg_cpu_temp message = {} message[\u0026quot;state\u0026quot;] = { \u0026quot;reported\u0026quot; : {\u0026quot;temperature\u0026quot; : comp_temp, \u0026quot;pressure\u0026quot; : event[\u0026quot;pressure\u0026quot;], \u0026quot;humidity\u0026quot; : event[\u0026quot;humidity\u0026quot;], \u0026quot;message\u0026quot; : event[\u0026quot;message\u0026quot;]}} logging.info(event) logging.info(message) except Exception as e: logging.error(e) client.update_thing_shadow(thingName=THING_NAME, payload=json.dumps(message)) return  The full example script can also be found here. We now need to pack this script in a zip file along with the Greengrass SDK, so we can create a Lambda function. We create the Lambda function and upload the zip file\n We then create an alias, navigate to the Greengrass console and associate the Lambda function with our Greengrass Group using the alias.\n  We then cofigure the Lambda function. We need to increase the timeout limit to at least 10 seconds, we need to enable access to /sys so it can get the CPU temperature of the Pi, and we should provide the environment variable as discussed above.\n  That is it for the Lambda function.\nSubscriptions We only need one subsription, one going from our device to the Lambda we just created.\n That is it for the first part. Once we deploy, We have a Thing publishing sensor readings, they are transformed and used to update the local Shadow. Right now there is not much to see though, as we have done nothing to make use of or even visualise the local Shadow. We will get there soon though.\nSetup Shadow Synchronisation In this section, we will set up Shadow synchronisation between the local Shadow and the Shadow of our device in the cloud.\nThis is the part of the architecture we will build in this section.  Synchronising the Shadow just means that the local Shadow service will send regular updates to the cloud based Shadow such that the status quo is reflected there as well. We would usually do this to support an application running in the cloud, but in this case we are doing it mostly for show.\nIt is important to note that the synchronisation works both ways. Updates that are done to the local Shadow will eventually be reflected in the cloud based Shadow and vice versa. We will not have anything directly updating the cloud Shadow in this case, however.\nSetting up synchronisation is actually fairly straight forward. We navigate to our Greengrass group and find the Device page. Next to the Device we added earlier it should be saing \u0026lsquo;Local Shadow Only\u0026rsquo;. All we have to do is to expand the options for that Device by clicking the three dots and selecting Enable Shadow Synchronisation.\n Now we deploy the change.\n We can test whether it works by navigating to the page of the particular Device and going to its Shadow tab. If everything we did in the previous section works and the Shadow synchronisation works, we should see that the Shadow gets updated.\n Machine Learning Inference at the Edge In this section, we will deploy a machine learning model into the Greengrass group and have it do inference based on the data coming from our Device.\nThis is the part of the architecture we will build in this section.  Specifically, we are going to create a Lambda function that loads a machine learning pipeline consisting of a model that transforms the data into features that are then evaluted in a neural network based model. We will get the data from the local Shadow such that the inference does not rely on live data and inference is effectively decoupled from the data stream.\nPrepare the Gateway Device In order for Greengrass Core to run Lambda functions it needs access to runtimes on the Gateway Device where it runs. When we set up Greengrass Core, we verified that our desired runtime, Python 3.7, was indeed present on the Device, our Pi, and accessible to Greengrass Core. Our approach to the use of additional libraries has been to include them in the Lambda deployment package. For instance, we included the Greengrass SDK with the Lambda function we created above.\nMachine learning frameworks like Tensorflow or MXNET are not just libraries but rely on their own runtimes. This means that using such frameworks with Greengrass is slightly more complicated, as we cannot just include the library with the Lambda. Lambdas running in a Greengrass Group can, however, utilise machine learning runtimes if they are installed and available. In fact any library can be used in a Lambda function without including it in the deployment package, as long as it is installed in a shared location on the device.\nFor this case we are going to use Tensorflow2 to do inference, but Greengrass does support other options.\nInstall Tensorflow We will install Tensorflow2 on our Gateway Device, the Pi. How this is done depends very much on the actual device. If you are following along using a Raspberry Pi, and a regular pip install does not work, you might want to check out these unofficial Tensorflow wheels.\nThe key to making it work, is to install Tensorflow in a shared location (e.g. using sudo pip install) where the Greengrass user, ggc_user, can access it. We can test whether the user can access Tensorflow with the following bash command:\nsudo -u ggc_user bash -c 'python3.7 -c \u0026quot;import tensorflow\u0026quot;'  Note, however, that this is no surefire way of knowing whether everything works as expected. Unless you are intimately familiar with your device, it can take a bit of debugging to work. I usually use a Lambda function that just imports Tensorflow and tries something simple like adding two constants and logging the result to test whether the install worked. I deploy the testing Lambda into the Greengrass Group and check the logs for the expected output any unexpected errors.\nOur reward for working all this out is that we are able to call Tensorflow2 from within our Lambda function. Now we are ready to do some machine learning.\nManage Machine Learning Resources To do inference, we are going to need a trained model. A trained should hold everything needed to recreate the function learned from the data during training. This includes the structure of the model, e.g. the layers of a neural network, along with weights, biases, and any other necessary resource. For Tensorflow2, trained models are given in the SavedModel format that can be loaded with a single line of code.\nThe resources of the trained model then need to be deployed into the Greengrass Group along with the Lambda function that will use it to do inference. Let us give it a try!\nA pre-trained model for our case Building a dataset and training a machine learning model a bit outside our scope for this demonstration and will obviously depend on the choice of ML framework and data science problem, but we are still going to need a model for the sake of example. Recall that we wanted to have a model that given readings of temperature, relative humidity, and atmospheric pressure would predict whether it is raining or not.\nI have prepared such a model and described how to save and load a SavedModel with Tensorflow2. It is actually a pipeline of two models closely resembling a real data science workflow. The first model takes in data points, pressure, temperature, and humidity, and standardises them. The second one is a small neural network that takes the standardised features as input and returns a value between 0 and 1, indicating a pseudo-probability of rain.\nWe will use these two models as examples of doing machine learning inference.\nPrepare machine learning resources In order to include machine learning resources like a Tensorflow SavedModel in a Greengrass deployment, they need to be stored somewhere where Greengrass can access them. Greengrass can access objects in S3 buckets, so this is where we will put our resources.\nHowever, Greengrass is a seperate service and needs permission to access other services. We already had Greengrass access Lambda to fetch deployment packages and that worked smoothly, but we will have to understand why before we can ensure the same for S3.\nGreengrass has a service role that determines what other services and actions it has permissions to use. The service role can be found in the AWS IoT console under the Settings tab where we also find our custom endpoint. Somewhere in the list of settings is the Greengrass service role.\n Per default, the policy attached to Greengrass is the managed policy AWSGreengrassResourceAccessRolePolicy. At the time of writing, the policy is at version 5 and, among other things, it contains these actions:\n{ \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Comment\u0026quot;: \u0026quot;NOTE: This is not the full or even a valid policy, just a snippet\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Sid\u0026quot;: \u0026quot;AllowGreengrassToGetLambdaFunctions\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;lambda:GetFunction\u0026quot;, \u0026quot;lambda:GetFunctionConfiguration\u0026quot; ], \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot; }, { \u0026quot;Sid\u0026quot;: \u0026quot;AllowGreengrassAccessToS3Objects\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;s3:GetObject\u0026quot; ], \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:s3:::*Greengrass*\u0026quot;, \u0026quot;arn:aws:s3:::*GreenGrass*\u0026quot;, \u0026quot;arn:aws:s3:::*greengrass*\u0026quot;, \u0026quot;arn:aws:s3:::*Sagemaker*\u0026quot;, \u0026quot;arn:aws:s3:::*SageMaker*\u0026quot;, \u0026quot;arn:aws:s3:::*sagemaker*\u0026quot; ] }, { \u0026quot;Sid\u0026quot;: \u0026quot;AllowGreengrassAccessToS3BucketLocation\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;s3:GetBucketLocation\u0026quot; ], \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot; } ] }  We can immediately see why getting Lambda functions worked to smoothly: this default policy allows Greengrass to get any Lambda function, as indicated by the \u0026quot;*\u0026quot; resource identifier. There is also an action allowing Greengrass to get objects from S3. This one however limits the permission to objects that include the string greengrass, sagemaker, or a few variations hereof.\nThis gives us a choice when storing our machine learning resources: we can either create a new service policy that allows Greengrass to access S3 objects in a format we specify, or we can comply with the constraints of the default policy and name our resources accordingly. The former might not be a good idea because replacing the policy with one we specify means forgoing the benefits of using a managed policy. So we will do the latter and create a bucket with a name containing the string greengrass and put our machine learning resources in there.\nA machine learning resource must be zipped, so we will zip the contents of the two SavedModel folders and put them in the S3 bucket. I have included the zipped models in the project repo as well.\nMachine learning resources in an S3 bucket.  Greengrass will unzip the contents when deploying into the Group. Now we just need to tell Greengrass where the resources are and where to put them.\nCreate machine learning resources in Greengrass Now we are ready to configure machine learning resources in Greengrass. To do so, we locate our Greengrass Group in the console and navigate to the Resources page and the Machine Learning tab. We click the \u0026lsquo;Add machine learning resource\u0026rsquo; button.\n Let us start by creating a resource for the standardiser model. First we will give the resouce a name. I went for standardiser but anything goes. Next, we will need to point to the resource in our S3 bucket. Under \u0026lsquo;Model source\u0026rsquo; we choose \u0026lsquo;Upload a model in S3\u0026rsquo;, select the bucket we just created, and then select the zipped standardiser model. Finally, we will specify a local path on which to keep the unzipped model. Greengrass will create this path on our Core Device and it will be available to the Lambda functions that this machine learning resource is attached to. Any path works, but remember it, as we will need it when we create the inference Lambda function. I went with /ggml/tensorflow/standardiser.\nWe have not created the Lambda function yet, so we cannot attach the resource just yet. We Will have a chance to do so later, though. Click Save to create the resource.\n This created the ML resource for the standardiser. We will need to repeat the process to create a resource for the neural network model, which I named rain_predictor and stored at /ggml/tensorflow/rain_predictor.\nInference Lambda We are almost done building the architecture of our demonstration. We just need the final and arguably most interesting piece; the Lambda function that does inference.\nThe function we are about to build will load the ML pipeline, fetch the latest data from the local shadow, perform the inference, and publish the result back to the local shadow. In pseudocode, we will do something like this:\nconnect to Greengrass crore load standardiser load neural network model while true: fetch data from the local shadow standardise the data evaluate features in the model determine prediction based on threshold publish reult to local shadow wait a little while  Connect and get readings We already know how to interact with the local shadow. We will use an environment variable to supply the name of our Thing\nimport greengrasssdk import os THING_NAME = os.environ[\u0026quot;THING_NAME\u0026quot;] client = greengrasssdk.client('iot-data')  We can then get the latest data from the local shadow\nthing_shadow = client.get_thing_shadow(thingName=THING_NAME)  The shadow requires a bit of unpacking\nimport logging import json def parse_shadow(thing_shadow): try: reported = thing_shadow[\u0026quot;state\u0026quot;][\u0026quot;reported\u0026quot;] readings = [reported[\u0026quot;pressure\u0026quot;], reported[\u0026quot;temperature\u0026quot;], reported[\u0026quot;humidity\u0026quot;]] except Exception as e: logging.error(\u0026quot;Failed to parse thing_shadow: \u0026quot; + repr(e)) return [readings] readings = parse_shadow(thing_shadow=json.loads(thing_shadow[\u0026quot;payload\u0026quot;]))  Load model In order to load our models, we need the paths that we defined for the corresponding ML resources:\nimport tensorflow as tf STANDARDISER_PATH = \u0026quot;/ggml/tensorflow/standardiser\u0026quot; MODEL_PATH = \u0026quot;/ggml/tensorflow/rain_predictor\u0026quot; # Load the model that standardises readings loaded_standardiser = tf.saved_model.load(STANDARDISER_PATH) inference_standardiser = loaded_standardiser.signatures[\u0026quot;serving_default\u0026quot;] # Load the model that predicts rain loaded_predictor = tf.saved_model.load(MODEL_PATH) inference_predictor = loaded_predictor.signatures[\u0026quot;serving_default\u0026quot;]  Inference Given the data and the models, we can go ahead and implement ML inference and publish the results\nCLASSIFICATION_THRESHOLD = 0.5 # Standardise readings to create model features feature_tensor = inference_standardiser(tf.constant(readings))['x_prime'] logging.info(feature_tensor) # Perform prediction raw_prediction = inference_predictor(feature_tensor)['y'].numpy() # Evaluate prediction prediction = (raw_prediction \u0026gt;= CLASSIFICATION_THRESHOLD).astype(int).tolist()[0][0] # Publish result to the local shadow shadow_update[\u0026quot;state\u0026quot;] = {\u0026quot;reported\u0026quot; : { \u0026quot;rain_prediction\u0026quot; : prediction } }  Create Lambda deployment package With a bit of additional error handling and logging, we have everythin we need for our inference Lambda\nimport greengrasssdk import tensorflow as tf import json import time import logging import os THING_NAME = os.environ[\u0026quot;THING_NAME\u0026quot;] STANDARDISER_PATH = \u0026quot;/ggml/tensorflow/standardiser\u0026quot; MODEL_PATH = \u0026quot;/ggml/tensorflow/rain_predictor\u0026quot; CLASSIFICATION_THRESHOLD = 0.5 # Load the model that standardises readings loaded_standardiser = tf.saved_model.load(STANDARDISER_PATH) inference_standardiser = loaded_standardiser.signatures[\u0026quot;serving_default\u0026quot;] # Load the model that predicts rain loaded_predictor = tf.saved_model.load(MODEL_PATH) inference_predictor = loaded_predictor.signatures[\u0026quot;serving_default\u0026quot;] client = greengrasssdk.client('iot-data') def parse_shadow(thing_shadow): try: reported = thing_shadow[\u0026quot;state\u0026quot;][\u0026quot;reported\u0026quot;] readings = [reported[\u0026quot;pressure\u0026quot;], reported[\u0026quot;temperature\u0026quot;], reported[\u0026quot;humidity\u0026quot;]] except Exception as e: logging.error(\u0026quot;Failed to parse thing_shadow: \u0026quot; + repr(e)) return [readings] # Note predictor expects shape (observations X num_features) shadow_update = {} while True: try: # Get readings from local Shadow thing_shadow = client.get_thing_shadow(thingName=THING_NAME) # Put readings in a list in the right order readings = parse_shadow(thing_shadow=json.loads(thing_shadow[\u0026quot;payload\u0026quot;])) # Standardise readings to create model features feature_tensor = inference_standardiser(tf.constant(readings))['x_prime'] logging.info(feature_tensor) # Perform prediction raw_prediction = inference_predictor(feature_tensor)['y'].numpy() # Evaluate prediction prediction = (raw_prediction \u0026gt;= CLASSIFICATION_THRESHOLD).astype(int).tolist()[0][0] # Publish result to the local shadow shadow_update[\u0026quot;state\u0026quot;] = {\u0026quot;reported\u0026quot; : { \u0026quot;rain_prediction\u0026quot; : prediction } } except Exception as e: logging.error(\u0026quot;Failed to do prediction: \u0026quot; + repr(e)) client.update_thing_shadow(thingName=THING_NAME, payload=json.dumps(shadow_update)) time.sleep(10) # Repeat every 10s # The function handler here will not be called. Our Lambda function # should be long running and stay in the infinite loop above. def function_handler(event, context): pass  The script can also be found here.\nWe zip this script along with the Greengrass SDK and create a deployment package.\n We then create an alias, go to the Greengrass console, and add the Lambda function to our Group.\nAttach machine learning resources Now we can finally attach the machine learning resources to our Lambda function. We navigate to our Greengrass Group and under the Lambdas tab select our inference Lambda. Under the Resources tab, we select the option to \u0026lsquo;Add machine learning resource\u0026rsquo;\n Since we have already created the resources, we select the option to \u0026lsquo;Attach an existing machine learning resource\u0026rsquo;.\n We select either of the two resources, click \u0026lsquo;Save\u0026rsquo;, and repeat the the process for the other resource.\n Configure the Lambda Our inference Lambda is almost done, we just need to configure it properly. All Lambda functions we have used with Greengrass so far have been on-demand functions that were spawned in response to an MQTT message. This inference Lambda is a bit different. Instead of waiting to process an input on-demand, we want this function run on on a fixed schedule, which we implemented by having the inference code repeat every 10 seconds. In fact, we do not want the Lambda to respnd to any events at all and consequently left the function_handler empty.\n# The function handler here will not be called. Our Lambda function # should be long lived and stay in the infinite loop above. def function_handler(event, context): pass  Once the Lambda is deployed to our Greengrass Group, we just want it to run forever in the infinite loop we created. This is called a long-lived Lambda, and we can choose this option on the configuration page of the Lambda in the Greengrass Group. While we are in there, we will also give the Lambda a longer timeout and some more memory. Our ML model is small, but ML models are often large and require much more memory.\n Deploy and Verify That is it; everything is in place for doing machine learning inference at the edge.\nFirst let us ensure that Greengrass is running using:\nps aux | grep -E 'greengrass.*daemon'  Then we deploy everything we have created.\n Finally, we make sure that the Thing is online and is publishing values from our sensor.\nNow, if everything works is right, we should be doing inference at the edge. We should be predicting whether it is raining or not and publishing the result to the local Shadow. Since the local Shadow is being synchronised with the cloud based Shadow, we should be able to see the predictions if we go to the Shadow page of our Thing.\n And there it is! It is a sunny day, so the prediction was right this time, but do not expect it to be very precise. Instead bask in the glory of accomplishment and enjoy the fact that you now know how to manage machine learning models in the cloud and do inference on the edge. Congratulations!\nIn Production While we have done much there are still many more things to consider when using Greengrass for machine learning workloads in production. Here is a short discussion of some of these considerations along with a few points and tricks that did not fit in the demonstration.\nLogging in Greengrass Greengrass features pretty extensive logging. Logs pertaining to the Lambda functions running in the Greengrass Group can be particularly useful during development as well as production. The Logs are stored on our gateway device on a path that depends on user ID and AWS region. It is fairly straightforward to add log entries from a Python Lambda function.\nimport logging # Log an error logging.error(\u0026quot;Hypothetical error\u0026quot;) # Log some information logging.info(\u0026quot;My value is 2\u0026quot;)  All sorts of things can and will go wrong when developing, and so a very useful Python design pattern to use in Lambda functions is the try and except with logging.\na = 4 try: # Do whatever we are trying to do a += 1 except Exception as e: # Log the variables at this time logging.info(\u0026quot;a is {0}\u0026quot;.format(a)) # Log the exception along with a description of what was supposed to happen logging.error(\u0026quot;Failed to do the thing I wanted: \u0026quot; + repr(e))  Indeed we did apply this design pattern in the examples for this demonstration so, when something is not working as expected, check the logs.\nCI/CD We implemented many different parts in this demonstration, and repeating this manual process is obviously not feasible for real IoTs with hundreds of devices. CloudFormation templates will work wonders for the cloud side of things. But, even if we are using AWS IoT services, an IoT very much is a hybrid setup. We still need to install and manage the software running on and near gateway devices and sensors. All in all this sets quite high demands for our CI/CD pipelines.\nFor data science projects, however, publishing models to an S3 bucket and inference code to Lambda are relatively trivial tasks, so at least this part of CI/CD can be much easier with Greengrass.\nCost We have not specifically addressed the subject of cost during this or the previous demonstrations. To be clear, everything we have done in this demonstration and the previous ones should be well within the Free Tier, assuming eligibility and that things are not left running indefinitely. But what about larger IoTs?\nPricing for AWS IoT and AWS Greengrass is fairly transparent and we can connect a lot of devices and send a lot of messages before raking up a bill of any significant size. Indeed, if we did not do Shadow synchronisation, we could copy the architecture of this demonstration, scaling it to hundreds of manufacturing lines, and it would cost us less than $2 per gateway device per year. So does that mean that doing IoT is super cheap? No, it just means that the bill lies elsewhere.\nFrom a cloud point of view, sending messages to AWS IoT does not do much. The messages are not kept or processed in any way, unless we do so actively. Herein lies a hidden cost: We are going to need more services like Kinesis, SQS, SNS, S3, or DynamoDB before we can start using our data. In particular, processing using cloud compute can be expensive. One of the key reasons for using Greengrass was to lower processing costs by using compute available at the edge. Yet, this means we have to have an edge.\nSo, from an edge point of view, we could argue that the whole cloud thing is just an add on to the costs that we already have in building and maintaining servers and networks around whatever process we building an IoT for.\nThe point is that, even though AWS IoT prices are reasonable and transparent, these are only a small part of the total cost and business case for an IoT. Depending on our intended applications and the tools available locally, it might or might not make sense to involve the cloud. That being said, IoT can be a cheap and fun way to get started with the cloud.\n","date":1592265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592265600,"objectID":"308d3410d62b2553d7974154587d3024","permalink":"/post/iot-poc-greengrass-ml/","publishdate":"2020-06-16T00:00:00Z","relpermalink":"/post/iot-poc-greengrass-ml/","section":"post","summary":"In this tutorial, we deploy and operate a machine learning model, in an IoT network at the edge with Greengrass.","tags":["IoT","Data","Data Engineering","Machine Learning"],"title":"Machine Learning at the Edge and other Advanced Features of Greengrass","type":"post"},{"authors":null,"categories":null,"content":"In this demonstration, we will add upon the previous, by having our gateway device, the Raspberry Pi, subscribe to messages on a topic.\nWith publishing, the information flow is from the device to AWS IoT, but with subscribing, the flow is reversed to be from AWS IoT to the client we configure for our device. Applications are obvious candidates for subscribers to messages but, as we will see, the ability to subscribe is extremely useful for structuring and managing devices remotely.\nIn general terms, we want our device to do the following\nprepare the sensor configure connection to AWS define what happens with subscriptions start subscribing while true react to any incoming messages get a sensor reading pack it up publish it  For the demonstration, are once again using the Bosch BME680 air quality sensor connected to a Raspberry Pi 3 model B+. The BME680 does four different measurements, and we will utilise the temperature, pressure, and humidity sensing capabilities. The Pi is just there to query the sensor and run the AWS IoT SDK. It essentially plays the part of a microcontroller, and so anything we accomplish here can be done with a microcontroller or any other compute device. In the final section of this demonstration, we will discuss some of the additional considerations for a similar setup in an actual industrial setting.\nSchematic of the architecture we are building in this demonstration. Note the two-way communication between IoT Core and our thing.  Connecting to AWS IoT and publishing messages were covered in the previous demonstration. In this demonstration, we focus on subscribing to messages and combining publishing and subscribing within one client.\nRegistering the Sensor in IoT Core Just as it is the case with publishing, we need to register the device that will subscribe to messages. We can use the same thing and certificate as in the previous demonstration, but we need to change the policy to allow subscription through using that certificate. For subscription to work, we need to add two additional statements to the policy. We need to allow iot:Subscribe to a topic filter and allow iot:Receive for a specific topic. The distinction between topic and topic filter can seem nebulous, but imagine a manufacturing line with hundreds of sensors publishing to topics with the prefix factoryA/line22. Then we might create a policy that allows subscription to all the topics factoryA/line22/*, where the asterisk is a wildcard, and policies that allow receiving of messages to specific topics such as factoryA/line22/milling/torque. Here is an example of such a policy document that allows subscription and receiving to a single topic.\n{ \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Publish\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/temperature\u0026quot;, \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/pressure\u0026quot;, \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/humidity\u0026quot;, \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/actions\u0026quot; ] }, { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Receive\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/actions\u0026quot; ] }, { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Subscribe\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:topicfilter/bme680/actions\u0026quot; ] }, { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Connect\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:client/simple-subscribing\u0026quot; ] } ] }  This is the actual policy document for the following examples. It might seem like we are repeating the same thing many times, but there is a good reason for it. The subscription action is only checked whenever a client connects to AWS, whereas the receive policy is checked each time a message is sent. This means that we have the option to disallow messages from a specific topic to devices using this certificate, even if they are already subscribing to the topic.\nSubscribing to Topics Like publishing, subscribing can be done with just one line of code. We just need to call the .subscribe() function of the MQTT client.\nAWSIoTMQTTClient.subscribe(topic, 1, callback_function)  The first argument is the topic to listen to. Note that the certificate provided to the client must have a policy that allows subscription to that specific topic.\nThe second argument is the Quality of Service, just as for publishing, 0 means that the message is delivered at most once and 1 means at least once. Remember that now the roles are reversed, and the client we are configuring is the one that will receive the message have to send a confirmation of a message received. Fortunately that is all taken care of behind the scenes in the client we are configuring.\nThe third argument is a custom function that is called whenever a message is received on the topic. This function should follow the pattern callback_function(client, userdata, message). message will then be an object containing the topic, message.topic, and the body, message.payload, of the message. The two variables client and userdata are there for compatibility of the callback stack; they are flagged for deprecation, and it is not recommended to rely on them. The simplest thing to do when receiving a message, save for doing nothing at all, would be to print the message. Such a function might look like this\ndef callback_function(client, userdata, message): print(\u0026quot;Received a new message:\\n{0}\u0026quot;.format(message.payload)) print(\u0026quot;from topic:\\n{0}\u0026quot;.format(message.topic))  In the next section, we will use this function to do cool things.\nThe subscription can be set up as soon as connection between the client and AWS IoT is established. The client will then listen for any published messages for as long as it lives or until the subscription is terminated. This also means that we do not have to implement an infinite loop like during publishing.\nWith this, we have everything needed to set up a subscription:\n# Configure client and connect myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId) myAWSIoTMQTTClient.configureEndpoint(host, port) myAWSIoTMQTTClient.configureCredentials(rootCAPath, privateKeyPath, certificatePath) myAWSIoTMQTTClient.configureAutoReconnectBackoffTime(1, 32, 20) myAWSIoTMQTTClient.configureOfflinePublishQueueing(-1) # Infinite offline Publish queueing myAWSIoTMQTTClient.configureDrainingFrequency(2) # Draining: 2 Hz myAWSIoTMQTTClient.configureConnectDisconnectTimeout(10) # 10 sec myAWSIoTMQTTClient.configureMQTTOperationTimeout(5) # 5 sec myAWSIoTMQTTClient.connect() time.sleep(2) # Define what happens when messages are received def callback_function(client, userdata, message): print(\u0026quot;Received a new message:\\n{0}\u0026quot;.format(message.payload)) print(\u0026quot;from topic:\\n{0}\u0026quot;.format(message.topic)) # Subscribe AWSIoTMQTTClient.subscribe(topic, 1, callback) # Wait for messages to arrive while True: time.sleep(5)  A full working example can be found here. We run the script from a terminal on the Pi:\npython simple_subscribing.py -e \u0026lt;your aws iot endpoint\u0026gt; -r \u0026lt;file containing root certificate\u0026gt; -c \u0026lt;file containing device certificate\u0026gt; -k \u0026lt;file containing private key\u0026gt; -id \u0026lt;a client ID\u0026gt; -t \u0026lt;the topic to subscribe to\u0026gt;  Nothing happens before we start publishing messages to our topic of choice. I ran the example on my Pi, using the topic /bme680/actions. I then moved to the test suite at AWS IoT Core \u0026gt; Test, and published a message to that topic.\n The console output on the Pi then looks like this:\nReceived a new message: { \u0026quot;message\u0026quot;: \u0026quot;Hello from AWS IoT Console\u0026quot; } from topic: bme680/action  Congratulations! You now know how to subscribe to a topic using the AWS IoT Python SDK. The real power of subscription, however, lies in combining it with publishing. In the next section, we will build a small example of how to use subscription with publishing to great effect.\nA Subscription Example In the case of simple publishing, we were getting temperature readings from the BME680 sensor and published them to AWS IoT. However, the BME680 sensor is also able to measure relative humidity and air pressure. In real life we would want to use this expensive sensor to measure all three at once, but for this case we are going to build a way for us to remotely toggle between measuring these three variables. We will set up a subsription that listens to commands published on a specific topic. We will then use the content of that message to change which variable is measured and published by the device and sensor.\nFirst we will choose our topics. We will publish on three different topics depending on the variable that we are measuring.\nbme680/temperature bme680/pressure bme680/humidity  In addition to this, we will reserve a topic for publishing actions to our device.\nbme680/action  Imagine now that we will publish messages on this topic telling the device what to do. For instance, we might send the message\n{ \u0026quot;action\u0026quot;:\u0026quot;pressure\u0026quot; }  telling the device to switch to measuring pressure and publish on the appropriate topic. Publishing this message will be simple enough using the AWS IoT test suite, but we need to code up the response behaviour first. To this end, we will use the callback function\ntopic = None variable = None def callback_function(client, userdata, message): payload = json.loads(message.payload) global pubtopic global variable if \u0026quot;action\u0026quot; not in payload: topic = None variable = None else: if payload[\u0026quot;action\u0026quot;] == \u0026quot;temperature\u0026quot;: topic = \u0026quot;bme680/temperature\u0026quot; variable = \u0026quot;temperature\u0026quot; elif payload[\u0026quot;action\u0026quot;] == \u0026quot;pressure\u0026quot;: topic = \u0026quot;bme680/pressure\u0026quot; variable = \u0026quot;pressure\u0026quot; elif payload[\u0026quot;action\u0026quot;] == \u0026quot;humidity\u0026quot;: topic = \u0026quot;bme680/humidity\u0026quot; variable = \u0026quot;humidity\u0026quot; else: topic = None variable = None  We will then use these global variables to adjust what variable we get from the sensor before publishing.\nwhile True: if sensor.get_sensor_data(): # Get the value currently toggled value = None if variable = \u0026quot;temperature\u0026quot;: value = sensor.data.temperature elif variable = \u0026quot;pressure\u0026quot;: value = sensor.data.pressure elif variable = \u0026quot;humidity\u0026quot;: value = sensor.data.humidity elif: value = None message = {} message['value'] = value message['variable'] = variable message['timestamp_utc'] = datetime.utcnow().strftime(\u0026quot;%Y-%m-%dT%H:%M:%S.%fZ\u0026quot;) message['status'] = \u0026quot;success\u0026quot; messageJson = json.dumps(message) # This is the actual publishing to AWS myAWSIoTMQTTClient.publish(topic, messageJson, 1) print('Published topic %s: %s\\n' % (topic, messageJson)) loopCount += 1 else: message = {} message['value'] = None message['timestamp_utc'] = datetime.utcnow().strftime(\u0026quot;%Y-%m-%dT%H:%M:%S.%fZ\u0026quot;) message['status'] = \u0026quot;fail\u0026quot; messageJson = json.dumps(message) # This is the actual publishing to AWS myAWSIoTMQTTClient.publish(topic, messageJson, 1) print('Published topic %s: %s\\n' % (topic, messageJson))  The whole script is here. When run, it will start to listen to the topic subscibed to. Once it receives a message with instructions it will start querying the sensor as instructed and publish. This way we can toggle between different sensors and even shut off messages when we do not need them and thus save money.\nThis might not be exactly the thing that you want your device to do, but now you have the building blocks to create whatever response you want. As a challenge, why not try to set up a topic that controls how often values are published from the device? With such functionality, you could adjust the tradeoff between storage cost and data granularity over time.\nIn Production Besides the considerations mentioned in the previous demonstration, a few additional considerations apply now that we are able to establish two way communication with our devices in the IoT.\nApplications First the fun part. What might we actually do with this added capability?\nAlternate data frequency If we store and process less data, it will cost us less but will also give the data scientists less of that precious data paydirt. We might want to change the frequency of the data according to current business priorities. We will almost definitely want to change the rate to respond to the process. A simple on/off switch for when the process is not running will work wonders. I would, however, love to see a combined IoT and analytics application that chooses the sampling frequency based on variance in the data and automatically adjusts sampling accordingly.\nHave an equipment-debugging mode The idea of a debugging mode is common in digital applications. IoT means brining the digital world to our physical equipment. Imagine having a debugging mode for our manufacturing equipment. Specifically, this could be a toggleable mode with telemetry from additional sources and at a high frequency.\nRespond to low-frequency changes Control loop managed by PLCs do a great job of keeping a process in control and running smoothly and continuosly. One thing they do not do, however, is respond well to low frequency changes and business-induced changes. Think of a batch changeover or the change between product variants - it takes time and effort to get the equipment running smoothly again. If we have actuating devices as part of the IoT we can start having our manufacturing equipment respond to business priorities or just deal with changes that the PLC does not consider. An example could be an automatic change of settings on a change of product variant according to the predictions of a simulation or a model.\nSecurity If you are in manufacturing or some other regulated context, it might sound scary to have a two way communication between your site and the cloud. In all fairness, this could pose a security risk, the magnitude of which depends on the extent of the liberties given to the IoT and connected applications. As developers, there are a number of considerations we can make to increase the robustness of the IoT and lessen the burden on ourselves when we maintain the application. This is by no means a full list, but just a few obvious starting points.\nDo not couple control loop and IoT The end goal of our IoT application might be a kind of outer automation that responds to rare changes and optimises business parameters, but coupling our IoT with quality critical process control might not be a good idea, at least right away. Remember that even though our vision camera is not directly connected to our gateway device, we might still be able to get that delicious data by reading it from a database associated with the vision system.\nLimit the power of actions Should someone with malicious content get access to publishing to a topic that initiates actions in the our gateway devices they will only be able to cause as much damage as we allow.\nFor one of my first setups, I made my device run any bash command sent from the cloud. This is a fun exercise, but probably a bad idea in a real manufactuing setting.\nTopic management One thing, I have found useful is to use seperate topic hierarchies for topics that are intended for publishing data and topics that are intended for triggering work or actions.\nWe have previously discussed using hierarchies of topics to structure data published from a manufacturing site. If we have a topic hierarchy like factoryA/line22/milling/torque, it might be tempting to make the action topic something like factoryA/line22/milling/action. This could be a bad idea, since it is easy to create a policy like factoryA/line22/* that allows access to publishing and action topics. If instead we make topics like action/factoryA/line22/milling then at least it is more difficult to make policy mistakes while still keeping some of the hierarchical structure.\nEven without considering mistakes, poor topic management can quickly create a weak spot for our IoT both in terms of security and developer friendliness. AWS does not manage our topics, so we need to do it. That being said, the AWS Device Shadow functionality might just be what we need to make this much simpler. Fortunately, Shadows are the subject of the next demonstration.\nRead about security best practices AWS documentation is quite extensive and has better explanations and recommendations for security than I could ever conceive. Make sure to stay on top of current security best practices.\n","date":1592265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592265600,"objectID":"cc27f66a0a99aeb162f9e6d0d8865879","permalink":"/post/iot-poc-pubsub/","publishdate":"2020-06-16T00:00:00Z","relpermalink":"/post/iot-poc-pubsub/","section":"post","summary":"In this tutorial, we will take a closer look at the pub/sub model of MQTT and demonstrate its usefulness by having a sensor publish data and change behaviour in response to subscribed messages.","tags":["IoT","Data","Data Engineering"],"title":"Publishing and Subscribing with AWS IoT","type":"post"},{"authors":null,"categories":null,"content":"In this tutorial, we will obtain a value from a sensor and publish it to a topic on AWS. No added shenanigans; this is as simple as it gets.\nAt the core of it, we want to grab a reading from the sensor, wrap it in a message with some useful metadata, and publish that to AWS IoT. We will program all the logic into a Python script that runs continuosly on a loop. Our script should end up being structured somewhat like this:\nPrepare the sensor Set up connection to AWS while true get a sensor reading pack it up publish it  For the demonstration we will be using the Bosch BME680 air quality sensor connected to a Raspberry Pi 3 model B+. The BME680 does four different measurements, but for this case we will only be measuring and publishing the temperature. The Pi is just there to query the sensor and run Python script with the AWS IoT SDK. It essentially plays the part of a microcontroller, and so anything we accomplish here can be done with a microcontroller or any other compute device. In the final section of this demonstration we will discuss some of the additional considerations for a similar setup in an actual industrial setting.\nSchematic of the architecture we are building in this demonstration and a picture of the actual hardware I used for developing.  Registering the Sensor in IoT Core Before we can start connecting a sensor to AWS, we need to register the sensor or system as a so-called Thing in AWS IoT Core. The AWS docs have a getting started guide which is pretty good. Follow the guide, but at the end of it, we should have the following:\n A device certificate file A private key file The root certificate file In the policy we attached to the certificate, we have allowed publishing from an ID and to a topic that we can remember  The three files should be installed on the controller device. In this case, that just means the files should be in accessible place on the Raspberry Pi. The ID will be used as clientID for the MQTT client that we will use to connect to AWS IoT later, and the topic is a flag that helps us direct data along the right path. We will discuss both of these concepts in detail below.\nThe policy used for the examples follows this pattern:\n{ \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Publish\u0026quot;, \u0026quot;iot:Receive\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/temperature\u0026quot; ] }, { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Connect\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:client/simple-publishing\u0026quot; ] } ] }  Setting up the SDK We will do scripting for this case using Python. AWS IoT currently has two SDKs for Python. For this case we will use version 1, which is easily installed using pip:\npip install AWSIoTPythonSDK  The AWS IoT code below should work for any version of Python, but the interaction with the BME680 sensor is written with Python 3.7 and would need tweaks to work with earlier versions.\nPublishing to AWS IoT Now we are ready to get started on developing with the SDK.\nPublishing a message to AWS using the Python SDK will look something like this\nAWSIoTMQTTClient.publish(topic, messageJSON, 1)  The AWSIoTMQTTClient is the object that we will use to configure and establish the connection to AWS IoT Core. The .publish() method publishes the message and takes three arguments: the topic to publish to, the message to be sent, and a Quality of Service (QoS) flag. Lets look at each of these in turn.\nTopics Messages in AWS IoT are distributed and filtered using topics. Topics are a kind of tag that we can use to identify the source of the message and distribute it accordingly. It is just a single string, generally in the format\nmain_tag/secondary_tag/tertiary_tag/etc  For instance, if we had several factories each with several manufacturing lines with several stations each eqipped with sensors, we might do something like\nfactoryA/line22/drying/temperature  and then have another sensor on the same line publish to\nfactoryA/line22/milling/torque  That way we can direct these messages to the store or dashboard for the same line but seperate lambda functions, if that is needed for our application.\nAn IoT thing needs permission to publish to a specific topic. This is done by adding a certificate with a permissive policy to the thing. By using the topic naming convention above and wildcards in the policy, we can create hierarchies and differentiated permissions for things in different parts of our application or factory setup.\nNow, for this demonstration example, we only have four sensors, and really we will only use one of them, so we will go with a simple topic. Like, say,\nbme680/temperature  We will dive deeper into topics in the next demonstrations, but for now we will leave it at this simple one.\nMessage The message contains the actual data along with any metadata. It is structured as a JSON and we can put whatever we want in there, but we will want the data point, a timestamp for the time of sampling, and maybe an idication whether the reading was succesful or not. In our script, we will structure the message to look something like this, when the sensor reading is successful\n{ \u0026quot;utc_timestamp\u0026quot;: 1581417910, \u0026quot;value\u0026quot;: 23.6, \u0026quot;origin\u0026quot;: \u0026quot;BME680 temperature\u0026quot;, \u0026quot;status\u0026quot;: \u0026quot;success\u0026quot; }  Quality of Service (QoS) The messages are published to AWS using the MQTT protocol. This is a protocol commonly used in manufacturing systems, and is documented online. The AWS flavour of MQTT is a slightly simpler implementation of the protocol.\nAs for Quality of Service (QoS), it is a flag specifying what happens when messages get lost in the network. The AWS flavour of MQTT accepts two QoS flags. The flag 0 means that the message is delivered to subsrcibers \u0026lsquo;at most once\u0026rsquo;. The flag 1 means that the message is delivered to subsribers \u0026lsquo;at least once\u0026rsquo;. So for QoS=0 the publisher will send the message once and then forget about it. If it does not get delivered, it is lost. For QoS=1, however, the message is sent, and the publisher then waits for a reply from the subscriber before forgetting the message, and resends if neccessary. This ensures that the subscriber gets the message at least once.\nNow, there are cases where QoS=0 is sufficient, but for this case we will use QoS=1.\nConnecting to AWS IoT Before we can publish a message, we need to set up and configure the connection to AWS IoT. For this, we are going to need many small bits of information. Let us start by setting up the client.\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient # Initialise client myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId)  First of all, we are giving our client a client ID. This ID is used by the message broker to recognise the specific client or application that it is communicating with. This is especially importtant when we start subscribing to topics as well. For now, we just provide an ID allowed by the policy that we made earlier.\nNext up we will setup the networking specifics.\nmyAWSIoTMQTTClient.configureEndpoint(host, port) myAWSIoTMQTTClient.configureCredentials(rootCAPath, privateKeyPath, certificatePath)  We are specifying where the MQTT messages are going and how they are authenticated. The host is our AWS IoT custom endpoint which we can find in the AWS Console under IoT Core \u0026gt; Settings. As for the port we will use the default 8883 for MQTT with the X.509 client certificate.\nThis brings us to the next order of business; certificates. The certificates are the ones we downloaded to our device earlier. We simply provide strings with the paths to each of these certificates; the root certificate file, the private key file, and finally the device certificate file.\nNext, we configure what happens when connection between the client and the broker on AWS IoT is lost.\nmyAWSIoTMQTTClient.configureAutoReconnectBackoffTime(1, 32, 20) myAWSIoTMQTTClient.configureOfflinePublishQueueing(-1) # Infinite offline Publish queueing myAWSIoTMQTTClient.configureDrainingFrequency(2) # Draining: 2 Hz myAWSIoTMQTTClient.configureConnectDisconnectTimeout(10) # 10 sec myAWSIoTMQTTClient.configureMQTTOperationTimeout(5) # 5 sec  With .configureAutoReconnectBackoffTime(1, 32, 20) we are telling the client to try to reconnect every 1 seconds after losing connection. If connection keeps being lost, for instance under poor networking conditions, this is exponentially increased to a maximum of every 32 seconds. This is to prevent having too many connection requests which would make the network conditions even worse. If connection is maintained for more than 20 seconds, the reconnect interval is reset to 1.\nNext we are telling the client to keep all untransmitted messages while connection is lost by setting .configureOfflinePublishQueueing(-1). If any other number is passed, this is the number of messages kept.\nWhen connection is reestablished, we will want to send off any kept messages, but not all at once. With .configureDrainingFrequency(2) we are telling the client to send one queued message every 2 seconds.\nIn a moment, we will connect the client, by sending a connect request to the broker on AWS IoT. The client will then expect an acknowledgement of the request, but we do not want to wait forever. .configureConnectDisconnectTimeout(10) tells the client to wait a maximum of 10 seconds before timing out.\nEarlier we decided to use QoS=1. This will only work if the server acknowledges any message sent. If that does not happen we will also want a timeout .configureMQTTOperationTimeout(5) means that we will wait 5 seconds for that acknowledgement.\nNow, all that remains is to attempt the connection.\n# Connect to AWS IoT myAWSIoTMQTTClient.connect()  Bringing it all together Here is our bare-bones script for connecting and publishing to AWS IoT.\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient import time # We will just hardcode the default port here, you might want a different one port = 8883 # default # Initialise the AWS IoT MQTT client myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId) myAWSIoTMQTTClient.configureEndpoint(host, port) myAWSIoTMQTTClient.configureCredentials(rootCAPath, privateKeyPath, certificatePath) # Configure the client myAWSIoTMQTTClient.configureAutoReconnectBackoffTime(1, 32, 20) myAWSIoTMQTTClient.configureOfflinePublishQueueing(-1) # Infinite offline Publish queueing myAWSIoTMQTTClient.configureDrainingFrequency(2) # 2 Hz myAWSIoTMQTTClient.configureConnectDisconnectTimeout(10) # 10 sec myAWSIoTMQTTClient.configureMQTTOperationTimeout(5) # 5 sec # Connect to AWS IoT myAWSIoTMQTTClient.connect() time.sleep(2) # Publish to the same topic in an eternal loop loopCount = 0 while True: message = {} message['sequence'] = loopCount message['timestamp_utc'] = datetime.utcnow().strftime(\u0026quot;%Y-%m-%dT%H:%M:%S.%fZ\u0026quot;) # Value and any other data needed here messageJson = json.dumps(message) # This is the actual publishing to AWS myAWSIoTMQTTClient.publish(topic, messageJson, 1) loopCount += 1 time.sleep(5)  The script simple_publishing.py is a full working example using the BME680 sensor. It can be called as follows\npython simple_publishing.py -e \u0026lt;your aws iot endpoint\u0026gt; -r \u0026lt;file containing root certificate\u0026gt; -c \u0026lt;file containing device certificate\u0026gt; -k \u0026lt;file containing private key\u0026gt; -id \u0026lt;a client ID\u0026gt; -t \u0026lt;the topic to publish to\u0026gt;  Running the Case Running this script on a Pi with the BME680 sensor, when it is working, it should look like this\nPublished topic bme680/temperature: {\u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;timestamp_utc\u0026quot;: \u0026quot;2020-02-15T16:43:16.226983Z\u0026quot;, \u0026quot;value\u0026quot;: 21.57999999999999, \u0026quot;sequence\u0026quot;: 25} Published topic bme680/temperature: {\u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;timestamp_utc\u0026quot;: \u0026quot;2020-02-15T16:43:17.348050Z\u0026quot;, \u0026quot;value\u0026quot;: 21.57999999999999, \u0026quot;sequence\u0026quot;: 26} Published topic bme680/temperature: {\u0026quot;status\u0026quot;: \u0026quot;success\u0026quot;, \u0026quot;timestamp_utc\u0026quot;: \u0026quot;2020-02-15T16:43:18.519356Z\u0026quot;, \u0026quot;value\u0026quot;: 21.57999999999999, \u0026quot;sequence\u0026quot;: 27}  But the most interesting part, of course, is whether the data gets to AWS. Let us say that we published to the topic BME680/temperature. We can open the AWS Console, go to IoT Core, and find the Test tab. Here we can subscribe to a topic. When we type in the topic BME680/temperature,\n We get the messages sent from the Pi.\n Congratulations, you are now publishing to AWS IoT! From here the messages can be redirected to whereever you want using AWS SQS, SNS, or Kinesis.\nIn Production This section is not part of the demonstration as such. It is but a short discussion of some of the considerations we have to take when bringing an IoT device to production in a manufacturing environment and how to improve upon the example to make it production ready.\nHardware Setup In real life, would we fire up a Raspberry PI running Python just to extract and publish data from a single sensor? No, probably not. In a real life setting, if we just wanted to publish data from a single sensor, we might use a microcontroller instead. On the other hand, if we are in an industrial setting and have hundreds of sensors that we want to query and publish, a Raspberry Pi will not be enough. Instead we might want to use proper gateway devices and controller modules. There are multiple options and suppliers of this type of hardware components, and which we choose all depends on our specific requirements for ease of installation, configurability, and data quality.\nNo matter what kind of hardware we have, our gateway device still needs to run some bit of software that gathers and publishes data to consumer applications. Many hardware suppliers also offer proprietary data feeders and even analytics, but now you know how to write your own simple data feeder using the AWS IoT SDK for Python.\nScript Improvement The focus for this demonstration was to demonstrate how to quickly get started publishing data to AWS IoT core with no added frills. Whether we use a microcontroller or a large server as our gateway device, we will want a bit more functionality for our script. Here are a few examples of what additional considerations we might take before deploying the device to production.\nLogging All sorts of expected and unexpected stuff will happen in production, and it is at least nice to have logs telling us what happened. The AWS IoT SDK actually comes with a sample script containing an example of logging:\nimport logging logger = logging.getLogger(\u0026quot;AWSIoTPythonSDK.core\u0026quot;) logger.setLevel(logging.DEBUG) # You might want to pass logging level to your script streamHandler = logging.StreamHandler() formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') streamHandler.setFormatter(formatter) logger.addHandler(streamHandler)  We would also add logging for the interaction with our sensor(s).\nError Handling Besides logging loggging unexpected events, we might also want to automatically handle some of them and avoid crashes that need manual attention. In the example we created above, two parts in particular are susceptible to errors; connecting the MQTT client to AWS and querying the sensor.\nThe connection might fail for several reasons, but a common one is that multiple devices try to reconnect at the same time after a restart of the process they are monitoring. In this case, nothing is wrong as such, and we can just have the devices retry the connection. We will want to introduce a bit of randomness into that process to avoid creating another bottleneck. An elegant way to implement such retrying is with progressive backoff logic, and the AWS IoT SDK actually includes a module to do just that.\nIn the example script, whenever we fail to retrieve a value from my BME680 air quality sensor, we just generate a message with a None value. Depending on the specific application, we might want to do something different. In another demonstration, we will have a look at implementing a Shadow for our device. The Shadow can act as an intermediary between the data feed and an application, ensuring that simulations and machine learning models always have the latest readings, while the live data feed contains the full diversity of values and failed readings.\nRemote Configuration One challenge we face when creating new data streams is specifying what data we need and how often we want to sample it. The dilemma is that we do not want to store too much data that will not be used but, on the other hand, to create good simulations or models, we need a good bit of historical data. What strategy to pursue is a business question but it behooves us as developers to allow for flexibility and build dials that allow us to adjust the tradeoff between cost and data quality/quantity. So let us think of an example of this.\nAt the end of the publishing loop, we tacitly added a line, time.sleep(5), that ultimately determines how often we query our sensor and publish the data. If we double that time, we halve the amount of data and potentially also halve our expenses for data storage on this variable. Before the applications are in place, however, it is not really clear how often we would like to sample. We can make an educated guess to get it started but, at the end of the day, we want to be able to change it. So it seems a poor idea to hardcode it like we did for this example. Indeed, for the next demonstration we will explore how to develop a dynamic device that can be configured remotely.\nDevice Lifecycle During the demonstration, we manually provisioned certificates for our device and started the script from the command line. For production purposes, especially if we have hundreds of devices, we might want to have a more rigid device lifecycle.\nStart up and restarts In a production setting, we will not want to go and restart the script manually each time there is an issue or our device restarts. This obviously becomes more relevant as the number of devices increases. If our gateway device runs Linux, we can just create a custom process to run our data feeder script as a service on boot. For a large fleet of devices we might want to consider introducing some randomness into the intitial connection requests to prevent a situation where all devices attempt to reconnect simultaneously after an outage.\nCertificates and security It is possible to get more advanced about provisioning certificates for devices. At the very least, we will want to script the provisioning process.\nEven when securely provisioned and deployed, it is still important to consider the security of the certificates. The certificates effectively allow some interaction with our AWS account and should an ill intentioned actor acquire access to these certificates they effectly gain free access to that functionality. AWS best practice is to use least privilege policies.\n","date":1592265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592265600,"objectID":"20253f5a8a1ee56328f81283f2f863e3","permalink":"/post/iot-poc-publishing/","publishdate":"2020-06-16T00:00:00Z","relpermalink":"/post/iot-poc-publishing/","section":"post","summary":"In this tutorial, we will obtain a value from a sensor and publish it to a topic on AWS.","tags":["IoT","Data","Data Engineering"],"title":"Publishing Industrial Data with AWS IoT","type":"post"},{"authors":null,"categories":null,"content":"On its own, a Thing Shadow might not look like much or even that useful. It certainly is an extra layer of complexity on top of publishing and subscribing. Shadows are, however, the foundation on which we can build Digital Twins and are an almost neccessity for applications that run machine learning models on IoT data.\nSo what exactly is the Shadow of a thing? In a moment we will dive into the technical details, but we can think of a Shadow as an entity that has the same abilities as a thing, it can send and receive messages, except that it is always an exact copy of the latest state of the thing. If the thing goes offline, the Shadow will still be there reporting the latest state. A Shadow is purely a software construct, there is no hardware, but it can live in the cloud, on the edge, or both.\nBefore we get started, it should be said that the documentation for Shadows is quite good and definitely worth a read. Instead of repeating the documentation, we will expand on the previous demonstrations of publishing and subscribing with AWS IoT and MQTT messages, to include a cloud based Shadow of our thing, the BME680 sensor. That is, we will not exemplify all of the Shadow functionality, rather we will get started using Shadows with an example that is as simple in functionality as possible. Once we are done with this case, we will have come far enough to start understanding how advanced functions and applications work.\nWe will try to do build a thing that does something along the lines of\nPrepare the sensor Set up connection to AWS while true get a sensor reading update the Shadow publish the reading confirm that the Shadow was updated  We will then look at the Shadow document using the AWS IoT test functionality.\nSchematic of the architecture we are building in this demonstration.  Basics of Device Shadows The Shadow of a thing is a JSON document containing predetermined fields. All devices registered in AWS IoT are given the Shadow functionality by default, though the JSON is only generated the first time the Shadow is updated. An example of a Shadow document could be\n{ \u0026quot;state\u0026quot;:{ \u0026quot;reported\u0026quot;:{ \u0026quot;value\u0026quot;: 27.87 } }, \u0026quot;metadata\u0026quot;:{ \u0026quot;reported\u0026quot;:{ \u0026quot;value\u0026quot;:{ \u0026quot;timestamp\u0026quot;:1583755496 } } }, \u0026quot;version\u0026quot;:4, \u0026quot;timestamp\u0026quot;:1583755643 }  Let us walk through each of the fields one at a time.\nstate holds the current values of the thing. The reported field should hold the current values as reported by the device itself. It can hold any number of reporting fields and a field can be an array.\nBesides reported the state field can also hold a desired field which can hold desired values as requested by an application or another device. This could be useful if we were doing a case with automation or maybe a home IoT project.\nThis could be the state of a thing consisting of a valve and a flow meter where an application or maybe a user has just requested a new state:\n{ \u0026quot;state\u0026quot;:{ \u0026quot;reported\u0026quot;:{ \u0026quot;flow\u0026quot;: 15.04, \u0026quot;valve_state\u0026quot;: \u0026quot;open\u0026quot; }, \u0026quot;desired\u0026quot;:{ \u0026quot;flow\u0026quot;: 0, \u0026quot;valve_state\u0026quot;: \u0026quot;closed\u0026quot; } } }  We will not use the desired field for this demonstration. We will just report the latest temperature of our Thing like this\n{ \u0026quot;state\u0026quot;:{ \u0026quot;reported\u0026quot;: { \u0026quot;temperature\u0026quot; : 21.6 } } }  The metadata field holds information on when each of the values in the state field were updated. The field follows the same schema as state and the information is given as a UTC timestamp, representing when the value was last updated.\nThe version field is a super useful feature. It is an integer that increases every time an update is made to the document, allowing applications and devices to know whether their local copy is the latest.\nThe timestamp field indicates the UTC timestamp of when the update was transmitted from AWS IoT.\nFields that are set to Null are deleted from the Shadow document rather than reporting the Null.\nThere are few additional features in Shadow document and they are neatly described in the developer guide. For now, we have all we need to get started.\nUpdate a Device Shadow Updating the Shadow of a device is done by sending a message to a specific topic. The topic is in the format $aws/things/yourDevice/shadow/update and depends on the name of the device registered in AWS IoT. If our device was called \u0026lsquo;factory3Airflow\u0026rsquo; then the topic would be $aws/things/factory3Airflow/shadow/update.\nThe update message might look something like this\n{ \u0026quot;state\u0026quot;: { \u0026quot;reported\u0026quot;: { \u0026quot;flow\u0026quot;: 2.6 } } }  Coding such a flow is quite similar to what we did for publishing, except the topic is a bit more elaborate. Assuming that the client ID is the same as the device name, we can configure a connection and start updating the Shadow like this:\n# Define neccessary topics topic_update = \u0026quot;$aws/things/\u0026quot; + clientId + \u0026quot;/shadow/update\u0026quot; # Configure connection to AWS IoT # ... # Keep updating the Shadow on an infinite loop while True: message = {} temperature = get_sensor_reading() message[\u0026quot;state\u0026quot;] = { \u0026quot;reported\u0026quot; : {\u0026quot;temperature\u0026quot; : temperature } } messageJson = json.dumps(message) # Update the Shadow myAWSIoTMQTTClient.publish(topic_update, messageJson, 1) time.sleep(30)  This is fine and all but how do we know that it works?\nSubscribing to Shadow Updates Whenever a Shadow is successfully updated, it generates and publishes a message to the topic $aws/things/yourDevice/shadow/update/accepted. Once again, the exact name changes based on our device name. By subscribing to this specific topic with QoS = 1, our device or application can recieve updates whenever there are changes to the Shadow.\nAnother useful topic to subscribe to is $aws/things/yourDevice/shadow/update/rejected. A message is published to this topic whenever an update fails and can thus provide excellent feedback for an application or for debugging.\nWe can subscribe to these topics just like we would any other topics. Again assuming that the client ID is identical to the device name, it might look something like this:\n# Define neccessary topics topic_update = \u0026quot;$aws/things/\u0026quot; + clientId + \u0026quot;/shadow/update\u0026quot; # Configure connection to AWS IoT # ... # Specify what to do, when we receive an update def callback_update_accecpted(client, userdata, message): # Just print the message print(\u0026quot;Got an update, on the topic:\u0026quot;) print(message.topic) print(\u0026quot;The message is this\u0026quot;) print(message.payload) # Specify what to do, when the update is rejected def callback_update_rejected(client, userdata, message): # Just print the message print(\u0026quot;The update was rejected. Received the following message:\u0026quot;) print(message.payload) # Subscribe myAWSIoTMQTTClient.subscribe(topic_update + \u0026quot;/accepted\u0026quot;, 1, callback_update_accepted) myAWSIoTMQTTClient.subscribe(topic_update + \u0026quot;/rejected\u0026quot;, 1, callback_update_rejected)  Policies for Shadows Before we move on to more Shadow related topics, we should take a look at the policies needed to allow devices and applications to utilise these special topics. Once again, the documentation is quite substantial and even provides specific examples for policies related to Shadow interaction. Here we will focus on constructing an example.\nImagine we have a device registered with the name my_sensor in AWS IoT. We would like to give the device access to establish a connection with AWS IoT, publish readings to the topic my_sensor/reading, update its Shadow, and subscribe to the accepted and rejected responses generated on Shadow update.\nWe already know how to construct statements to allow connection and publishing.\n{ \u0026quot;Statement\u0026quot;: [ { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Publish\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/my_sensor/reading\u0026quot; ] }, { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Connect\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:client/my_sensor\u0026quot; ] } ] }  To allow the desired Shadow interactions, we will add another resource to the publish action, mentioning the topic $aws/things/my_sensor/shadow/update:\n{ \u0026quot;Statement\u0026quot;: [ { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Publish\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/my_sensor/reading\u0026quot;, \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update\u0026quot; ] } ] }  To allow subscription we will add subscription and receive actions for two resources - one for each topic.\n{ \u0026quot;Statement\u0026quot;: [ { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Subscribe\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:topicfilter/$aws/things/my_sensor/shadow/update/accepted\u0026quot;, \u0026quot;arn:aws:iot:your-region:your-aws-account:topicfilter/$aws/things/my_sensor/shadow/update/rejected\u0026quot; ] }, { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Receive\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update/accepted\u0026quot;, \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update/rejected\u0026quot; ] } ] }  Given that the two subscription topics have the same root and that there are more update/ topics to subsrcibe to, it is tempting to add something along the lines of $aws/things/my_sensor/shadow/update/*, giving a wildcard for anything below the update root. While this would indeed work as intended now, AWS reserves the right to add additional reserved topics to the existing structure. If we were to use a policy with this type of wildcard, we thus risk allowing access to future topics causing unintended behaviour or information breaches. Therefore AWS discourages the use of wildcards in this way.\nOur final policy looks like this:\n{ \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Publish\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/my_sensor/reading\u0026quot;, \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update\u0026quot; ] }, { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Connect\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:client/my_sensor\u0026quot; ] }, { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Subscribe\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:topicfilter/$aws/things/my_sensor/shadow/update/accepted\u0026quot;, \u0026quot;arn:aws:iot:your-region:your-aws-account:topicfilter/$aws/things/my_sensor/shadow/update/rejected\u0026quot; ] }, { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: [ \u0026quot;iot:Receive\u0026quot; ], \u0026quot;Resource\u0026quot;: [ \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update/accepted\u0026quot;, \u0026quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update/rejected\u0026quot; ] } ] }  Simple Shadow Updating Now we have everything we need to build a full demonstration of Shadow interaction. We know that we can structure the interaction in exactly the same way as with regular publishing and subscribing but with two key differences. The first is that we will publish and subscribe to the specific Shadow topics. The second is that our published message follows the Shadow document schema. Here is an example; We can have our callback functions do whatever we want, but I just wrote out some simple print statements:\n# Define topic for updates topic_update = \u0026quot;$aws/things/\u0026quot; + clientId + \u0026quot;/shadow/update\u0026quot; # Configure connection to AWS IoT # ... # Specify what to do, when we receive an update def callback_update_accepted(client, userdata, message): # Just print the message print(\u0026quot;Got an update, on the topic:\u0026quot;) print(str(message.topic)) print(\u0026quot;The message is this\u0026quot;) print(str(message.payload)) # Specify what to do, when the update is rejected def callback_update_rejected(client, userdata, message): # Just print the message print(\u0026quot;The update was rejected. Received the following message:\u0026quot;) print(str(message.payload)) # Subscribe myAWSIoTMQTTClient.subscribe(topic_update + \u0026quot;/accepted\u0026quot;, 1, callback_update_accepted) time.sleep(2) myAWSIoTMQTTClient.subscribe(topic_update + \u0026quot;/rejected\u0026quot;, 1, callback_update_rejected) time.sleep(2) # Publish to the same topic in a loop forever while True: message = {} if sensor.get_sensor_data(): temperature = sensor.data.temperature else: temperature = None message[\u0026quot;state\u0026quot;] = { \u0026quot;reported\u0026quot; : {\u0026quot;temperature\u0026quot; : temperature } } messageJson = json.dumps(message) # Update the Shadow myAWSIoTMQTTClient.publish(topic_update, messageJson, 1) time.sleep(15)  The full working script is here. Remember that the clientID is assumed to be the name of the thing. We could register a thing called my_sensor in AWS IoT and give its certificate a policy like the one we developed above. Then we can run this script on our Raspberry Pi with the BME680 sensor. Like this:\npython3 shadow.py -e \u0026lt;your aws iot endpoint\u0026gt; -r \u0026lt;file containing root certificate\u0026gt; -c \u0026lt;file containing device certificate\u0026gt; -k \u0026lt;file containing private key\u0026gt; -id \u0026lt;a client ID\u0026gt;  With this, we are publishing the latest sensor readings directly to the Shadow and then regurgitating the message generated when the update is accepted or rejected. When it works, the output should look something like this:\nGot an update, on the topic: $aws/things/my_sensor/shadow/update/accepted The message is this b'{\u0026quot;state\u0026quot;:{\u0026quot;reported\u0026quot;:{\u0026quot;temperature\u0026quot;:35.48}},\u0026quot;metadata\u0026quot;:{\u0026quot;reported\u0026quot;:{\u0026quot;temperature\u0026quot;:{\u0026quot;timestamp\u0026quot;:1584104617}}},\u0026quot;version\u0026quot;:99,\u0026quot;timestamp\u0026quot;:1584104617}'  If your setup is not working, make sure to check exactly which component is failing. If you are getting errors in the connection part, check whether your keys are for the right certificate and whether the certificate is activated. If you are getting an error in the subscription or publishing parts, check whether your policy gives the right accesses. Finally, you should not get any messages on the /update/rejected subject. If you do, one possible reason is that the message follows a wrong format.\nMore Shadow Topics Congratulations! You now know how to set up a Shadow for your device and you are ready to start building the foundation for your digital twin application. There are, however, a couple of extra details that you might want to know about before you start building the application.\nGet the Shadow If our application just listens to the /update/accepted we will have achieved nothing more by going through the Shadow compared to just plain publishing. The real power of Shadows is in always having the latest reading from our device available, while decoupling the device and the application.\nNow that we are having the device update its Shadow each time a new reading is available, we can start having our application access that Shadow document whenever it needs it. We can always view the Shadow document of our thing by going to AWS IoT \u0026gt; Manage \u0026gt; Things, then selecting our device and go to the \u0026lsquo;Shadow\u0026rsquo; tab\n This is nice for demonstration and debugging purposes, but our application needs to access the document programatically. The MQTT protocol does not do requests, and operates using the publish and subscribe model only. So the way for our application to request the Shadow document on demand is to publish a request to a specific topic and subscribe to a response topic. Note that there is an alternative based on a REST API, which we will discuss in a section below, but for now we will stick to the MQTT way. By sending an empty request, {}, to the topic $aws/things/yourDevice/shadow/get our application can trigger the Shadow to publish a copy of the current Shadow document to the subject $aws/things/yourDevice/shadow/get/accepted. The easiest way to see it in action is by subscribing to the $aws/things/yourDevice/shadow/get/# topicfilter in the test console and then publish an empty message to /get. I gave it a try here\n This is also an excellent opportunity to explore what happens, when we do something unexpected. Here I published a string instead of a JSON, for instance:\n The /get topic also has a /rejected subtopic that gives helpful error messages when requests are rejected.\nDelete the Shadow We now know how to update and get the Shadow document. Now we just need to know how to delete it. By publishing an empty message to the topic $aws/things/yourDevice/shadow/delete we delete the Shadow document for yourDevice. On successful deletion, a confirmation is published to /delete/accepted and a message is published to /delete/rejected otherwise. Let us try to delete the Shadow, then try to get it, and see what happens:\n  We get an error message because there is no Shadow document to get.\nShadow MQTT Topics Summary In summary, all Shadow interaction topics are prefixed with $aws/things/yourDevice/shadow where yourDevice is the ID of our thing as registered in AWS IoT. We interact with the Shadow in three ways: we can update the Shadow, get the Shadow, or delete the Shadow. These functions are triggered when messages are published to the topics /update, /get, or /delete repectively. When the actions succeed, messages are published to the /accepted subtopic. When the actions fail, messages are published to the /rejected subtopic with useful information for debugging.\nNot covered in this demonstration are the /update/document and /update/delta topics. The docs have more about Shadow interaction topics along with sample example policies.\nThe Shadow Client Depending on the apllication and how we manage topics, it might be easier to use the special Shadow client that is included in the SDK. The Shadow client, once configured, takes care of publishing and subscribing to the right topics. That is, it does exactly what we did above but with fewer lines of code and without us having to state the topics explicitly.\nThe client is configured and connected like any other MQTT client:\nfrom AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTShadowClient myAWSIoTMQTTShadowClient = AWSIoTMQTTShadowClient(clientId) myAWSIoTMQTTShadowClient.configureEndpoint(host, port) myAWSIoTMQTTShadowClient.configureCredentials(rootCAPath, privateKeyPath, certificatePath) myAWSIoTMQTTShadowClient.configureAutoReconnectBackoffTime(1, 32, 20) myAWSIoTMQTTShadowClient.configureConnectDisconnectTimeout(10) myAWSIoTMQTTShadowClient.configureMQTTOperationTimeout(5) myAWSIoTMQTTShadowClient.connect()  Now we create a handler, that takes care of the publishing and subscribing. All we have to do is pass it the name of the Thing, which we will assume is the same as the client ID:\n# Handles publishing and subscribing to Shadow topics # Persists subscription deviceShadowHandler = myAWSIoTMQTTShadowClient.createShadowHandlerWithName(clientID, True)  The handler will subscribe to the response topics from the Shadow. By setting the second argument to True, we are telling the handler to persist the subscription, i.e. not close the subscription when a response is received. Depending on the application, it might be neccessary to close the subscription once a response is received. But since we only have one client interacting with the Shadow in our case, we can safely persist the subscription and avoid resubscribing every time we send an update.\nAs with every other subscription, we need to tell the client what to do when a message is received with a callback function. The callback function is provided to the handler when we perform an update, but before we get there we need to actually define a function. The callback function for a Shadow client looks a bit different from the callback functions we saw for regular subscribing. It has a payload object, which contains the Shadow document, assuming that the update is accepted. It then has a responseStatus string, which can be either \u0026quot;timeout\u0026quot;, \u0026quot;accepted\u0026quot;, or \u0026quot;rejected\u0026quot; depending on how the update event went. Finally there is a token which can be used to trace the request, but we will not discuss it here. Here is an example of a callback function for an update request.\nimport json def shadow_callback_update(payload, responseStatus, token): if responseStatus == \u0026quot;timeout\u0026quot;: print(\u0026quot;The update request timed out.\u0026quot;) if responseStatus == \u0026quot;accepted\u0026quot;: payloadDict = json.loads(payload) print(\u0026quot;The update request was accepted, here is the new state:\u0026quot;) print(payloadDict[\u0026quot;state\u0026quot;]) if responseStatus == \u0026quot;rejected\u0026quot;: print(\u0026quot;The update request was rejected.\u0026quot;)  Finally, we can start updating the Shadow. The message still has to follow the Shadow document syntax:\nwhile true: message = {} temperature = get_temperature() # Dummy function message[\u0026quot;state\u0026quot;] = { \u0026quot;reported\u0026quot; : {\u0026quot;temperature\u0026quot; : temperature } } deviceShadowHandler.shadowUpdate(json.dumps(message), shadow_callback_update, 6) time.sleep(5)  This will send an update to the reported temperature state of the Shadow document. The handler will time out after six seconds, as specified in the third argument. The handler will then wait for the response and invoke the callback function once a response is received.\nIn Production This section is not part of the demonstration as such. It is but a short discussion of some of the considerations we might take when bringing the Shadow feature into production. There are not many addtional considerations besides those discussed for publishing and subscribing, but here are some of them.\nDecouple Application and Data Stream In order for Shadows to be a boon and not just an added operational burden, it is important that we develop applications that utilise it properly. An example of an application that might benefit greatly from using Shadows is one that relies on machine learning models to predict outcomes for displaying or acting on. A machine learning algorithm needs all its features at the same time to produce a prediction, whereas the physical reality of our sensing equipment is that different features are reported at differing times and at different frequencies. Instead of having a large layer of business logic in front of the machine learning algorithm, the application could just serve the latest values as stored in the Shadow. This effectively decouples the data stream and the machine learning model, ensuring that our application can keep running even if a device is broken.\nThis is a general view of how a Shadow could fit into the larger IoT.  Shadow HTTP Interactions Chances are that we do not want our application to deal with the MQTT protocol. The publish subscribe model works well for the IoT part where data is flowing to and from multiple sources to multiple targets. Our application, however, often just needs the latest piece of data, and it is a bit of hassle to deal with an MQTT client, publishing, and subscribing just to get a single piece of data once in a while.\nOne of the major advantages of the Shadow functionality is that each Shadow exposes a REST API to which we can send regular HTTP requests and retrieve data.\nThe API is exposed at\nhttps://endpoint/things/yourDevice/shadow  Where the endpoint is our custom AWS IoT endpoint and yourDevice is the name of our Thing as registered in AWS IoT. We can send regular Get, Update, and Delete HTTP requests to this endpoint and get, update, or delete the Shadow correspondingly. Note though that the entity sending the requests must have permissions to do so. This can be achieved with an IAM user with proper policies.\n","date":1592265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592265600,"objectID":"5c63ec7a3ecf45f9352f7118d5b6ff2b","permalink":"/post/iot-poc-shadow/","publishdate":"2020-06-16T00:00:00Z","relpermalink":"/post/iot-poc-shadow/","section":"post","summary":"In this tutorial, we discuss the usefulness of thing shadows in industrial IoT, by demonstrating how it keeps the pub/sub network alive even if the thing intermittently goes offline.","tags":["IoT","Data","Data Engineering"],"title":"Thing Shadows with AWS IoT","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"","tags":null,"title":"About","type":"widget_page"}]