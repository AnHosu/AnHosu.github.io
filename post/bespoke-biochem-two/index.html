<!DOCTYPE html><html lang="en-us" >

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.1.0 for Hugo" />
  

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Anders E. Nielsen" />

  
  
  
    
  
  <meta name="description" content="Developing a bespoke Bayesian model for high throughput screening assays" />

  
  <link rel="alternate" hreflang="en-us" href="../../post/bespoke-biochem-two/" />

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    <meta name="theme-color" content="#023e8a" />
  

  
  
    
    <script src="../../js/mathjax-config.js"></script>
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">

    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather%7CRoboto+Mono&display=swap">
      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="../../css/wowchemy.f7eaf83122b08ab266aaa8a2d08cb1e8.css" />

  



  

  

  




  
  
  

  

  
    <link rel="manifest" href="../../index.webmanifest" />
  

  <link rel="icon" type="image/png" href="../../media/icon_hu0b500a15011e1e483635372eebf6e1df_24681_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="../../media/icon_hu0b500a15011e1e483635372eebf6e1df_24681_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="../../post/bespoke-biochem-two/" />

  
  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image" />
  
  <meta property="og:site_name" content="anders e" />
  <meta property="og:url" content="/post/bespoke-biochem-two/" />
  <meta property="og:title" content="Bespoke Bayesian Model for High Throughput Biochemical Assays | anders e" />
  <meta property="og:description" content="Developing a bespoke Bayesian model for high throughput screening assays" /><meta property="og:image" content="/post/bespoke-biochem-two/featured.jpg" />
    <meta property="twitter:image" content="/post/bespoke-biochem-two/featured.jpg" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2021-04-23T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2022-04-23T10:54:00&#43;02:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/bespoke-biochem-two/"
  },
  "headline": "Bespoke Bayesian Model for High Throughput Biochemical Assays",
  
  "image": [
    "/post/bespoke-biochem-two/featured.jpg"
  ],
  
  "datePublished": "2021-04-23T00:00:00Z",
  "dateModified": "2022-04-23T10:54:00+02:00",
  
  "author": {
    "@type": "Person",
    "name": "Anders E. Nielsen"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "anders e",
    "logo": {
      "@type": "ImageObject",
      "url": "/media/icon_hu0b500a15011e1e483635372eebf6e1df_24681_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Developing a bespoke Bayesian model for high throughput screening assays"
}
</script>

  

  

  

  





  <title>Bespoke Bayesian Model for High Throughput Biochemical Assays | anders e</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="e2827ca157657b4f14da423a60593a1a" >

  
  
  
  
  
  
  
  
  <script src="../../js/wowchemy-init.min.a8a181ea67095ef9fbb0e99ffbf585a0.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="../../">anders e</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="../../">anders e</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="../../#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link  active" href="../../post/"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="../../about/"><span>About</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    <article class="article">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Bespoke Bayesian Model for High Throughput Biochemical Assays</h1>

  

  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    2022-04-23
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    23 min read
  </span>
  

  
  
  
  
  
  

  
  

</div>

  




<div class="btn-links mb-3">
  
  








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header" href="https://github.com/AnHosu/bespoke-bayesian-biochem" target="_blank" rel="noopener">
    <i class="fab fa-github mr-1"></i>
    Go to project repo
  </a>


</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 480px;">
  <div style="position: relative">
    <img src="../../post/bespoke-biochem-two/featured_hu221dfa8f612834238d78c3a47b5e4d42_3091717_720x0_resize_q75_lanczos.jpg" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    <div class="article-style">
      
<script src="../../post/bespoke-biochem-two/index_files/header-attrs/header-attrs.js"></script>


<p>I am on a quest to improve the model fitting I do on biochemical assays. For some time, I have had this feeling that I should be able to extract more information from the data gathered in biochemical assays, in particular assays with a high throughput.</p>
<p>In <a href="../../project/bespoke-biochem-one">two previous studies</a> we built bespoke Bayesian models to fit observations from a biochemical assay with kinetics that could be represented by the Hill equation. In those studies, we fit a single curves one at a time. In this study, we extend the model to capture the additional information available when screening a large number of compounds in parallel.</p>
<p>We start by setting a seed and some nice colours for plotting.</p>
<pre class="r"><code>library(ggplot2)
library(magrittr)

colour &lt;- list(
  orange_dark = &quot;#fb8500&quot;,
  orange_light = &quot;#ffb703&quot;,
  blue_dark = &quot;#023047&quot;,
  azure = &quot;#219ebc&quot;,
  blue_light = &quot;#8ecae6&quot;
)

set.seed(4444)</code></pre>
<div id="high-troughput-biochemical-experiments" class="section level1">
<h1>High Troughput Biochemical Experiments</h1>
<p>With Bayesian models, we can take advantage of our domain expertise to produce clear answers to our scientific hypotheses and to quantify uncertainty in data and hypotheses. It does, however, require that we are able to represent our expertise as probabilistic models. So before we dive into the Bayesian engine, let’s discuss our biochemistry knowledge and the data we might get from a high throughput experiment.</p>
<p>We are considering compounds that are potential ligands to receptors and cause a tissue response according to the Hill equation</p>
<p><span class="math display">\[\mu_{ij} = top - \frac{bottom_j - top}{1 + 10^{(\log_{10}(IC_{50,j}) - \log_{10}([A_i]))^{n_H}}}\]</span></p>
<p>Where <span class="math inline">\(\mu_{ij}\)</span> is the tissue response of the <span class="math inline">\(j\)</span>’th compound at concentration <span class="math inline">\([A_i]\)</span>.</p>
<p>The equation looks slightly different from the previous studies because we now have multiple compounds in a screening study. The equation also encodes a few assumptions about such an assay. First of all, we are assuming that the tissue response in the absence of ligand, <span class="math inline">\(top\)</span>, is the same for all tested compounds. Similarly, we are assuming that the kinetics of the tissue response, as represented by the Hill number, <span class="math inline">\(n_H\)</span>, stays the same for all compounds. For the maximum tissue response, <span class="math inline">\(bottom_j\)</span>, and the concentration at half response, <span class="math inline">\(\log_{10}(IC_{50,j})\)</span>, however, we are assuming that each compound has its own parameter.</p>
<p>These assumptions might not hold true for every experiment, but if we imagine that we are screening compounds for a good drug candidate and we are looking at the same tissue response for each of them, these assumptions should hold.</p>
<p>As in previous studies, I opt for synthetic data. This has two advantages; we are forced to consider the underlying process that generates our experiment data and, after we have applied a model, we can compare the output to our known truth. We can code the first part of the generative process with a simple function</p>
<pre class="r"><code>hill_function &lt;- function(log_conc, bottom, top, log_IC50, nH) {
  top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH))
}</code></pre>
<p>Now, our observations are not perfect and will be subject to some noise. For this study, we are going to assume that all observations were made in the same batch, under the same conditions, and at the same time such that they have identically distributed noise. Specifically, we will give the observations some Gaussian noise.</p>
<pre class="r"><code>assay_response &lt;- function(log_conc, bottom, top, log_IC50, nH, sigma) {
  noise &lt;- rnorm(length(log_conc), 0, sigma)
  hill_function(log_conc, bottom, top, log_IC50, nH) + noise
}</code></pre>
<p>Next we should consider what type of screening we are doing. There are a couple of different options. We could screen a lot of random compounds for activity. While this is a common scenario, it is not too interesting to model, as we expect that the vast majority of tested compounds will have no activity. In this study, as in the previous, we instead imagine the case where we produce a large number of variations on an endogenous ligand, in the hopes that we stumble upon something with more desirable properties like higher potency.</p>
<p>So we produce 100 modifications to an endogenous ligand which has known parameters <span class="math inline">\(\log_{10}(IC_{50}) = -7.2\)</span> and <span class="math inline">\(bottom = 0\)</span>. We expect that the modifications might cause us to lose potency, i.e. increase <span class="math inline">\(\log_{10}(IC_{50})\)</span>, and efficacy, i.e. increase <span class="math inline">\(bottom\)</span>, most of the time. To add a little extra challenge, I am adding compounds that have extremely low <span class="math inline">\(\log_{10}(IC_{50})\)</span> corresponding to the case where our modification almost or completely removes potency.</p>
<p>With this, we have the final part of the generative model:</p>
<pre class="r"><code>n_compounds &lt;- 100

true_parameters &lt;- tibble::tibble(
  compound = seq(1, n_compounds),
  bottom = 1 - rlnorm(n_compounds, -0.25, 0.125),
  log_IC50 = rnorm(n_compounds, -5, 1.5) + rexp(n_compounds, 3),
  top = 1.02,
  nH = 0.99,
  sigma = 0.15
)</code></pre>
<p>With the generative model in place, we can draw a few of the true curves that we will sample from and estimate in our hypothetical screening experiment.</p>
<pre class="r"><code>true_curves &lt;- purrr::pmap(
  true_parameters,
  ~ geom_function(
    fun = hill_function,
    args = list(
      top = ..4,
      bottom = ..2,
      nH = ..5,
      log_IC50 = ..3
    ),
    colour = colour$blue_dark,
    alpha = 0.5
  )
)

p &lt;- ggplot() +
  xlim(-9, -1) +
  theme_minimal() +
  labs(
    x = &quot;Ligand concentration [M]&quot;,
    y = &quot;True tissue response&quot;,
    title = &quot;Sample True Tissue Responses&quot;
  )

Reduce(`+`, true_curves[1:10], init = p)</code></pre>
<p><img src="../../post/bespoke-biochem-two/index_files/figure-html/generative_model-1.png" width="90%" /></p>
</div>
<div id="bespoke-bayesian-model" class="section level1">
<h1>Bespoke Bayesian Model</h1>
<p>Now that we understand the generative process and we have some data, we can start considering a Bayesian model. We need to specify two things; a set of relations that describe the generative process and priors for any parameters. If this seems similar to what we just did in the previous section, it is because it is. The Baysian model should reflect the process that generated the data. So let’s get started.</p>
<div id="likelihood-model" class="section level2">
<h2>Likelihood Model</h2>
<p>In our screening assay, we will consider <span class="math inline">\(M\)</span> compounds <span class="math inline">\(j = 1, ..., M\)</span>. For each compound, we measure an assay response, <span class="math inline">\(y_{ij}\)</span>, for a number, <span class="math inline">\(i = 1, ..., N\)</span>, of ligand concentrations <span class="math inline">\([A_{ij}]\)</span>. We also know that the assay response averages to the tissue response, <span class="math inline">\(\mu_{ij}\)</span>, but that observations are noisy:</p>
<p><span class="math display">\[y_{ij} \sim {\sf Normal}(\mu_{ij}, \sigma)\]</span></p>
<p>Note that the noise parameter, <span class="math inline">\(\sigma\)</span>, is the same for all <span class="math inline">\(M\)</span> compounds.</p>
<p>The tissue response is a deterministic function of four kinetic parameters, as described by the Hill equation:</p>
<p><span class="math display">\[\mu_{ij} = top - \frac{bottom_j - top}{1 + 10^{(\log_{10}(IC_{50,j}) - \log_{10}([A_{ij}]))^{n_H}}}\]</span></p>
</div>
<div id="priors" class="section level2">
<h2>Priors</h2>
<p>For the minimum response parameter, <span class="math inline">\(top\)</span>, we will specify a narrow prior, as we have no indication that it should be anything other than 1.</p>
<p><span class="math display">\[top \sim {\sf Normal}(1, 0.01)\]</span></p>
<p>In a real scenario the Hill number, <span class="math inline">\(n_H\)</span>, will probably be well know before high throughput screening experiments are done. For the purpose of demonstration, however, we will give it a relatively wide prior and hope to learn the true number from our data, in this case.</p>
<p><span class="math display">\[n_H \sim {\sf LogNormal}(0, 0.5)\]</span></p>
<p>For sigma <span class="math inline">\(\sigma\)</span>, we put a prior that corresponds to a mean standard deviation that is 10% of the assay window. We also want very high noise to be very unlikely.</p>
<p><span class="math display">\[\sigma \sim {\sf Exp}(10)\]</span></p>
<p>We now have multiple <span class="math inline">\(bottom_i\)</span> parameters to consider.</p>
<p>We know that the most likely scenario is where our modification causes the ligand to lose efficacy yielding a minimum tissue response somewhere between 0 and 1. However, there is a small chance that our superior design yields a ligand that is more efficacious than the endogenous ligand and thus has a minimum response below 0. Our prior for the <span class="math inline">\(bottom\)</span> parameter should thus be concentrated between 0 and 1 but with some probability below 0. Let’s try a normal prior.</p>
<p>The question that remains is whether this argument is true for all <span class="math inline">\(bottom_i\)</span>. We are going to assume that it is and use the same prior for all <span class="math inline">\(bottom_i\)</span>.</p>
<p><span class="math display">\[bottom_i \sim {\sf Normal}(0.25, 0.25)\]</span></p>
<p>The modified ligand is likely to lose potency, i.e. have a higher <span class="math inline">\(\log_{10}(IC_{50,i})\)</span>, compared to the endogenous ligand which has <span class="math inline">\(\log_{10}(IC_{50,i}) = -7.2\)</span>, but we might get lucky and see an increase. This is not much to go on, but it should still allow us to use a somewhat narrow prior. Again, we will use the same prior for all <span class="math inline">\(\log_{10}(IC_{50,i})\)</span>.</p>
<p>We added a bit of an extra challenge, allowing for some compounds to have very high <span class="math inline">\(\log_{10}(IC_{50,i})\)</span>. For now, we are going to pretend that we do not have that knowledge and see what this prior will do for us. In a real world scenario, we never know the true distributions. The best priors arise by applying our scientific experience and logic.</p>
<p><span class="math display">\[\log_{10}(IC_{50}) \sim {\sf Normal}(-6, 1.5)\]</span></p>
</div>
</div>
<div id="prior-predictive-simulation" class="section level1">
<h1>Prior Predictive Simulation</h1>
<p>With the model and priors in place, we should control the sensibility of them with a prior predictive check. So let’s imagine that we perform the screening experiment, sampling the underlying parameters from our prior distributions, and have a look at the hypothetical observations that would arise.</p>
<p>Let’s go ahead and define a function for sampling our priors and simulating a screening experiment.</p>
<pre class="r"><code>prior_parameters &lt;- function(n_compounds = NULL,
                             bottom_mean = NULL,
                             bottom_sd = NULL,
                             top_mean = NULL,
                             top_sd = NULL,
                             log_IC50_mean = NULL,
                             log_IC50_sd = NULL,
                             nH_meanlog = NULL,
                             nH_sdlog = NULL,
                             sigma_rate = NULL) {
  tibble::tibble(
      compound = seq(1, n_compounds),
      bottom = rnorm(n_compounds, bottom_mean, bottom_sd),
      log_IC50 = rnorm(n_compounds, log_IC50_mean, log_IC50_sd),
      top = rnorm(1, top_mean, top_sd),
      nH = rlnorm(1, nH_meanlog, nH_sdlog),
      sigma = rexp(1, sigma_rate)
    )
}

screening_experiment &lt;- function(parameters, log_conc) {
  parameters %&gt;% 
    tidyr::expand_grid(log_conc = log_conc) %&gt;%
    dplyr::mutate(
      response = assay_response(log_conc, bottom, top, log_IC50, nH, sigma)
    )
}</code></pre>
<p>Now we can do our prior predictive check by performing a hypothetical experiment with our priors</p>
<pre class="r"><code>priors &lt;- list(
  bottom_mean &lt;- 0.25,
  bottom_sd &lt;- 0.25,
  top_mean &lt;- 1,
  top_sd &lt;- 0.01,
  log_IC50_mean &lt;- -6,
  log_IC50_sd &lt;- 1.5,
  nH_meanlog &lt;- 0,
  nH_sdlog &lt;- 0.5,
  sigma_rate &lt;- 10
)

replicate(
  10,
  rlang::exec(
    prior_parameters,
    n_compounds = 5,
    !!!priors
  ),
  simplify = FALSE
) %&gt;%
  dplyr::bind_rows(.id = &quot;rep&quot;) %&gt;%
  dplyr::mutate(rep = paste0(rep, &quot;-&quot;, compound)) %&gt;%
  screening_experiment(log_conc = seq(-10, -2, length.out = 100)) %&gt;%
  ggplot(aes(x = log_conc, y = response, group = rep)) +
    geom_line(colour = colour$blue_dark, alpha = 0.5) +
    theme_minimal() +
    labs(
    x = &quot;log ligand concentration&quot;,
    y = &quot;response&quot;,
    title = &quot;Prior Samples&quot;
    )</code></pre>
<p><img src="../../post/bespoke-biochem-two/index_files/figure-html/prior_predictive_check-1.png" width="90%" /></p>
<p>Our prior understanding of the data generating process predicts a diverse set of curves. One of the things that often surprises me is the large number of seeming outliers, even with conservative estimates for noise. Given variance and enough samples, we are bound to see some weird behaviour.</p>
<p>I think that these hypothetical samples seem like a fair representation of the samples I expect to get from the assay. If for some reason we thought that the hypothetical samples looked too extreme or did not represent the full range of possible observations, we would have to go back and adjust our priors.</p>
</div>
<div id="bayesian-model" class="section level1">
<h1>Bayesian Model</h1>
<p>Now it is time for the fun part. First we implement the complete Bayesian model, consisting of our observational model and prior distributions, in Stan.</p>
<p>The trick here is to define an index variable that keeps track of parameters for individual curves.</p>
<pre class="r"><code>writeLines(readLines(&quot;hill_equation_screening.stan&quot;))</code></pre>
<pre><code>data {
  int&lt;lower=0&gt; N;
  int&lt;lower=0&gt; M;
  int&lt;lower=0&gt; curve_ind[N];
  vector[N] log_conc;
  vector[N] y;
}

parameters {
  real top;
  vector&lt;upper=top&gt;[M] bottom;
  vector[M] log_IC50;
  real&lt;lower=0&gt; nH;
  real&lt;lower=0&gt; sigma;
  
}

model {
  vector[N] mu;
  bottom ~ normal(0.25, 0.25);
  top ~ normal(1, 0.01);
  log_IC50 ~ normal(-6, 1.5);
  nH ~ normal(1, 0.01);
  sigma ~ exponential(10);
  for ( i in 1:N ) {
    mu[i] = top + (bottom[curve_ind[i]] - top) 
                  / (1 + 10^((log_IC50[curve_ind[i]] - log_conc[i])*nH));
  }
  y ~ normal(mu, sigma);
}

generated quantities {
  vector[N] mu;
  vector[N] y_sampled;
  for ( i in 1:N ) {
    mu[i] = top + (bottom[curve_ind[i]] - top) 
                  / (1 + 10^((log_IC50[curve_ind[i]] - log_conc[i])*nH));
    y_sampled[i] = normal_rng(mu[i], sigma);
  }
}</code></pre>
<div id="conditioning" class="section level2">
<h2>Conditioning</h2>
<p>Next we need some data to condition our model on. So we perform a simulated screening experiment using our true parameters. Recall that we have 100 compounds. In the screening experiment we will sample the tissue response for each compound at 6 different concentrations.</p>
<pre class="r"><code>assay_window &lt;- seq(-8, -2, length.out = 6)

observations &lt;- screening_experiment(
  parameters = true_parameters,
  log_conc = assay_window
)

data &lt;- list(
  N = nrow(observations),
  M = max(observations$compound),
  curve_ind = observations$compound,
  log_conc = observations$log_conc,
  y = observations$response
)

post &lt;- rstan::stan_model(&quot;hill_equation_screening.stan&quot;) %&gt;%
  rstan::sampling(
    data = data,
    chains = 4,
    cores = 4,
    seed = 4444
  )

# Extract samples from the posterior distribution
posterior_samples &lt;- rstan::extract(post) %&gt;% tibble::as_tibble()</code></pre>
</div>
</div>
<div id="examining-the-posterior" class="section level1">
<h1>Examining the Posterior</h1>
<p>Before applying the model, we should do some quality assurance. Since we have simulated data, we can of course compare the posterior distributions to our known truth, and we will definitely do that, in a moment. In real problems, however, the truth is not known and we have to rely on other approaches.</p>
<p>Here I have three approaches that rely only on the model and the data. None of the approaches will tell us whether the model is a good one, but they will often indicate any problems.</p>
<div id="quality-of-the-monte-carlo-simulation" class="section level2">
<h2>Quality of the Monte Carlo Simulation</h2>
<p>The first thing we can do is do a quality check of the Monte Carlo sampling. Stan usually complains when something seems wrong, but we can also check some specific diagnostics.</p>
<p>I often get divergent transitions when I build multilevel models and they are a signal that there are areas of the model space that are difficult to traverse. Often they can be fixed by increasing the <code>adapt_delta</code> parameter like we did in a previous study. When that does not work, it is a sign that maybe the model needs to be re-parametrised. For our model in this study, we should not have that problem, though.</p>
<pre class="r"><code>rstan::check_divergences(post)</code></pre>
<pre><code>0 of 4000 iterations ended with a divergence.</code></pre>
<p>When Stan complains about maximum tree depth it is because the Monte Carlo sampler was unable to fully explore some parts of the model space. It is really only an efficiency metric, but a common piece of advise when experiencing tree depth warnings is to use narrower priors. I also often find that I see this warning when I have forgotten to put an explicit prior on a parameter. In this case, we have put a lot of thought into our priors and they should be good.</p>
<pre class="r"><code>rstan::check_treedepth(post)</code></pre>
<pre><code>0 of 4000 iterations saturated the maximum tree depth of 10.</code></pre>
</div>
<div id="convergence" class="section level2">
<h2>Convergence</h2>
<p>We should also check check whether each of our parameters have properly converged. Stan provides two metrics for us to review. <span class="math inline">\(\hat{R}\)</span> is a measure of convergence and when <span class="math inline">\(\hat{R} &gt; 1.01\)</span> it is an indication that the posterior samples aren’t quite representative of the true posterior distribution.</p>
<p><span class="math inline">\(n\_eff\)</span> is an estimate of the number of true samples our chains represent. If the number of effective samples is low compared to the number of samples we chose to take after warm up, it indicates that it was difficult for the Monte Carlo sampler to figure out that parameter in the grand scheme of things. Sometimes it helps to increase <code>adapt_delta</code> and do more warm-up samples, but I find that it is also often indicative of data that is very incompatible with the model and its priors. In this study, we ran four chains with 1000 samples after warm-up, so we would like to see at least several hundred effective samples.</p>
<p>Let’s just have a look at the parameters that proved to be most difficult.</p>
<pre class="r"><code>post_summaries &lt;- rstan::summary(
  post,
  pars = c(&quot;bottom&quot;, &quot;log_IC50&quot;),
  probs = NULL
)$summary

tibble::as_tibble(post_summaries) %&gt;%
  dplyr::select(-c(mean, se_mean, sd)) %&gt;%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %&gt;%
  dplyr::mutate(dplyr::across(-parameter, round, digits = 3)) %&gt;%
  dplyr::arrange(desc(Rhat)) %&gt;%
  dplyr::slice_head(n = 10) %&gt;%
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">parameter</th>
<th align="right">n_eff</th>
<th align="right">Rhat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">log_IC50[83]</td>
<td align="right">1177.101</td>
<td align="right">1.003</td>
</tr>
<tr class="even">
<td align="left">bottom[2]</td>
<td align="right">4258.387</td>
<td align="right">1.002</td>
</tr>
<tr class="odd">
<td align="left">log_IC50[2]</td>
<td align="right">4483.525</td>
<td align="right">1.002</td>
</tr>
<tr class="even">
<td align="left">log_IC50[37]</td>
<td align="right">1349.972</td>
<td align="right">1.002</td>
</tr>
<tr class="odd">
<td align="left">log_IC50[71]</td>
<td align="right">2269.627</td>
<td align="right">1.002</td>
</tr>
<tr class="even">
<td align="left">bottom[26]</td>
<td align="right">3953.336</td>
<td align="right">1.001</td>
</tr>
<tr class="odd">
<td align="left">bottom[32]</td>
<td align="right">6086.841</td>
<td align="right">1.001</td>
</tr>
<tr class="even">
<td align="left">bottom[37]</td>
<td align="right">1252.062</td>
<td align="right">1.001</td>
</tr>
<tr class="odd">
<td align="left">bottom[44]</td>
<td align="right">4487.325</td>
<td align="right">1.001</td>
</tr>
<tr class="even">
<td align="left">bottom[71]</td>
<td align="right">4270.506</td>
<td align="right">1.001</td>
</tr>
</tbody>
</table>
<p>It looks like our parameters have converged nicely.</p>
<p>Note that some parameters have <span class="math inline">\(n\_eff\)</span> that are quite a bit below the 4000 samples after warm-up. This is not necessarily a cause for concern, but in case it is very low and we want to use the distribution for predictive purposes, it might be a good idea to increase the number of samples after warm-up a bit.</p>
</div>
<div id="data-replication-check" class="section level2">
<h2>Data Replication Check</h2>
<p>A great sanity check for a model is whether it is able to replicate the data. Our model is fully generative, meaning we can generate hypothetical samples. For a good model, when we generate a number of samples corresponding to the number of data points, the qualitative properties those samples should be similar to those of the original data. Parameters like mean and variance will be very similar, as those are basically the parameters we conditioned on the data, but more qualitative aspects like minimum data point, maximum, or general shape are not a given.</p>
<p>In the Stan script, I included some generated quantities that are essentially sample observations, so we can compare. We will skip comparing maximum and minimum and just compare the overall shape.</p>
<pre class="r"><code>ggplot() +
  geom_histogram(
    data = observations,
    mapping = aes(x = response, y = ..density.., fill = &quot;Observed responses&quot;),
    bins = 30,
    alpha = 0.5
  ) +
  geom_histogram(
    data = tibble::tibble(y_sampled = as.vector(posterior_samples$y_sampled)),
    mapping = aes(x = y_sampled, y = ..density.., fill = &quot;Posterior samples&quot;),
    bins = 300,
    alpha = 0.5
  ) +
  theme_minimal() +
  scale_fill_manual(values = list(
    &quot;Observed responses&quot; = colour$azure,
    &quot;Posterior samples&quot; = colour$blue_dark
  )) +
  labs(
    fill = &quot;&quot;,
    y = &quot;Density&quot;,
    x = &quot;Response&quot;,
    title = &quot;Shape Check&quot;
  )</code></pre>
<p><img src="../../post/bespoke-biochem-two/index_files/figure-html/shape_check-1.png" width="90%" /></p>
<p>It really looks like out model replicates the data quite nicely. Usually the concerns are whether the tails match; if the data has minimum points that are outside what the model yields or if the samples span a much wider range than the data, it might be cause to rethink the model.</p>
</div>
</div>
<div id="results" class="section level1">
<h1>Results</h1>
<p>Our model and the posterior samples seem to be of decent quality, so let’s put them to use.</p>
<div id="posterior-marginal-distributions" class="section level2">
<h2>Posterior Marginal Distributions</h2>
<p>So our model has 203 parameters, 2 for each of the 100 compounds and 3 parameters that are shared between all of them. Let’s see what we have learned about the three shared parameters.</p>
<pre class="r"><code># True parameters of the simulation.
truth &lt;- true_parameters %&gt;%
  dplyr::slice_head(n = 1) %&gt;%
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &quot;parameter&quot;,
    values_to = &quot;truth&quot;
  )

# A number of draws from our priors to match the number of draws we have from
#  the posterior
prior_samples &lt;- replicate(
  nrow(posterior_samples),
  rlang::exec(
    prior_parameters,
    n_compounds = 1,
    !!!priors
  ),
  simplify = FALSE
) %&gt;% 
  dplyr::bind_rows() %&gt;%
  dplyr::select(top, nH, sigma) %&gt;% 
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &quot;parameter&quot;,
    values_to = &quot;sample&quot;
  )

# Plot each of the marginal distributions, comparing prior, posterior, and true
#  simulation parameters
posterior_samples %&gt;%
  dplyr::select(top, nH, sigma) %&gt;%
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &quot;parameter&quot;,
    values_to = &quot;sample&quot;
  ) %&gt;%
  dplyr::left_join(truth, by = &quot;parameter&quot;) %&gt;%
  ggplot() +
  geom_histogram(
    data = prior_samples,
    mapping = aes(x = sample, fill = &quot;Prior&quot;),
    bins = 50,
    alpha = 0.5
  ) +
  geom_histogram(aes(x = sample, fill = &quot;Posterior&quot;), bins = 50, alpha = 0.5) +
  geom_vline(aes(xintercept = truth, colour = &quot;truth&quot;), alpha = 0.5) +
  facet_wrap(~ parameter, scales = &quot;free&quot;) +
  theme_minimal() +
  scale_colour_manual(values = c(&quot;truth&quot; = colour$orange_light)) +
  scale_fill_manual(values = c(
    &quot;Prior&quot; = colour$azure,
    &quot;Posterior&quot; = colour$blue_dark
  )) +
  labs(
    y = &quot;Posterior sample count&quot;,
    x = &quot;&quot;,
    colour = &quot;&quot;,
    fill = &quot;&quot;,
    title = &quot;Marginal Posterior and Prior Distributions&quot;
  )</code></pre>
<p><img src="../../post/bespoke-biochem-two/index_files/figure-html/posterior_marginals_shared-1.png" width="90%" /></p>
<p>And some summary statistics</p>
<pre class="r"><code>post_summaries &lt;- rstan::summary(
  post,
  pars = c(&quot;top&quot;, &quot;nH&quot;, &quot;sigma&quot;),
  probs = c(0.055, 0.5, 0.945)
)$summary

tibble::as_tibble(post_summaries) %&gt;%
  dplyr::select(-c(mean, se_mean, sd)) %&gt;%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %&gt;%
  dplyr::mutate(dplyr::across(-parameter, round, digits = 2)) %&gt;%
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">parameter</th>
<th align="right">5.5%</th>
<th align="right">50%</th>
<th align="right">94.5%</th>
<th align="right">n_eff</th>
<th align="right">Rhat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">top</td>
<td align="right">1.02</td>
<td align="right">1.03</td>
<td align="right">1.04</td>
<td align="right">4667.23</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">nH</td>
<td align="right">0.99</td>
<td align="right">1.00</td>
<td align="right">1.02</td>
<td align="right">9232.87</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">sigma</td>
<td align="right">0.15</td>
<td align="right">0.15</td>
<td align="right">0.16</td>
<td align="right">2994.32</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>When we fitted the curve for each individual compound, we ended up with posteriors that were very similar to our priors, indicating that the data was insufficient to provide additional information. In this case, however, we share information about the curve shape, sample noise, and the minimum response among all compounds. The pooling of all that information causes us to get very exact estimates for the curve shape and the sample noise. The estimates are even essentially equal to the truth. For the minimum response, our prior is still very informative compared to the data, so the posterior distribution has barely changed.</p>
<p>These results are quite profound. Even with a relatively wide prior on <span class="math inline">\(n_H\)</span>, corresponding to little knowledge about the kinetics of the response, we were able to estimate those exact kinetics, despite the data being intended for a different purpose. In real problems, we would often be much more sure about that parameter. Similarly, we have a very exact estimate of the experiment noise. If we regularly run such screening experiments this would be a great metric to track over time.</p>
<p>We cannot look at parameters and curves for each of the compounds, so lets just pick a couple, including one that is difficult to fit. As with the shared parameters, we compare the posterior samples to the prior distribution and our known truth.</p>
<pre class="r"><code>example_compounds &lt;- c(1:5, 93)

# True parameters of the simulation.
truth &lt;- true_parameters %&gt;%
  dplyr::filter(compound %in% example_compounds) %&gt;%
  tidyr::pivot_longer(
    -compound,
    names_to = &quot;parameter&quot;,
    values_to = &quot;truth&quot;
  )

# A number of draws from our priors to match the number of draws we have from
#  the posterior
prior_samples &lt;- replicate(
  nrow(posterior_samples),
  rlang::exec(
    prior_parameters,
    n_compounds = 1,
    !!!priors
  ),
  simplify = FALSE
) %&gt;% 
  dplyr::bind_rows() %&gt;%
  dplyr::select(bottom, log_IC50) %&gt;% 
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &quot;parameter&quot;,
    values_to = &quot;sample&quot;
  ) %&gt;%
  tidyr::expand_grid(compound = example_compounds)

# Plot each of the marginal distributions, comparing prior, posterior, and true
#  simulation parameters
lapply(example_compounds, function(i) {
  tibble::tibble(
    bottom = posterior_samples$bottom[,i],
    log_IC50 = posterior_samples$log_IC50[,i],
    compound = i
  )
}) %&gt;% 
  dplyr::bind_rows() %&gt;%
  tidyr::pivot_longer(
    -compound,
    names_to = &quot;parameter&quot;,
    values_to = &quot;sample&quot;
  ) %&gt;%
  dplyr::left_join(truth, by = c(&quot;parameter&quot;, &quot;compound&quot;)) %&gt;%
  ggplot() +
  geom_histogram(
    data = prior_samples,
    mapping = aes(x = sample, fill = &quot;Prior&quot;),
    bins = 50,
    alpha = 0.5
  ) +
  geom_histogram(aes(x = sample, fill = &quot;Posterior&quot;), bins = 50, alpha = 0.5) +
  geom_vline(aes(xintercept = truth, colour = &quot;truth&quot;), alpha = 0.5) +
  facet_grid(rows = vars(compound), cols = vars(parameter), scales = &quot;free&quot;) +
  theme_minimal() +
  theme(strip.text.y = element_text(angle = 0)) +
  scale_colour_manual(values = c(&quot;truth&quot; = colour$orange_light)) +
  scale_fill_manual(values = c(
    &quot;Prior&quot; = colour$azure,
    &quot;Posterior&quot; = colour$blue_dark
  )) +
  labs(
    y = &quot;Posterior sample count&quot;,
    x = &quot;&quot;,
    colour = &quot;&quot;,
    fill = &quot;&quot;,
    title = &quot;Marginal Posterior and Prior Distributions&quot;
  )</code></pre>
<p><img src="../../post/bespoke-biochem-two/index_files/figure-html/posterior_marginals_compounds-1.png" width="90%" /></p>
<p>And some summary statistics</p>
<pre class="r"><code>post_summaries &lt;- rstan::summary(
  post,
  pars = c(&quot;bottom&quot;, &quot;log_IC50&quot;),
  probs = c(0.055, 0.5, 0.945)
)$summary

tibble::as_tibble(post_summaries) %&gt;%
  dplyr::select(-c(mean, se_mean, sd)) %&gt;%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %&gt;%
  dplyr::mutate(dplyr::across(-parameter, signif, digits = 4)) %&gt;%
  dplyr::filter(stringr::str_detect(
    parameter,
    paste0(&quot;(\\[&quot;, example_compounds, &quot;\\])&quot;, collapse = &quot;|&quot;)
  )) %&gt;%
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">parameter</th>
<th align="right">5.5%</th>
<th align="right">50%</th>
<th align="right">94.5%</th>
<th align="right">n_eff</th>
<th align="right">Rhat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">bottom[1]</td>
<td align="right">-0.26640</td>
<td align="right">0.02345</td>
<td align="right">0.2899</td>
<td align="right">6103.0</td>
<td align="right">1.0000</td>
</tr>
<tr class="even">
<td align="left">bottom[2]</td>
<td align="right">-0.05292</td>
<td align="right">0.30550</td>
<td align="right">0.5976</td>
<td align="right">4258.0</td>
<td align="right">1.0020</td>
</tr>
<tr class="odd">
<td align="left">bottom[3]</td>
<td align="right">0.25210</td>
<td align="right">0.42120</td>
<td align="right">0.5831</td>
<td align="right">5681.0</td>
<td align="right">0.9995</td>
</tr>
<tr class="even">
<td align="left">bottom[4]</td>
<td align="right">0.04298</td>
<td align="right">0.18550</td>
<td align="right">0.3221</td>
<td align="right">6510.0</td>
<td align="right">0.9996</td>
</tr>
<tr class="odd">
<td align="left">bottom[5]</td>
<td align="right">-0.14800</td>
<td align="right">0.07444</td>
<td align="right">0.2785</td>
<td align="right">5360.0</td>
<td align="right">1.0000</td>
</tr>
<tr class="even">
<td align="left">bottom[93]</td>
<td align="right">0.01054</td>
<td align="right">0.22520</td>
<td align="right">0.4813</td>
<td align="right">1621.0</td>
<td align="right">0.9996</td>
</tr>
<tr class="odd">
<td align="left">log_IC50[1]</td>
<td align="right">-3.38700</td>
<td align="right">-2.84400</td>
<td align="right">-2.3980</td>
<td align="right">4842.0</td>
<td align="right">1.0000</td>
</tr>
<tr class="even">
<td align="left">log_IC50[2]</td>
<td align="right">-3.26300</td>
<td align="right">-2.54000</td>
<td align="right">-1.9200</td>
<td align="right">4484.0</td>
<td align="right">1.0020</td>
</tr>
<tr class="odd">
<td align="left">log_IC50[3]</td>
<td align="right">-5.83300</td>
<td align="right">-4.93800</td>
<td align="right">-4.1330</td>
<td align="right">6467.0</td>
<td align="right">0.9993</td>
</tr>
<tr class="even">
<td align="left">log_IC50[4]</td>
<td align="right">-6.41500</td>
<td align="right">-5.83600</td>
<td align="right">-5.2860</td>
<td align="right">7889.0</td>
<td align="right">0.9995</td>
</tr>
<tr class="odd">
<td align="left">log_IC50[5]</td>
<td align="right">-4.60200</td>
<td align="right">-3.93300</td>
<td align="right">-3.3400</td>
<td align="right">5696.0</td>
<td align="right">1.0000</td>
</tr>
<tr class="even">
<td align="left">log_IC50[93]</td>
<td align="right">-6.41600</td>
<td align="right">-4.05500</td>
<td align="right">-3.4590</td>
<td align="right">801.6</td>
<td align="right">1.0010</td>
</tr>
</tbody>
</table>
<p>At first glance, these results may seem unimpressive. Even though the posterior has concentrated compared to our prior, it is still fairly wide. Even the compounds with the narrowest estimate of potency has a 89% interval for <span class="math inline">\(\log_{10}(IC_{50})\)</span> spanning more than a unit, corresponding to more than an order of magnitude difference in concentration. That is quite a bit.</p>
<p>Seen from another perspective though, we only had six data points to estimate each of those two parameters. If we were extremely confident in the resulting estimates that would be very suspicious. The means of the marginal posterior distributions are close to the truth, so we have good estimates for any downstream analysis, but the relatively wide distributions are there to remind us that our estimate is uncertain.</p>
</div>
<div id="posterior-predictive" class="section level2">
<h2>Posterior Predictive</h2>
<p>One way to understand how much, or how little, our model has learned from the data is to visualise the posterior predictions along with the original data. Here is a curve where things went rather well</p>
<pre class="r"><code>example_curves &lt;- tibble::tibble(curve = c(3, 93))
example_curves$post_pred &lt;- purrr::map(example_curves$curve, function(i) {
  posterior_samples %&gt;%
  dplyr::mutate(
    log_IC50 = log_IC50[, i],
    bottom = bottom[, i]
  ) %&gt;%
  tidyr::expand_grid(log_conc = seq(-2, -9, length.out = 50)) %&gt;% 
  dplyr::mutate(tissue_response = purrr::pmap_dbl(
    list(log_conc, bottom, top, log_IC50, nH),
    hill_function
  )) %&gt;%
  dplyr::group_by(log_conc) %&gt;%
  dplyr::summarise(
    response_mean = mean(tissue_response),
    response_upper = quantile(tissue_response, probs = 0.945),
    response_lower = quantile(tissue_response, probs = 0.055)
  ) %&gt;%
  ggplot() +
  geom_ribbon(
    aes(
      x = log_conc,
      ymin = response_lower,
      ymax = response_upper,
      fill = &quot;89% interval&quot;
    ),
    alpha = 0.5
  ) +
  geom_line(aes(x = log_conc, y = response_mean, colour = &quot;Posterior mean&quot;)) +
  geom_point(
    data = dplyr::filter(observations, compound == i),
    aes(x = log_conc, y = response, colour = &quot;Observations&quot;)
  ) +
  geom_function(
    fun = hill_function,
    args = true_parameters[i, -c(1,6)],
    mapping = aes(colour = &quot;True tissue response&quot;)
  ) +
  labs(
    y = &quot;Tissue response&quot;,
    x = &quot;Log ligand concentration [M]&quot;,
    colour = &quot;&quot;,
    fill = &quot;&quot;,
    title = paste(&quot;Posterior Predictive for Compound&quot;, i)
  ) +
  scale_fill_manual(values = c(&quot;89% interval&quot; = colour$azure)) +
  theme_minimal()
})
example_curves$post_pred_coloured &lt;- purrr::map(
  example_curves$post_pred,
  function(p) {
    p + scale_colour_manual(values = c(
      &quot;Posterior mean&quot; = colour$blue_dark,
      &quot;Observations&quot; = colour$orange_light,
      &quot;True tissue response&quot; = colour$orange_dark
    ))
  }
)
example_curves$post_pred_coloured[[1]]</code></pre>
<p><img src="../../post/bespoke-biochem-two/index_files/figure-html/posterior_predictive-1.png" width="90%" /></p>
<p>Our model is very open about its uncertainty. While the posterior mean is a great compromise between the data points, the model also knows that the assay is noisy, and it has used the pooled estimate of that noise across all curves to give us this nice interval for any point prediction. Not also how the model has confidently ruled out one of the points as an outlier. I think this is a lot of information gained from just a few points of data.</p>
<p>Now let’s have a look at a more difficult case</p>
<pre class="r"><code>example_curves$post_pred_coloured[[2]]</code></pre>
<p><img src="../../post/bespoke-biochem-two/index_files/figure-html/posterior_predictive_2-1.png" width="90%" /></p>
<p>This one is difficult because we did not get any good points on the curved part of the tissue response. This makes the estimate for <span class="math inline">\(\log_{10}(IC_{50})\)</span> very uncertain, resulting in the bulge in the middle. Despite all this, the 89% interval nicely contains the true tissue response.</p>
</div>
<div id="model-comparison" class="section level2">
<h2>Model Comparison</h2>
<p>Before we wrap up, I want to highlight why I like this approach to modelling my screening assay data in this way by comparing it to a classic model fitting method.</p>
<p>For the comparison, we will use non-linear least squares to directly fit the Hill equation to the data points for a compound. We cannot put flexible priors on the parameters, but we can set constraints that limit the parameters to a range comparable to that of the priors in our Bayesian model.</p>
<p>Again let’s start by looking at the case where things go well.</p>
<pre class="r"><code>example_curves$model_comp &lt;- purrr::map2(
  example_curves$curve,
  example_curves$post_pred,
  function(curve, p) {
    mod &lt;- nls(
      response ~ top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH)),
      data = dplyr::filter(observations, compound == curve),
      algorithm = &quot;port&quot;,
      start = list(bottom = 0.25, top = 1, log_IC50 = -6, nH = 1),
      lower = list(bottom = -0.3, top = 0.98, log_IC50 = -9, nH = 0),
      upper = list(bottom = 1.0, top = 1.02, log_IC50 = -3, nH = 2)
    )
    
    p +
      geom_function(
        fun = hill_function,
        args = mod$m$getPars(),
        mapping = aes(colour = &quot;NLS fit&quot;)
      ) +
      scale_colour_manual(values = c(
        &quot;Posterior mean&quot; = colour$blue_dark,
        &quot;Observations&quot; = colour$orange_light,
        &quot;True tissue response&quot; = colour$orange_dark,
        &quot;NLS fit&quot; = &quot;black&quot;
      ))
  }
)

example_curves$model_comp[[1]]</code></pre>
<p><img src="../../post/bespoke-biochem-two/index_files/figure-html/model_comp-1.png" width="90%" /></p>
<p>The least squares model is almost identical to our posterior mean estimate and both are close to the truth. This is not altogether surprising, as we had great data points to fit the model curve on. However, only the Bayesian model comes with an estimate of the uncertainty. With the least squares model, we could easily grow overconfident in the fitted parameters.</p>
<p>Let’s have a look at the more difficult case.</p>
<pre class="r"><code>example_curves$model_comp[[2]]</code></pre>
<p><img src="../../post/bespoke-biochem-two/index_files/figure-html/model_comp_2-1.png" width="90%" /></p>
<p>In this case, the least squares fit was not really able to find a good foothold in the data, yet it confidently reports the fitted parameters. Granted, our Bayesian model had its troubles too, but at least it reports the extreme uncertainty.</p>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>In this study, we built and explored a Bayesian model for understanding large compound screening assays. We showed that we can use our prior knowledge to build a bespoke model and that such a model provides us with more useful information than a conventional least squares model. We experienced that it takes a bit more work to ensure the quality of a Bayesian model, but we tried out a few ways to do so.</p>
</div>
<div id="next-steps" class="section level1">
<h1>Next Steps</h1>
<p>In the preceding study, we assumed that the compounds were random perturbations on a known endogenous ligand. We also assumed that the observations arose under similar circumstances such that they shared a common noise parameter. These assumptions may hold in some cases, but often we know more about our data than that.</p>
<p>Maybe the permutations could be described with categories or other labels.</p>
<p>Maybe we performed our screening assay in batches across multiple days, resulting in a possible batch effect on observation data quality.</p>
<p>Either of these cases add another layer of complexity, but batch effects and labels are both things we can handle with a bespoke Bayesian model. These are the subjects of a future study. Stay tuned!</p>
</div>
<div id="license" class="section level1">
<h1>License</h1>
<p>The content of this project itself is licensed under the <a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International license</a>, and the underlying code is licensed under the <a href="https://github.com/AnHosu/bespoke-bayesian-biochem/blob/main/LICENSE">GNU General Public License v3.0 license</a>.</p>
</div>

    </div>

    






<div class="article-tags">
  
  <a class="badge badge-light" href="../../tag/bayesian-data-analysis/">Bayesian data analysis</a>
  
  <a class="badge badge-light" href="../../tag/bayesian-statistics/">Bayesian statistics</a>
  
  <a class="badge badge-light" href="../../tag/r/">R</a>
  
  <a class="badge badge-light" href="../../tag/stan/">Stan</a>
  
  <a class="badge badge-light" href="../../tag/statistics/">Statistics</a>
  
  <a class="badge badge-light" href="../../tag/modelling/">Modelling</a>
  
  <a class="badge badge-light" href="../../tag/biochemistry/">Biochemistry</a>
  
</div>













  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="../../"><img class="avatar mr-3 avatar-circle" src="../../author/anders-e.-nielsen/avatar_huaf22d72e35256be9d48177f1f21d9377_326351_270x270_fill_q75_lanczos_center.jpg" alt="Anders E. Nielsen"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="../../">Anders E. Nielsen</a></h5>
      <h6 class="card-subtitle">Data Professional &amp; Research Scientist</h6>
      <p class="card-text">I apply modern data technology to solve real-world problems. My interests include statistics, machine learning, computational biology, and IoT.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:andellegaard@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/anders-ellegaard-nielsen-6a0857125/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/AnHosu" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>
















  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="../../post/bespoke-biochem-three/">Bespoke Bayesian Model for Batch Effects in High Throughput Biochemical Assays</a></li>
      
      <li><a href="../../post/bespoke-biochem-one/">Bespoke Bayesian Model for Biochemical Assays</a></li>
      
      <li><a href="../../post/bayesian-olympics/">Olympic Athletes over Time - A Tidy Bayesian Data Exploration</a></li>
      
      <li><a href="../../post/acquisition-functions-r/">Acquisition Functions for Bayesian Optimisation</a></li>
      
      <li><a href="../../post/kernels-r/">Kernels for Gaussian Processes</a></li>
      
    </ul>
  </div>
  





  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  

  

  
  <p class="powered-by">
    © 2023 Anders E. Nielsen
  </p>
  

  
  






  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a>, <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a>, and <a href="https://github.com/rstudio/blogdown" target="_blank" rel="noopener">R Blogdown</a>.
    
  </p>
</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      

      
      

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js"></script>
        
      

    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    <script src="../../js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js"></script>

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="../../en/js/wowchemy.min.cf8ca859a9b74f8b1cd804621b13e5f1.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
