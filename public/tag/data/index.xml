<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data | anders e</title>
    <link>/tag/data/</link>
      <atom:link href="/tag/data/index.xml" rel="self" type="application/rss+xml" />
    <description>Data</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2023 Anders E. Nielsen</copyright><lastBuildDate>Tue, 16 Jun 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hu0b500a15011e1e483635372eebf6e1df_24681_512x512_fill_lanczos_center_3.png</url>
      <title>Data</title>
      <link>/tag/data/</link>
    </image>
    
    <item>
      <title>Build an Edge with Greengrass</title>
      <link>/post/iot-poc-greengrass/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/post/iot-poc-greengrass/</guid>
      <description>&lt;p&gt;It is time to create an edge; to take advantage of the compute that is available right where the data is gathered. Even if we use the AWS IoT services, there are several ways and plenty of 3&lt;sup&gt;rd&lt;/sup&gt; party software we could apply for device management and creating an edge. The AWS offering is Greengrass, a piece of software running on our gateway device and an accompanying cloud service. In this demonstration, we introduce key concepts in the context of an IoT edge using Greengrass.&lt;br&gt;
In this demonstration we will&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install AWS Greengrass Core on our Raspberry Pi&lt;/li&gt;
&lt;li&gt;Register the Pi as a Core Device in the AWS Greengrass console&lt;/li&gt;
&lt;li&gt;Connect a our sensor as a thing through Greengrass, sending data to AWS IoT&lt;/li&gt;
&lt;li&gt;Define a calculation in the cloud and deploy it onto the edge using a Lambda function in Greengrass
&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_group_architecture.png&#34; alt=&#34;iot setup&#34;&gt;
  This is the architecture we are building in this demonstration.
&lt;/div&gt;
&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;
&lt;p&gt;When we walk through the demonstration, it might seem like a lot of hassle and extra steps to go through before data is flowing and we reach what is essentially the same state as in previous demonstrations, where we just &lt;a href=&#34;../../post/iot-poc-publishing/&#34;&gt;published&lt;/a&gt; readings and &lt;a href=&#34;../../post/iot-poc-pubsub/&#34;&gt;subscribed&lt;/a&gt; directly in the script that also queried our sensor. Indeed, Greengrass is not intended for use with a single sensor. Imagine, however, that we are managing hundreds of sensors on a factory floor. The factory might be far away, or the gowning procedure might prohibit frequent visits, but even if our desk is right next to the manufacturing line, we still do not want to physically go there each time we deploy changes to sensor data streams, restart devices, define new signal processing, or update software. Greengrass allows us to define functionality in the cloud and deploy it to our device with a click.&lt;br&gt;&lt;br&gt;
Another important aspect of our IoT application to consider is cost. It is tempting to just send all raw data to storage in the cloud. Cloud storage is indeed inexpensive, but it is not free. What is worse, however, is the cost of compute. Cloud compute offers unprecedented flexibility, but it is expensive, so we generally want to use it to handle loads with varying intensity or low predictability, e.g. for hosting the application that uses data from the IoT setup. As an example of a case where we might quickly incur a large and unnecessary bill, imagine a set of vibration sensors. Vibration sensors are useful for predictive maintenance applications, since the patterns in vibrations from components like bearings and motors might be good predictors for the health of the component. An industrial grade vibration sensor might be able to sample acceleration thousands of times per second. If we were to store the data from just a few vibration sensors, we would quickly fill up enough storage to accomodate years worth of data from other sources like factory floor temperature and humidity. Furthermore, since it is not the acceleration itself but characteristics of the vibrations we are interested in, each time we use the data we would have to do signal processing and recalculate features. If we do that using cloud compute, we will work up quite a bill. The financially and environmentally responsible way to implement vibration sensors is to do the signal processing as close to the sampling point as possible and then only store the calculated features. We still want the flexibility of developing in the cloud and deploying to a remote device, however. While we will not work with signal processing in this demonstration, we will create an example of data transformation and deploy it from the cloud to the Raspberry Pi using Greengrass.&lt;br&gt;&lt;br&gt;
Conceptually, the setup for this demonstration is a bit different from that of the three previous demonstrations. The hardware is exactly the same but, in previous demonstrations, our Raspberry Pi acted the part of a microcontroller and essentially did not do a lot of work. In this demonstration, we will make use of the compute available on the Raspberry Pi, install Greengrass, and use it to manage the sensor. To demonstrate the concept of edge calculations, we will create a transformation that corrects for the fact that the temperature sensor is right next the CPU of our Pi.&lt;br&gt;&lt;br&gt;
Let us get started!&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/hardware_setup.jpg&#34; alt=&#34;iot setup&#34;&gt;
    Notice that the BME680 air quality sensor is right next to the CPU of the Pi, which interferes with the temperature readings. The edge calculation example of this demonstration will attempt to correct the temperature reading from the BME680 by substracting an amount based on the current CPU temperature.
&lt;/div&gt;
&lt;h1 id=&#34;install-and-configure-greengrass&#34;&gt;Install and Configure Greengrass&lt;/h1&gt;
&lt;p&gt;The AWS Greengrass service consists of two main elements. The first, Greengrass Core, is a piece of software that is installed on our gateway device, in our case, the Raspberry Pi. Its main functionality is being an MQTT broker like IoT Core, but acting locally. However, it has other available functionality such as the ability to manage and run Lambda functions. We loosely refer to the gateway device and Greengrass Core as an &amp;lsquo;Edge&amp;rsquo;. The software is configured to communicate with Greengrass in AWS IoT, which constitutes the other element. We loosely refer to AWS IoT as the &amp;lsquo;Cloud&amp;rsquo; part.&lt;br&gt;&lt;br&gt;
The process of installing Greengrass Core depends a lot on our device and its operating system, but the docs contain a &lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/module2.html&#34; title=&#34;install Greengrass&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;general guide&lt;/a&gt;. I used apt to install Greengrass on the Pi. When following this guide, you will&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/gg-config.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Register the Greengrass Core&lt;/a&gt; in AWS IoT. Remember to download the package with certificates onto your device&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/what-is-gg.html#gg-core-download-tab&#34; title=&#34;ggc software&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Download&lt;/a&gt; the packaged software for your specific device and operating system&lt;/li&gt;
&lt;li&gt;Set up the user group (ggc_group) and user (ggc_user) that Greengrass Core will assume on your device&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/gg-device-start.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unpack software&lt;/a&gt; and install certificates&lt;/li&gt;
&lt;li&gt;Download and install the root CA certificate&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If it is not already available on the device, we might want to install the Java 8 runtime&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo apt install openjdk-8-jdk
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this demonstration we will use Python 3.7 for the functions we deploy into Greengrass Core. Therefore we also need to make sure that Python 3.7 is available to Greengrass core on the device.&lt;br&gt;&lt;br&gt;
In order for Greengrass to use these runtimes, the names of the binaries must be very specific. Python must be named &lt;code&gt;Python3.7&lt;/code&gt; and the Java runtime must be named &lt;code&gt;Java8&lt;/code&gt;. If the versions installed are correct, but the binaries are not named the way Greengrass expects, e.g. Java 8 is just called &lt;code&gt;Java&lt;/code&gt;, we can either rename them or create symlinks:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# These are examples. Modify to your particular setup
sudo ln -s /usr/bin/python3 /usr/bin/python3.7
sudo ln -s /usr/bin/java /usr/bin/java8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have done all these steps, we might want to check that we have all the dependencies we need by running the Greengrass dependency checker:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir greengrass-dependency-checker-GGCv1.10.x
cd greengrass-dependency-checker-GGCv1.10.x
wget https://github.com/aws-samples/aws-greengrass-samples/raw/master/greengrass-dependency-checker-GGCv1.10.x.zip
unzip greengrass-dependency-checker-GGCv1.10.x.zip
cd greengrass-dependency-checker-GGCv1.10.x
sudo ./check_ggc_dependencies | more
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dependency checker will also provide hints if it cannot locate Python or Java. Make sure these are available. We do not need the other optional dependencies.&lt;br&gt;
When all is set up and configured, we can start Greengrass by running&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd /greengrass/ggc/core/
sudo ./greengrassd start
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Greengrass Core will need to be running on our device in order to establish a connection between Core and the cloud. You can walk through the &lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/module3-I.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AWS hello world cases&lt;/a&gt; to familiarise yourself with Greengrass. We are going to do many of the same things in this demonstration but in a slightly different order and using our hardware setup instead of simulated devices.&lt;/p&gt;
&lt;h1 id=&#34;build-a-greengrass-group&#34;&gt;Build a Greengrass Group&lt;/h1&gt;
&lt;p&gt;During the setup, we created a Greengrass Group. The Group will eventually consist of one core device (in our case the Pi) and a variety of entities associated with the core. Our eventual goal is to have data sent from a thing that is associated with the core to the cloud. To reach that ambition we need to configure the thing, i.e. our sensor, a Lambda function that will move the data to the cloud, and subscriptions. We will go through each of these components in turn, starting with the thing.&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;associate-a-thing-with-a-greengrass-group&#34;&gt;Associate a Thing with a Greengrass Group&lt;/h2&gt;
&lt;p&gt;To associate our thing, the sensor, with the core, we follow the &lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/device-group.html&#34; title=&#34;register a thing in Greengrass&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;guidelines&lt;/a&gt;, and go to AWS IoT &amp;gt; Greengrass &amp;gt; Groups, choose the group we just created, go to Devices, and click &amp;ldquo;Add Device&amp;rdquo;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_device_add.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;The creation procedure is similar to the procedure for any other Thing registered in AWS IoT. Indeed, after registering the device, we will be able to find it under the AWS IoT &amp;gt; Manage tab and we are even able to associate existing devices with a core. I actually reused the device from the &lt;a href=&#34;../../post/iot-poc-publishing/#registering-the-sensor-in-iot-core&#34;&gt;publishing&lt;/a&gt; demonstration for this demo.&lt;br&gt;
Note that before the device is fully associated with the core, the change needs to be deployed. We will go through how to do this after configuring a few more things.&lt;/p&gt;
&lt;h2 id=&#34;connect-a-device-to-greengrass-core&#34;&gt;Connect a Device to Greengrass Core&lt;/h2&gt;
&lt;p&gt;In this section, we will setup up a script that connects to the core with the eventual goal of publishing readings from the sensor to a topic. The messages will never reach the cloud, however. Instead, the messages are published into the core device on a topic that only lives within the the Greengrass group. The logic is something along the lines of&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;setup sensor
connect to Greengrass core
while true
	get sensor values
	publish to local topic
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This logic is very similar to what we did in the case of simple &lt;a href=&#34;../../post/iot-poc-publishing/&#34;&gt;publishing&lt;/a&gt;, and indeed the two cases are very similar. The main difference is that we will set up and configure a client that connects to the local MQTT broker in Greengrass Core rather than the cloud based broker in IoT Core.&lt;br&gt;&lt;br&gt;
To connect a device/thing to Greengrass core, we use the same MQTT client as always and, as usual, we will need a variety of resources to establish the right connection.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient

myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId)
myAWSIoTMQTTClient.configureCredentials(groupCA, privateKeyPath, certificatePath)
myAWSIoTMQTTClient.configureEndpoint(coreHost, corePort)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let us discuss each of these resources in turn.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;clientId&lt;/code&gt; could be anything allowed by the policy we created for our thing in the previous step. To keep down complexity, using the device ID is a prudent idea.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;privateKeyPath&lt;/code&gt; is the complete path to the key associated with the certificate created earlier for our thing.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;certificatePath&lt;/code&gt; is the complete path to the certificate for our thing that we created earlier.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;groupCA&lt;/code&gt; is the certificate authority for our Greengrass group and is used to authenticate that our thing is indeed connected to the intended Greengrass core when sending and receiving messages. In a moment we will walk through how to obtain this certificate. Note that this is &lt;em&gt;not&lt;/em&gt; the root certificate authority used when communicating with AWS IoT Core.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;coreHost&lt;/code&gt; is the server running the Greengrass Core, i.e. our core device&lt;/li&gt;
&lt;li&gt;&lt;code&gt;corePort&lt;/code&gt; is the port on which our thing will communicate with the core using the MQTT protocol. The default setting when generating a new Greengrass Core is 8883, but we could &lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/gg-core.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;configure&lt;/a&gt; this, if we wanted to.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The three first elements are realtively straight forward; we know these from when we created the thing and its certificate in the first place. The three remaining resources, however, require a bit of additional work. The group certificate is managed by AWS and by default it is rotated every 7 days. This requires a little bit of effort on our part when connecting things to the core, but is worth it for the free added security. Since the the Greengrass Core is connected to AWS, AWS also knows the host and port, and so while we are querying AWS for the group certificate, we can also retrieve these two pieces of information. This process of retrieving connection information is called core discovery and is the only time our thing will connect to the cloud. Once connected to the core, all communication will be with it.&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;core-discovery&#34;&gt;Core Discovery&lt;/h3&gt;
&lt;p&gt;To set up the discovery process, we need a special dicovery client that is also included in the AWS IoT SDK&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from AWSIoTPythonSDK.core.greengrass.discovery.providers import DiscoveryInfoProvider

discoveryInfoProvider = DiscoveryInfoProvider()
discoveryInfoProvider.configureEndpoint(host)
discoveryInfoProvider.configureCredentials(rootCAPath, certificatePath, privateKeyPath)
discoveryInfoProvider.configureTimeout(10)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The discovery client is set up using the usual materials; the AWS IoT custom endpoint for our account, the AWS root certificate authority, the private key, and certificate for our thing. We also tell the client to wait a maximum of 10 seconds before timing out a connection attempt.&lt;br&gt;
The client can be used to send a discovery request to AWS and fetch connection information for the core. It works like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Returns list of AWSIoTPythonSDK.core.greengrass.discovery.models.DiscoveryInfo objects
discoveryInfo = discoveryInfoProvider.discover(thingName)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We provide the thing name of the thing for which we are looking up connection information. In most of our applications this is probably the same as our client ID, but in this case it &lt;em&gt;has&lt;/em&gt; to be the name of our thing as registered in AWS.&lt;br&gt;
If the request is successful, &lt;code&gt;discoveryInfo&lt;/code&gt; will hold information about Greengrass groups that the device belongs to (a device can belong to several groups, but each group has exactly one core). Of interest to us are the certificate authorities and the connection information, the lists of which can be accessed as such:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Returns list of AWSIoTPythonSDK.core.greengrass.discovery.models.CoreConnectivtyInfo objects
caList = discoveryInfo.getAllCas()
# Returns list of tuples (CA content, group ID)
coreList = discoveryInfo.getAllCores()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These are lists with each entry representing a core. If our device only belongs to a single Greengrass core, this list will only have one entry. We can get the certificate authority for the first available core like this&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;groupId, ca = caList[0]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each core might have several connection options so we might like to keep them in a list to loop over later&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;coreInfo = coreList[0]
# Get a list of tuples (host, port)
coreConnectivityInfoList = coreInfo.connectivityInfoList
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have everything we need to have out thing automatically discover and connect to the Greengrass core:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from AWSIoTPythonSDK.core.greengrass.discovery.providers import DiscoveryInfoProvider
from AWSIoTPythonSDK.core.protocol.connection.cores import ProgressiveBackOffCore
from AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient
# Configure client for gg core discovery
discoveryInfoProvider = DiscoveryInfoProvider()
discoveryInfoProvider.configureEndpoint(host)
discoveryInfoProvider.configureCredentials(rootCAPath, certificatePath, privateKeyPath)
discoveryInfoProvider.configureTimeout(10)
# Discover gg cores for the thing
discoveryInfo = discoveryInfoProvider.discover(thingName)
# Get connection info
caList = discoveryInfo.getAllCas()
coreList = discoveryInfo.getAllCores()
# Get info for the first core
groupId, ca = caList[0]
coreInfo = coreList[0]
coreConnectivityInfoList = coreInfo.connectivityInfoList

# Since the MQTT client expects a certificate file we have to
#  put the group certificate authority into a file and save
#  the path
groupCA = GROUP_CA_PATH + groupId + &amp;quot;_CA_&amp;quot; + str(uuid.uuid4()) + &amp;quot;.crt&amp;quot;
if not os.path.exists(GROUP_CA_PATH):
    os.makedirs(GROUP_CA_PATH)
groupCAFile = open(groupCA, &amp;quot;w&amp;quot;)
groupCAFile.write(ca)
groupCAFile.close()
    
# Initialise the MQTT client
myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId)
myAWSIoTMQTTClient.configureCredentials(groupCA, privateKeyPath, certificatePath)

# Loop over and try connection with each set of host name and port
connected = False
for connectionInfo in coreConnectivityInfoList:
    coreHost = connectionInfo.host
    corePort = connectionInfo.port
    myAWSIoTMQTTClient.configureEndpoint(coreHost, corePort)
    try:
        myAWSIoTMQTTClient.connect()
        connected = True
        break
    except BaseException as e:
        pass
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is the most condensed code needed to implement discovery, but in production we will want to add much more logging, error handling, retries for discoveries, and other frills. See the section below on Greengrass in production for a further discussion on how to improve the thing script for a real world scenario.&lt;/p&gt;
&lt;h3 id=&#34;publish-inside-the-greengrass-group&#34;&gt;Publish inside the Greengrass Group&lt;/h3&gt;
&lt;p&gt;Now that our thing is connected to the core in its Greengrass group we can start publishing data to a local topic. From the point of view of our thing, this works just like publishing to a topic on AWS IoT. Using the client we configured:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;myAWSIoTMQTTClient.publish(topic, messageJson, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this, we have everything needed to run our thing running. The &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/greengrass_thing.py&#34; title=&#34;example script&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;example script&lt;/a&gt; for this section summarises everything we have done so far but contains a bit more detail. It is based off of the &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/basicDiscovery.py&#34; title=&#34;AWS IoT SDK basic discovery example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;example&lt;/a&gt; included with the AWS IoT SDK and was adapted to be used with our hardware setup. Note that the functionality in this script is running on the same Pi as the Greengrass software. In a real production setting, however, the two are likely to be seperate physical devices.&lt;br&gt;&lt;br&gt;
Once again, it is worth noting that if we have not deployed after associating the thing with the core, then our core device does not yet know that it is allowed to associate with the thing and the discovery process will fail. Specifically, we will get a &lt;code&gt;DiscoveryDataNotFoundException&lt;/code&gt;. It happens to me all the time, but all we need to do is deploy the change. We will do so shortly.&lt;br&gt;&lt;br&gt;
Even assuming that the Greengrass core is running and the thing script is publishing values, not much is happening yet. If we go to the AWS IoT test test client in the console and subscribe to the topic that the thing is publishing to, there should be no values flowing in, as nothing is being sent there. In order for us to see data flowing into the cloud, we have to grab the data in Greengrass Core and pass it on to a new topic that is published to the cloud.&lt;br&gt;
The way this is done with Greengrass is by defining a Lambda function in AWS and deploying onto the core.&lt;/p&gt;
&lt;h2 id=&#34;write-lambda-functions-for-greengrass&#34;&gt;Write Lambda Functions for Greengrass&lt;/h2&gt;
&lt;p&gt;Lambda functions are a huge subject on their own and, for the purposes of this demonstration, we will assume at least some fammiliarity with the concept. We will still walk through each step needed to writing a Lambda for the edge, but if you are new to AWS Lambda, you might want to read the &lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/getting-started.html&#34; title=&#34;AWS Lambda getting started&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;getting started guide&lt;/a&gt; to get a feel for the terminology. Lambda is a pretty cool service, and chances are that you will find it useful for plenty of other applications.&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;lambda-code&#34;&gt;Lambda Code&lt;/h3&gt;
&lt;p&gt;The first Lambda we will write is very simple. It should take an incoming MQTT message, parse the message, and republish it on a new topic to AWS IoT. So something along the lines of&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;get incoming message
extract body of message
republish body to new topic
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Very linear, if we assume that the code is only run when there is an incoming message. This is exactly the power of Lambda. We can make a MQTT message, such as the ones we publish from the sensor, trigger a Lambda function. In the next section, we will go through how to set up the trigger. For now, just assume that the code we write is triggered each time there is a message.&lt;br&gt;
A Lambda always has a function handler that contains the details of whatever triggered the function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def function_handler(event, context):
    # event holds the message body
    # context holds the incoming topic etc.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can name the function whatever we want, just as long as we remember that name and give it the input objects &lt;code&gt;event&lt;/code&gt; and &lt;code&gt;context&lt;/code&gt;.&lt;br&gt;
The &lt;code&gt;event&lt;/code&gt; object holds the body of the MQTT message that triggered the Lambda. This is essentially the json we want to pass on to a new topic.&lt;br&gt;
The &lt;code&gt;context&lt;/code&gt; object holds all sorts of information on what triggered the Lambda, including the topic of the message. We do not really need any of this information now, so we can just ignore it.&lt;br&gt;&lt;br&gt;
In order to republish to AWS IoT, we are, as usual, going to need an MQTT client. Remember though that we went through all sorts of trouble to connect the core to AWS IoT and that the core is itself an MQTT broker, so there is no need to set up a new client and connection. Instead, we use one of the clients included in the &lt;a href=&#34;https://github.com/aws/aws-greengrass-core-sdk-python&#34; title=&#34;Greengrass Python SDK&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Greengrass SDK&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import greengrasssdk

client = greengrasssdk.client(&#39;iot-data&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We do not have to install the SDK on our device, but we will need to include it in our Lambda. There are multiple client types included in the SDK, and since we are doing IoT stuff, we need the &lt;code&gt;iot-data&lt;/code&gt; client.&lt;br&gt;&lt;br&gt;
Now we just need to decide on the topic to publish to. This needs to be a topic allowed in the policy for the core. With that, we have everything needed for the Lambda function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import greengrasssdk

REPUB_TOPIC = &#39;republish/reading&#39;

client = greengrasssdk.client(&#39;iot-data&#39;)

def function_handler(event, context):
    client.publish(topic=REPUB_TOPIC, payload=event)
    return
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is all we need to republish. The full example with a few extra frills, such as adding the incoming topic to the output body, is &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/greengrass_simple_lambda.py&#34; title=&#34;Simple Lambda example for Greengrass&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. Let us now look at creating the actual Lambda.&lt;/p&gt;
&lt;h3 id=&#34;create-a-lambda-function&#34;&gt;Create a Lambda Function&lt;/h3&gt;
&lt;p&gt;To create a Lambda function, we navigate to the AWS Lambda console. Under &amp;lsquo;Functions&amp;rsquo; we click &amp;lsquo;Create Function&amp;rsquo;.&lt;br&gt;
In the wizard, we choose &amp;lsquo;Author from scratch&amp;rsquo;, give our function a name, and choose our Python runtime. I named mine &amp;lsquo;repub_temp&amp;rsquo; and have been using Python 3.7 for the example. Then we click &amp;lsquo;Create Function&amp;rsquo;. This might take a moment.&lt;br&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/lambda_create.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;The next thing we need to do is to prepare our code for the Lambda function. So leave the console for a little while and locate the Python script we just created. Now download the &lt;a href=&#34;https://github.com/aws/aws-greengrass-core-sdk-python/tree/master/greengrasssdk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Greengrass SDK&lt;/a&gt; folder. We only need the &amp;lsquo;greengrasssdk&amp;rsquo; folder, not the examples, docs, etc. Now package the Greengrass SDK and the Python script into a .zip.&lt;br&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/lambda_package.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Now jump back to the console and scroll down to the &amp;lsquo;Function Code&amp;rsquo; window. In the &amp;lsquo;Code entry type&amp;rsquo; dropdown, select the &amp;lsquo;Upload a .zip file&amp;rsquo; option and upload the .zip file we just created. Also make sure to change the Handler to &lt;code&gt;&amp;lt;function file&amp;gt;.&amp;lt;our handler function&amp;gt;&lt;/code&gt;, in the case of this example, it is &lt;code&gt;greengrass_simple_lambda.function_handler&lt;/code&gt;. Click &amp;lsquo;Save&amp;rsquo; to save the changes.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/lambda_function_code.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Now scroll up and, under the &amp;lsquo;Actions&amp;rsquo; dropdown, select &amp;lsquo;Publish new version&amp;rsquo;. We can optionally provide a version description.&lt;br&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img height=&#34;100&#34; src=&#34;../../project/iot-poc/images/lambda_actions.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Now we go to &amp;lsquo;Actions&amp;rsquo; again and select &amp;lsquo;Create alias&amp;rsquo;. We give the alias a name and point it to the version we just created. Greengrass does not support pointers to the &lt;code&gt;$latest&lt;/code&gt; version, so make sure to select a specific version.&lt;br&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/lambda_alias.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Now that our Lambda has been fully defined, we need to associate it with the Greengrass core.&lt;/p&gt;
&lt;h3 id=&#34;attach-a-lambda-to-greengrass&#34;&gt;Attach a Lambda to Greengrass&lt;/h3&gt;
&lt;p&gt;Navigate to the Greengrass console. Go to &amp;lsquo;Groups&amp;rsquo; and select the Greengrass group. Then go to the &amp;lsquo;Lambdas&amp;rsquo; menu and click &amp;lsquo;Add Lambda&amp;rsquo;.&lt;br&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_add.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Choose &amp;lsquo;Use an existing Lambda function&amp;rsquo;. Select the Lambda function we just created and click &amp;lsquo;Next&amp;rsquo;. Select the alias we just created and click &amp;lsquo;Finish&amp;rsquo;.&lt;br&gt;
That is it for the Lambda. Now the final piece of the puzzle is ensuring that data flows from the sensor to the Lambda function and then from the Lambda function to the cloud. This is done with subscriptions.&lt;/p&gt;
&lt;h2 id=&#34;configure-subscriptions-in-greengrass&#34;&gt;Configure Subscriptions in Greengrass&lt;/h2&gt;
&lt;p&gt;Subscriptions are the way to configure where what data goes inside the Greengrass group. They specify the pubsub verticies between the things and Lambdas of the group and offer filtering capabilities.&lt;br&gt;&lt;br&gt;
To set up a subscription, go to the Greengrass console. Go to &amp;lsquo;Groups&amp;rsquo; and select our Greengrass group. Then go to the &amp;lsquo;Subscriptions&amp;rsquo; menu and click &amp;lsquo;Add Subscription&amp;rsquo;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_subscription_add.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;When setting up at subscription we are asked to specify the source and the target. The source and target could be many things, including a specific device/thing, a Lambda function, the cloud, or a Shadow. Subscriptions are one-way, so a two-way communication between two entities within the group would require two subscriptions.&lt;br&gt;
For this demonstration specifically, we want to set up a subscription from our thing which generates and publishes data locally to the Lambda function we created. The thing can be found under the &amp;lsquo;Devices&amp;rsquo; tab and the function under the &amp;lsquo;Lambdas&amp;rsquo; tab.&lt;br&gt;
Clicking &amp;lsquo;Next&amp;rsquo; the first time will spawn a topic filter box. This is an optional filter we can specify to make data flows even more dynamic. I have given an example here, but it is not neccessary for the purposes of this demonstration. Click &amp;lsquo;Next&amp;rsquo; again and &amp;lsquo;Finish&amp;rsquo; to create the subscription.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_subscription_tolambda.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;We need one more subscription, namely the one telling Greengrass that we are publishing data from the Lambda function to the Cloud. We set up another subscription; this time setting the Lambda function as the source and &amp;lsquo;IoT Cloud&amp;rsquo; as the target. Again we can specify an optional filter.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_subscription_fromlambda.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Now all the pieces are in place. We are ready to deploy.&lt;/p&gt;
&lt;h2 id=&#34;deploy-a-greengrass-group&#34;&gt;Deploy a Greengrass Group&lt;/h2&gt;
&lt;p&gt;Right now, nothing is running on our gateway device except for the Greengrass daemon. Unless we have deployed along the way, none of the device configurations, Lambda function, or subscriptions have made their way onto the core.&lt;br&gt;
Before deploying, we should make sure that the Greengrass Daemon is actually running on our gateway device. From a shell on our device&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ps aux | grep -E &#39;greengrass.*daemon&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the output from this command includes a root entry for &lt;code&gt;/greengrass/ggc/packages/1.10.1/bin/daemon&lt;/code&gt;, then the daemon is running. If the daemon is not running, recall that we can start it using:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd /greengrass/ggc/core/
sudo ./greengrassd start
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we are ready to deploy. Fortunately it is very simple to deploy everything we have specified. From our group in the Greengrass console, we are always within sight of the &amp;lsquo;Action&amp;rsquo; dropdown menu which has a &amp;lsquo;Deploy&amp;rsquo; option that we will now click on and utilise. If all goes well the status of our device will go from &amp;lsquo;Is pending&amp;rsquo; to &amp;lsquo;In progress&amp;rsquo; to &amp;lsquo;Successfully completed&amp;rsquo;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=150 src=&#34;../../project/iot-poc/images/greengrass_deploy.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;h2 id=&#34;put-everything-together&#34;&gt;Put Everything Together&lt;/h2&gt;
&lt;p&gt;To get the example for this section to work, we need to do a few things in the correct order.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Ensure that the device representing our sensor is associated with the core&lt;/li&gt;
&lt;li&gt;Ensure that the &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/greengrass_simple_lambda.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lambda function&lt;/a&gt; is defined and associated with the core&lt;/li&gt;
&lt;li&gt;Ensure that there is a subscription from the device to the Lambda function and another subscription from the Lambda function to the cloud&lt;/li&gt;
&lt;li&gt;Ensure that the Greengrass daemon is running&lt;/li&gt;
&lt;li&gt;Deploy everything&lt;/li&gt;
&lt;li&gt;Run the discovery and publishing &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/greengrass_thing.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;script&lt;/a&gt; for the sensor device&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can run the script like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3.7 greengrass_thing.py -e &amp;lt;AWS IoT custom endpoint&amp;gt; -r &amp;lt;root CA&amp;gt; -c &amp;lt;thing certificate&amp;gt; -k &amp;lt;private key&amp;gt; -id &amp;lt;client ID&amp;gt; -t &amp;lt;local topic&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And let us quickly look at whether it is working by going to the IoT test client. If we have done everythin correctly, we should not see any data published on the local topic from the sensor device. Rather, we should see data from the topic &lt;code&gt;republish/reading&lt;/code&gt; topic that we defined in the Lambda script. Let us see.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_test.png&#34; alt=&#34;iot setup&#34;&gt;
	&lt;br&gt;
&lt;/div&gt;
&lt;p&gt;It is indeed working!&lt;br&gt;&lt;br&gt;
Congratulations! You now know how to work with Greengrass and you have all the neccessary components to create your own Greengrass groups and create powerful IoTs with edges. However, if you are interested and want to know why we went through so much trouble to connect our device through Greengrass, I have another small example demonstrating the concept and power of &amp;lsquo;calculations on the edge&amp;rsquo;.&lt;/p&gt;
&lt;h1 id=&#34;do-calculations-on-the-edge&#34;&gt;Do Calculations on the Edge&lt;/h1&gt;
&lt;p&gt;Compared to &lt;a href=&#34;../../post/iot-poc-publishing/&#34;&gt;simple publishing&lt;/a&gt;, having a device publish its data through Greengrass might seem like a large unnecessary hassle. Indeed, sometimes it is, but as soon as our IoT starts to grow beyond a few devices, there will be headaches that are much more simple to solve when Greengrass and, in particular, Lambda is there.&lt;br&gt;
In this example, we will demonstrate the utility of the setup through a simple example. I placed the BME680 air quality sensor quite close to the CPU of my Pi, meaning that the temperature of the CPU will interfere with what I really want to measure; the temperature of the air. If we were to obtain the temperature of the CPU, we might be able to calcualte a compensated temperature that is more representative of the air temperature. A quick disclaimer before we begin: there are a plethora of ways to avoid or compensate for this particular problem, including extending the sensor away from the Pi or including the compensation logic in the feeder script, but for the sake of this example assume that we have no flexibility in terms of the hardware and are aiming for a high degree of flexibility and maintainability in the software we create.&lt;br&gt;&lt;br&gt;
Specifically, we will create a Lambda function that performs the compensation for us. We will go for something simple like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;compensated_temperature = 2 * temperature_reading - average_cpu_temperature
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a very rough estimate, but it will get us going with a minimum viable solution.&lt;br&gt;
Since we are working with a Raspberry Pi, we can easily get the CPU temperature by reading the file &lt;code&gt;/sys/class/thermal/thermal_zone0/temp&lt;/code&gt; like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def get_cpu_temperature():
    f = open(&amp;quot;/sys/class/thermal/thermal_zone0/temp&amp;quot;)
    raw_temp = f.read()
    f.close()
    return float(raw_temp)/1000.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;CPU temperatures can be somewhat jittery, so let us read the temperature in an interval an get the average before we calculate the compensated temperature&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for n in range(8):
    cpu_temps.append(get_cpu_temperature())
    time.sleep(1)
avg_cpu_temp = sum(cpu_temps)/float(len(cpu_temps))
# Compensated temperature
comp_temp = 2*input_temperature - avg_cpu_temp
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That is really all there is to it, and this is all we need to add to the previous example. The &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/greengrass_sys_lambda.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;full Lambda function example&lt;/a&gt; has a few extra frills such as error handing and logging. The next step is to define this Lambda function and associate it with the Greengrass group. We could create a new Lambda function, but I opted to update the Lambda function we created in the previous section. To do so, open the function in the Lambda console, insert the &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/greengrass_sys_lambda.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code&lt;/a&gt; and publish a new version. Then, from the &amp;lsquo;Version&amp;rsquo; dropdown menu, select the alias we created earlier.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img height=170 src=&#34;../../project/iot-poc/images/lambda_new_alias.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Scroll down a bit, find the &amp;lsquo;Alias configuration&amp;rsquo;, and point the alias to the version of the Lambda we just created. Click &amp;lsquo;Save&amp;rsquo; to save changes.&lt;br&gt;&lt;br&gt;
Before we deploy, the Lambda will need some additional configuring. By default, any Lambda will timeout after 3 seconds, but ours will be running for at least 8 seconds to get an average CPU temperature. Furthermore, Lambda functions running in Greengrass to not have access to local resources under &lt;code&gt;/sys&lt;/code&gt;. We will need to change these defaults.&lt;br&gt;
Go to the Greengrass console and select the group. Under the Lambda menu, click the three dots in the upper right of the Lambda function, we just modified and select &amp;lsquo;Edit configuration&amp;rsquo;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_configure.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Set the timeout to 10 seconds and enable access to &lt;code&gt;/sys&lt;/code&gt;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_configurations.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;All that is left is to deploy the Greengrass group from the Greengrass console. The resulting output to the cloud should look exactly like before. This time around though, the temperature readings should look a bit more realistic.&lt;br&gt;&lt;br&gt;
Congratulations! You are now doing calculations on the edge. It might not feel like much, but consider how we might have gone about solving the problem in other ways.&lt;br&gt;
We could have published CPU temperature readings to the cloud and done the calcualtions using Lambda functions, SQL queries, or EC2 compute in the cloud. The cost of the additional storage and the cloud compute would make such a solution several times more expensive that what we just did.&lt;br&gt;
We could have put the calculations directly in the feeder script. While this would cost slightly less than our solution, it increases the operational burden. Sensors and microcontrollers are generally less accessible, especially in a manufacturing context. With our solution, we can manage the calculations in the cloud from the comfort of our chair or even home. If we wanted to start recording the temperature in Kelvins, all we would have to do is add the calculation to our Lambda function and deploy the changes.&lt;br&gt;&lt;br&gt;
This was a very simple example of edge calculations managed from the cloud. Greengrass is, however, capable of handling much more complex setups than what we just built. Specifically, it is even possible to deploy machine learning models that are trained in the cloud onto the edge. These advanced features of Greengrass are the subject of the &lt;a href=&#34;../../post/iot-poc-greengrass_ml/&#34; title=&#34;Advanced features of Greengrass demo&#34;&gt;next demonstration&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;in-production&#34;&gt;In Production&lt;/h1&gt;
&lt;p&gt;This section is not part of the demonstration as such. It is but a short discussion of some of the considerations we have to take when bringing Greengrass to production in a manufacturing environment and how to improve upon the examples to make them production ready. Considerations from &lt;a href=&#34;../../post/iot-poc-publishing/#in-production&#34;&gt;previous demonstrations&lt;/a&gt; still apply.&lt;/p&gt;
&lt;h2 id=&#34;default-vs-custom-core-config&#34;&gt;Default vs Custom Core Config&lt;/h2&gt;
&lt;p&gt;Note that in the demonstration we just went for the default options when setting up the Greengrass core. This creates a new ploicy for the certificate attached to the core. The policy is extremely permissive and, while it works great for demonstration purposes, it might not be what we want in a production setting.&lt;br&gt;
The great thing about Greengrass is that we can define aggregations and handle the diversity of incoming data at the edge and then only publish to a set of neatly organised topics to the cloud. This means that we can manage a diverse set of topics and devices at the edge but still have a very restrictive policy for communication with the cloud.&lt;/p&gt;
&lt;h2 id=&#34;handle-certificate-authority-rotation&#34;&gt;Handle Certificate Authority Rotation&lt;/h2&gt;
&lt;p&gt;Per default, the CA for the local MQTT server run by Greengrass is rotated every 7 days. We can adjust this to be more or less frequent, but if the Greengrass core remains connected to the cloud it will eventually be rotated. This is a layer of free added security that we do not have to manage, but it requires a bit of extra development considerations for our devices.&lt;br&gt;
In particular, our devices must be able to handle a situation where the CA obtained in the initial discovery process is no longer valid. Depending on our production architecture, we might have to call the discovery process again.&lt;br&gt;
More details are available in the &lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/device-auth.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; in the section &amp;lsquo;Certificate Rotation on the Local MQTT Server&amp;rsquo;.&lt;/p&gt;
&lt;h2 id=&#34;manage-the-greengrass-lifecycle&#34;&gt;Manage the Greengrass Lifecycle&lt;/h2&gt;
&lt;p&gt;Chances are that the device running Greengrass core will need to reboot at some point. Rather than starting the Greengrass daemon manually, we want it to start automatically on reboot. The &lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/install-ggc.html#ggc-package-manager-systemd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; has information of how to do so but, for a Raspberry Pi, it is fairly straightforward to do using systemd.&lt;br&gt;&lt;br&gt;
Verify that the Greengrass configuration option to use systemd is set to yes. The config file can be found on the Greengrass device at &lt;code&gt;/greengrass/config/config.json&lt;/code&gt;. Ensure that &lt;code&gt;&amp;quot;useSystemd&amp;quot; : &amp;quot;yes&amp;quot;&lt;/code&gt;, otherwise change it.&lt;br&gt;&lt;br&gt;
Make service a service file at &lt;code&gt;/etc/systemd/system/greengrass.service&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[Unit]
Description=Greengrass Daemon

[Service]
Type=forking
PIDFile=/var/run/greengrassd.pid
Restart=on-failure
ExecStart=/greengrass/ggc/core/greengrassd start
ExecReload=/greengrass/ggc/core/greengrassd restart
ExecStop=/greengrass/ggc/core/greengrassd stop

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Make the service exeutable&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo chmod u+rwx /etc/systemd/system/greengrass.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Add service to systemd&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;systemctl enable greengrass.service
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Test the service by rebooting the device and confirming that the Greengrass daemon is running. We can check whether the daemon is running with&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ps aux | grep -E &#39;greengrass.*daemon&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;connection-retries-and-progressive-backoff-logic&#34;&gt;Connection Retries and Progressive Backoff Logic&lt;/h2&gt;
&lt;p&gt;Imagine the following situation. We have a couple of hundred sensors that connect to one or a few Greengrass core devices, and all run off of the same power supply. At one point, the power supply is switched off, maybe it is maintenance maybe it is an error, but after a while power returns and our sensors and their controllers reboot. We set up the controllers such that they will automatically try to reconnect with the core. This is fine, but suddenly the core is getting hundreds of connection requests within a few seconds, so the controllers are receiving errors. Now, obviously there is nothing wrong with the core devices; they are just getting too many requests, so we will want the controllers to retry the connection before giving up. However, we do not want to have them all retry at the same time lest we repeat the story again.&lt;br&gt;
The idea behind progressive backoff logic is to keep retrying but waiting progressively longer for each retry as well as throwing a bit of randomness into the wait time. One type of backoff logic, exponential backoff, waits exponentially longer before each retry. Here is a bit of Python style pseudocode showing the basics of it&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import time

retries = 0
wait_time = 2
while retries &amp;lt; max_retries:
    try:
        connect()
        break
    except connectionFailedException:
        time.sleep(wait_time)
        wait_time += wait_time*1.5
        wait_time += random_number
        retries += 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/general/latest/gr/api-retries.html&#34; title=&#34;AWS Docs on retries&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Each AWS SDK implements&lt;/a&gt; some sort of backoff logic and so does the AWS IoT SDK, so we do not have to do it ourselves. To increase clarity, I did not include the retry logic in the examples for this demonstration, but it is fairly straightforward to get started&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from AWSIoTPythonSDK.core.protocol.connection.cores import ProgressiveBackOffCore

backOffCore = ProgressiveBackOffCore()
retries = 0
while retries &amp;lt; max_retries:
    try:
        connect()
        break
    except connectionFailedException:
        backOffCore.backOff()
        retries += 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The SDK also ships with an &lt;a href=&#34;https://github.com/aws/aws-iot-device-sdk-python/blob/master/samples/greengrass/basicDiscovery.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;example&lt;/a&gt; very similiar to what we did in the previous sections and also implements this backoff method.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Industrial IoT with AWS and Python</title>
      <link>/project/iot-poc/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/project/iot-poc/</guid>
      <description>&lt;p&gt;This is an introduction to and a series of demonstrations of concepts in Industrial Internet of Things (iIoT). It is a port of my &lt;a href=&#34;https://github.com/AnHosu/iot_poc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt;, where all code and materials are available.&lt;br&gt;
On one hand, it is a simple introduction to how we might go about getting our sensor data from sensors to the cloud. On the other hand, we will dive into advanced IoT concepts. So if you are looking for demonstrations of concepts like edge inference, device fleet management, MQTT, and shadow records you have come to the right place.&lt;br&gt;&lt;br&gt;
There are many ways to do IoT and there is an ocean of offerings out there. This introduction focuses on AWS IoT services like IoT Core and Greengrass and uses the AWS IoT SDK for Python. The concepts are transferrable to other services, but we will write code specifically for AWS IoT and we will do so mostly in Python.&lt;br&gt;&lt;br&gt;
AWS offers multiple ways to ingest and store data but, for industrial scale sensor data, it especially makes sense to look at the AWS IoT and streaming offerings. However, even here there are different ways to go about doing the same thing and the nuances can get confusing. This tutorial consists of a general introduction and five seperate demonstrations designed to exemplify increasingly complex IoT functionality. In each demonstration, We will work from scratch to the full setup, making it a full proof of concept for an AWS IoT architecture. I recommend starting at case 1 and working your way through each case before proceeding to the next. A full disclaimer before you get started though; the tutorial does reflect some subjective opinions and I am by no means an expert on the subject, but the tutorial arises from my work with IoT in a manufacturing setting.&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;contents&#34;&gt;Contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-hardware-setup&#34;&gt;Hardware Setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#case-setups&#34;&gt;Cases&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#1-publish-industrial-data-with-aws-iot&#34;&gt;Simple Publishing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#2-publish-and-subscribe&#34;&gt;Publish and Subscribe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#3-utilise-thing-shadows&#34;&gt;Utilise Thing Shadows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#4-build-an-edge-with-greengrass&#34;&gt;Build an Edge with Greengrass&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#5-advanced-greengrass-features&#34;&gt;Advanced Features and ML in Greengrass&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#iot-with-aws-iot&#34;&gt;Introduction to AWS IoT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;the-hardware-setup&#34;&gt;The Hardware Setup&lt;/h1&gt;
&lt;p&gt;It would not be IoT without at least one device. The demonstrations focus on the software layer but use actual hardware, not simulations, to prove concepts. I have been using a Raspberry Pi 3 Model B+ along with a Bosch BME680 sensor on a &lt;a href=&#34;https://shop.pimoroni.com/products/bme680-breakout&#34; title=&#34;Pimoroni BME680 breakout&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;breakout&lt;/a&gt;. Any sensor would do, but I like this one and this particular breakout beacause it has a nice &lt;a href=&#34;https://github.com/pimoroni/bme680-python&#34; title=&#34;Pimoroni BME680 library&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;library&lt;/a&gt; which allows us to reduce the amount of code we need to query our sensor to a minimum. Furthermore, this particular sensor has four different components, allowing us to measure temperature, atmospheric pressure, relative humidity, and, with a bit of additional work, air quality. I will not elaborate too much on this particular sensor equipment for this demonstration and I will try to be clear about when you can replace my example code with code querying your particular sensor.&lt;br&gt;&lt;br&gt;
In IoT terms the sensor is the &amp;lsquo;Thing&amp;rsquo; or &amp;lsquo;Device&amp;rsquo;, and our Raspberry Pi is the &amp;lsquo;Edge&amp;rsquo; or &amp;lsquo;Gateway Device&amp;rsquo;. Names are not too important and, in real life, you would use different hardware for different situations.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;images/hardware_setup.jpg&#34; alt=&#34;iot setup&#34;&gt;
	&lt;br&gt;
    Raspberry Pi 3 Model B+ with the BME680 sensor. The sensor is intentionally placed quite close to the CPU, which will interfere with the temperature readings. In demonstration 4, we will deploy calculations from AWS onto the Pi to correct for this, as an example of edge calculations.
    &lt;br&gt;
    &lt;br&gt;
&lt;/div&gt;
&lt;p&gt;Hardware-wise everything will be the same throughout each demonstration; BME680 connected to the Pi which is connected to the internet. If you are using the same breakout, take a look at &lt;a href=&#34;https://learn.pimoroni.com/tutorial/sandyj/getting-started-with-bme680-breakout&#34; title=&#34;BME680 tutorial&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this tutorial&lt;/a&gt; to set it up.&lt;/p&gt;
&lt;h1 id=&#34;demonstrations&#34;&gt;Demonstrations&lt;/h1&gt;
&lt;p&gt;The five demonstrations are the main attraction of this tutorial, and if you are looking for examples and code snippets, then go ahead and dive right in. If you prefer a bit of theoretical background before you get started, then jump to the next section before starting the cases.&lt;/p&gt;
&lt;h2 id=&#34;1-publish-industrial-data-with-aws-iot&#34;&gt;1) Publish Industrial Data with AWS IoT&lt;/h2&gt;
&lt;p&gt;The simplest way to do IoT with AWS. We will register our sensor as a thing in AWS IoT Core and will be using the AWS IoT Python SDK to publish sensor readings to a topic. We go through concepts such as things, topics, MQTT, and more.&lt;br&gt;
In this case, the Raspberry Pi is simply simulating a microcontroller that will query the sensor and publish the result.&lt;br&gt;&lt;br&gt;
&lt;a href=&#34;../../post/iot-poc-publishing/&#34; title=&#34;simple publishing case&#34;&gt;Get started here&lt;/a&gt;.
Here is the full &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/simple_publishing.py&#34; title=&#34;simple publishing example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;example script&lt;/a&gt;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=&#34;500&#34; src=&#34;images/publishing_architecture.png&#34; alt=&#34;IoT overview&#34;&gt;
  &lt;br&gt;
  Schematic of the architecture we are building in the demonstration of publishing.
&lt;/div&gt;
&lt;h2 id=&#34;2-publish-and-subscribe&#34;&gt;2) Publish and Subscribe&lt;/h2&gt;
&lt;p&gt;In this case, we build upon the previous case and will construct a setup where our device will not just send data but also respond to messages sent to it.&lt;br&gt;
The Raspberry Pi is still just simulating a microcontroller, but we start to see how having compute at the edge is useful and can be managed with AWS IoT.&lt;br&gt;&lt;br&gt;
&lt;a href=&#34;../../post/iot-poc-pubsub&#34; title=&#34;simple pub/sub case&#34;&gt;Get started here&lt;/a&gt;. Here is the full &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/simple_pubsub.py&#34; title=&#34;simple pubsub example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;example script&lt;/a&gt;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=&#34;500&#34; src=&#34;images/pubsub_architecture.png&#34; alt=&#34;pubsub overview&#34;&gt;
  &lt;br&gt;
  Schematic of the architecture we are building in the demonstration of publishing and subscribing.
&lt;/div&gt;
&lt;h2 id=&#34;3-utilise-thing-shadows&#34;&gt;3) Utilise Thing Shadows&lt;/h2&gt;
&lt;p&gt;Using the Thing Shadow feature of AWS IoT, we will create a twin/shadow of our device in the cloud and update it whenever a new reading is available. We could use this cool feature to build a digital twin of our process.&lt;br&gt;
The Raspberry Pi is still simulating a microcontroller that will query the sensor, but instead of just publishing the result, it will update the Shadow document of the thing, our sensor.&lt;br&gt;&lt;br&gt;
&lt;a href=&#34;../../post/iot-poc-shadow/&#34; title=&#34;Shadow case&#34;&gt;Get started here&lt;/a&gt;. Here is the full &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/shadow.py&#34; title=&#34;shadow example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;example script&lt;/a&gt;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;images/shadow_architecture.png&#34; alt=&#34;iot setup&#34;&gt;
	&lt;br&gt;
  Schematic of the architecture we are building in the demonstration of Shadow functionality.
&lt;/div&gt;
&lt;h2 id=&#34;4-build-an-edge-with-greengrass&#34;&gt;4) Build an Edge with Greengrass&lt;/h2&gt;
&lt;p&gt;Now our Pi will act the part of gateway device. The gateway device effectively represents an edge that is manageable from the cloud and where data transformations or calculations can happen. This could be signal processing, edge analytics, or even machine learning models. Greengrass is the AWS software offering for gateway devices. In this demonstration, we will set up Greengrass on the Pi, connect a thing, our sensor, to Greengrass, and deploy a calculation from the cloud to the edge using a Lambda function.&lt;br&gt;&lt;br&gt;
&lt;a href=&#34;../../post/iot-poc-greengrass&#34; title=&#34;Greengrass case&#34;&gt;Get started here&lt;/a&gt;. Here is the full &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/greengrass_thing.py&#34; title=&#34;Example of Thing for Greengrass&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;example script for a local device&lt;/a&gt; and the &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/greengrass_sys_lambda.py&#34; title=&#34;Lambda example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lambda function&lt;/a&gt; we will deploy into Greengrass Core.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;images/greengrass_group_architecture.png&#34; alt=&#34;iot setup&#34;&gt;
    &lt;br&gt;
    This is the architecture we are building in the demonstration of Greengrass functionality.
	&lt;br&gt;
&lt;/div&gt;
&lt;h2 id=&#34;5-advanced-greengrass-features&#34;&gt;5) Advanced Greengrass Features&lt;/h2&gt;
&lt;p&gt;In this final demonstration, we will combine everything from the previous demonstrations to deploy a machine learning model from the cloud into Greengrass and do inference at the edge. This requires us to explore additional advanced features and configurations of Greengrass, but shows how, with a few means and a bit of engineering, we can achieve quite complex functionality.&lt;br&gt;&lt;br&gt;
&lt;a href=&#34;../../post/iot-poc-greengrass-ml&#34; title=&#34;Advanced Greengrass case&#34;&gt;Get started here&lt;/a&gt;. This demonstration uses the same &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/greengrass_thing.py&#34; title=&#34;Example of Thing for Greengrass&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;example script for a local device&lt;/a&gt; as the previous but has two new examples of Lambda functions, &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/ml_inference_lambda.py&#34; title=&#34;ML inference Lambda&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;including one&lt;/a&gt; doing machine learning inference.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;images/greengrass_ml_architecture.png&#34; alt=&#34;Greengrass ML Demo Architechture&#34;&gt;
	&lt;br&gt;
    This is the architechture of the application we will build in the demonstration of advanced Greengrass Features.
&lt;/div&gt;
&lt;h1 id=&#34;iot-with-aws-iot&#34;&gt;IoT with AWS IoT&lt;/h1&gt;
&lt;p&gt;This section has a bit of theoretical context for the demonstrations. We will try to understand some core concepts of internet of things in the context of an industrial setting and AWS IoT.&lt;/p&gt;
&lt;h2 id=&#34;things&#34;&gt;Things&lt;/h2&gt;
&lt;p&gt;Let us start with the Things in an internet of things. In an industrial setting, a thing is often anything that has a measurable state, is being actively measured, and is connected to a network. A simple example might be temperature at the factory floor. This is obviously a critical variable in many manufacturing processes and one can often find old school thermometers installed here and there. These are not things, however, until they are connected to a network either directly or indirectly through a gateway device. Other examples could be the airflow through a specific nozzle or the injection pressure for the plastic in an injection moulding process. The airflow could be measured using a flowmeter and the injection pressure with a pressure sensor. These could then be connected to a small computer that in turn connects to the internet.&lt;br&gt;&lt;br&gt;
Given this vague definition of things, an obvious question arises for those who have been in a manufacturing context for a while. Manufacturing processes are usually associated with process control loops. These include connecting key process parameters to a process logic controller (PLC) that in turn controls actuators to regulate the process. An example would be the flow of water through a pipe, measured by a flow sensor and regulated by the opening or closing of a valve. The question is: are these control loops also IoT?&lt;br&gt;The answer is that they could be. The process parameters and the state of the valve are all potential things that when connected to a network could become things in an internet of things. The key difference between IoT and a control loop would be all the other things and applications that might be on the network. The PLC is there to do process control, not neccessarily to send or store data, and connecting it to new networks could be a major risk for the manufacturing process, but also potentially unlocks the data for new valuable applications. In IoT, we use dedicated devices to buffer and send data to storage in the cloud or somewhere else.&lt;br&gt;&lt;br&gt;
One network that an IoT could take advantage of is a cloud. Cloud service providers like AWS and Azure have IoT-specific offerings that can help build new IoTs. AWS is our cloud of choice for this tutorial. In AWS IoT Core, we can &lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/create-aws-thing.html&#34; title=&#34;how to register a thing in AWS IoT Core&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;register&lt;/a&gt; and manage our things. A thing is the highest level of granularity, and it makes sense to register each parameter we measure as a seperate thing. We can then aggregate and manage hierarchies of things using &lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/iot-thing-management.html&#34; title=&#34;about managing hierarchies of things&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;groups and types&lt;/a&gt;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;images/iot_overview.png&#34; alt=&#34;iot setup&#34;&gt;
	&lt;br&gt;
&lt;/div&gt;
&lt;h2 id=&#34;the-edge-and-gateway-devices&#34;&gt;The Edge and Gateway Devices&lt;/h2&gt;
&lt;p&gt;We stumbled up the term gateway devices a few times. A gateway device is basically just a computer. It could be as small as a microcontroller and as large as a distributed compute system. In this tutorial we will use a Raspberry Pi to play the part of gateway device. In an industrial setting the gateway devices are there to do the things that a PLC should not do, like connecting to the internet, doing heavy calculations, and buffering data. It might be obvious at this point, but the gateway device is essentially what is referred to as the &amp;lsquo;edge&amp;rsquo;. Running machine learning at the edge essentially means having a machine learning algorithm do inference using the compute in our gateway device. A gateway device can be used for a bunch of other things though, such as signal processesing, data aggregation, or data transformation. Imagine for instance that our sensor reports the factory floor temperature in degrees Celcius. Maybe we want to convert that into Kelvins before sending and storing it in the cloud. Of course we could store the measurement in Celcius and then do the transformation later or directly in our application, but that would be more expensive (cloud compute is expensive, cloud storage is cheap) and less elegant. We run our computations at the edge whenever it makes sense and save money.&lt;br&gt;&lt;br&gt;
The edge device is where we will run the client that connects to AWS IoT, sends data, and maybe receives instructions. To do so we will use the AWS IoT Python SDK. AWS also provides software for managing and running our applications on gateway devices. These are called Greengrass and SiteWise (which is just additional software on top of Greengrass). Greengrass allows us to do cool things such as running Lambda functions and deploy machine learning models from the cloud to the edge. Greengrass and its functionality is covered in demonstrations 4 and 5.&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;shadows&#34;&gt;Shadows&lt;/h2&gt;
&lt;p&gt;We are doing IoT for a reason. Maybe we are building a dashboard for the operators of our manufacturing line, maybe we are developing a predictive maintenance model that uses measured parameters from the line to predict the remaining lifespan of a critical component. Whatever our application, we will need fresh data from our things. Unless we have gone all in on a massive synchronisation effort, our data points will not arrive at exactly matching timestamps, however. Factory floor humidity might be reported every 5 minutes while frequency and amplitude of a vibrating element might be reported every 15 seconds. Maybe the gateway device handling data from our flow sensors has been updating its software such that no values have been reported for the past 12 minutes. What does our application do when the refresh rate might be every 30 seconds? If all values are stored in a database, the application could just grab the latest values, but that might not be possible or introduce unwanted latency. There is another way, however.&lt;br&gt;&lt;br&gt;
A Shadow record is a record of the latest process parameters, such that the currently most reliable view of reality is always available for applications. The notion is similar to a database, the key difference being that this record only ever keeps the latest entry. With such a record we can design our application to do what it needs to do and even dynamically correct for old data without ever worrying about not having available data or waiting for data to appear, thus effectively decoupling the IoT and our application.&lt;br&gt;&lt;br&gt;
Shadow records are a part of the AWS IoT offering. Each thing registered in AWS IoT automatically has a shadow, which is a json document containing the latest record for that thing, assuming we have set up our IoT to update it. In demonstration 3, we will explore how to interact with shadows in the cloud. Using Greengrass, we can also keep a shadow on the edge and even enable shadow synchronisation between the edge and the cloud. In this way our applications running at the edge can access shadow records with low latency, while cloud based applications have a copy available to them as well. We will explore the use of local shadows with Greengrass for a machine learning application in demonstration 5.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=&#34;500&#34; src=&#34;images/shadow_flow.png&#34; alt=&#34;iot setup&#34;&gt;
	&lt;br&gt;
&lt;/div&gt;
&lt;h2 id=&#34;sdk&#34;&gt;SDK&lt;/h2&gt;
&lt;p&gt;We will be using the Python SDK to configure the client that communicates with AWS. This means that our gateway device has to be able to run Python. This is no problem on a Raspberry Pi, but would not work for a microcontroller and probably would not be ideal for a web application. AWS IoT offers SDKs for a bunch of &lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/iot-sdks.html&#34; title=&#34;AWS IoT SDKs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;other languages&lt;/a&gt;, however.&lt;br&gt;
This tutorial uses the &lt;a href=&#34;https://github.com/aws/aws-iot-device-sdk-python&#34; title=&#34;AWS IoT Python SDK V1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;first version&lt;/a&gt; of the Python SDK. A &lt;a href=&#34;https://github.com/aws/aws-iot-device-sdk-python-v2&#34; title=&#34;AWS IoT Python SDK V2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;version two&lt;/a&gt; that uses a very different syntax was released, but will not be covered here.&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-mqtt-protocol&#34;&gt;The MQTT Protocol&lt;/h2&gt;
&lt;p&gt;Communication with AWS is facilitated by the MQTT protocol. This is a protocol commonly used in manufacturing systems, and is documented &lt;a href=&#34;http://mqtt.org/documentation&#34; title=&#34;MQTT documentation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;online&lt;/a&gt;. The &lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/mqtt.html&#34; title=&#34;AWS MQTT Documentation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AWS flavour&lt;/a&gt; of MQTT is a slightly simpler implementation of the protocol. Communicating using HTTPS is also possible but is not covered in this tutorial.&lt;br&gt;&lt;br&gt;
To get started using the MQTT protocol with AWS IoT, we only need to know a few concepts: message, topic, quality of service (QoS), publishing, and subsribing. These concepts are summarised right here, but we will discuss them in detail when they show up in the demonstrations.&lt;/p&gt;
&lt;h3 id=&#34;messages&#34;&gt;Messages&lt;/h3&gt;
&lt;p&gt;At the core of MQTT is the message, The message contains the actual data along with any metadata. It is structured as a json and we can put whatever we want in there, but we will want the reading from our thing, a timestamp for the time of sampling, and maybe an idication whether the reading was succesful or not.&lt;/p&gt;
&lt;h3 id=&#34;topics&#34;&gt;Topics&lt;/h3&gt;
&lt;p&gt;Messages in AWS are distributed and filtered using topics. Topics are a kind of tag that we can use to identify the source of the message and distribute it accordingly. It is just a single string, generally in the format&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;main_tag/secondary_tag/tertiary_tag/etc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For instance, if we had several factories each with several manufacturing lines with several stations each eqipped with sensors, we might do something like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;factoryA/line22/drying/temperature
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then have another sensor on the same line publish to&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;factoryA/line22/milling/torque
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That way we can direct these messages to the store or dashboard for the same line but seperate Lambda functions, if that is needed for our application.&lt;br&gt;
The topic system is quite flexible and we will have to rely on our own rigid naming conventions if we want to effectivly utilise topics in an application with many things. Some specific topics are reserved for specific purposes such as interacting with shadows. We will dive deeper into the use of topics and reserved topics in the demonstrations.&lt;/p&gt;
&lt;h3 id=&#34;publishing-and-subscribing&#34;&gt;Publishing and Subscribing&lt;/h3&gt;
&lt;p&gt;Messages are transmitted using the publish subscribe model. A message always has a single publisher. The publisher client is the origin of the message and will publish that message to a given topic. A topic can have several publishes, meaning that several clients can publish messages to the same topic. Messages reach their destination through subscribers. Subscribers are clients that listen to a topic to get whatever messages are published there. A topic can also have multiple subscribers.&lt;/p&gt;
&lt;h3 id=&#34;serverbroker&#34;&gt;Server/Broker&lt;/h3&gt;
&lt;p&gt;The MQTT server is responsible for orchestrating the MQTT communication. It is the server that will authenticate MQTT clients and will route messages from publishers to subscribers using topic filters. AWS IoT Cores is essentially an infinitely scalable MQTT server. Greengrass is also an MQTT server that runs locally on a gateway device.&lt;/p&gt;
&lt;h3 id=&#34;client&#34;&gt;Client&lt;/h3&gt;
&lt;p&gt;The MQTT client is used to create an MQTT publisher or a subscriber. The core functionality of the AWS IoT SDKs is to abstract away the intricacies of setting up and authenticating an MQTT client.&lt;/p&gt;
&lt;h3 id=&#34;quality-of-service&#34;&gt;Quality of Service&lt;/h3&gt;
&lt;p&gt;Quality of Service, abbreviated QoS, is a flag specifying what happens when messages get lost in the network. The AWS flavour of MQTT accepts two QoS flags. The flag 0 means that the message is delivered to subsrcibers &amp;lsquo;at most once&amp;rsquo;. The flag 1 means that the message is delivered to subsribers &amp;lsquo;at least once&amp;rsquo;. So for &lt;code&gt;QoS = 0&lt;/code&gt; the publisher will send the message once and then forget about it. If it does not get delivered, it is lost. For &lt;code&gt;QoS = 1&lt;/code&gt;, however, the message is sent, and the publisher then waits for a reply from the subscriber before forgetting the message, and resends if neccessary. This ensures that the subscriber gets the message at least once.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine Learning at the Edge and other Advanced Features of Greengrass</title>
      <link>/post/iot-poc-greengrass-ml/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/post/iot-poc-greengrass-ml/</guid>
      <description>&lt;p&gt;We are about to build something really cool. Machine learning inference managed from the cloud but performed at the edge might sound like a sequence of flimsy business colloquialisms and to some extent they might be. In this demonstration, however, we will dive into the actual technical substance behind these terms.&lt;br&gt;
Specifically, we will discuss and apply advanced features of AWS Greengrass, including&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Creating and interacting with a local Shadow&lt;/li&gt;
&lt;li&gt;Shadow synchronisation with the cloud&lt;/li&gt;
&lt;li&gt;Decoupling data generation and application using a Shadow&lt;/li&gt;
&lt;li&gt;Long-lived Lambda functions&lt;/li&gt;
&lt;li&gt;Machine learning resources&lt;/li&gt;
&lt;li&gt;Machine learning inference in the Greengrass Group with a Tensorflow2 model&lt;/li&gt;
&lt;li&gt;The Greengrass service role&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The target of the demonstration is to build a small IoT application that predicts whether it is raining or not, given the current temperature, relative humidity, and pressure. The weather data comes from our BME680 air quality sensor, and our Raspberry Pi 3B+ will play the role of gateway device but also runs the code querying the sensor.&lt;br&gt;
We will be utilising expertise from the previous demonstrations of &lt;a href=&#34;../../post/iot-poc-publishing/&#34;&gt;publishing&lt;/a&gt;, &lt;a href=&#34;../../post/iot-poc-pubsub/&#34;&gt;subscribing&lt;/a&gt;, &lt;a href=&#34;../../post/iot-poc-shadow/&#34;&gt;Shadows&lt;/a&gt;, and &lt;a href=&#34;../../post/iot-poc-greengrass/&#34;&gt;general Greengrass features&lt;/a&gt;.&lt;br&gt;&lt;/p&gt;
&lt;h1 id=&#34;set-up&#34;&gt;Set Up&lt;/h1&gt;
&lt;p&gt;To build the target demonstration, we will walk through three parts. First we will set up a local Shadow within our Greengrass group and use obtained sensor values to contiuously update the Shadow. Then we will enable synchronisation between the local Shadow and a cloud copy of the Shadow. Last, but not least, we will set up inference with a Tensorflow2 machine learning model.&lt;br&gt;
We will not cover installing and setting up Greengrass Group with a device, as this was covered in the &lt;a href=&#34;../../post/iot-poc-greengrass/#install-and-configure-greengrass&#34;&gt;general introduction to Greengrass&lt;/a&gt;. Be sure to refer to previous demonstrations when in doubt.&lt;br&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_ml_architecture.png&#34; alt=&#34;Greengrass ML Demo Architechture&#34;&gt;
    This is the overall architechture of the application we will build in this demonstration.
&lt;/div&gt;
&lt;p&gt;Let us get started!&lt;/p&gt;
&lt;h1 id=&#34;publish-to-local-shadow&#34;&gt;Publish to Local Shadow&lt;/h1&gt;
&lt;p&gt;In this section, we will set up a local Shadow and build a Lambda function that takes values published by our sensor and updates the Shadow.&lt;br&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_ml_architecture_repub.png&#34; alt=&#34;Greengrass ML Demo Architechture&#34;&gt;
	&lt;br&gt;
    This is the part of the architecture we will build in this section.
&lt;/div&gt;
&lt;h2 id=&#34;prepare-the-thing&#34;&gt;Prepare the Thing&lt;/h2&gt;
&lt;p&gt;We &lt;a href=&#34;../../post/iot-poc-greengrass/#associate-a-thing-with-a-greengrass-group&#34;&gt;register and add&lt;/a&gt; our Thing, the sensor, to our Greengrass group.&lt;br&gt;
We already have a &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/greengrass_thing.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;script&lt;/a&gt; that connects our Thing and publishes readings to our Greengrass Group on a local topic. There is no need to modify it in any way. We will just leave it running, continuously publishing values to a local topic. I went with the topic &lt;code&gt;bme680/readings&lt;/code&gt; but any topic goes.&lt;/p&gt;
&lt;h2 id=&#34;the-local-shadow-service&#34;&gt;The Local Shadow Service&lt;/h2&gt;
&lt;p&gt;Any Thing we include in our Greengrass Group lives only inside the Group and only connects to the cloud when first discovering the Group. This is great for reducing the number of devices connected to the cloud, but it also means that we cannot directly take advantage of the Shadow that is in the cloud.&lt;br&gt;
Fortunately, Greengrass provides a Local Shadow Service inside Greengrass that we can use instead. The local Shadow service works in a very similar way to the Shadow in the cloud. The Shadow document follows the same schema, it is interacted with using the exact same topics, and it can be get, updated, and deleted. The Shadow lives inside the Greengrass Group and is only accessible to entities connected to the group.&lt;br&gt;
For instance, assume we have a Thing called &lt;code&gt;my_sensor&lt;/code&gt; and an MQTT client that is connected to our Greengrass Core, we can publish an update to the Shadow of our Thing like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient
import json
client = AWSIoTMQTTClient(&#39;my_sensor&#39;)
# Connect the client to Greengrass Core 
# ... left out for clarity
# Build an update for the Shadow
message = {}
message[&amp;quot;state&amp;quot;] = { &amp;quot;reported&amp;quot; : {&amp;quot;temperature&amp;quot; : 12. } } 
# Publish the update to the Shadow
client.publish(&#39;$aws/things/my_sensor/shadow/update&#39;, json.dumps(message))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The message goes to whichever MQTT server the client is connected to. Since we are connected to Greengrass Core and not AWS IoT, the message never reaches the cloud. So even though the topic is exactly the same as if we were updating the cloud based Shadow, the cloud based Shadow is not updated.&lt;br&gt;
As a matter of fact, the message also does not reach the local Shadow. At least not yet. Since we are working with local topics, we need to &lt;a href=&#34;../../post/iot-poc-greengrass/#configure-subscriptions-in-greengrass&#34;&gt;set up subscriptions&lt;/a&gt; and deploy them to the Group before any messages are relayed.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_subscription_toshadow.png&#34; alt=&#34;Subscription with local Shadow&#34;&gt;
&lt;/div&gt;
&lt;p&gt;This is how it could look, but since there is a much easier way, this is not how we will do it.&lt;/p&gt;
&lt;h2 id=&#34;republish-to-shadow&#34;&gt;Republish to Shadow&lt;/h2&gt;
&lt;p&gt;We will build a Lambda function that will reside in the Greengrass Group. Its purpose is twofold: it will do a bit of transformation on the sensor readings and it will republish the readings as an update to the local Shadow.&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;interact-with-the-local-shadow-service-from-a-lambda-function&#34;&gt;Interact with the local Shadow service from a Lambda function&lt;/h3&gt;
&lt;p&gt;For a Greengrass MQTT client running in a Lambda function that is deployed into a Greengrass Group, interacting with the local Shadow service is very straight forward. We connect and then perform the action we desire:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import greengrasssdk
import json
# Hardcoding the thing name is not a good idea. We will look at an alternative
#  in a moment
THING_NAME = &#39;my_sensor&#39;
# Define and connect the client
client = greengrasssdk.client(&#39;iot-data&#39;)
# Update the Shadow
update = {&amp;quot;state&amp;quot; : { &amp;quot;reported&amp;quot; : {&amp;quot;value&amp;quot; : 3 }}}
client.update_thing_shadow(thingName=THING_NAME, payload=json.dumps(message))
# Get the Shadow
shadow = client.get_thing_shadow(thingName=THING_NAME)
shadow = json.loads(shadow[&#39;payload&#39;]) # It takes a bit of unpacking...
# Delete the Shadow
client.delete_thing_shadow(thingName=THING_NAME)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is no need to deal with callback functions - everthing is taken care of behind the scenes. Furthermore, there is no need to explicitly define the subscriptions in the Greengrass Group for these actions. As long as we use the Greengrass MQTT client, the messages find their way to the local Shadow service, which is just a set of hidden Lambda functions.&lt;br&gt;&lt;br&gt;
We now know everything we need to have our Lambda function perform the transformations we need and update the Shadow. There is just one small aesthetic detail to attend to before we can start building.&lt;/p&gt;
&lt;h3 id=&#34;setting-environment-variables-for-lambda-functions-in-greengrass&#34;&gt;Setting environment variables for Lambda functions in Greengrass&lt;/h3&gt;
&lt;p&gt;In the snippet above, we hard coded the device ID, the Thing name into the Lambda function. This will work just fine, but it does make the Lambda function difficult to reuse. We do, however, have a better option. We can provide Lambda functions running in a Greengrass Group with environment variables. Environment variables are key-value pairs that are specified outside the running script but can be accessed at runtime. If you are already familiar with environment variables for Lambdas running in the cloud, they work in a very similar fashion, but are specified in a different place when used with Greengrass. Let us take it step by step.&lt;br&gt;
First we will need to decide on a key-value structure. We will go with the key being &lt;code&gt;THING_NAME&lt;/code&gt; and the value being the ID of our device.&lt;br&gt;
Then we need to write our Lambda function to take advantage of the environment variable. This is fairly straight forward, in Python:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
THING_NAME = os.environ(&#39;THING_NAME&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last step we need is to actually provide the environment variable to the instance of our Lambda function in the Greengrass Group. We do this by locating our Greengrass Group in the console and configure the Lambda in question.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_configure.png&#34; alt=&#34;Configure Greengrass Lambda&#34;&gt;
	Note that the name of your Greengrass Group and Lambdas may be different
&lt;/div&gt;
&lt;p&gt;At the bottom of the configuration options, we find a set of fields where we can provide key value pairs, and we just go ahead and provide ours.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_environment_variable.png&#34; alt=&#34;Environment variable&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Now, when we deploy the Lambda function, the environment variable will be available for use. This means that if we have multiple sensors we we can use the same Lambda Alias to create multiple Lambda functions deployed to the Greengrass Group serving their exact device. Less code and less work for us.&lt;/p&gt;
&lt;h3 id=&#34;build-the-republishing-lambda-function&#34;&gt;Build the republishing Lambda function&lt;/h3&gt;
&lt;p&gt;With a bit of additional logging and error handling, we have our Lambda function for transforming and republishing the weather data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import greengrasssdk
import logging
import json
import time
import os

THING_NAME = os.environ[&amp;quot;THING_NAME&amp;quot;]

client = greengrasssdk.client(&#39;iot-data&#39;)

def get_cpu_temperature():
    &#39;&#39;&#39;
    Gets the CPU temperature of a Raspberry Pi in deg. C
    &#39;&#39;&#39;
    try:
        f = open(&amp;quot;/sys/class/thermal/thermal_zone0/temp&amp;quot;)
        raw_temp = f.read()
        f.close()
        cpu_temp = float(raw_temp)/1000.0
    except Exception as e:
        logging.error(&#39;Unable to obtain CPU temperature. &#39; + repr(e))
    return cpu_temp

def get_topic(context):
    try:
        topic = context.client_context.custom[&#39;subject&#39;]
    except Exception as e:
        logging.error(&#39;Unable to read a topic. &#39; + repr(e))
    return topic
    
def get_temperature(event):
    try:
        temperature = float(event[&amp;quot;temperature&amp;quot;])
    except Exception as e:
        logging.error(&#39;Unable to parse message body. &#39; + repr(e))
    return temperature

def function_handler(event, context):
    try:
        input_temperature = get_temperature(event)
        cpu_temps = []
        for _ in range(8):
            cpu_temps.append(get_cpu_temperature())
            time.sleep(1)
        avg_cpu_temp = sum(cpu_temps)/float(len(cpu_temps))
        # Compensated temperature
        comp_temp = 2*input_temperature - avg_cpu_temp
        message = {}
        message[&amp;quot;state&amp;quot;] = { &amp;quot;reported&amp;quot; : {&amp;quot;temperature&amp;quot; : comp_temp,
                                            &amp;quot;pressure&amp;quot; : event[&amp;quot;pressure&amp;quot;],
                                            &amp;quot;humidity&amp;quot; : event[&amp;quot;humidity&amp;quot;],
                                            &amp;quot;message&amp;quot; : event[&amp;quot;message&amp;quot;]}}
        logging.info(event)
        logging.info(message)
    except Exception as e:
        logging.error(e)
    client.update_thing_shadow(thingName=THING_NAME, payload=json.dumps(message))
    return
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The full example script can also be found &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/greengrass_repub_lambda.py&#34; title=&#34;Lambda for publishing to Shadow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. We now need to pack this script in a zip file along with the Greengrass SDK, so we can create a Lambda function. We create the Lambda function and upload the zip file&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/lambda_repub.png&#34; alt=&#34;Repub Lambda&#34;&gt;
&lt;/div&gt;
&lt;p&gt;We then create an alias, navigate to the Greengrass console and associate the Lambda function with our Greengrass Group using the alias.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_add.png&#34; alt=&#34;Repub Lambda&#34;&gt;
&lt;/div&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_add_existing.png&#34; alt=&#34;Repub Lambda&#34;&gt;
&lt;/div&gt;
&lt;p&gt;We then cofigure the Lambda function. We need to increase the timeout limit to at least 10 seconds, we need to enable access to &lt;code&gt;/sys&lt;/code&gt; so it can get the CPU temperature of the Pi, and we should provide the environment variable as discussed above.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_configure.png&#34; alt=&#34;Configure Greengrass Lambda&#34;&gt;
&lt;/div&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_configurations_repub.png&#34; alt=&#34;Configure repub Lambda&#34;&gt;
&lt;/div&gt;
&lt;p&gt;That is it for the Lambda function.&lt;/p&gt;
&lt;h2 id=&#34;subscriptions&#34;&gt;Subscriptions&lt;/h2&gt;
&lt;p&gt;We only need one subsription, one going from our device to the Lambda we just created.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_subscription_repub_shadow.png&#34; alt=&#34;Repub to Shadow subscription&#34;&gt;
&lt;/div&gt;
&lt;p&gt;That is it for the first part. Once we deploy, We have a Thing publishing sensor readings, they are transformed and used to update the local Shadow. Right now there is not much to see though, as we have done nothing to make use of or even visualise the local Shadow. We will get there soon though.&lt;/p&gt;
&lt;h1 id=&#34;setup-shadow-synchronisation&#34;&gt;Setup Shadow Synchronisation&lt;/h1&gt;
&lt;p&gt;In this section, we will set up Shadow synchronisation between the local Shadow and the Shadow of our device in the cloud.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_ml_architecture_sync.png&#34; alt=&#34;Greengrass ML Demo Architechture&#34;&gt;
    This is the part of the architecture we will build in this section.
&lt;/div&gt;
&lt;p&gt;Synchronising the Shadow just means that the local Shadow service will send regular updates to the cloud based Shadow such that the status quo is reflected there as well. We would usually do this to support an application running in the cloud, but in this case we are doing it mostly for show.&lt;br&gt;
It is important to note that the synchronisation works both ways. Updates that are done to the local Shadow will eventually be reflected in the cloud based Shadow and vice versa. We will not have anything directly updating the cloud Shadow in this case, however.&lt;br&gt;
Setting up synchronisation is actually fairly straight forward. We navigate to our Greengrass group and find the Device page. Next to the Device we added earlier it should be saing &amp;lsquo;Local Shadow Only&amp;rsquo;. All we have to do is to expand the options for that Device by clicking the three dots and selecting Enable Shadow Synchronisation.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_shadow_sync_enable.png&#34; alt=&#34;Local to Cloud Shadow Sync&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Now we deploy the change.&lt;br&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img src=&#34;../../project/iot-poc/images/greengrass_deploy.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;We can test whether it works by navigating to the page of the particular Device and going to its Shadow tab. If everything we did in the previous section works and the Shadow synchronisation works, we should see that the Shadow gets updated.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_shadow_sync_working.png&#34; alt=&#34;Shadow sync working&#34;&gt;
&lt;/div&gt;
&lt;h1 id=&#34;machine-learning-inference-at-the-edge&#34;&gt;Machine Learning Inference at the Edge&lt;/h1&gt;
&lt;p&gt;In this section, we will deploy a machine learning model into the Greengrass group and have it do inference based on the data coming from our Device.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_ml_architecture_inference.png&#34; alt=&#34;Greengrass ML Demo Architechture&#34;&gt;
    This is the part of the architecture we will build in this section.
&lt;/div&gt;
&lt;p&gt;Specifically, we are going to create a Lambda function that loads a machine learning pipeline consisting of a model that transforms the data into features that are then evaluted in a neural network based model. We will get the data from the local Shadow such that the inference does not rely on live data and inference is effectively decoupled from the data stream.&lt;/p&gt;
&lt;h2 id=&#34;prepare-the-gateway-device&#34;&gt;Prepare the Gateway Device&lt;/h2&gt;
&lt;p&gt;In order for Greengrass Core to run Lambda functions it needs access to runtimes on the Gateway Device where it runs. When we set up Greengrass Core, we &lt;a href=&#34;../../post/iot-poc-greengrass/#install-and-configure-greengrass&#34;&gt;verified&lt;/a&gt; that our desired runtime, Python 3.7, was indeed present on the Device, our Pi, and accessible to Greengrass Core. Our approach to the use of additional libraries has been to include them in the Lambda deployment package. For instance, we included the Greengrass SDK with the Lambda function we created above.&lt;br&gt;
Machine learning frameworks like Tensorflow or MXNET are not just libraries but rely on their own runtimes. This means that using such frameworks with Greengrass is slightly more complicated, as we cannot just include the library with the Lambda. Lambdas running in a Greengrass Group can, however, utilise machine learning runtimes if they are installed and available. In fact any library can be used in a Lambda function without including it in the deployment package, as long as it is installed in a shared location on the device.&lt;br&gt;
For this case we are going to use Tensorflow2 to do inference, but Greengrass does support &lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/ml-inference.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;other options&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;install-tensorflow&#34;&gt;Install Tensorflow&lt;/h3&gt;
&lt;p&gt;We will &lt;a href=&#34;https://www.tensorflow.org/install&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;install Tensorflow2&lt;/a&gt; on our Gateway Device, the Pi. How this is done depends very much on the actual device. If you are following along using a Raspberry Pi, and a regular &lt;code&gt;pip&lt;/code&gt; install does not work, you might want to check out these &lt;a href=&#34;https://github.com/PINTO0309/Tensorflow-bin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;unofficial Tensorflow wheels&lt;/a&gt;.&lt;br&gt;
The key to making it work, is to install Tensorflow in a shared location (e.g. using &lt;code&gt;sudo pip install&lt;/code&gt;) where the Greengrass user, &lt;code&gt;ggc_user&lt;/code&gt;, can access it. We can test whether the user can access Tensorflow with the following bash command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo -u ggc_user bash -c &#39;python3.7 -c &amp;quot;import tensorflow&amp;quot;&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note, however, that this is no surefire way of knowing whether everything works as expected. Unless you are intimately familiar with your device, it can take a bit of debugging to work. I usually use a Lambda function that just imports Tensorflow and tries something simple like adding two constants and logging the result to test whether the install worked. I deploy the testing Lambda into the Greengrass Group and check the logs for the expected output any unexpected errors.&lt;br&gt;&lt;br&gt;
Our reward for working all this out is that we are able to call Tensorflow2 from within our Lambda function. Now we are ready to do some machine learning.&lt;/p&gt;
&lt;h2 id=&#34;manage-machine-learning-resources&#34;&gt;Manage Machine Learning Resources&lt;/h2&gt;
&lt;p&gt;To do inference, we are going to need a trained model. A trained should hold everything needed to recreate the function learned from the data during training. This includes the structure of the model, e.g. the layers of a neural network, along with weights, biases, and any other necessary resource. For Tensorflow2, trained models are given in the SavedModel format that can be loaded with a single line of code.&lt;br&gt;
The resources of the trained model then need to be deployed into the Greengrass Group along with the Lambda function that will use it to do inference. Let us give it a try!&lt;/p&gt;
&lt;h3 id=&#34;a-pre-trained-model-for-our-case&#34;&gt;A pre-trained model for our case&lt;/h3&gt;
&lt;p&gt;Building a dataset and training a machine learning model a bit outside our scope for this demonstration and will obviously depend on the choice of ML framework and data science problem, but we are still going to need a model for the sake of example. Recall that we wanted to have a model that given readings of temperature, relative humidity, and atmospheric pressure would predict whether it is raining or not.&lt;br&gt;
I have &lt;a href=&#34;https://github.com/AnHosu/tf-save-model/blob/master/tf-save-model.ipynb&#34; title=&#34;Create a servable model with TF2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;prepared&lt;/a&gt; such a model and described how to save and load a SavedModel with Tensorflow2. It is actually a pipeline of two models closely resembling a real data science workflow. The first model takes in data points, pressure, temperature, and humidity, and standardises them. The second one is a small neural network that takes the standardised features as input and returns a value between 0 and 1, indicating a pseudo-probability of rain.&lt;br&gt;
We will use these two models as examples of doing machine learning inference.&lt;/p&gt;
&lt;h3 id=&#34;prepare-machine-learning-resources&#34;&gt;Prepare machine learning resources&lt;/h3&gt;
&lt;p&gt;In order to include machine learning resources like a Tensorflow SavedModel in a Greengrass deployment, they need to be stored somewhere where Greengrass can access them. Greengrass can access objects in S3 buckets, so this is where we will put our resources.&lt;br&gt;
However, Greengrass is a seperate service and needs permission to access other services. We already had Greengrass access Lambda to fetch deployment packages and that worked smoothly, but we will have to understand why before we can ensure the same for S3.&lt;br&gt;&lt;br&gt;
Greengrass has a service role that determines what other services and actions it has permissions to use. The service role can be found in the AWS IoT console under the Settings tab where we also find our custom endpoint. Somewhere in the list of settings is the Greengrass service role.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_iot_settings_greengrassrole.png&#34; alt=&#34;Greengrass service role&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Per default, the policy attached to Greengrass is the managed policy &lt;code&gt;AWSGreengrassResourceAccessRolePolicy&lt;/code&gt;. At the time of writing, &lt;a href=&#34;https://console.aws.amazon.com/iam/home?region=eu-west-1#/policies/arn:aws:iam::aws:policy/service-role/AWSGreengrassResourceAccessRolePolicy&#34; title=&#34;GG Service managed policy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;the policy&lt;/a&gt; is at version 5 and, among other things, it contains these actions:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
	&amp;quot;Comment&amp;quot;: &amp;quot;NOTE: This is not the full or even a valid policy, just a snippet&amp;quot;,
    &amp;quot;Statement&amp;quot;: [
        {
            &amp;quot;Sid&amp;quot;: &amp;quot;AllowGreengrassToGetLambdaFunctions&amp;quot;,
            &amp;quot;Action&amp;quot;: [
                &amp;quot;lambda:GetFunction&amp;quot;,
                &amp;quot;lambda:GetFunctionConfiguration&amp;quot;
            ],
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Resource&amp;quot;: &amp;quot;*&amp;quot;
        },
        {
            &amp;quot;Sid&amp;quot;: &amp;quot;AllowGreengrassAccessToS3Objects&amp;quot;,
            &amp;quot;Action&amp;quot;: [
                &amp;quot;s3:GetObject&amp;quot;
            ],
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Resource&amp;quot;: [
                &amp;quot;arn:aws:s3:::*Greengrass*&amp;quot;,
                &amp;quot;arn:aws:s3:::*GreenGrass*&amp;quot;,
                &amp;quot;arn:aws:s3:::*greengrass*&amp;quot;,
                &amp;quot;arn:aws:s3:::*Sagemaker*&amp;quot;,
                &amp;quot;arn:aws:s3:::*SageMaker*&amp;quot;,
                &amp;quot;arn:aws:s3:::*sagemaker*&amp;quot;
            ]
        },
        {
            &amp;quot;Sid&amp;quot;: &amp;quot;AllowGreengrassAccessToS3BucketLocation&amp;quot;,
            &amp;quot;Action&amp;quot;: [
                &amp;quot;s3:GetBucketLocation&amp;quot;
            ],
            &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
            &amp;quot;Resource&amp;quot;: &amp;quot;*&amp;quot;
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can immediately see why getting Lambda functions worked to smoothly: this default policy allows Greengrass to get any Lambda function, as indicated by the &lt;code&gt;&amp;quot;*&amp;quot;&lt;/code&gt; resource identifier. There is also an action allowing Greengrass to get objects from S3. This one however limits the permission to objects that include the string &lt;code&gt;greengrass&lt;/code&gt;, &lt;code&gt;sagemaker&lt;/code&gt;, or a few variations hereof.&lt;br&gt;
This gives us a choice when storing our machine learning resources: we can either create a new service policy that allows Greengrass to access S3 objects in a format we specify, or we can comply with the constraints of the default policy and name our resources accordingly. The former might not be a good idea because replacing the policy with one we specify means forgoing the benefits of using a managed policy. So we will do the latter and create a bucket with a name containing the string &lt;code&gt;greengrass&lt;/code&gt; and put our machine learning resources in there.&lt;br&gt;&lt;br&gt;
A machine learning resource must be zipped, so we will zip the contents of the two SavedModel folders and put them in the S3 bucket. I have &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/ml_resources/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;included&lt;/a&gt; the zipped models in the project repo as well.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_ml_s3_resource.png&#34; alt=&#34;ML Resources in a bucket&#34;&gt;
	Machine learning resources in an S3 bucket.
&lt;/div&gt;
&lt;p&gt;Greengrass will unzip the contents when deploying into the Group. Now we just need to tell Greengrass where the resources are and where to put them.&lt;/p&gt;
&lt;h3 id=&#34;create-machine-learning-resources-in-greengrass&#34;&gt;Create machine learning resources in Greengrass&lt;/h3&gt;
&lt;p&gt;Now we are ready to configure machine learning resources in Greengrass. To do so, we locate our Greengrass Group in the console and navigate to the Resources page and the Machine Learning tab. We click the &amp;lsquo;Add machine learning resource&amp;rsquo; button.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_ml_add_resource.png&#34; alt=&#34;Add ML Resource&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Let us start by creating a resource for the standardiser model. First we will give the resouce a name. I went for &lt;code&gt;standardiser&lt;/code&gt; but anything goes. Next, we will need to point to the resource in our S3 bucket. Under &amp;lsquo;Model source&amp;rsquo; we choose &amp;lsquo;Upload a model in S3&amp;rsquo;, select the bucket we just created, and then select the zipped standardiser model. Finally, we will specify a local path on which to keep the unzipped model. Greengrass will create this path on our Core Device and it will be available to the Lambda functions that this machine learning resource is attached to. Any path works, but remember it, as we will need it when we create the inference Lambda function. I went with &lt;code&gt;/ggml/tensorflow/standardiser&lt;/code&gt;.&lt;br&gt;
We have not created the Lambda function yet, so we cannot attach the resource just yet. We Will have a chance to do so later, though. Click Save to create the resource.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_ml_create_resource.png&#34; alt=&#34;Add ML Resource&#34;&gt;
&lt;/div&gt;
&lt;p&gt;This created the ML resource for the standardiser. We will need to repeat the process to create a resource for the neural network model, which I named &lt;code&gt;rain_predictor&lt;/code&gt; and stored at &lt;code&gt;/ggml/tensorflow/rain_predictor&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;inference-lambda&#34;&gt;Inference Lambda&lt;/h2&gt;
&lt;p&gt;We are almost done building the architecture of our demonstration. We just need the final and arguably most interesting piece; the Lambda function that does inference.&lt;br&gt;
The function we are about to build will load the ML pipeline, fetch the latest data from the local shadow, perform the inference, and publish the result back to the local shadow. In pseudocode, we will do something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;connect to Greengrass crore
load standardiser
load neural network model
while true:
	fetch data from the local shadow
	standardise the data
	evaluate features in the model
	determine prediction based on threshold
	publish reult to local shadow
	wait a little while
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;connect-and-get-readings&#34;&gt;Connect and get readings&lt;/h3&gt;
&lt;p&gt;We already know how to interact with the local shadow. We will use an environment variable to supply the name of our Thing&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import greengrasssdk
import os

THING_NAME = os.environ[&amp;quot;THING_NAME&amp;quot;]

client = greengrasssdk.client(&#39;iot-data&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then get the latest data from the local shadow&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;thing_shadow = client.get_thing_shadow(thingName=THING_NAME)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The shadow requires a bit of unpacking&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import logging
import json

def parse_shadow(thing_shadow):
    try:
        reported = thing_shadow[&amp;quot;state&amp;quot;][&amp;quot;reported&amp;quot;]
        readings = [reported[&amp;quot;pressure&amp;quot;],
                    reported[&amp;quot;temperature&amp;quot;],
                    reported[&amp;quot;humidity&amp;quot;]]
    except Exception as e:
        logging.error(&amp;quot;Failed to parse thing_shadow: &amp;quot; + repr(e))
    return [readings]

readings = parse_shadow(thing_shadow=json.loads(thing_shadow[&amp;quot;payload&amp;quot;]))
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;load-model&#34;&gt;Load model&lt;/h3&gt;
&lt;p&gt;In order to load our models, we need the paths that we defined for the corresponding ML resources:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import tensorflow as tf

STANDARDISER_PATH = &amp;quot;/ggml/tensorflow/standardiser&amp;quot;
MODEL_PATH = &amp;quot;/ggml/tensorflow/rain_predictor&amp;quot;

# Load the model that standardises readings
loaded_standardiser = tf.saved_model.load(STANDARDISER_PATH)
inference_standardiser = loaded_standardiser.signatures[&amp;quot;serving_default&amp;quot;]

# Load the model that predicts rain
loaded_predictor = tf.saved_model.load(MODEL_PATH)
inference_predictor = loaded_predictor.signatures[&amp;quot;serving_default&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;inference&#34;&gt;Inference&lt;/h3&gt;
&lt;p&gt;Given the data and the models, we can go ahead and implement ML inference and publish the results&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;CLASSIFICATION_THRESHOLD = 0.5

# Standardise readings to create model features
feature_tensor = inference_standardiser(tf.constant(readings))[&#39;x_prime&#39;]
logging.info(feature_tensor)
# Perform prediction
raw_prediction = inference_predictor(feature_tensor)[&#39;y&#39;].numpy()
# Evaluate prediction
prediction = (raw_prediction &amp;gt;= CLASSIFICATION_THRESHOLD).astype(int).tolist()[0][0]
# Publish result to the local shadow
shadow_update[&amp;quot;state&amp;quot;] = {&amp;quot;reported&amp;quot; : { &amp;quot;rain_prediction&amp;quot; : prediction } }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;create-lambda-deployment-package&#34;&gt;Create Lambda deployment package&lt;/h3&gt;
&lt;p&gt;With a bit of additional error handling and logging, we have everythin we need for our inference Lambda&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import greengrasssdk
import tensorflow as tf
import json
import time
import logging
import os

THING_NAME = os.environ[&amp;quot;THING_NAME&amp;quot;]
STANDARDISER_PATH = &amp;quot;/ggml/tensorflow/standardiser&amp;quot;
MODEL_PATH = &amp;quot;/ggml/tensorflow/rain_predictor&amp;quot;
CLASSIFICATION_THRESHOLD = 0.5

# Load the model that standardises readings
loaded_standardiser = tf.saved_model.load(STANDARDISER_PATH)
inference_standardiser = loaded_standardiser.signatures[&amp;quot;serving_default&amp;quot;]

# Load the model that predicts rain
loaded_predictor = tf.saved_model.load(MODEL_PATH)
inference_predictor = loaded_predictor.signatures[&amp;quot;serving_default&amp;quot;]

client = greengrasssdk.client(&#39;iot-data&#39;)

def parse_shadow(thing_shadow):
    try:
        reported = thing_shadow[&amp;quot;state&amp;quot;][&amp;quot;reported&amp;quot;]
        readings = [reported[&amp;quot;pressure&amp;quot;],
                    reported[&amp;quot;temperature&amp;quot;],
                    reported[&amp;quot;humidity&amp;quot;]]
    except Exception as e:
        logging.error(&amp;quot;Failed to parse thing_shadow: &amp;quot; + repr(e))
    return [readings] # Note predictor expects shape (observations X num_features)

shadow_update = {}
while True:
    try:
        # Get readings from local Shadow
        thing_shadow = client.get_thing_shadow(thingName=THING_NAME)
        # Put readings in a list in the right order
        readings = parse_shadow(thing_shadow=json.loads(thing_shadow[&amp;quot;payload&amp;quot;]))
        # Standardise readings to create model features
        feature_tensor = inference_standardiser(tf.constant(readings))[&#39;x_prime&#39;]
        logging.info(feature_tensor)
        # Perform prediction
        raw_prediction = inference_predictor(feature_tensor)[&#39;y&#39;].numpy()
        # Evaluate prediction
        prediction = (raw_prediction &amp;gt;= CLASSIFICATION_THRESHOLD).astype(int).tolist()[0][0]
        # Publish result to the local shadow
        shadow_update[&amp;quot;state&amp;quot;] = {&amp;quot;reported&amp;quot; : { &amp;quot;rain_prediction&amp;quot; : prediction } }
    except Exception as e:
        logging.error(&amp;quot;Failed to do prediction: &amp;quot; + repr(e))
        
    client.update_thing_shadow(thingName=THING_NAME, payload=json.dumps(shadow_update))
    time.sleep(10) # Repeat every 10s

# The function handler here will not be called. Our Lambda function
#  should be long running and stay in the infinite loop above.
def function_handler(event, context):
    pass
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The script can also be found &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/ml_inference_lambda.py&#34; title=&#34;Inference Lambda script&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;br&gt;&lt;br&gt;
We zip this script along with the Greengrass SDK and create a deployment package.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/lambda_ggml_inference.png&#34; alt=&#34;Inference Lambda&#34;&gt;
&lt;/div&gt;
&lt;p&gt;We then create an alias, go to the Greengrass console, and add the Lambda function to our Group.&lt;/p&gt;
&lt;h3 id=&#34;attach-machine-learning-resources&#34;&gt;Attach machine learning resources&lt;/h3&gt;
&lt;p&gt;Now we can finally attach the machine learning resources to our Lambda function. We navigate to our Greengrass Group and under the Lambdas tab select our inference Lambda. Under the Resources tab, we select the option to &amp;lsquo;Add machine learning resource&amp;rsquo;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_resources_add.png&#34; alt=&#34;Attach ML resources&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Since we have already created the resources, we select the option to &amp;lsquo;Attach an existing machine learning resource&amp;rsquo;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_resources_existing.png&#34; alt=&#34;Attach ML resources&#34;&gt;
&lt;/div&gt;
&lt;p&gt;We select either of the two resources, click &amp;lsquo;Save&amp;rsquo;, and repeat the the process for the other resource.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_resources.png&#34; alt=&#34;Attach ML resources&#34;&gt;
&lt;/div&gt;
&lt;h3 id=&#34;configure-the-lambda&#34;&gt;Configure the Lambda&lt;/h3&gt;
&lt;p&gt;Our inference Lambda is almost done, we just need to configure it properly. All Lambda functions we have used with Greengrass so far have been on-demand functions that were spawned in response to an MQTT message. This inference Lambda is a bit different. Instead of waiting to process an input on-demand, we want this function run on on a fixed schedule, which we implemented by having the inference code repeat every 10 seconds. In fact, we do not want the Lambda to respnd to any events at all and consequently left the &lt;code&gt;function_handler&lt;/code&gt; empty.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# The function handler here will not be called. Our Lambda function
#  should be long lived and stay in the infinite loop above.
def function_handler(event, context):
    pass
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the Lambda is deployed to our Greengrass Group, we just want it to run forever in the infinite loop we created. This is called a long-lived Lambda, and we can choose this option on the configuration page of the Lambda in the Greengrass Group. While we are in there, we will also give the Lambda a longer timeout and some more memory. Our ML model is small, but ML models are often large and require much more memory.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/greengrass_lambda_configurations_longlived.png&#34; alt=&#34;Config long-lived Lambda&#34;&gt;
&lt;/div&gt;
&lt;h1 id=&#34;deploy-and-verify&#34;&gt;Deploy and Verify&lt;/h1&gt;
&lt;p&gt;That is it; everything is in place for doing machine learning inference at the edge.&lt;br&gt;
First let us ensure that Greengrass is running using:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ps aux | grep -E &#39;greengrass.*daemon&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we deploy everything we have created.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img src=&#34;../../project/iot-poc/images/greengrass_deploy.png&#34; alt=&#34;iot setup&#34;&gt;
&lt;/div&gt;
&lt;p&gt;Finally, we make sure that the Thing is online and is publishing values from our sensor.&lt;br&gt;&lt;br&gt;
Now, if everything works is right, we should be doing inference at the edge. We should be predicting whether it is raining or not and publishing the result to the local Shadow. Since the local Shadow is being synchronised with the cloud based Shadow, we should be able to see the predictions if we go to the Shadow page of our Thing.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_shadow_mlpred.png&#34; alt=&#34;Shadow with prediction&#34;&gt;
&lt;/div&gt;
&lt;p&gt;And there it is! It is a sunny day, so the prediction was right this time, but do not expect it to be very precise. Instead bask in the glory of accomplishment and enjoy the fact that you now know how to manage machine learning models in the cloud and do inference on the edge. Congratulations!&lt;/p&gt;
&lt;h1 id=&#34;in-production&#34;&gt;In Production&lt;/h1&gt;
&lt;p&gt;While we have done much there are still many more things to consider when using Greengrass for machine learning workloads in production. Here is a short discussion of some of these considerations along with a few points and tricks that did not fit in the demonstration.&lt;/p&gt;
&lt;h2 id=&#34;logging-in-greengrass&#34;&gt;Logging in Greengrass&lt;/h2&gt;
&lt;p&gt;Greengrass features pretty extensive &lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/greengrass-logs-overview.html&#34; title=&#34;AWS Greengrass docs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;logging&lt;/a&gt;. Logs pertaining to the Lambda functions running in the Greengrass Group can be particularly useful during development as well as production. The Logs are stored on our gateway device on a path that depends on user ID and AWS region. It is fairly straightforward to add log entries from a Python Lambda function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import logging
# Log an error
logging.error(&amp;quot;Hypothetical error&amp;quot;)
# Log some information
logging.info(&amp;quot;My value is 2&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All sorts of things can and will go wrong when developing, and so a very useful Python design pattern to use in Lambda functions is the try and except with logging.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;a = 4
try:
	# Do whatever we are trying to do
	a += 1
except Exception as e:
	# Log the variables at this time
	logging.info(&amp;quot;a is {0}&amp;quot;.format(a))
	# Log the exception along with a description of what was supposed to happen
	logging.error(&amp;quot;Failed to do the thing I wanted: &amp;quot; + repr(e))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed we did apply this design pattern in the examples for this demonstration so, when something is not working as expected, check the logs.&lt;/p&gt;
&lt;h2 id=&#34;cicd&#34;&gt;CI/CD&lt;/h2&gt;
&lt;p&gt;We implemented many different parts in this demonstration, and repeating this manual process is obviously not feasible for real IoTs with hundreds of devices. &lt;a href=&#34;https://docs.aws.amazon.com/greengrass/latest/developerguide/cloudformation-support.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CloudFormation templates&lt;/a&gt; will work wonders for the cloud side of things. But, even if we are using AWS IoT services, an IoT very much is a hybrid setup. We still need to install and manage the software running on and near gateway devices and sensors. All in all this sets quite high demands for our CI/CD pipelines.&lt;br&gt;
For data science projects, however, publishing models to an S3 bucket and inference code to Lambda are relatively trivial tasks, so at least this part of CI/CD can be much easier with Greengrass.&lt;/p&gt;
&lt;h2 id=&#34;cost&#34;&gt;Cost&lt;/h2&gt;
&lt;p&gt;We have not specifically addressed the subject of cost during this or the previous demonstrations. To be clear, everything we have done in this demonstration and the previous ones should be well within the Free Tier, assuming eligibility and that things are not left running indefinitely. But what about larger IoTs?&lt;br&gt;&lt;br&gt;
Pricing for &lt;a href=&#34;https://aws.amazon.com/iot-core/pricing/&#34; title=&#34;AWS IoT Core pricing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AWS IoT&lt;/a&gt; and &lt;a href=&#34;https://aws.amazon.com/greengrass/pricing/&#34; title=&#34;AWS Greengrass pricing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AWS Greengrass&lt;/a&gt; is fairly transparent and we can connect a lot of devices and send a lot of messages before raking up a bill of any significant size. Indeed, if we did not do Shadow synchronisation, we could copy the architecture of this demonstration, scaling it to hundreds of manufacturing lines, and it would cost us less than $2 per gateway device per year. So does that mean that doing IoT is super cheap? No, it just means that the bill lies elsewhere.&lt;br&gt;
From a cloud point of view, sending messages to AWS IoT does not do much. The messages are not kept or processed in any way, unless we do so actively. Herein lies a hidden cost: We are going to need more services like Kinesis, SQS, SNS, S3, or DynamoDB before we can start using our data. In particular, processing using cloud compute can be expensive. One of the key reasons for using Greengrass was to lower processing costs by using compute available at the edge. Yet, this means we have to have an edge.&lt;br&gt;
So, from an edge point of view, we could argue that the whole cloud thing is just an add on to the costs that we already have in building and maintaining servers and networks around whatever process we building an IoT for.&lt;br&gt;&lt;br&gt;
The point is that, even though AWS IoT prices are reasonable and transparent, these are only a small part of the total cost and business case for an IoT. Depending on our intended applications and the tools available locally, it might or might not make sense to involve the cloud. That being said, IoT can be a cheap and fun way to get started with the cloud.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Publishing and Subscribing with AWS IoT</title>
      <link>/post/iot-poc-pubsub/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/post/iot-poc-pubsub/</guid>
      <description>&lt;p&gt;In this demonstration, we will add upon the &lt;a href=&#34;../../post/iot-poc-publishing/&#34; title=&#34;simple publishing&#34;&gt;previous&lt;/a&gt;, by having our gateway device, the Raspberry Pi, subscribe to messages on a topic.&lt;br&gt;&lt;br&gt;
With publishing, the information flow is from the device to AWS IoT, but with subscribing, the flow is reversed to be from AWS IoT to the client we configure for our device. Applications are obvious candidates for subscribers to messages but, as we will see, the ability to subscribe is extremely useful for structuring and managing devices remotely.&lt;br&gt;&lt;br&gt;
In general terms, we want our device to do the following&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;prepare the sensor
configure connection to AWS
define what happens with subscriptions
start subscribing
while true
    react to any incoming messages
    get a sensor reading
    pack it up
    publish it
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the demonstration, are once again using the Bosch BME680 air quality sensor connected to a Raspberry Pi 3 model B+. The BME680 does four different measurements, and we will utilise the temperature, pressure, and humidity sensing capabilities. The Pi is just there to query the sensor and run the AWS IoT SDK. It essentially plays the part of a microcontroller, and so anything we accomplish here can be done with a microcontroller or any other compute device. In the final section of this demonstration, we will discuss some of the additional considerations for a similar setup in an actual industrial setting.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=&#34;500&#34; src=&#34;../../project/iot-poc/images/pubsub_architecture.png&#34; alt=&#34;pubsub overview&#34;&gt;
  &lt;br&gt;
  Schematic of the architecture we are building in this demonstration. Note the two-way communication between IoT Core and our thing.
&lt;/div&gt;
&lt;br&gt;
&lt;p&gt;Connecting to AWS IoT and publishing messages were covered in the &lt;a href=&#34;../../post/iot-poc-publishing/&#34;&gt;previous&lt;/a&gt; demonstration. In this demonstration, we focus on subscribing to messages and combining publishing and subscribing within one client.&lt;/p&gt;
&lt;h1 id=&#34;registering-the-sensor-in-iot-core&#34;&gt;Registering the Sensor in IoT Core&lt;/h1&gt;
&lt;p&gt;Just as it is the case with publishing, we need to register the device that will subscribe to messages. We can use the same thing and certificate as in the &lt;a href=&#34;../../post/iot-poc-publishing/#registering-the-sensor-in-iot-core&#34;&gt;previous demonstration&lt;/a&gt;, but we need to change the policy to allow subscription through using that certificate.
For subscription to work, we need to add two additional statements to the policy. We need to allow &lt;code&gt;iot:Subscribe&lt;/code&gt; to a topic filter and allow &lt;code&gt;iot:Receive&lt;/code&gt; for a specific topic. The distinction between topic and topic filter can seem nebulous, but imagine a manufacturing line with hundreds of sensors publishing to topics with the prefix &lt;code&gt;factoryA/line22&lt;/code&gt;. Then we might create a policy that allows subscription to all the topics &lt;code&gt;factoryA/line22/*&lt;/code&gt;, where the asterisk is a wildcard, and policies that allow receiving of messages to specific topics such as &lt;code&gt;factoryA/line22/milling/torque&lt;/code&gt;.
Here is an example of such a policy document that allows subscription and receiving to a single topic.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
  &amp;quot;Statement&amp;quot;: [
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [
        &amp;quot;iot:Publish&amp;quot;
      ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/temperature&amp;quot;,
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/pressure&amp;quot;,
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/humidity&amp;quot;,
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/actions&amp;quot;
      ]
    },
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [
        &amp;quot;iot:Receive&amp;quot;
      ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/actions&amp;quot;
      ]
    },
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [
        &amp;quot;iot:Subscribe&amp;quot;
      ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topicfilter/bme680/actions&amp;quot;
      ]
    },
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [
        &amp;quot;iot:Connect&amp;quot;
      ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:client/simple-subscribing&amp;quot;
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is the actual policy document for the following examples. It might seem like we are repeating the same thing many times, but there is a good reason for it. The subscription action is only checked whenever a client connects to AWS, whereas the receive policy is checked each time a message is sent. This means that we have the option to disallow messages from a specific topic to devices using this certificate, even if they are already subscribing to the topic.&lt;/p&gt;
&lt;h1 id=&#34;subscribing-to-topics&#34;&gt;Subscribing to Topics&lt;/h1&gt;
&lt;p&gt;Like publishing, subscribing can be done with just one line of code. We just need to call the &lt;a href=&#34;https://s3.amazonaws.com/aws-iot-device-sdk-python-docs/sphinx/html/index.html#AWSIoTPythonSDK.MQTTLib.AWSIoTMQTTClient.subscribe&#34; title=&#34;subscribe docs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;.subscribe()&lt;/a&gt; function of the MQTT client.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;AWSIoTMQTTClient.subscribe(topic, 1, callback_function)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first argument is the topic to listen to. Note that the certificate provided to the client must have a policy that allows subscription to that specific topic.&lt;br&gt;
The second argument is the Quality of Service, &lt;a href=&#34;../../post/iot-poc-publishing/#quality-of-service-qos&#34;&gt;just as for publishing&lt;/a&gt;, 0 means that the message is delivered at most once and 1 means at least once. Remember that now the roles are reversed, and the client we are configuring is the one that will receive the message have to send a confirmation of a message received. Fortunately that is all taken care of behind the scenes in the client we are configuring.&lt;br&gt;
The third argument is a custom function that is called whenever a message is received on the topic. This function should follow the pattern &lt;code&gt;callback_function(client, userdata, message)&lt;/code&gt;. &lt;code&gt;message&lt;/code&gt; will then be an object containing the topic, &lt;code&gt;message.topic&lt;/code&gt;, and the body, &lt;code&gt;message.payload&lt;/code&gt;, of the message. The two variables &lt;code&gt;client&lt;/code&gt; and &lt;code&gt;userdata&lt;/code&gt; are there for compatibility of the callback stack; they are flagged for deprecation, and it is not recommended to rely on them. The simplest thing to do when receiving a message, save for doing nothing at all, would be to print the message. Such a function might look like this&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def callback_function(client, userdata, message):
    print(&amp;quot;Received a new message:\n{0}&amp;quot;.format(message.payload))
    print(&amp;quot;from topic:\n{0}&amp;quot;.format(message.topic))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next section, we will use this function to do cool things.&lt;br&gt;&lt;br&gt;
The subscription can be set up as soon as connection between the client and AWS IoT is established. The client will then listen for any published messages for as long as it lives or until the subscription is terminated. This also means that we do not have to implement an infinite loop like during publishing.&lt;br&gt;&lt;br&gt;
With this, we have everything needed to set up a subscription:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Configure client and connect
myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId)
myAWSIoTMQTTClient.configureEndpoint(host, port)
myAWSIoTMQTTClient.configureCredentials(rootCAPath, privateKeyPath, certificatePath)
myAWSIoTMQTTClient.configureAutoReconnectBackoffTime(1, 32, 20)
myAWSIoTMQTTClient.configureOfflinePublishQueueing(-1)  # Infinite offline Publish queueing
myAWSIoTMQTTClient.configureDrainingFrequency(2)  # Draining: 2 Hz
myAWSIoTMQTTClient.configureConnectDisconnectTimeout(10)  # 10 sec
myAWSIoTMQTTClient.configureMQTTOperationTimeout(5)  # 5 sec
myAWSIoTMQTTClient.connect()
time.sleep(2)

# Define what happens when messages are received
def callback_function(client, userdata, message):
    print(&amp;quot;Received a new message:\n{0}&amp;quot;.format(message.payload))
    print(&amp;quot;from topic:\n{0}&amp;quot;.format(message.topic))

# Subscribe
AWSIoTMQTTClient.subscribe(topic, 1, callback)

# Wait for messages to arrive
while True:
    time.sleep(5)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A full working example can be found &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/simple_subscribing.py&#34; title=&#34;simple subscribing example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. We run the script from a terminal on the Pi:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python simple_subscribing.py -e &amp;lt;your aws iot endpoint&amp;gt; -r &amp;lt;file containing root certificate&amp;gt; -c &amp;lt;file containing device certificate&amp;gt; -k &amp;lt;file containing private key&amp;gt; -id &amp;lt;a client ID&amp;gt; -t &amp;lt;the topic to subscribe to&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nothing happens before we start publishing messages to our topic of choice. I ran the example on my Pi, using the topic &lt;code&gt;/bme680/actions&lt;/code&gt;. I then moved to the test suite at AWS IoT Core &amp;gt; Test, and published a message to that topic.&lt;br&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_iot_test_simple_subscribe.PNG&#34; alt=&#34;simple subscribe&#34;&gt;
  &lt;br&gt;
&lt;/div&gt;
&lt;p&gt;The console output on the Pi then looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Received a new message:
{
    &amp;quot;message&amp;quot;: &amp;quot;Hello from AWS IoT Console&amp;quot;
}
from topic:
bme680/action
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Congratulations! You now know how to subscribe to a topic using the AWS IoT Python SDK. The real power of subscription, however, lies in combining it with publishing. In the next section, we will build a small example of how to use subscription with publishing to great effect.&lt;/p&gt;
&lt;h1 id=&#34;a-subscription-example&#34;&gt;A Subscription Example&lt;/h1&gt;
&lt;p&gt;In the case of simple publishing, we were getting temperature readings from the BME680 sensor and published them to AWS IoT. However, the BME680 sensor is also able to measure relative humidity and air pressure. In real life we would want to use this expensive sensor to measure all three at once, but for this case we are going to build a way for us to remotely toggle between measuring these three variables. We will set up a subsription that listens to commands published on a specific topic. We will then use the content of that message to change which variable is measured and published by the device and sensor.&lt;br&gt;
First we will choose our topics. We will publish on three different topics depending on the variable that we are measuring.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bme680/temperature
bme680/pressure
bme680/humidity
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In addition to this, we will reserve a topic for publishing actions to our device.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bme680/action
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Imagine now that we will publish messages on this topic telling the device what to do. For instance, we might send the message&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;action&amp;quot;:&amp;quot;pressure&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;telling the device to switch to measuring pressure and publish on the appropriate topic. Publishing this message will be simple enough using the AWS IoT test suite, but we need to code up the response behaviour first. To this end, we will use the callback function&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;topic = None
variable = None
def callback_function(client, userdata, message):
    payload = json.loads(message.payload)
    global pubtopic
    global variable
    if &amp;quot;action&amp;quot; not in payload:
        topic = None
        variable = None
    else:
        if payload[&amp;quot;action&amp;quot;] == &amp;quot;temperature&amp;quot;:
            topic = &amp;quot;bme680/temperature&amp;quot;
            variable = &amp;quot;temperature&amp;quot;
        elif payload[&amp;quot;action&amp;quot;] == &amp;quot;pressure&amp;quot;:
            topic = &amp;quot;bme680/pressure&amp;quot;
            variable = &amp;quot;pressure&amp;quot;
        elif payload[&amp;quot;action&amp;quot;] == &amp;quot;humidity&amp;quot;:
            topic = &amp;quot;bme680/humidity&amp;quot;
            variable = &amp;quot;humidity&amp;quot;
        else:
            topic = None
            variable = None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will then use these global variables to adjust what variable we get from the sensor before publishing.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;while True:
    if sensor.get_sensor_data():
        # Get the value currently toggled
        value = None
        if variable = &amp;quot;temperature&amp;quot;:
            value = sensor.data.temperature
        elif variable = &amp;quot;pressure&amp;quot;:
            value = sensor.data.pressure
        elif variable = &amp;quot;humidity&amp;quot;:
            value = sensor.data.humidity
        elif:
            value = None
        message = {}
        message[&#39;value&#39;] = value
        message[&#39;variable&#39;] = variable
        message[&#39;timestamp_utc&#39;] = datetime.utcnow().strftime(&amp;quot;%Y-%m-%dT%H:%M:%S.%fZ&amp;quot;)
        message[&#39;status&#39;] = &amp;quot;success&amp;quot;
        messageJson = json.dumps(message)
         # This is the actual publishing to AWS
        myAWSIoTMQTTClient.publish(topic, messageJson, 1)
        print(&#39;Published topic %s: %s\n&#39; % (topic, messageJson))
        loopCount += 1
    else:
        message = {}
        message[&#39;value&#39;] = None
        message[&#39;timestamp_utc&#39;] = datetime.utcnow().strftime(&amp;quot;%Y-%m-%dT%H:%M:%S.%fZ&amp;quot;)
        message[&#39;status&#39;] = &amp;quot;fail&amp;quot;
        messageJson = json.dumps(message)
         # This is the actual publishing to AWS
        myAWSIoTMQTTClient.publish(topic, messageJson, 1)
        print(&#39;Published topic %s: %s\n&#39; % (topic, messageJson))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The whole script is &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/simple_pubsub.py&#34; title=&#34;simple pubsub example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. When run, it will start to listen to the topic subscibed to. Once it receives a message with instructions it will start querying the sensor as instructed and publish. This way we can toggle between different sensors and even shut off messages when we do not need them and thus save money.&lt;br&gt;
This might not be exactly the thing that you want your device to do, but now you have the building blocks to create whatever response you want. As a challenge, why not try to set up a topic that controls how often values are published from the device? With such functionality, you could adjust the tradeoff between storage cost and data granularity over time.&lt;/p&gt;
&lt;h1 id=&#34;in-production&#34;&gt;In Production&lt;/h1&gt;
&lt;p&gt;Besides the considerations mentioned in the &lt;a href=&#34;../../post/iot-poc-publishing/#in-production&#34;&gt;previous demonstration&lt;/a&gt;, a few additional considerations apply now that we are able to establish two way communication with our devices in the IoT.&lt;/p&gt;
&lt;h2 id=&#34;applications&#34;&gt;Applications&lt;/h2&gt;
&lt;p&gt;First the fun part. What might we actually do with this added capability?&lt;/p&gt;
&lt;h3 id=&#34;alternate-data-frequency&#34;&gt;Alternate data frequency&lt;/h3&gt;
&lt;p&gt;If we store and process less data, it will cost us less but will also give the data scientists less of that precious data paydirt. We might want to change the frequency of the data according to current business priorities. We will almost definitely want to change the rate to respond to the process. A simple on/off switch for when the process is not running will work wonders. I would, however, love to see a combined IoT and analytics application that chooses the sampling frequency based on variance in the data and automatically adjusts sampling accordingly.&lt;/p&gt;
&lt;h3 id=&#34;have-an-equipment-debugging-mode&#34;&gt;Have an equipment-debugging mode&lt;/h3&gt;
&lt;p&gt;The idea of a debugging mode is common in digital applications. IoT means brining the digital world to our physical equipment. Imagine having a debugging mode for our manufacturing equipment. Specifically, this could be a toggleable mode with telemetry from additional sources and at a high frequency.&lt;/p&gt;
&lt;h3 id=&#34;respond-to-low-frequency-changes&#34;&gt;Respond to low-frequency changes&lt;/h3&gt;
&lt;p&gt;Control loop managed by PLCs do a great job of keeping a process in control and running smoothly and continuosly. One thing they do not do, however, is respond well to low frequency changes and business-induced changes. Think of a batch changeover or the change between product variants - it takes time and effort to get the equipment running smoothly again. If we have actuating devices as part of the IoT we can start having our manufacturing equipment respond to business priorities or just deal with changes that the PLC does not consider. An example could be an automatic change of settings on a change of product variant according to the predictions of a simulation or a model.&lt;/p&gt;
&lt;h2 id=&#34;security&#34;&gt;Security&lt;/h2&gt;
&lt;p&gt;If you are in manufacturing or some other regulated context, it might sound scary to have a two way communication between your site and the cloud. In all fairness, this could pose a security risk, the magnitude of which depends on the extent of the liberties given to the IoT and connected applications. As developers, there are a number of considerations we can make to increase the robustness of the IoT and lessen the burden on ourselves when we maintain the application. This is by no means a full list, but just a few obvious starting points.&lt;/p&gt;
&lt;h3 id=&#34;do-not-couple-control-loop-and-iot&#34;&gt;Do not couple control loop and IoT&lt;/h3&gt;
&lt;p&gt;The end goal of our IoT application might be a kind of outer automation that responds to rare changes and optimises business parameters, but coupling our IoT with quality critical process control might not be a good idea, at least right away. Remember that even though our vision camera is not directly connected to our gateway device, we might still be able to get that delicious data by reading it from a database associated with the vision system.&lt;/p&gt;
&lt;h3 id=&#34;limit-the-power-of-actions&#34;&gt;Limit the power of actions&lt;/h3&gt;
&lt;p&gt;Should someone with malicious content get access to publishing to a topic that initiates actions in the our gateway devices they will only be able to cause as much damage as we allow.&lt;br&gt;
For one of my first setups, I made my device run any bash command sent from the cloud. This is a fun exercise, but probably a bad idea in a real manufactuing setting.&lt;/p&gt;
&lt;h3 id=&#34;topic-management&#34;&gt;Topic management&lt;/h3&gt;
&lt;p&gt;One thing, I have found useful is to use seperate topic hierarchies for topics that are intended for publishing data and topics that are intended for triggering work or actions.&lt;br&gt;
We have &lt;a href=&#34;project/iot-poc-publishing/#topics&#34;&gt;previously&lt;/a&gt; discussed using hierarchies of topics to structure data published from a manufacturing site. If we have a topic hierarchy like &lt;code&gt;factoryA/line22/milling/torque&lt;/code&gt;, it might be tempting to make the action topic something like &lt;code&gt;factoryA/line22/milling/action&lt;/code&gt;. This could be a bad idea, since it is easy to create a policy like &lt;code&gt;factoryA/line22/*&lt;/code&gt; that allows access to publishing and action topics. If instead we make topics like &lt;code&gt;action/factoryA/line22/milling&lt;/code&gt; then at least it is more difficult to make policy mistakes while still keeping some of the hierarchical structure.&lt;br&gt;
Even without considering mistakes, poor topic management can quickly create a weak spot for our IoT both in terms of security and developer friendliness. AWS does not manage our topics, so we need to do it. That being said, the AWS Device Shadow functionality might just be what we need to make this much simpler. Fortunately, Shadows are the subject of the &lt;a href=&#34;../../post/iot-poc-shadow/&#34;&gt;next demonstration&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;read-about-security-best-practices&#34;&gt;Read about security best practices&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/security.html&#34; title=&#34;AWS IoT Security Docs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AWS documentation&lt;/a&gt; is quite extensive and has better explanations and recommendations for security than I could ever conceive. Make sure to stay on top of current security best practices.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Publishing Industrial Data with AWS IoT</title>
      <link>/post/iot-poc-publishing/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/post/iot-poc-publishing/</guid>
      <description>&lt;p&gt;In this tutorial, we will obtain a value from a sensor and publish it to a topic on AWS. No added shenanigans; this is as simple as it gets.&lt;br&gt;&lt;br&gt;
At the core of it, we want to grab a reading from the sensor, wrap it in a message with some useful metadata, and publish that to AWS IoT. We will program all the logic into a Python script that runs continuosly on a loop. Our script should end up being structured somewhat like this:&lt;br&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Prepare the sensor
Set up connection to AWS
while true
    get a sensor reading
    pack it up
    publish it
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the demonstration we will be using the Bosch BME680 air quality sensor connected to a Raspberry Pi 3 model B+. The BME680 does four different measurements, but for this case we will only be measuring and publishing the temperature. The Pi is just there to query the sensor and run Python script with the AWS IoT SDK. It essentially plays the part of a microcontroller, and so anything we accomplish here can be done with a microcontroller or any other compute device. In the final section of this demonstration we will discuss some of the additional considerations for a similar setup in an actual industrial setting.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img height=&#34;200&#34; src=&#34;../../project/iot-poc/images/publishing_architecture.png&#34; alt=&#34;IoT overview&#34;&gt;
	&lt;img height=&#34;200&#34; src=&#34;../../project/iot-poc/images/hardware_setup.jpg&#34; alt=&#34;Hardware setup&#34;&gt;
  &lt;br&gt;
  Schematic of the architecture we are building in this demonstration and a picture of the actual hardware I used for developing.
&lt;/div&gt;
&lt;h1 id=&#34;registering-the-sensor-in-iot-core&#34;&gt;Registering the Sensor in IoT Core&lt;/h1&gt;
&lt;p&gt;Before we can start connecting a sensor to AWS, we need to register the sensor or system as a so-called Thing in AWS IoT Core. The AWS docs have a &lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/register-device.html&#34; title=&#34;AWS IoT docs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;getting started guide&lt;/a&gt; which is pretty good. Follow the guide, but at the end of it, we should have the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A device certificate file&lt;/li&gt;
&lt;li&gt;A private key file&lt;/li&gt;
&lt;li&gt;The root certificate file&lt;/li&gt;
&lt;li&gt;In the policy we attached to the certificate, we have allowed publishing from an ID and to a topic that we can remember&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The three files should be installed on the controller device. In this case, that just means the files should be in accessible place on the Raspberry Pi. The ID will be used as clientID for the MQTT client that we will use to connect to AWS IoT later, and the topic is a flag that helps us direct data along the right path. We will discuss both of these concepts in detail below.&lt;br&gt;&lt;br&gt;
The policy used for the examples follows this pattern:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
  &amp;quot;Statement&amp;quot;: [
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [
        &amp;quot;iot:Publish&amp;quot;,
        &amp;quot;iot:Receive&amp;quot;
      ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/bme680/temperature&amp;quot;
      ]
    },
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [
        &amp;quot;iot:Connect&amp;quot;
      ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:client/simple-publishing&amp;quot;
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;setting-up-the-sdk&#34;&gt;Setting up the SDK&lt;/h1&gt;
&lt;p&gt;We will do scripting for this case using Python. AWS IoT currently has two SDKs for Python. For this case we will use version 1, which is easily installed using pip:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install AWSIoTPythonSDK
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The AWS IoT code below should work for any version of Python, but the interaction with the BME680 sensor is written with Python 3.7 and would need tweaks to work with earlier versions.&lt;/p&gt;
&lt;h1 id=&#34;publishing-to-aws-iot&#34;&gt;Publishing to AWS IoT&lt;/h1&gt;
&lt;p&gt;Now we are ready to get started on developing with the SDK.&lt;br&gt;
Publishing a message to AWS using the Python SDK will look something like this&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;AWSIoTMQTTClient.publish(topic, messageJSON, 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The AWSIoTMQTTClient is the object that we will use to configure and establish the connection to AWS IoT Core. The &lt;a href=&#34;https://s3.amazonaws.com/aws-iot-device-sdk-python-docs/sphinx/html/index.html#AWSIoTPythonSDK.MQTTLib.AWSIoTMQTTClient.publish&#34; title=&#34;AWS docs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;.publish()&lt;/a&gt; method publishes the message and takes three arguments: the topic to publish to, the message to be sent, and a Quality of Service (QoS) flag. Lets look at each of these in turn.&lt;/p&gt;
&lt;h3 id=&#34;topics&#34;&gt;Topics&lt;/h3&gt;
&lt;p&gt;Messages in AWS IoT are distributed and filtered using topics. Topics are a kind of tag that we can use to identify the source of the message and distribute it accordingly. It is just a single string, generally in the format&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;main_tag/secondary_tag/tertiary_tag/etc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For instance, if we had several factories each with several manufacturing lines with several stations each eqipped with sensors, we might do something like&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;factoryA/line22/drying/temperature
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then have another sensor on the same line publish to&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;factoryA/line22/milling/torque
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That way we can direct these messages to the store or dashboard for the same line but seperate lambda functions, if that is needed for our application.&lt;br&gt;
An IoT thing needs permission to publish to a specific topic. This is done by adding a certificate with a permissive policy to the thing. By using the topic naming convention above and wildcards in the policy, we can create hierarchies and differentiated permissions for things in different parts of our application or factory setup.&lt;br&gt;
Now, for this demonstration example, we only have four sensors, and really we will only use one of them, so we will go with a simple topic. Like, say,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bme680/temperature
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will dive deeper into topics in the next demonstrations, but for now we will leave it at this simple one.&lt;/p&gt;
&lt;h3 id=&#34;message&#34;&gt;Message&lt;/h3&gt;
&lt;p&gt;The message contains the actual data along with any metadata. It is structured as a &lt;a href=&#34;https://www.youtube.com/watch?v=wI1CWzNtE-M&#34; title=&#34;JSON tutorial&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;JSON&lt;/a&gt; and we can put whatever we want in there, but we will want the data point, a timestamp for the time of sampling, and maybe an idication whether the reading was succesful or not. In our script, we will structure the message to look something like this, when the sensor reading is successful&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;utc_timestamp&amp;quot;: 1581417910,
    &amp;quot;value&amp;quot;: 23.6,
    &amp;quot;origin&amp;quot;: &amp;quot;BME680 temperature&amp;quot;,
    &amp;quot;status&amp;quot;: &amp;quot;success&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;quality-of-service-qos&#34;&gt;Quality of Service (QoS)&lt;/h3&gt;
&lt;p&gt;The messages are published to AWS using the MQTT protocol. This is a protocol commonly used in manufacturing systems, and is documented &lt;a href=&#34;http://mqtt.org/documentation&#34; title=&#34;MQTT documentation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;online&lt;/a&gt;. The &lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/mqtt.html&#34; title=&#34;AWS MQTT Documentation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AWS flavour&lt;/a&gt; of MQTT is a slightly simpler implementation of the protocol.&lt;br&gt;
As for Quality of Service (QoS), it is a flag specifying what happens when messages get lost in the network. The AWS flavour of MQTT accepts two QoS flags. The flag 0 means that the message is delivered to subsrcibers &amp;lsquo;at most once&amp;rsquo;. The flag 1 means that the message is delivered to subsribers &amp;lsquo;at least once&amp;rsquo;. So for QoS=0 the publisher will send the message once and then forget about it. If it does not get delivered, it is lost. For QoS=1, however, the message is sent, and the publisher then waits for a reply from the subscriber before forgetting the message, and resends if neccessary. This ensures that the subscriber gets the message at least once.&lt;br&gt;
Now, there are cases where QoS=0 is sufficient, but for this case we will use QoS=1.&lt;/p&gt;
&lt;h1 id=&#34;connecting-to-aws-iot&#34;&gt;Connecting to AWS IoT&lt;/h1&gt;
&lt;p&gt;Before we can publish a message, we need to set up and configure the connection to AWS IoT. For this, we are going to need many small bits of information. Let us start by setting up the client.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient
# Initialise client
myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First of all, we are giving our client a client ID. This ID is used by the message broker to recognise the specific client or application that it is communicating with. This is especially importtant when we start subscribing to topics as well. For now, we just provide an ID allowed by the policy that we made earlier.&lt;br&gt;&lt;br&gt;
Next up we will setup the networking specifics.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;myAWSIoTMQTTClient.configureEndpoint(host, port)
myAWSIoTMQTTClient.configureCredentials(rootCAPath, privateKeyPath, certificatePath)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are specifying where the MQTT messages are going and how they are authenticated. The host is our AWS IoT custom endpoint which we can find in the AWS Console under IoT Core &amp;gt; Settings. As for the port we will use the default 8883 for MQTT with the X.509 client certificate.&lt;br&gt;&lt;br&gt;
This brings us to the next order of business; certificates. The certificates are the ones we downloaded to our device earlier. We simply provide strings with the paths to each of these certificates; the root certificate file, the private key file, and finally the device certificate file.&lt;br&gt;
Next, we configure what happens when connection between the client and the broker on AWS IoT is lost.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;myAWSIoTMQTTClient.configureAutoReconnectBackoffTime(1, 32, 20)
myAWSIoTMQTTClient.configureOfflinePublishQueueing(-1)  # Infinite offline Publish queueing
myAWSIoTMQTTClient.configureDrainingFrequency(2)  # Draining: 2 Hz
myAWSIoTMQTTClient.configureConnectDisconnectTimeout(10)  # 10 sec
myAWSIoTMQTTClient.configureMQTTOperationTimeout(5)  # 5 sec
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With &lt;code&gt;.configureAutoReconnectBackoffTime(1, 32, 20)&lt;/code&gt; we are telling the client to try to reconnect every 1 seconds after losing connection. If connection keeps being lost, for instance under poor networking conditions, this is exponentially increased to a maximum of every 32 seconds. This is to prevent having too many connection requests which would make the network conditions even worse. If connection is maintained for more than 20 seconds, the reconnect interval is reset to 1.&lt;br&gt;
Next we are telling the client to keep all untransmitted messages while connection is lost by setting &lt;code&gt;.configureOfflinePublishQueueing(-1)&lt;/code&gt;. If any other number is passed, this is the number of messages kept.&lt;br&gt;
When connection is reestablished, we will want to send off any kept messages, but not all at once. With &lt;code&gt;.configureDrainingFrequency(2)&lt;/code&gt; we are telling the client to send one queued message every 2 seconds.&lt;br&gt;
In a moment, we will connect the client, by sending a connect request to the broker on AWS IoT. The client will then expect an acknowledgement of the request, but we do not want to wait forever. &lt;code&gt;.configureConnectDisconnectTimeout(10)&lt;/code&gt; tells the client to wait a maximum of 10 seconds before timing out.&lt;br&gt;
Earlier we decided to use QoS=1. This will only work if the server acknowledges any message sent. If that does not happen we will also want a timeout &lt;code&gt;.configureMQTTOperationTimeout(5)&lt;/code&gt; means that we will wait 5 seconds for that acknowledgement.&lt;br&gt;&lt;br&gt;
Now, all that remains is to attempt the connection.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Connect to AWS IoT
myAWSIoTMQTTClient.connect()
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;bringing-it-all-together&#34;&gt;Bringing it all together&lt;/h1&gt;
&lt;p&gt;Here is our bare-bones script for connecting and publishing to AWS IoT.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTClient
import time

# We will just hardcode the default port here, you might want a different one
port = 8883 # default

# Initialise the AWS IoT MQTT client
myAWSIoTMQTTClient = AWSIoTMQTTClient(clientId)
myAWSIoTMQTTClient.configureEndpoint(host, port)
myAWSIoTMQTTClient.configureCredentials(rootCAPath, privateKeyPath, certificatePath)

# Configure the client
myAWSIoTMQTTClient.configureAutoReconnectBackoffTime(1, 32, 20)
myAWSIoTMQTTClient.configureOfflinePublishQueueing(-1)  # Infinite offline Publish queueing
myAWSIoTMQTTClient.configureDrainingFrequency(2)  # 2 Hz
myAWSIoTMQTTClient.configureConnectDisconnectTimeout(10)  # 10 sec
myAWSIoTMQTTClient.configureMQTTOperationTimeout(5)  # 5 sec

# Connect to AWS IoT
myAWSIoTMQTTClient.connect()
time.sleep(2)

# Publish to the same topic in an eternal loop
loopCount = 0
while True:
    message = {}
    message[&#39;sequence&#39;] = loopCount
    message[&#39;timestamp_utc&#39;] = datetime.utcnow().strftime(&amp;quot;%Y-%m-%dT%H:%M:%S.%fZ&amp;quot;)
    # Value and any other data needed here
    messageJson = json.dumps(message)
    # This is the actual publishing to AWS
    myAWSIoTMQTTClient.publish(topic, messageJson, 1)
    loopCount += 1
    time.sleep(5)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The script &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/simple_publishing.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;simple_publishing.py&lt;/a&gt; is a full working example using the BME680 sensor. It can be called as follows&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python simple_publishing.py -e &amp;lt;your aws iot endpoint&amp;gt; -r &amp;lt;file containing root certificate&amp;gt; -c &amp;lt;file containing device certificate&amp;gt; -k &amp;lt;file containing private key&amp;gt; -id &amp;lt;a client ID&amp;gt; -t &amp;lt;the topic to publish to&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;running-the-case&#34;&gt;Running the Case&lt;/h1&gt;
&lt;p&gt;Running this script on a Pi with the BME680 sensor, when it is working, it should look like this&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Published topic bme680/temperature: {&amp;quot;status&amp;quot;: &amp;quot;success&amp;quot;, &amp;quot;timestamp_utc&amp;quot;: &amp;quot;2020-02-15T16:43:16.226983Z&amp;quot;, &amp;quot;value&amp;quot;: 21.57999999999999, &amp;quot;sequence&amp;quot;: 25}

Published topic bme680/temperature: {&amp;quot;status&amp;quot;: &amp;quot;success&amp;quot;, &amp;quot;timestamp_utc&amp;quot;: &amp;quot;2020-02-15T16:43:17.348050Z&amp;quot;, &amp;quot;value&amp;quot;: 21.57999999999999, &amp;quot;sequence&amp;quot;: 26}

Published topic bme680/temperature: {&amp;quot;status&amp;quot;: &amp;quot;success&amp;quot;, &amp;quot;timestamp_utc&amp;quot;: &amp;quot;2020-02-15T16:43:18.519356Z&amp;quot;, &amp;quot;value&amp;quot;: 21.57999999999999, &amp;quot;sequence&amp;quot;: 27}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But the most interesting part, of course, is whether the data gets to AWS. Let us say that we published to the topic &lt;code&gt;BME680/temperature&lt;/code&gt;. We can open the AWS Console, go to IoT Core, and find the Test tab. Here we can subscribe to a topic. When we type in the topic &lt;code&gt;BME680/temperature&lt;/code&gt;,&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_iot_test_simple_publish.PNG&#34; alt=&#34;iot setup&#34;&gt;
	&lt;br&gt;
&lt;/div&gt;
&lt;p&gt;We get the messages sent from the Pi.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_iot_message_simple_publish.PNG&#34; alt=&#34;iot setup&#34;&gt;
	&lt;br&gt;
&lt;/div&gt;
&lt;p&gt;Congratulations, you are now publishing to AWS IoT! From here the messages can be redirected to whereever you want using AWS SQS, SNS, or Kinesis.&lt;br&gt;&lt;/p&gt;
&lt;h1 id=&#34;in-production&#34;&gt;In Production&lt;/h1&gt;
&lt;p&gt;This section is not part of the demonstration as such. It is but a short discussion of some of the considerations we have to take when bringing an IoT device to production in a manufacturing environment and how to improve upon the example to make it production ready.&lt;/p&gt;
&lt;h2 id=&#34;hardware-setup&#34;&gt;Hardware Setup&lt;/h2&gt;
&lt;p&gt;In real life, would we fire up a Raspberry PI running Python just to extract and publish data from a single sensor? No, probably not. In a real life setting, if we just wanted to publish data from a single sensor, we might use a microcontroller instead. On the other hand, if we are in an industrial setting and have hundreds of sensors that we want to query and publish, a Raspberry Pi will not be enough. Instead we might want to use proper gateway devices and controller modules. There are multiple options and suppliers of this type of hardware components, and which we choose all depends on our specific requirements for ease of installation, configurability, and data quality.&lt;br&gt;
No matter what kind of hardware we have, our gateway device still needs to run some bit of software that gathers and publishes data to consumer applications. Many hardware suppliers also offer proprietary data feeders and even analytics, but now you know how to write your own simple data feeder using the AWS IoT SDK for Python.&lt;/p&gt;
&lt;h2 id=&#34;script-improvement&#34;&gt;Script Improvement&lt;/h2&gt;
&lt;p&gt;The focus for this demonstration was to demonstrate how to quickly get started publishing data to AWS IoT core with no added frills. Whether we use a microcontroller or a large server as our gateway device, we will want a bit more functionality for our script. Here are a few examples of what additional considerations we might take before deploying the device to production.&lt;/p&gt;
&lt;h3 id=&#34;logging&#34;&gt;Logging&lt;/h3&gt;
&lt;p&gt;All sorts of expected and unexpected stuff will happen in production, and it is at least nice to have logs telling us what happened. The AWS IoT SDK actually comes with a &lt;a href=&#34;https://github.com/aws/aws-iot-device-sdk-python/blob/master/samples/basicPubSub/basicPubSub.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sample&lt;/a&gt; script containing an example of logging:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import logging
logger = logging.getLogger(&amp;quot;AWSIoTPythonSDK.core&amp;quot;)
logger.setLevel(logging.DEBUG) # You might want to pass logging level to your script
streamHandler = logging.StreamHandler()
formatter = logging.Formatter(&#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#39;)
streamHandler.setFormatter(formatter)
logger.addHandler(streamHandler)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We would also add logging for the interaction with our sensor(s).&lt;/p&gt;
&lt;h3 id=&#34;error-handling&#34;&gt;Error Handling&lt;/h3&gt;
&lt;p&gt;Besides logging loggging unexpected events, we might also want to automatically handle some of them and avoid crashes that need manual attention. In the example we created above, two parts in particular are susceptible to errors; connecting the MQTT client to AWS and querying the sensor.&lt;br&gt;
The connection might fail for several reasons, but a common one is that multiple devices try to reconnect at the same time after a restart of the process they are monitoring. In this case, nothing is wrong as such, and we can just have the devices retry the connection. We will want to introduce a bit of randomness into that process to avoid creating another bottleneck. An elegant way to implement such retrying is with progressive backoff logic, and the AWS IoT SDK actually includes a module to do just that.&lt;br&gt;
In the example script, whenever we fail to retrieve a value from my BME680 air quality sensor, we just generate a message with a None value. Depending on the specific application, we might want to do something different. In another demonstration, we will have a look at &lt;a href=&#34;../../post/iot-poc-shadow&#34; title=&#34;Shadow demonstration&#34;&gt;implementing a Shadow&lt;/a&gt; for our device. The Shadow can act as an intermediary between the data feed and an application, ensuring that simulations and machine learning models always have the latest readings, while the live data feed contains the full diversity of values and failed readings.&lt;/p&gt;
&lt;h3 id=&#34;remote-configuration&#34;&gt;Remote Configuration&lt;/h3&gt;
&lt;p&gt;One challenge we face when creating new data streams is specifying what data we need and how often we want to sample it. The dilemma is that we do not want to store too much data that will not be used but, on the other hand, to create good simulations or models, we need a good bit of historical data. What strategy to pursue is a business question but it behooves us as developers to allow for flexibility and build dials that allow us to adjust the tradeoff between cost and data quality/quantity. So let us think of an example of this.&lt;br&gt;
At the end of the publishing loop, we tacitly added a line, &lt;code&gt;time.sleep(5)&lt;/code&gt;, that ultimately determines how often we query our sensor and publish the data. If we double that time, we halve the amount of data and potentially also halve our expenses for data storage on this variable. Before the applications are in place, however, it is not really clear how often we would like to sample. We can make an educated guess to get it started but, at the end of the day, we want to be able to change it. So it seems a poor idea to hardcode it like we did for this example. Indeed, for the &lt;a href=&#34;../../post/iot-poc-pubsub&#34; title=&#34;Pulish and subscribe demo&#34;&gt;next demonstration&lt;/a&gt; we will explore how to develop a dynamic device that can be configured remotely.&lt;/p&gt;
&lt;h2 id=&#34;device-lifecycle&#34;&gt;Device Lifecycle&lt;/h2&gt;
&lt;p&gt;During the demonstration, we manually provisioned certificates for our device and started the script from the command line. For production purposes, especially if we have hundreds of devices, we might want to have a more rigid device lifecycle.&lt;/p&gt;
&lt;h3 id=&#34;start-up-and-restarts&#34;&gt;Start up and restarts&lt;/h3&gt;
&lt;p&gt;In a production setting, we will not want to go and restart the script manually each time there is an issue or our device restarts. This obviously becomes more relevant as the number of devices increases. If our gateway device runs Linux, we can just create a custom process to run our data feeder script as a service on boot. For a large fleet of devices we might want to consider introducing some randomness into the intitial connection requests to prevent a situation where all devices attempt to reconnect simultaneously after an outage.&lt;/p&gt;
&lt;h3 id=&#34;certificates-and-security&#34;&gt;Certificates and security&lt;/h3&gt;
&lt;p&gt;It is possible to get &lt;a href=&#34;https://aws.amazon.com/blogs/iot/provisioning-with-a-bootstrap-certificate-in-aws-iot-core/&#34; title=&#34;bootstrap certificate demonstration&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;more advanced&lt;/a&gt; about provisioning certificates for devices. At the very least, we will want to script the provisioning process.&lt;br&gt;
Even when securely provisioned and deployed, it is still important to consider the security of the certificates. The certificates effectively allow some interaction with our AWS account and should an ill intentioned actor acquire access to these certificates they effectly gain free access to that functionality. AWS best practice is to use &lt;a href=&#34;https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html&#34; title=&#34;IAM Best Practices&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;least privilege&lt;/a&gt; policies.&lt;br&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Thing Shadows with AWS IoT</title>
      <link>/post/iot-poc-shadow/</link>
      <pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/post/iot-poc-shadow/</guid>
      <description>&lt;p&gt;On its own, a Thing Shadow might not look like much or even that useful. It certainly is an extra layer of complexity on top of publishing and subscribing. Shadows are, however, the foundation on which we can build Digital Twins and are an almost neccessity for applications that run machine learning models on IoT data.&lt;br&gt;&lt;br&gt;
So what exactly is the Shadow of a thing? In a moment we will dive into the technical details, but we can think of a Shadow as an entity that has the same abilities as a thing, it can send and receive messages, except that it is always an exact copy of the latest state of the thing. If the thing goes offline, the Shadow will still be there reporting the latest state. A Shadow is purely a software construct, there is no hardware, but it can live in the cloud, on the edge, or both.&lt;br&gt;&lt;br&gt;
Before we get started, it should be said that the &lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/iot-device-shadows.html&#34; title=&#34;AWS thing shadow docs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; for Shadows is quite good and definitely worth a read. Instead of repeating the documentation, we will expand on the previous demonstrations of &lt;a href=&#34;../../post/iot-poc-publishing/&#34; title=&#34;Publishing demonstration&#34;&gt;publishing&lt;/a&gt; and &lt;a href=&#34;../../post/iot-poc-pubsub/&#34; title=&#34;pub/sub demonstration&#34;&gt;subscribing&lt;/a&gt; with AWS IoT and MQTT messages, to include a cloud based Shadow of our thing, the BME680 sensor. That is, we will not exemplify all of the Shadow functionality, rather we will get started using Shadows with an example that is as simple in functionality as possible. Once we are done with this case, we will have come far enough to start understanding how advanced functions and applications work.&lt;br&gt;&lt;br&gt;
We will try to do build a thing that does something along the lines of&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Prepare the sensor
Set up connection to AWS
while true
    get a sensor reading
    update the Shadow
    publish the reading
    confirm that the Shadow was updated
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will then look at the Shadow document using the AWS IoT test functionality.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/shadow_architecture.png&#34; alt=&#34;iot setup&#34;&gt;
  Schematic of the architecture we are building in this demonstration.
&lt;/div&gt;
&lt;h1 id=&#34;basics-of-device-shadows&#34;&gt;Basics of Device Shadows&lt;/h1&gt;
&lt;p&gt;The Shadow of a thing is a JSON document containing predetermined fields. All devices registered in AWS IoT are given the Shadow functionality by default, though the JSON is only generated the first time the Shadow is updated. An example of a Shadow document could be&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;state&amp;quot;:{
      &amp;quot;reported&amp;quot;:{
        &amp;quot;value&amp;quot;: 27.87
      }
    },
    &amp;quot;metadata&amp;quot;:{
      &amp;quot;reported&amp;quot;:{
        &amp;quot;value&amp;quot;:{
          &amp;quot;timestamp&amp;quot;:1583755496
        }
      }
    },
    &amp;quot;version&amp;quot;:4,
    &amp;quot;timestamp&amp;quot;:1583755643
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let us walk through each of the fields one at a time.&lt;br&gt;&lt;br&gt;
&lt;code&gt;state&lt;/code&gt; holds the current values of the thing. The &lt;code&gt;reported&lt;/code&gt; field should hold the current values as reported by the device itself. It can hold any number of reporting fields and a field can be an array.&lt;br&gt;
Besides &lt;code&gt;reported&lt;/code&gt; the &lt;code&gt;state&lt;/code&gt; field can also hold a &lt;code&gt;desired&lt;/code&gt; field which can hold desired values as requested by an application or another device. This could be useful if we were doing a case with automation or maybe a home IoT project.&lt;br&gt;&lt;br&gt;
This could be the state of a thing consisting of a valve and a flow meter where an application or maybe a user has just requested a new state:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;state&amp;quot;:{
      &amp;quot;reported&amp;quot;:{
        &amp;quot;flow&amp;quot;: 15.04,
        &amp;quot;valve_state&amp;quot;: &amp;quot;open&amp;quot;
      },
      &amp;quot;desired&amp;quot;:{
          &amp;quot;flow&amp;quot;: 0,
          &amp;quot;valve_state&amp;quot;: &amp;quot;closed&amp;quot;
      }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will not use the desired field for this demonstration. We will just report the latest temperature of our Thing like this&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;state&amp;quot;:{
      &amp;quot;reported&amp;quot;: { &amp;quot;temperature&amp;quot; : 21.6 }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;metadata&lt;/code&gt; field holds information on when each of the values in the &lt;code&gt;state&lt;/code&gt; field were updated. The field follows the same schema as &lt;code&gt;state&lt;/code&gt; and the information is given as a UTC timestamp, representing when the value was last updated.&lt;br&gt;&lt;br&gt;
The &lt;code&gt;version&lt;/code&gt; field is a super useful feature. It is an integer that increases every time an update is made to the document, allowing applications and devices to know whether their local copy is the latest.&lt;br&gt;&lt;br&gt;
The &lt;code&gt;timestamp&lt;/code&gt; field indicates the UTC timestamp of when the update was transmitted from AWS IoT.&lt;br&gt;&lt;br&gt;
Fields that are set to &lt;code&gt;Null&lt;/code&gt; are deleted from the Shadow document rather than reporting the &lt;code&gt;Null&lt;/code&gt;.&lt;br&gt;&lt;br&gt;
There are few additional features in Shadow document and they are neatly described in the &lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/device-shadow-document.html&#34; title=&#34;Shadow document developer guide&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;developer guide&lt;/a&gt;. For now, we have all we need to get started.&lt;/p&gt;
&lt;h2 id=&#34;update-a-device-shadow&#34;&gt;Update a Device Shadow&lt;/h2&gt;
&lt;p&gt;Updating the Shadow of a device is done by sending a message to a specific topic. The topic is in the format &lt;code&gt;$aws/things/yourDevice/shadow/update&lt;/code&gt; and depends on the name of the device registered in AWS IoT. If our device was called &amp;lsquo;factory3Airflow&amp;rsquo; then the topic would be &lt;code&gt;$aws/things/factory3Airflow/shadow/update&lt;/code&gt;.&lt;br&gt;
The update message might look something like this&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;state&amp;quot;: {
        &amp;quot;reported&amp;quot;: {
            &amp;quot;flow&amp;quot;: 2.6
        }
    }
} 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Coding such a flow is quite similar to what we did for &lt;a href=&#34;../../post/iot-poc-publishing/&#34; title=&#34;publishing case&#34;&gt;publishing&lt;/a&gt;, except the topic is a bit more elaborate. Assuming that the client ID is the same as the device name, we can configure a connection and start updating the Shadow like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define neccessary topics
topic_update = &amp;quot;$aws/things/&amp;quot; + clientId + &amp;quot;/shadow/update&amp;quot;

# Configure connection to AWS IoT
# ...

# Keep updating the Shadow on an infinite loop
while True:
    message = {}
    temperature = get_sensor_reading()
    message[&amp;quot;state&amp;quot;] = { &amp;quot;reported&amp;quot; : {&amp;quot;temperature&amp;quot; : temperature } }
    messageJson = json.dumps(message)
    # Update the Shadow
    myAWSIoTMQTTClient.publish(topic_update, messageJson, 1)
    time.sleep(30)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is fine and all but how do we know that it works?&lt;/p&gt;
&lt;h2 id=&#34;subscribing-to-shadow-updates&#34;&gt;Subscribing to Shadow Updates&lt;/h2&gt;
&lt;p&gt;Whenever a Shadow is successfully updated, it generates and publishes a message to the topic &lt;code&gt;$aws/things/yourDevice/shadow/update/accepted&lt;/code&gt;. Once again, the exact name changes based on our device name. By subscribing to this specific topic with QoS = 1, our device or application can recieve updates whenever there are changes to the Shadow.&lt;br&gt;&lt;br&gt;
Another useful topic to subscribe to is &lt;code&gt;$aws/things/yourDevice/shadow/update/rejected&lt;/code&gt;. A message is published to this topic whenever an update fails and can thus provide excellent feedback for an application or for debugging.&lt;br&gt;&lt;br&gt;
We can subscribe to these topics just like we would any other topics. Again assuming that the client ID is identical to the device name, it might look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define neccessary topics
topic_update = &amp;quot;$aws/things/&amp;quot; + clientId + &amp;quot;/shadow/update&amp;quot;

# Configure connection to AWS IoT
# ...

# Specify what to do, when we receive an update
def callback_update_accecpted(client, userdata, message):
    # Just print the message
    print(&amp;quot;Got an update, on the topic:&amp;quot;)
    print(message.topic)
    print(&amp;quot;The message is this&amp;quot;)
    print(message.payload)

# Specify what to do, when the update is rejected
def callback_update_rejected(client, userdata, message):
    # Just print the message
    print(&amp;quot;The update was rejected. Received the following message:&amp;quot;)
    print(message.payload)

# Subscribe
myAWSIoTMQTTClient.subscribe(topic_update + &amp;quot;/accepted&amp;quot;, 1, callback_update_accepted)
myAWSIoTMQTTClient.subscribe(topic_update + &amp;quot;/rejected&amp;quot;, 1, callback_update_rejected)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;policies-for-shadows&#34;&gt;Policies for Shadows&lt;/h2&gt;
&lt;p&gt;Before we move on to more Shadow related topics, we should take a look at the policies needed to allow devices and applications to utilise these special topics. Once again, the documentation is quite substantial and even provides &lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/device-shadow-mqtt.html&#34; title=&#34;Shadow policy examples&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;specific examples&lt;/a&gt; for policies related to Shadow interaction. Here we will focus on constructing an example.&lt;br&gt;&lt;br&gt;
Imagine we have a device registered with the name &lt;code&gt;my_sensor&lt;/code&gt; in AWS IoT. We would like to give the device access to establish a connection with AWS IoT, publish readings to the topic &lt;code&gt;my_sensor/reading&lt;/code&gt;, update its Shadow, and subscribe to the accepted and rejected responses generated on Shadow update.&lt;br&gt;
We already know how to construct statements to allow connection and publishing.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;Statement&amp;quot;: [
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [ &amp;quot;iot:Publish&amp;quot; ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/my_sensor/reading&amp;quot;
      ]
    },
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [ &amp;quot;iot:Connect&amp;quot; ],
      &amp;quot;Resource&amp;quot;: [ 
        &amp;quot;arn:aws:iot:your-region:your-aws-account:client/my_sensor&amp;quot; 
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To allow the desired Shadow interactions, we will add another resource to the publish action, mentioning the topic &lt;code&gt;$aws/things/my_sensor/shadow/update&lt;/code&gt;:&lt;br&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;Statement&amp;quot;: [
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [ &amp;quot;iot:Publish&amp;quot; ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/my_sensor/reading&amp;quot;,
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update&amp;quot;
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To allow subscription we will add subscription and receive actions for two resources - one for each topic.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;Statement&amp;quot;: [
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [ &amp;quot;iot:Subscribe&amp;quot; ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topicfilter/$aws/things/my_sensor/shadow/update/accepted&amp;quot;,
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topicfilter/$aws/things/my_sensor/shadow/update/rejected&amp;quot;
      ]
    },
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [ &amp;quot;iot:Receive&amp;quot; ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update/accepted&amp;quot;,
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update/rejected&amp;quot;
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Given that the two subscription topics have the same root and that there are more &lt;code&gt;update/&lt;/code&gt; topics to subsrcibe to, it is tempting to add something along the lines of &lt;code&gt;$aws/things/my_sensor/shadow/update/*&lt;/code&gt;, giving a wildcard for anything below the update root. While this would indeed work as intended now, AWS reserves the right to add additional reserved topics to the existing structure. If we were to use a policy with this type of wildcard, we thus risk allowing access to future topics causing unintended behaviour or information breaches. Therefore AWS discourages the use of wildcards in this way.&lt;br&gt;
Our final policy looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
  &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
  &amp;quot;Statement&amp;quot;: [
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [ &amp;quot;iot:Publish&amp;quot; ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/my_sensor/reading&amp;quot;,
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update&amp;quot;
      ]
    },
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [ &amp;quot;iot:Connect&amp;quot; ],
      &amp;quot;Resource&amp;quot;: [ 
        &amp;quot;arn:aws:iot:your-region:your-aws-account:client/my_sensor&amp;quot; 
      ]
    },
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [ &amp;quot;iot:Subscribe&amp;quot; ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topicfilter/$aws/things/my_sensor/shadow/update/accepted&amp;quot;,
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topicfilter/$aws/things/my_sensor/shadow/update/rejected&amp;quot;
      ]
    },
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [ &amp;quot;iot:Receive&amp;quot; ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update/accepted&amp;quot;,
        &amp;quot;arn:aws:iot:your-region:your-aws-account:topic/$aws/things/my_sensor/shadow/update/rejected&amp;quot;
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;simple-shadow-updating&#34;&gt;Simple Shadow Updating&lt;/h1&gt;
&lt;p&gt;Now we have everything we need to build a full demonstration of Shadow interaction. We know that we can structure the interaction in exactly the same way as with regular publishing and subscribing but with two key differences. The first is that we will publish and subscribe to the specific Shadow topics. The second is that our published message follows the Shadow document schema. Here is an example; We can have our callback functions do whatever we want, but I just wrote out some simple print statements:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define topic for updates
topic_update = &amp;quot;$aws/things/&amp;quot; + clientId + &amp;quot;/shadow/update&amp;quot;

# Configure connection to AWS IoT
# ...

# Specify what to do, when we receive an update
def callback_update_accepted(client, userdata, message):
    # Just print the message
    print(&amp;quot;Got an update, on the topic:&amp;quot;)
    print(str(message.topic))
    print(&amp;quot;The message is this&amp;quot;)
    print(str(message.payload))

# Specify what to do, when the update is rejected
def callback_update_rejected(client, userdata, message):
    # Just print the message
    print(&amp;quot;The update was rejected. Received the following message:&amp;quot;)
    print(str(message.payload))

# Subscribe
myAWSIoTMQTTClient.subscribe(topic_update + &amp;quot;/accepted&amp;quot;, 1, callback_update_accepted)
time.sleep(2)
myAWSIoTMQTTClient.subscribe(topic_update + &amp;quot;/rejected&amp;quot;, 1, callback_update_rejected)
time.sleep(2)
# Publish to the same topic in a loop forever
while True:    
    message = {}
    if sensor.get_sensor_data():
        temperature = sensor.data.temperature
    else:
        temperature = None
    message[&amp;quot;state&amp;quot;] = { &amp;quot;reported&amp;quot; : {&amp;quot;temperature&amp;quot; : temperature } }
    messageJson = json.dumps(message)
    # Update the Shadow
    myAWSIoTMQTTClient.publish(topic_update, messageJson, 1)
    time.sleep(15)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The full working script is &lt;a href=&#34;https://github.com/AnHosu/iot_poc/blob/master/example_scripts/shadow.py&#34; title=&#34;Shadow example&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. Remember that the clientID is assumed to be the name of the thing. We could register a thing called &lt;code&gt;my_sensor&lt;/code&gt; in AWS IoT and give its certificate a policy like the one we developed above. Then we can run this script on our Raspberry Pi with the BME680 sensor. Like this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python3 shadow.py -e &amp;lt;your aws iot endpoint&amp;gt; -r &amp;lt;file containing root certificate&amp;gt; -c &amp;lt;file containing device certificate&amp;gt; -k &amp;lt;file containing private key&amp;gt; -id &amp;lt;a client ID&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this, we are publishing the latest sensor readings directly to the Shadow and then regurgitating the message generated when the update is accepted or rejected. When it works, the output should look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Got an update, on the topic:
$aws/things/my_sensor/shadow/update/accepted
The message is this
b&#39;{&amp;quot;state&amp;quot;:{&amp;quot;reported&amp;quot;:{&amp;quot;temperature&amp;quot;:35.48}},&amp;quot;metadata&amp;quot;:{&amp;quot;reported&amp;quot;:{&amp;quot;temperature&amp;quot;:{&amp;quot;timestamp&amp;quot;:1584104617}}},&amp;quot;version&amp;quot;:99,&amp;quot;timestamp&amp;quot;:1584104617}&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If your setup is not working, make sure to check exactly which component is failing. If you are getting errors in the connection part, check whether your keys are for the right certificate and whether the certificate is activated. If you are getting an error in the subscription or publishing parts, check whether your policy gives the right accesses. Finally, you should not get any messages on the &lt;code&gt;/update/rejected&lt;/code&gt; subject. If you do, one possible reason is that the message follows a wrong format.&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;h1 id=&#34;more-shadow-topics&#34;&gt;More Shadow Topics&lt;/h1&gt;
&lt;p&gt;Congratulations! You now know how to set up a Shadow for your device and you are ready to start building the foundation for your digital twin application. There are, however, a couple of extra details that you might want to know about before you start building the application.&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;get-the-shadow&#34;&gt;Get the Shadow&lt;/h2&gt;
&lt;p&gt;If our application just listens to the &lt;code&gt;/update/accepted&lt;/code&gt; we will have achieved nothing more by going through the Shadow compared to just plain publishing. The real power of Shadows is in always having the latest reading from our device available, while decoupling the device and the application.&lt;br&gt;
Now that we are having the device update its Shadow each time a new reading is available, we can start having our application access that Shadow document whenever it needs it. We can always view the Shadow document of our thing by going to AWS IoT &amp;gt; Manage &amp;gt; Things, then selecting our device and go to the &amp;lsquo;Shadow&amp;rsquo; tab&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_shadow_document.png&#34; alt=&#34;Shadow document&#34;&gt;
&lt;/div&gt;
&lt;p&gt;This is nice for demonstration and debugging purposes, but our application needs to access the document programatically. The MQTT protocol does not do requests, and operates using the publish and subscribe model only. So the way for our application to request the Shadow document on demand is to publish a request to a specific topic and subscribe to a response topic. Note that there is an alternative based on a REST API, which we will discuss in a &lt;a href=&#34;shadow.md#in-production&#34;&gt;section&lt;/a&gt; below, but for now we will stick to the MQTT way.
By sending an empty request, &lt;code&gt;{}&lt;/code&gt;, to the topic &lt;code&gt;$aws/things/yourDevice/shadow/get&lt;/code&gt; our application can trigger the Shadow to publish a copy of the current Shadow document to the subject &lt;code&gt;$aws/things/yourDevice/shadow/get/accepted&lt;/code&gt;. The easiest way to see it in action is by subscribing to the &lt;code&gt;$aws/things/yourDevice/shadow/get/#&lt;/code&gt; topicfilter in the test console and then publish an empty message to &lt;code&gt;/get&lt;/code&gt;. I gave it a try here&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_shadow_get.png&#34; alt=&#34;Shadow get&#34;&gt;
&lt;/div&gt;
&lt;p&gt;This is also an excellent opportunity to explore what happens, when we do something unexpected. Here I published a string instead of a JSON, for instance:&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_shadow_get_rejected.png&#34; alt=&#34;Shadow get&#34;&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;/get&lt;/code&gt; topic also has a &lt;code&gt;/rejected&lt;/code&gt; subtopic that gives helpful error messages when requests are rejected.&lt;/p&gt;
&lt;h2 id=&#34;delete-the-shadow&#34;&gt;Delete the Shadow&lt;/h2&gt;
&lt;p&gt;We now know how to update and get the Shadow document. Now we just need to know how to delete it. By publishing an empty message to the topic &lt;code&gt;$aws/things/yourDevice/shadow/delete&lt;/code&gt; we delete the Shadow document for &lt;code&gt;yourDevice&lt;/code&gt;. On successful deletion, a confirmation is published to &lt;code&gt;/delete/accepted&lt;/code&gt; and a message is published to &lt;code&gt;/delete/rejected&lt;/code&gt; otherwise. Let us try to delete the Shadow, then try to get it, and see what happens:&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_shadow_delete.png&#34; alt=&#34;shadow delete&#34;&gt;
&lt;/div&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/aws_shadow_delete_get.png&#34; alt=&#34;shadow delete get&#34;&gt;
&lt;/div&gt;
&lt;p&gt;We get an error message because there is no Shadow document to get.&lt;/p&gt;
&lt;h2 id=&#34;shadow-mqtt-topics-summary&#34;&gt;Shadow MQTT Topics Summary&lt;/h2&gt;
&lt;p&gt;In summary, all Shadow interaction topics are prefixed with &lt;code&gt;$aws/things/yourDevice/shadow&lt;/code&gt; where &lt;code&gt;yourDevice&lt;/code&gt; is the ID of our thing as registered in AWS IoT. We interact with the Shadow in three ways: we can update the Shadow, get the Shadow, or delete the Shadow. These functions are triggered when messages are published to the topics &lt;code&gt;/update&lt;/code&gt;, &lt;code&gt;/get&lt;/code&gt;, or &lt;code&gt;/delete&lt;/code&gt; repectively. When the actions succeed, messages are published to the &lt;code&gt;/accepted&lt;/code&gt; subtopic. When the actions fail, messages are published to the &lt;code&gt;/rejected&lt;/code&gt; subtopic with useful information for debugging.&lt;br&gt;
Not covered in this demonstration are the &lt;code&gt;/update/document&lt;/code&gt; and &lt;code&gt;/update/delta&lt;/code&gt; topics. The &lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/device-shadow-mqtt.html&#34; title=&#34;Shadow interaction docs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;docs&lt;/a&gt; have more about Shadow interaction topics along with sample example policies.&lt;/p&gt;
&lt;h2 id=&#34;the-shadow-client&#34;&gt;The Shadow Client&lt;/h2&gt;
&lt;p&gt;Depending on the apllication and how we manage topics, it might be easier to use the special Shadow client that is included in the SDK. The Shadow client, once configured, takes care of publishing and subscribing to the right topics. That is, it does exactly what we did above but with fewer lines of code and without us having to state the topics explicitly.&lt;br&gt;
The client is configured and connected like any other MQTT client:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from AWSIoTPythonSDK.MQTTLib import AWSIoTMQTTShadowClient

myAWSIoTMQTTShadowClient = AWSIoTMQTTShadowClient(clientId)
myAWSIoTMQTTShadowClient.configureEndpoint(host, port)
myAWSIoTMQTTShadowClient.configureCredentials(rootCAPath, privateKeyPath, certificatePath)
myAWSIoTMQTTShadowClient.configureAutoReconnectBackoffTime(1, 32, 20)
myAWSIoTMQTTShadowClient.configureConnectDisconnectTimeout(10)
myAWSIoTMQTTShadowClient.configureMQTTOperationTimeout(5)
myAWSIoTMQTTShadowClient.connect()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we create a handler, that takes care of the publishing and subscribing. All we have to do is pass it the name of the Thing, which we will assume is the same as the client ID:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Handles publishing and subscribing to Shadow topics
# Persists subscription
deviceShadowHandler = myAWSIoTMQTTShadowClient.createShadowHandlerWithName(clientID, True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The handler will subscribe to the response topics from the Shadow. By setting the second argument to True, we are telling the handler to persist the subscription, i.e. not close the subscription when a response is received. Depending on the application, it might be neccessary to close the subscription once a response is received. But since we only have one client interacting with the Shadow in our case, we can safely persist the subscription and avoid resubscribing every time we send an update.&lt;br&gt;
As with every other subscription, we need to tell the client what to do when a message is received with a callback function. The callback function is provided to the handler when we perform an update, but before we get there we need to actually define a function. The callback function for a Shadow client looks a bit different from the callback functions we saw for regular subscribing. It has a &lt;code&gt;payload&lt;/code&gt; object, which contains the Shadow document, assuming that the update is accepted. It then has a &lt;code&gt;responseStatus&lt;/code&gt; string, which can be either &lt;code&gt;&amp;quot;timeout&amp;quot;&lt;/code&gt;, &lt;code&gt;&amp;quot;accepted&amp;quot;&lt;/code&gt;, or &lt;code&gt;&amp;quot;rejected&amp;quot;&lt;/code&gt; depending on how the update event went. Finally there is a &lt;code&gt;token&lt;/code&gt; which can be used to trace the request, but we will not discuss it here. Here is an example of a callback function for an update request.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import json

def shadow_callback_update(payload, responseStatus, token):
    if responseStatus == &amp;quot;timeout&amp;quot;:
        print(&amp;quot;The update request timed out.&amp;quot;)
    if responseStatus == &amp;quot;accepted&amp;quot;:
        payloadDict = json.loads(payload)
        print(&amp;quot;The update request was accepted, here is the new state:&amp;quot;)
        print(payloadDict[&amp;quot;state&amp;quot;])
    if responseStatus == &amp;quot;rejected&amp;quot;:
        print(&amp;quot;The update request was rejected.&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we can start updating the Shadow. The message still has to follow the Shadow document syntax:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;while true:
    message = {}
    temperature = get_temperature() # Dummy function
    message[&amp;quot;state&amp;quot;] = { &amp;quot;reported&amp;quot; : {&amp;quot;temperature&amp;quot; : temperature } }
    deviceShadowHandler.shadowUpdate(json.dumps(message), shadow_callback_update, 6)
    time.sleep(5)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will send an update to the reported temperature state of the Shadow document. The handler will time out after six seconds, as specified in the third argument. The handler will then wait for the response and invoke the callback function once a response is received.&lt;/p&gt;
&lt;h1 id=&#34;in-production&#34;&gt;In Production&lt;/h1&gt;
&lt;p&gt;This section is not part of the demonstration as such. It is but a short discussion of some of the considerations we might take when bringing the Shadow feature into production. There are not many addtional considerations besides those discussed for &lt;a href=&#34;../../post/iot-poc-publishing/#in-production&#34;&gt;publishing&lt;/a&gt; and &lt;a href=&#34;../../post/iot-poc-pubsub/#in-production&#34;&gt;subscribing&lt;/a&gt;, but here are some of them.&lt;/p&gt;
&lt;h2 id=&#34;decouple-application-and-data-stream&#34;&gt;Decouple Application and Data Stream&lt;/h2&gt;
&lt;p&gt;In order for Shadows to be a boon and not just an added operational burden, it is important that we develop applications that utilise it properly. An example of an application that might benefit greatly from using Shadows is one that relies on machine learning models to predict outcomes for displaying or acting on. A machine learning algorithm needs all its features at the same time to produce a prediction, whereas the physical reality of our sensing equipment is that different features are reported at differing times and at different frequencies. Instead of having a large layer of business logic in front of the machine learning algorithm, the application could just serve the latest values as stored in the Shadow. This effectively decouples the data stream and the machine learning model, ensuring that our application can keep running even if a device is broken.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
	&lt;img width=500 src=&#34;../../project/iot-poc/images/shadow_flow.png&#34; alt=&#34;iot setup&#34;&gt;
  This is a general view of how a Shadow could fit into the larger IoT.
&lt;/div&gt;
&lt;h2 id=&#34;shadow-http-interactions&#34;&gt;Shadow HTTP Interactions&lt;/h2&gt;
&lt;p&gt;Chances are that we do not want our application to deal with the MQTT protocol. The publish subscribe model works well for the IoT part where data is flowing to and from multiple sources to multiple targets. Our application, however, often just needs the latest piece of data, and it is a bit of hassle to deal with an MQTT client, publishing, and subscribing just to get a single piece of data once in a while.&lt;br&gt;
One of the major advantages of the Shadow functionality is that each Shadow exposes a &lt;a href=&#34;https://docs.aws.amazon.com/iot/latest/developerguide/device-shadow-rest-api.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;REST API&lt;/a&gt; to which we can send regular HTTP requests and retrieve data.&lt;br&gt;
The API is exposed at&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://endpoint/things/yourDevice/shadow
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where the &lt;code&gt;endpoint&lt;/code&gt; is our custom AWS IoT endpoint and &lt;code&gt;yourDevice&lt;/code&gt; is the name of our Thing as registered in AWS IoT. We can send regular Get, Update, and Delete HTTP requests to this endpoint and get, update, or delete the Shadow correspondingly. Note though that the entity sending the requests must have permissions to do so. This can be achieved with an IAM user with proper policies.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
