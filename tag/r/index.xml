<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R | anders e</title>
    <link>/tag/r/</link>
      <atom:link href="/tag/r/index.xml" rel="self" type="application/rss+xml" />
    <description>R</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2023 Anders E. Nielsen</copyright><lastBuildDate>Fri, 16 Jun 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hu0b500a15011e1e483635372eebf6e1df_24681_512x512_fill_lanczos_center_3.png</url>
      <title>R</title>
      <link>/tag/r/</link>
    </image>
    
    <item>
      <title>Initial Designs for Bayesian Optimisation</title>
      <link>/post/initial-designs-r/</link>
      <pubDate>Fri, 16 Jun 2023 00:00:00 +0000</pubDate>
      <guid>/post/initial-designs-r/</guid>
      <description>&lt;!DOCTYPE html&gt;
&lt;html xmlns=&#34;http://www.w3.org/1999/xhtml&#34; lang=&#34;&#34; xml:lang=&#34;&#34;&gt;&lt;head&gt;
  &lt;meta charset=&#34;utf-8&#34;&gt;
  &lt;meta name=&#34;generator&#34; content=&#34;quarto-0.2.243&#34;&gt;
  &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0, user-scalable=yes&#34;&gt;
  &lt;title&gt;index&lt;/title&gt;
  &lt;style&gt;
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre &gt; code.sourceCode { white-space: pre; position: relative; }
    pre &gt; code.sourceCode &gt; span { display: inline-block; line-height: 1.25; }
    pre &gt; code.sourceCode &gt; span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode &gt; span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre &gt; code.sourceCode { white-space: pre-wrap; }
    pre &gt; code.sourceCode &gt; span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code &gt; span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code &gt; span &gt; a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre &gt; code.sourceCode &gt; span &gt; a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  &lt;/style&gt;

  &lt;script src=&#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js&#34;&gt;&lt;/script&gt;
  &lt;script&gt;document.addEventListener(&#34;DOMContentLoaded&#34;, function () {
   var mathElements = document.getElementsByClassName(&#34;math&#34;);
   var macros = [];
   for (var i = 0; i &lt; mathElements.length; i++) {
    var texText = mathElements[i].firstChild;
    if (mathElements[i].tagName == &#34;SPAN&#34;) {
     katex.render(texText.data, mathElements[i], {
      displayMode: mathElements[i].classList.contains(&#39;display&#39;),
      throwOnError: false,
      macros: macros,
      fleqn: false
     });
  }}});
  &lt;/script&gt;
  &lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css&#34;&gt;
  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&#34;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&#34;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
  &lt;script src=&#34;index_files/libs/clipboard/clipboard.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tabby.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/popper.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tippy.umd.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/anchor.min.js&#34;&gt;&lt;/script&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/tippy.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/light-border.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-html.min.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-syntax-highlighting.css&#34; rel=&#34;stylesheet&#34;&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;&lt;a href=&#34;../bayes-opt-r&#34;&gt;Bayesian optimisation&lt;/a&gt; is a powerful optimisation technique for black-box functions and processes with expensive evaluations. It is popular for hyperparameter tuning in machine learning, but has many real-world applications as well.&lt;/p&gt;
&lt;p&gt;One of the key components of Bayesian optimisation is the initial experiment design, which forms the foundation for the first fit of the surrogate model. In this post, we will discuss the importance of initial experiment designs in Bayesian optimisation and dive into a few different ways to sample such initial designs.&lt;/p&gt;
&lt;p&gt;Along with the discussion are example implementations in R.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(ggplot2)&lt;/span&gt;
&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(magrittr)&lt;/span&gt;
&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;set.seed&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;4444&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;initial-experiment-designs&#34; class=&#34;anchored&#34;&gt;Initial Experiment Designs&lt;/h2&gt;
&lt;p&gt;Bayesian optimisation works by constructing a surrogate probabilistic model, typically a Gaussian process, of the objective function. The surrogate model is then used to guide the search for an optimum through sequential experimentation. The initial experiment design influences this process in two major ways: it provides initial data points for fitting the surrogate model and it is the initial trade off between exploration and exploitation.&lt;/p&gt;
&lt;p&gt;In the initial design, we decide on a set of &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; samples &lt;span class=&#34;math inline&#34;&gt;\mathbf{X} = \{\mathbf{x}_1, \dots, \mathbf{x}_n\}&lt;/span&gt;. Each point, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt;, is somewhere in the search space, &lt;span class=&#34;math inline&#34;&gt;\mathcal{X} \in \mathbb{R}^d&lt;/span&gt;, with dimensionality &lt;span class=&#34;math inline&#34;&gt;d&lt;/span&gt;. Ideally, we want to restrict the optimisation to a subset of &lt;span class=&#34;math inline&#34;&gt;\mathbb{R}^d&lt;/span&gt; and the initial design can help achieve that by keeping the samples within a realistic range. For the base designs discussed here, the search space &lt;span class=&#34;math inline&#34;&gt;\mathcal{X} = [0,1]^d&lt;/span&gt; is assumed. It is a good idea to normalise the input dimensions, but when normalised inputs are not an option, the range &lt;span class=&#34;math inline&#34;&gt;[0,1]&lt;/span&gt; can easily be scaled to a broader range, as discussed later.&lt;/p&gt;
&lt;p&gt;Considering that the experimental budget is limited and that it is expensive to evaluate the objective function, the number of initial training samples should be limited. However, considering that the surrogate models generally are not great for extrapolation, the number of initial samples should not be too small either.&lt;/p&gt;
&lt;p&gt;In general, the initial training data should be chosen to provide a good representation of the objective function. This means that the data should be chosen to cover the range of each input dimension. The data should also include inputs that are expected to be both good and bad performers.&lt;/p&gt;
&lt;p&gt;An initial design might not always be necessary. If the Gaussian process was defined with a very strong prior, then it could be applied to generate experiments right away. For some processes, historical data might be available to get the experimentation started. Previous experience, experiments, or datasets might also be useful for initialising Bayesian optimisation &lt;span class=&#34;citation&#34; data-cites=&#34;Feurer2015&#34;&gt;[1]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Most often though, we do not really know where to start. At best, we might have a vague idea of the general effect of our input features on the measured output. In these cases, we can apply a design, so let’s look at some examples.&lt;/p&gt;
&lt;h4 id=&#34;an-example-case&#34; class=&#34;anchored&#34;&gt;An Example Case&lt;/h4&gt;
&lt;p&gt;To demonstrate each design, we imagine a situation where we are doing Bayesian optimisation on an objective process with two input dimensions. We have decided that we want to take 10 initial samples.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# 2D design with 10 samples&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;d &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We also define a simple plot to visualise the design.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;plot_design &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(samples, &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;data.frame&lt;/span&gt;(samples) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X1, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; X2), &lt;span class=&#34;at&#34;&gt;size =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-5&#34;&gt;&lt;a href=&#34;#cb3-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-6&#34;&gt;&lt;a href=&#34;#cb3-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb3-7&#34;&gt;&lt;a href=&#34;#cb3-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; title,&lt;/span&gt;
&lt;span id=&#34;cb3-8&#34;&gt;&lt;a href=&#34;#cb3-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Dimension 1&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb3-9&#34;&gt;&lt;a href=&#34;#cb3-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Dimension 2&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-10&#34;&gt;&lt;a href=&#34;#cb3-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb3-11&#34;&gt;&lt;a href=&#34;#cb3-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now we are ready to look at our first design.&lt;/p&gt;
&lt;h2 id=&#34;random-sampling&#34; class=&#34;anchored&#34;&gt;Random Sampling&lt;/h2&gt;
&lt;p&gt;The first, and arguably most simple, example of an initial design is Random Sampling. As the name suggests this design is completely random. Each dimension for each point is simply sampled from the uniform distribution &lt;span class=&#34;citation&#34; data-cites=&#34;McKay1979&#34;&gt;[2]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{x} \sim \text{Unif}(0, 1)&lt;/span&gt; The implementation is just a single line:&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;random_sampling &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(n, d) &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;runif&lt;/span&gt;(n &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; d), n, d)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Random sampling represents a focus on exploration in the face of uncertainty. The main advantage of the random design is its ease of implementation, but it is also important to note that it is trivial to add additional samples to this design. The main drawback is that it is not guaranteed to efficiently sample the search space - there is a chance of points with close proximity, which is a waste we usually cannot afford in Bayesian optimisation. A Latin Hypercube Design can remedy this drawback.&lt;/p&gt;
&lt;h4 id=&#34;random-sampling-in-2d&#34; class=&#34;anchored&#34;&gt;Random Sampling in 2D&lt;/h4&gt;
&lt;p&gt;Here is a random sampling design for our imagined case.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;random_sampling&lt;/span&gt;(n, d)&lt;/span&gt;
&lt;span id=&#34;cb5-2&#34;&gt;&lt;a href=&#34;#cb5-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_design&lt;/span&gt;(samples, &lt;span class=&#34;st&#34;&gt;&#34;Random Sampling&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/random_sampling-1.png&#34; width=&#34;576&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The main thing to notice is the clusters of points and large swaths of empty space. This seems a bit wasteful, when each evaluation of the objective function is expensive.&lt;/p&gt;
&lt;h2 id=&#34;latin-hypercube-sampling&#34; class=&#34;anchored&#34;&gt;Latin Hypercube Sampling&lt;/h2&gt;
&lt;p&gt;Latin Hypercube Sampling (LHS) is a stratified sampling technique that ensures a balanced distribution of samples across the search space. The key idea behind LHS is to divide each dimension of the search space into equally sized intervals and randomly sample one point from each interval. LHS still samples each point from a uniform distribution, but restricts the intervals for each point &lt;span class=&#34;citation&#34; data-cites=&#34;McKay1979&#34;&gt;[2]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Given a search space with &lt;span class=&#34;math inline&#34;&gt;d&lt;/span&gt; dimensions or features, we want to sample &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; points, such that they satisfy a Latin Hypercube of evenly spaced intervals.&lt;/p&gt;
&lt;p&gt;We do this by dividing each dimension into &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; equally spaced intervals. Then, for each dimension, we sample a random permutation of the numbers &lt;span class=&#34;math inline&#34;&gt;1, ..., n&lt;/span&gt; and the resulting sequence determines which interval of that dimension is sampled for each of the &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; samples. This ensures that each interval in each dimension is sampled exactly once. Finally a sample is drawn from each of the chosen intervals.&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;x_{j,i}&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;j = 1, ..., n&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;i = 1, ..., d&lt;/span&gt; be the &lt;span class=&#34;math inline&#34;&gt;i^{\text{th}}&lt;/span&gt; dimension of the &lt;span class=&#34;math inline&#34;&gt;j^{\text{th}}&lt;/span&gt; sample. Let &lt;span class=&#34;math inline&#34;&gt;\mathbf{\pi}_i&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;i = 1, ..., d&lt;/span&gt; be &lt;span class=&#34;math inline&#34;&gt;d&lt;/span&gt; independent random permutations of the numbers &lt;span class=&#34;math inline&#34;&gt;\{1,...,n\}&lt;/span&gt;, then&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{x}_{i,:} = \frac{\mathbf{\pi}_i - 1 + \mathbf{\nu}_i}{n}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{i,:}&lt;/span&gt; is the &lt;span class=&#34;math inline&#34;&gt;i^{\text{th}}&lt;/span&gt; dimension of all samples, and&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{\nu}_i \sim \text{Unif}(0, 1)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here is an implementation of LHS:&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Latin Hypercube Sampling&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-2&#34;&gt;&lt;a href=&#34;#cb6-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-3&#34;&gt;&lt;a href=&#34;#cb6-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param n &amp;lt;int&amp;gt; number of samples&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-4&#34;&gt;&lt;a href=&#34;#cb6-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param d &amp;lt;int&amp;gt; number of features&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-5&#34;&gt;&lt;a href=&#34;#cb6-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-6&#34;&gt;&lt;a href=&#34;#cb6-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return matrix of shape (n,d)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-7&#34;&gt;&lt;a href=&#34;#cb6-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;latin_hypercube_sampling &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(n, d) {&lt;/span&gt;
&lt;span id=&#34;cb6-8&#34;&gt;&lt;a href=&#34;#cb6-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;nrow =&lt;/span&gt; n, &lt;span class=&#34;at&#34;&gt;ncol =&lt;/span&gt; d)&lt;/span&gt;
&lt;span id=&#34;cb6-9&#34;&gt;&lt;a href=&#34;#cb6-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;for&lt;/span&gt; (i &lt;span class=&#34;cf&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;d) samples[, i] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;sample&lt;/span&gt;(n) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;runif&lt;/span&gt;(n)&lt;/span&gt;
&lt;span id=&#34;cb6-10&#34;&gt;&lt;a href=&#34;#cb6-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  (samples &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; n&lt;/span&gt;
&lt;span id=&#34;cb6-11&#34;&gt;&lt;a href=&#34;#cb6-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;LHS ensures a uniform coverage of the search space, which is great for efficient exploration. Furthermore, it is relatively simple to implement, so it is an easy place to start.&lt;/p&gt;
&lt;p&gt;A large drawback of LHS is that additional points cannot be sampled after the design is complete. Imagine a scenario where we are about to do Bayesian optimisation, but we chose an initial number of samples, &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt;, that was too small, so we are unable to fit a useful surrogate model. We have already done the &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; samples and they are good, but we would like to add just a few more, &lt;span class=&#34;math inline&#34;&gt;m&lt;/span&gt;, initial samples before starting optimisation in earnest. Unfortunately, we cannot add the &lt;span class=&#34;math inline&#34;&gt;m&lt;/span&gt; points to the original LHS. Neither is the LHS of size &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; a subset of the LHS of size &lt;span class=&#34;math inline&#34;&gt;n + m&lt;/span&gt;. To get a LHS of size &lt;span class=&#34;math inline&#34;&gt;n + m&lt;/span&gt;, we would have to create an entirely new design. The intuition for this is that, as part of the design, we split each dimension into &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; equally spaced intervals, so we cannot retroactively split them into &lt;span class=&#34;math inline&#34;&gt;n + m&lt;/span&gt;, once the &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; samples are done. Another way to think about it is that the design is generated in a for loop over each dimension, so the total number of samples must be known from the beginning. In practice, we could use some space-filling criterion or just random sampling to generate the &lt;span class=&#34;math inline&#34;&gt;m&lt;/span&gt; points, but they would not fit in the Latin Hypercube.&lt;/p&gt;
&lt;h4 id=&#34;lhs-in-2d&#34; class=&#34;anchored&#34;&gt;LHS in 2D&lt;/h4&gt;
&lt;p&gt;Here is LHS applied to our running example:&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb7&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb7-1&#34;&gt;&lt;a href=&#34;#cb7-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;latin_hypercube_sampling&lt;/span&gt;(n, d)&lt;/span&gt;
&lt;span id=&#34;cb7-2&#34;&gt;&lt;a href=&#34;#cb7-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_design&lt;/span&gt;(samples, &lt;span class=&#34;st&#34;&gt;&#34;Latin Hypercube Sampling&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/lhs-1.png&#34; width=&#34;576&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The main thing to notice in this design is the neat stratification of each dimension.&lt;/p&gt;
&lt;h2 id=&#34;quasi-random-design&#34; class=&#34;anchored&#34;&gt;Quasi-Random Design&lt;/h2&gt;
&lt;p&gt;The pure random sampling design struggled to provide an efficient exploration of the search space. The LHS design had guaranteed space filling but had the drawback of not being expandable. What we might want is a space filling design that we can keep adding points to if necessary.&lt;/p&gt;
&lt;p&gt;To create such a design, we turn to quasi random numbers. Quasi random numbers are deterministic sequences of numbers that uniformly fill a space. A quasi random number generator will sequentially generate a set of numbers in such a way that the unit cube is filled evenly. Unless randomness is added, the generator will produce the same sequence when restarted. Even if the generator was stopped, we can start it from where it left off and continue generating points that are compatible with the initially generated sequence.&lt;/p&gt;
&lt;h4 id=&#34;example-sobol-sequence-in-2d&#34; class=&#34;anchored&#34;&gt;Example: Sobol Sequence in 2D&lt;/h4&gt;
&lt;p&gt;Several quasi random number generators exist. One example is a Sobol sequence, which is demonstrated here for our running example.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb8&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb8-1&#34;&gt;&lt;a href=&#34;#cb8-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; randtoolbox&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sobol&lt;/span&gt;(n, d)&lt;/span&gt;
&lt;span id=&#34;cb8-2&#34;&gt;&lt;a href=&#34;#cb8-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_design&lt;/span&gt;(samples, &lt;span class=&#34;st&#34;&gt;&#34;Quasi-Random Design&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/sobol-1.png&#34; width=&#34;576&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The main thing to notice in this design is the neat stratification of each dimension, just like we had for LHS.&lt;/p&gt;
&lt;p&gt;In case we had to expand the initial design, we can just resume the generator and get additional points that fit with the ones previously generated.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb9&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb9-1&#34;&gt;&lt;a href=&#34;#cb9-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;samples_next &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; randtoolbox&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sobol&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;8&lt;/span&gt;, d, &lt;span class=&#34;at&#34;&gt;init =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;FALSE&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb9-2&#34;&gt;&lt;a href=&#34;#cb9-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_design&lt;/span&gt;(samples, &lt;span class=&#34;st&#34;&gt;&#34;Quasi-Random Design with Additional Samples&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb9-3&#34;&gt;&lt;a href=&#34;#cb9-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb9-4&#34;&gt;&lt;a href=&#34;#cb9-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;data.frame&lt;/span&gt;(samples_next),&lt;/span&gt;
&lt;span id=&#34;cb9-5&#34;&gt;&lt;a href=&#34;#cb9-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X1, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; X2, &lt;span class=&#34;at&#34;&gt;color =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;additional samples&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb9-6&#34;&gt;&lt;a href=&#34;#cb9-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;size =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb9-7&#34;&gt;&lt;a href=&#34;#cb9-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb9-8&#34;&gt;&lt;a href=&#34;#cb9-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/sobol_extended-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The additional samples fit snugly in the unoccupied spaces between the first batch of samples.&lt;/p&gt;
&lt;h2 id=&#34;improving-initial-designs&#34; class=&#34;anchored&#34;&gt;Improving Initial Designs&lt;/h2&gt;
&lt;p&gt;In their pure, unmodified form, random sampling, LHS, and quasi random sequences all represent designs that efficiently explore the unit cube in the face of complete uncertainty. That works well if we have normalised inputs with no prior intuition for which part of the range might be optimal. If, however, we have prior intuition, we should try to incorporate it in the initial design.&lt;/p&gt;
&lt;p&gt;Imagine for instance that we are trying to optimise the settings on a piece of manufacturing equipment. Cranking all the dials and levers to their maximum position is a valid setting, but it would very likely result in very poor performance, so we should probably try to include more points closer to the median settings and fewer points at the extremes, in our initial design.&lt;/p&gt;
&lt;p&gt;To incorporate such prior knowledge or intuition we can scale or transform the unit cube design.&lt;/p&gt;
&lt;h4 id=&#34;scaling-feature-bounds&#34; class=&#34;anchored&#34;&gt;Scaling feature bounds&lt;/h4&gt;
&lt;p&gt;Imagine that we have a design for two input dimensions:&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb10&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb10-1&#34;&gt;&lt;a href=&#34;#cb10-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;latin_hypercube_sampling&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We are happy with the first dimension, but we would like to have the second dimension range from -2 to 4.&lt;/p&gt;
&lt;p&gt;To linearly scale a feature from the unit range &lt;span class=&#34;math inline&#34;&gt;\mathbf{x} \in [0,1]&lt;/span&gt; to a different range &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{scaled} \in [a,b]&lt;/span&gt;, we simply apply the transformation&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{x}_{scaled} = \mathbf{x}(b - a) + a&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the case of our example&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb11&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb11-1&#34;&gt;&lt;a href=&#34;#cb11-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design_transformed &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;cbind&lt;/span&gt;(design[, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;], design[, &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;] &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; (&lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb11-2&#34;&gt;&lt;a href=&#34;#cb11-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_design&lt;/span&gt;(design_transformed, &lt;span class=&#34;st&#34;&gt;&#34;Linearly Scaled Design&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/scaled_design-1.png&#34; width=&#34;384&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;It should be noted that for the best performance of Gaussian processes in Bayesian optimisation, the scale should be similar across features. Additionally, for the kernels that have length scale parameters, the interpretability of those parameters are complicated by differing scales. Normalising to the unit cube is generally a good idea for the actual calculations, but for presentation purposes we might want to scale to a range that matches the physical setting.&lt;/p&gt;
&lt;h4 id=&#34;applying-prior-knowledge-to-a-design&#34; class=&#34;anchored&#34;&gt;Applying prior knowledge to a design&lt;/h4&gt;
&lt;p&gt;Samples that are uniformly distributed in the unit cube can easily be scaled to any other distribution that fits with our prior intuition.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{\hat{x}_{i,:}} = Q(\mathbf{x}_{i,:},\theta)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{i,:}&lt;/span&gt; is the &lt;span class=&#34;math inline&#34;&gt;i^{\text{th}}&lt;/span&gt; dimension of all samples and &lt;span class=&#34;math inline&#34;&gt;Q&lt;/span&gt; is the quantile function of a distribution with parameters &lt;span class=&#34;math inline&#34;&gt;\theta&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For instance, let’s make a design with two feature dimensions. For demonstration purposes, we will do a design with many points:&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb12&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb12-1&#34;&gt;&lt;a href=&#34;#cb12-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;latin_hypercube_sampling&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;40&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now we want the first feature to be normally distributed with mean at 1 and a standard deviation of 2. We want our second dimension to be positive but with a preference towards small values, so we will transform it to an exponential distribution with rate 1.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb13&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb13-1&#34;&gt;&lt;a href=&#34;#cb13-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design[,&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;qnorm&lt;/span&gt;(design[,&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;], &lt;span class=&#34;at&#34;&gt;mean =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sd =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb13-2&#34;&gt;&lt;a href=&#34;#cb13-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design[,&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;qexp&lt;/span&gt;(design[,&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;], &lt;span class=&#34;at&#34;&gt;rate =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb13-3&#34;&gt;&lt;a href=&#34;#cb13-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_design&lt;/span&gt;(design, &lt;span class=&#34;st&#34;&gt;&#34;Prior Informed Design&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/qscale-1.png&#34; width=&#34;576&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The main thing to notice in this design is that the dimensions are scaled to match a prior distribution but the samples still retain the stratification of the LHS design.&lt;/p&gt;
&lt;p&gt;We could have chosen any distribution that fits with our prior intuition or knowledge about where we might obtain good samples.&lt;/p&gt;
&lt;h2 id=&#34;designing-with-discrete-or-categorical-features&#34; class=&#34;anchored&#34;&gt;Designing with Discrete or Categorical Features&lt;/h2&gt;
&lt;p&gt;So far, we have tacitly assumed that all our features are continuous. This is not always the case and it is easy to imagine a situation where we want to include a discrete or categorical feature in the initial design. Let’s look at how we can extend the continuous unit cube designs to include discrete or categorical features.&lt;/p&gt;
&lt;p&gt;We can turn a continuous range into a discrete range by cutting it into intervals. For instance, imagine that we had a discrete feature with five possible values. To include it in the initial design, we generate a dimension for this feature, just as we would for a continuous feature. We then define five intervals along the unit range and let each interval correspond to a step in the discrete feature.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb14&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb14-1&#34;&gt;&lt;a href=&#34;#cb14-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;latin_hypercube_sampling&lt;/span&gt;(n, d)&lt;/span&gt;
&lt;span id=&#34;cb14-2&#34;&gt;&lt;a href=&#34;#cb14-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design[,&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;cut&lt;/span&gt;(design[,&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;], &lt;span class=&#34;at&#34;&gt;breaks =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb14-3&#34;&gt;&lt;a href=&#34;#cb14-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_design&lt;/span&gt;(design, &lt;span class=&#34;st&#34;&gt;&#34;Design with Discrete Feature&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The intervals do not have to be even. We can define the breaks that match with the nature of our discrete feature.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb15&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb15-1&#34;&gt;&lt;a href=&#34;#cb15-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;latin_hypercube_sampling&lt;/span&gt;(n, d)&lt;/span&gt;
&lt;span id=&#34;cb15-2&#34;&gt;&lt;a href=&#34;#cb15-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design[,&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;cut&lt;/span&gt;(design[,&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;], &lt;span class=&#34;at&#34;&gt;breaks =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.3&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.7&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.8&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb15-3&#34;&gt;&lt;a href=&#34;#cb15-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_design&lt;/span&gt;(design, &lt;span class=&#34;st&#34;&gt;&#34;Design with Discrete Feature and Uneaven Intervals&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;When given as input to a surrogate model for Bayesian optimisation, it might be easier to keep pretending that the discrete feature is continuous. For presentation purposes, we can transform the feature into something more in line with the physical process. Alternatively, we could treat the discrete feature as categorical.&lt;/p&gt;
&lt;p&gt;To include a categorical feature in the initial design, we can use the same trick of cutting the unit range into even intervals and then assign each a category label.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb16&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb16-1&#34;&gt;&lt;a href=&#34;#cb16-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;data.frame&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;latin_hypercube_sampling&lt;/span&gt;(n, d))&lt;/span&gt;
&lt;span id=&#34;cb16-2&#34;&gt;&lt;a href=&#34;#cb16-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design[,&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;cut&lt;/span&gt;(design[,&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;], &lt;span class=&#34;at&#34;&gt;breaks =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;), &lt;span class=&#34;at&#34;&gt;labels =&lt;/span&gt; letters[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;])&lt;/span&gt;
&lt;span id=&#34;cb16-3&#34;&gt;&lt;a href=&#34;#cb16-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_design&lt;/span&gt;(design, &lt;span class=&#34;st&#34;&gt;&#34;Design with Categorical Feature&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This approach works particularly well with LHS, as this design offers guaranteed even stratification when &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; is an integer multiple of &lt;span class=&#34;math inline&#34;&gt;d&lt;/span&gt;. The same is not true for random sampling or quasi random sequences.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb17&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb17-1&#34;&gt;&lt;a href=&#34;#cb17-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;data.frame&lt;/span&gt;(randtoolbox&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sobol&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;, d))&lt;/span&gt;
&lt;span id=&#34;cb17-2&#34;&gt;&lt;a href=&#34;#cb17-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;design[,&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;cut&lt;/span&gt;(design[,&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;], &lt;span class=&#34;at&#34;&gt;breaks =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;), &lt;span class=&#34;at&#34;&gt;labels =&lt;/span&gt; letters[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;])&lt;/span&gt;
&lt;span id=&#34;cb17-3&#34;&gt;&lt;a href=&#34;#cb17-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_design&lt;/span&gt;(design, &lt;span class=&#34;st&#34;&gt;&#34;Design with Categorical Feature, Uneaven Distribution&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Once we have defined the sampling scheme, we can turn the categorical feature into one-hot features that can be given as inputs to a surrogate model for Bayesian optimisation.&lt;/p&gt;
&lt;div class=&#34;cell&#34; data-tbl-colwidths=&#34;20&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb18&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb18-1&#34;&gt;&lt;a href=&#34;#cb18-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb18-2&#34;&gt;&lt;a href=&#34;#cb18-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  randtoolbox&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sobol&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;, d),&lt;/span&gt;
&lt;span id=&#34;cb18-3&#34;&gt;&lt;a href=&#34;#cb18-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;X1&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;X2&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb18-4&#34;&gt;&lt;a href=&#34;#cb18-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-5&#34;&gt;&lt;a href=&#34;#cb18-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb18-6&#34;&gt;&lt;a href=&#34;#cb18-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;X2 =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;cut&lt;/span&gt;(X2, &lt;span class=&#34;at&#34;&gt;breaks =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;), &lt;span class=&#34;at&#34;&gt;labels =&lt;/span&gt; letters[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;]),&lt;/span&gt;
&lt;span id=&#34;cb18-7&#34;&gt;&lt;a href=&#34;#cb18-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;value =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-8&#34;&gt;&lt;a href=&#34;#cb18-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-9&#34;&gt;&lt;a href=&#34;#cb18-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tidyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;pivot_wider&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;names_from =&lt;/span&gt; X2, &lt;span class=&#34;at&#34;&gt;values_from =&lt;/span&gt; value, &lt;span class=&#34;at&#34;&gt;values_fill =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-10&#34;&gt;&lt;a href=&#34;#cb18-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  knitr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;kable&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;digits =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;row.names =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;FALSE&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;align =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;l&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;X1&lt;/th&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;c&lt;/th&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;b&lt;/th&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;d&lt;/th&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;e&lt;/th&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;a&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0.500&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0.750&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0.250&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0.375&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0.875&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0.625&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0.125&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0.188&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0.688&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0.938&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 class=&#34;unnumbered&#34; id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body&#34; role=&#34;doc-bibliography&#34;&gt;
&lt;div id=&#34;ref-Feurer2015&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[1] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Feurer&lt;/span&gt;, M., &lt;span class=&#34;smallcaps&#34;&gt;Springenberg&lt;/span&gt;, J. and &lt;span class=&#34;smallcaps&#34;&gt;Hutter&lt;/span&gt;, F. (2015). Initializing bayesian hyperparameter optimization via meta-learning. &lt;em&gt;Proceedings of the AAAI Conference on Artificial Intelligence&lt;/em&gt; &lt;strong&gt;29&lt;/strong&gt; Available at &lt;a href=&#34;https://ojs.aaai.org/index.php/AAAI/article/view/9354&#34;&gt;https://ojs.aaai.org/index.php/AAAI/article/view/9354&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-McKay1979&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[2] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;McKay&lt;/span&gt;, M. D., &lt;span class=&#34;smallcaps&#34;&gt;Beckman&lt;/span&gt;, R. J. and &lt;span class=&#34;smallcaps&#34;&gt;Conover&lt;/span&gt;, W. J. (1979). A comparison of three methods for selecting values of input variables in the analysis of output from a computer code. &lt;em&gt;Technometrics&lt;/em&gt; &lt;strong&gt;21&lt;/strong&gt; 239–45 Available at &lt;a href=&#34;http://www.jstor.org/stable/1268522&#34;&gt;http://www.jstor.org/stable/1268522&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;license&#34;&gt;License&lt;/h1&gt;
&lt;p&gt;The content of this project itself is licensed under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International license&lt;/a&gt;, and the underlying code is licensed under the &lt;a href=&#34;https://github.com/AnHosu/bayes-opt/blob/6e25a7a4ec88edac9b55dea2b51382d21030a998/LICENSE&#34;&gt;GNU General Public License v3.0 license&lt;/a&gt;.&lt;/p&gt;
&lt;script type=&#34;application/javascript&#34;&gt;
window.document.addEventListener(&#34;DOMContentLoaded&#34;, function (event) {
  const tabsets =  window.document.querySelectorAll(&#34;.panel-tabset-tabby&#34;)
  tabsets.forEach(function(tabset) {
    const tabby = new Tabby(&#39;#&#39; + tabset.id);
  });
  const icon = &#34;&#34;;
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: &#39;right&#39;,
    icon: icon
  };
  anchorJS.add(&#39;.anchored&#39;);
  const clipboard = new window.ClipboardJS(&#39;.code-copy-button&#39;, {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on(&#39;success&#39;, function(e) {
    // button target
    const button = e.trigger;
    // don&#39;t keep focus
    button.blur();
    // flash &#34;checked&#34;
    button.classList.add(&#39;code-copy-button-checked&#39;);
    setTimeout(function() {
      button.classList.remove(&#39;code-copy-button-checked&#39;);
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: &#39;light-border&#39;,
      placement: &#39;bottom-start&#39;
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-noteref&#34;]&#39;);
  for (var i=0; i&lt;noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute(&#39;href&#39;);
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, &#34;&#34;);
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-biblioref&#34;]&#39;);
  for (var i=0; i&lt;bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute(&#39;data-cites&#39;).split(&#39; &#39;);
    tippyHover(ref, function() {
      var popup = window.document.createElement(&#39;div&#39;);
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement(&#39;div&#39;);
        citeDiv.classList.add(&#39;hanging-indent&#39;);
        citeDiv.classList.add(&#39;csl-entry&#39;);
        var biblioDiv = window.document.getElementById(&#39;ref-&#39; + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
&lt;/script&gt;


&lt;/body&gt;&lt;/html&gt;</description>
    </item>
    
    <item>
      <title>Alternative Surrogate Models for Bayesian Optimisation</title>
      <link>/post/surrogate-alternatives-r/</link>
      <pubDate>Thu, 15 Jun 2023 00:00:00 +0000</pubDate>
      <guid>/post/surrogate-alternatives-r/</guid>
      <description>&lt;!DOCTYPE html&gt;
&lt;html xmlns=&#34;http://www.w3.org/1999/xhtml&#34; lang=&#34;&#34; xml:lang=&#34;&#34;&gt;&lt;head&gt;
  &lt;meta charset=&#34;utf-8&#34;&gt;
  &lt;meta name=&#34;generator&#34; content=&#34;quarto-0.2.243&#34;&gt;
  &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0, user-scalable=yes&#34;&gt;
  &lt;title&gt;index&lt;/title&gt;
  &lt;style&gt;
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre &gt; code.sourceCode { white-space: pre; position: relative; }
    pre &gt; code.sourceCode &gt; span { display: inline-block; line-height: 1.25; }
    pre &gt; code.sourceCode &gt; span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode &gt; span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre &gt; code.sourceCode { white-space: pre-wrap; }
    pre &gt; code.sourceCode &gt; span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code &gt; span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code &gt; span &gt; a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre &gt; code.sourceCode &gt; span &gt; a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  &lt;/style&gt;

  &lt;script src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js&#34; type=&#34;text/javascript&#34;&gt;&lt;/script&gt;
  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&#34;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&#34;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
  &lt;script src=&#34;index_files/libs/clipboard/clipboard.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tabby.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/popper.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tippy.umd.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/anchor.min.js&#34;&gt;&lt;/script&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/tippy.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/light-border.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-html.min.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-syntax-highlighting.css&#34; rel=&#34;stylesheet&#34;&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;&lt;a href=&#34;../bayes-opt-r&#34;&gt;Bayesian optimisation&lt;/a&gt; is a powerful optimisation technique for black-box functions and processes with expensive evaluations. It is popular for hyperparameter tuning in machine learning, but has many real-world applications as well.&lt;/p&gt;
&lt;p&gt;One of the key components of Bayesian optimisation is the surrogate model, which models the objective function and helps guide optimisation by being a cheap to evaluate representation of our posterior beliefs. Gaussian processes (GPs) are commonly used as surrogate functions, as they offer many of the qualities we need, when doing Bayesian optimisation. However, there are alternatives to GPs and, in this post, we will dive into the role of surrogate models in Bayesian optimisation, focusing on four types of surrogate models that are &lt;em&gt;not&lt;/em&gt; GPs.&lt;/p&gt;
&lt;p&gt;Specifically, we will discuss ensembles, Bayesian Neural Networks, bespoke Bayesian models, and Student’s t processes as potential surrogate models for Bayesian optimisation. Along with the discussion, are implementations in R.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(ggplot2)&lt;/span&gt;
&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(magrittr)&lt;/span&gt;
&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;seed &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4444&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb1-4&#34;&gt;&lt;a href=&#34;#cb1-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;set.seed&lt;/span&gt;(seed)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;surrogate-models-in-bayesian-optimisation&#34; class=&#34;anchored&#34;&gt;Surrogate Models in Bayesian Optimisation&lt;/h2&gt;
&lt;p&gt;In Bayesian optimisation, we are conducting experiments on an objective function or process, &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;, that is very expensive to evaluate. The objective function is evaluated on a search space, &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{X}\)&lt;/span&gt;, one point, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x} \in \mathcal{X}\)&lt;/span&gt;, at a time and we are looking for the point, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}^+\)&lt;/span&gt; , that optimises the objective function. We do this in a sequential manner, where we consider the next point, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_{t+1}\)&lt;/span&gt;, given the knowledge from all previously sampled points. To help decide on the next point, we employ an acquisition function, &lt;span class=&#34;math inline&#34;&gt;\(a(\mathbf{x})\)&lt;/span&gt;, that should be easy to optimise on the search space:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathbf{x}_{t+1} = \arg\max_{\mathbf{x} \in \mathcal{X}} a(\mathbf{x})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The acquisition function is itself a function of the surrogate model. The surrogate is a regression model that is used to approximate the objective function and it provides predictions of the objective function values and uncertainty estimates at unobserved points in the search space.&lt;/p&gt;
&lt;p&gt;Specifically, many acquisition functions are functions of the mean &lt;span class=&#34;math inline&#34;&gt;\(\mu(\mathbf{x})\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma(\mathbf{x})\)&lt;/span&gt; across the search space. The surrogate model should provide estimates of those two. In this definition is also the implicit assumption that the likelihood of the surrogate model is Gaussian.&lt;/p&gt;
&lt;p&gt;Gaussian processes, are often used as surrogate models because they explicitly satisfy this assumption. With a Gaussian process, it is easy to isolate the two necessary components. &lt;span class=&#34;math inline&#34;&gt;\(\mu(\mathbf{x})\)&lt;/span&gt; is simply the posterior predictive mean function and &lt;span class=&#34;math inline&#34;&gt;\(\sigma(\mathbf{x})\)&lt;/span&gt; is an entry on the diagonal in the covariance matrix of the posterior predictive distribution.&lt;/p&gt;
&lt;p&gt;There are, however, alternatives to Gaussian processes as surrogates and four of them are discussed below. While there are &lt;a href=&#34;.../post/acquisition-functions-r/&#34;&gt;acquisition functions&lt;/a&gt; that rely on more complex mechanisms, this post focuses on surrogate models that support acquisition functions which are in some way a function of &lt;span class=&#34;math inline&#34;&gt;\(\mu(\mathbf{x})\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma(\mathbf{x})\)&lt;/span&gt;. The first three also assume a Gaussian likelihood, whereas the last surrogate discussed, Student’s t processes, assumes a Student’s t likelihood and consequently requires a modification to the acquisition function.&lt;/p&gt;
&lt;h4 id=&#34;an-example-problem&#34; class=&#34;anchored&#34;&gt;An Example Problem&lt;/h4&gt;
&lt;p&gt;To demonstrate the surrogate models, we need a toy problem. We will use a simple objective function with noise and a single dimension.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;objective_function &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(x) &lt;span class=&#34;fu&#34;&gt;sin&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;12&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; x) &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; x &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; x&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We assume that we want to minimise this function. There are two minima in the search space &lt;span class=&#34;math inline&#34;&gt;\(\mathcal{X} = [0,1]\)&lt;/span&gt;, so it will not be too easy to minimise.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;p&gt;&lt;/p&gt;&lt;details&gt;
&lt;summary&gt;Show the code&lt;/summary&gt;&lt;p&gt;&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_function&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;fun =&lt;/span&gt; objective_function) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;xlim&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-5&#34;&gt;&lt;a href=&#34;#cb3-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;x&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;f(x)&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Objective Function&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We will approximate the the objective function with different surrogate models.&lt;/p&gt;
&lt;p&gt;Each surrogate model will receive the same five training points. For evaluating the acquisition function, we use a prediction grid to approximate the search space.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt;  &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fl&#34;&gt;0.02&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.3&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.75&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.98&lt;/span&gt;), &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;noise &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.05&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;objective_function&lt;/span&gt;(X_train) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, noise)&lt;/span&gt;
&lt;span id=&#34;cb4-4&#34;&gt;&lt;a href=&#34;#cb4-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;), &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;For reference, here is a Gaussian process conditioned on the five training points along with the Expected Improvement (EI) acquisition function evaluated across search space.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;p&gt;&lt;/p&gt;&lt;details&gt;
&lt;summary&gt;Show the code&lt;/summary&gt;&lt;p&gt;&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; RBF Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-2&#34;&gt;&lt;a href=&#34;#cb5-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-3&#34;&gt;&lt;a href=&#34;#cb5-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-4&#34;&gt;&lt;a href=&#34;#cb5-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-5&#34;&gt;&lt;a href=&#34;#cb5-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param l length scale&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-6&#34;&gt;&lt;a href=&#34;#cb5-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma_f scale parameter &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-7&#34;&gt;&lt;a href=&#34;#cb5-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-8&#34;&gt;&lt;a href=&#34;#cb5-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-9&#34;&gt;&lt;a href=&#34;#cb5-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;rbf_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb5-10&#34;&gt;&lt;a href=&#34;#cb5-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb5-11&#34;&gt;&lt;a href=&#34;#cb5-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb5-12&#34;&gt;&lt;a href=&#34;#cb5-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sqdist &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;(X1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(X2))) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-13&#34;&gt;&lt;a href=&#34;#cb5-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X1&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-14&#34;&gt;&lt;a href=&#34;#cb5-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X2&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-15&#34;&gt;&lt;a href=&#34;#cb5-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma_f&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;exp&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; l&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; sqdist)&lt;/span&gt;
&lt;span id=&#34;cb5-16&#34;&gt;&lt;a href=&#34;#cb5-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb5-17&#34;&gt;&lt;a href=&#34;#cb5-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-18&#34;&gt;&lt;a href=&#34;#cb5-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Get Parameters of the Posterior Gaussian Process&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-19&#34;&gt;&lt;a href=&#34;#cb5-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-20&#34;&gt;&lt;a href=&#34;#cb5-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function used for the Gaussian process&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-21&#34;&gt;&lt;a href=&#34;#cb5-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_pred matrix (m, d) of prediction points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-22&#34;&gt;&lt;a href=&#34;#cb5-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-23&#34;&gt;&lt;a href=&#34;#cb5-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-24&#34;&gt;&lt;a href=&#34;#cb5-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-25&#34;&gt;&lt;a href=&#34;#cb5-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param ... named parameters for the kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-26&#34;&gt;&lt;a href=&#34;#cb5-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-27&#34;&gt;&lt;a href=&#34;#cb5-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return list of mean (mu) and covariance (sigma) for the Gaussian&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-28&#34;&gt;&lt;a href=&#34;#cb5-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;posterior &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, X_pred, X_train, y_train, &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt;, ...) {&lt;/span&gt;
&lt;span id=&#34;cb5-29&#34;&gt;&lt;a href=&#34;#cb5-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X_pred), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-30&#34;&gt;&lt;a href=&#34;#cb5-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X_train), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-31&#34;&gt;&lt;a href=&#34;#cb5-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(y_train))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(y_train) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(y_train), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-32&#34;&gt;&lt;a href=&#34;#cb5-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_train, X_train, ...) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;
&lt;span id=&#34;cb5-33&#34;&gt;&lt;a href=&#34;#cb5-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_s &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_train, X_pred, ...)&lt;/span&gt;
&lt;span id=&#34;cb5-34&#34;&gt;&lt;a href=&#34;#cb5-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_ss &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_pred, X_pred, ...) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;
&lt;span id=&#34;cb5-35&#34;&gt;&lt;a href=&#34;#cb5-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_inv &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;solve&lt;/span&gt;(K)&lt;/span&gt;
&lt;span id=&#34;cb5-36&#34;&gt;&lt;a href=&#34;#cb5-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(K_s) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_inv) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; y_train&lt;/span&gt;
&lt;span id=&#34;cb5-37&#34;&gt;&lt;a href=&#34;#cb5-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; K_ss &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(K_s) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_inv) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_s&lt;/span&gt;
&lt;span id=&#34;cb5-38&#34;&gt;&lt;a href=&#34;#cb5-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma)&lt;/span&gt;
&lt;span id=&#34;cb5-39&#34;&gt;&lt;a href=&#34;#cb5-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb5-40&#34;&gt;&lt;a href=&#34;#cb5-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-41&#34;&gt;&lt;a href=&#34;#cb5-41&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Gaussian Negative log-Likelihood of a Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-42&#34;&gt;&lt;a href=&#34;#cb5-42&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-43&#34;&gt;&lt;a href=&#34;#cb5-43&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-44&#34;&gt;&lt;a href=&#34;#cb5-44&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-45&#34;&gt;&lt;a href=&#34;#cb5-45&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-46&#34;&gt;&lt;a href=&#34;#cb5-46&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-47&#34;&gt;&lt;a href=&#34;#cb5-47&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-48&#34;&gt;&lt;a href=&#34;#cb5-48&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return function with kernel parameters as input and negative log likelihood&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-49&#34;&gt;&lt;a href=&#34;#cb5-49&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; as output&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-50&#34;&gt;&lt;a href=&#34;#cb5-50&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;nll &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, X_train, y_train, noise) {&lt;/span&gt;
&lt;span id=&#34;cb5-51&#34;&gt;&lt;a href=&#34;#cb5-51&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(params) {&lt;/span&gt;
&lt;span id=&#34;cb5-52&#34;&gt;&lt;a href=&#34;#cb5-52&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    n &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]]&lt;/span&gt;
&lt;span id=&#34;cb5-53&#34;&gt;&lt;a href=&#34;#cb5-53&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    K &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(kernel, &lt;span class=&#34;at&#34;&gt;X1 =&lt;/span&gt; X_train, &lt;span class=&#34;at&#34;&gt;X2 =&lt;/span&gt; X_train, &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;params)&lt;/span&gt;
&lt;span id=&#34;cb5-54&#34;&gt;&lt;a href=&#34;#cb5-54&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    L &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;chol&lt;/span&gt;(K &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(n))&lt;/span&gt;
&lt;span id=&#34;cb5-55&#34;&gt;&lt;a href=&#34;#cb5-55&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    a &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;backsolve&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;r =&lt;/span&gt; L, &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;forwardsolve&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(L), &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; y_train))&lt;/span&gt;
&lt;span id=&#34;cb5-56&#34;&gt;&lt;a href=&#34;#cb5-56&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(y_train)&lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt;a &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;sum&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;log&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(L))) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;n&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;log&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;pi)&lt;/span&gt;
&lt;span id=&#34;cb5-57&#34;&gt;&lt;a href=&#34;#cb5-57&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb5-58&#34;&gt;&lt;a href=&#34;#cb5-58&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb5-59&#34;&gt;&lt;a href=&#34;#cb5-59&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-60&#34;&gt;&lt;a href=&#34;#cb5-60&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Gaussian Process Regression&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-61&#34;&gt;&lt;a href=&#34;#cb5-61&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-62&#34;&gt;&lt;a href=&#34;#cb5-62&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-63&#34;&gt;&lt;a href=&#34;#cb5-63&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-64&#34;&gt;&lt;a href=&#34;#cb5-64&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-65&#34;&gt;&lt;a href=&#34;#cb5-65&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-66&#34;&gt;&lt;a href=&#34;#cb5-66&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param ... parameters of the kernel function with initial guesses. Due to the&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-67&#34;&gt;&lt;a href=&#34;#cb5-67&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; optimiser used, all parameters must be given and the order unfortunately&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-68&#34;&gt;&lt;a href=&#34;#cb5-68&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; matters&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-69&#34;&gt;&lt;a href=&#34;#cb5-69&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-70&#34;&gt;&lt;a href=&#34;#cb5-70&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return function that takes a matrix of prediction points as input and&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-71&#34;&gt;&lt;a href=&#34;#cb5-71&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; returns the posterior predictive distribution for the output&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-72&#34;&gt;&lt;a href=&#34;#cb5-72&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gpr &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, X_train, y_train, &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt;, ...) {&lt;/span&gt;
&lt;span id=&#34;cb5-73&#34;&gt;&lt;a href=&#34;#cb5-73&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  kernel_nll &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;nll&lt;/span&gt;(kernel, X_train, y_train, noise)&lt;/span&gt;
&lt;span id=&#34;cb5-74&#34;&gt;&lt;a href=&#34;#cb5-74&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  param &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(...)&lt;/span&gt;
&lt;span id=&#34;cb5-75&#34;&gt;&lt;a href=&#34;#cb5-75&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  opt &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;optim&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;par =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(param)), &lt;span class=&#34;at&#34;&gt;fn =&lt;/span&gt; kernel_nll)&lt;/span&gt;
&lt;span id=&#34;cb5-76&#34;&gt;&lt;a href=&#34;#cb5-76&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  opt_param &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; opt&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;par&lt;/span&gt;
&lt;span id=&#34;cb5-77&#34;&gt;&lt;a href=&#34;#cb5-77&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X_pred) {&lt;/span&gt;
&lt;span id=&#34;cb5-78&#34;&gt;&lt;a href=&#34;#cb5-78&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-79&#34;&gt;&lt;a href=&#34;#cb5-79&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      posterior,&lt;/span&gt;
&lt;span id=&#34;cb5-80&#34;&gt;&lt;a href=&#34;#cb5-80&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;kernel =&lt;/span&gt; kernel,&lt;/span&gt;
&lt;span id=&#34;cb5-81&#34;&gt;&lt;a href=&#34;#cb5-81&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb5-82&#34;&gt;&lt;a href=&#34;#cb5-82&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb5-83&#34;&gt;&lt;a href=&#34;#cb5-83&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_train,&lt;/span&gt;
&lt;span id=&#34;cb5-84&#34;&gt;&lt;a href=&#34;#cb5-84&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; noise,&lt;/span&gt;
&lt;span id=&#34;cb5-85&#34;&gt;&lt;a href=&#34;#cb5-85&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;opt_param&lt;/span&gt;
&lt;span id=&#34;cb5-86&#34;&gt;&lt;a href=&#34;#cb5-86&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb5-87&#34;&gt;&lt;a href=&#34;#cb5-87&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-88&#34;&gt;&lt;a href=&#34;#cb5-88&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu,&lt;/span&gt;
&lt;span id=&#34;cb5-89&#34;&gt;&lt;a href=&#34;#cb5-89&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma),&lt;/span&gt;
&lt;span id=&#34;cb5-90&#34;&gt;&lt;a href=&#34;#cb5-90&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;Sigma =&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma,&lt;/span&gt;
&lt;span id=&#34;cb5-91&#34;&gt;&lt;a href=&#34;#cb5-91&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;parameters =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;set_names&lt;/span&gt;(opt_param, &lt;span class=&#34;fu&#34;&gt;names&lt;/span&gt;(param))&lt;/span&gt;
&lt;span id=&#34;cb5-92&#34;&gt;&lt;a href=&#34;#cb5-92&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb5-93&#34;&gt;&lt;a href=&#34;#cb5-93&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb5-94&#34;&gt;&lt;a href=&#34;#cb5-94&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb5-95&#34;&gt;&lt;a href=&#34;#cb5-95&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-96&#34;&gt;&lt;a href=&#34;#cb5-96&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Expected Improvement Acquisition Function for a Gaussian Surrogate&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-97&#34;&gt;&lt;a href=&#34;#cb5-97&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-98&#34;&gt;&lt;a href=&#34;#cb5-98&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param mu vector of length m. Mean of a Gaussian process at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-99&#34;&gt;&lt;a href=&#34;#cb5-99&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma vector of length m. The diagonal of the covariance matrix of a&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-100&#34;&gt;&lt;a href=&#34;#cb5-100&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Gaussian process evaluated at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-101&#34;&gt;&lt;a href=&#34;#cb5-101&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_best scalar. Best mean prediction so far on observed points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-102&#34;&gt;&lt;a href=&#34;#cb5-102&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param xi scalar, exploration/exploitation trade off&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-103&#34;&gt;&lt;a href=&#34;#cb5-103&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param task one of &#34;max&#34; or &#34;min&#34;, indicating the optimisation problem&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-104&#34;&gt;&lt;a href=&#34;#cb5-104&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-105&#34;&gt;&lt;a href=&#34;#cb5-105&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return EI, vector of length m&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-106&#34;&gt;&lt;a href=&#34;#cb5-106&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;expected_improvement &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(mu, sigma, y_best, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.01&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;task =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;min&#34;&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb5-107&#34;&gt;&lt;a href=&#34;#cb5-107&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (task &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;min&#34;&lt;/span&gt;) imp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; y_best &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; xi&lt;/span&gt;
&lt;span id=&#34;cb5-108&#34;&gt;&lt;a href=&#34;#cb5-108&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (task &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;max&#34;&lt;/span&gt;) imp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; y_best &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; xi&lt;/span&gt;
&lt;span id=&#34;cb5-109&#34;&gt;&lt;a href=&#34;#cb5-109&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(imp)) &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#39;task must be &#34;min&#34; or &#34;max&#34;&#39;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-110&#34;&gt;&lt;a href=&#34;#cb5-110&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  Z &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; imp &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; sigma&lt;/span&gt;
&lt;span id=&#34;cb5-111&#34;&gt;&lt;a href=&#34;#cb5-111&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; imp &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;pnorm&lt;/span&gt;(Z) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; sigma &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dnorm&lt;/span&gt;(Z)&lt;/span&gt;
&lt;span id=&#34;cb5-112&#34;&gt;&lt;a href=&#34;#cb5-112&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei[sigma &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.0&lt;/span&gt;] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-113&#34;&gt;&lt;a href=&#34;#cb5-113&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei&lt;/span&gt;
&lt;span id=&#34;cb5-114&#34;&gt;&lt;a href=&#34;#cb5-114&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb5-115&#34;&gt;&lt;a href=&#34;#cb5-115&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-116&#34;&gt;&lt;a href=&#34;#cb5-116&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Plot of a Gaussian Process in One Dimension&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-117&#34;&gt;&lt;a href=&#34;#cb5-117&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-118&#34;&gt;&lt;a href=&#34;#cb5-118&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param mu vector of length m. Mean of a Gaussian process at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-119&#34;&gt;&lt;a href=&#34;#cb5-119&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma vector of length m. The diagonal of the covariance matrix of a&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-120&#34;&gt;&lt;a href=&#34;#cb5-120&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Gaussian process evaluated at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-121&#34;&gt;&lt;a href=&#34;#cb5-121&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_pred matrix of dimensions (m X 1) representing m prediction points &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-122&#34;&gt;&lt;a href=&#34;#cb5-122&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; with one dimension.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-123&#34;&gt;&lt;a href=&#34;#cb5-123&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix of dimensions (n X 1) representing n training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-124&#34;&gt;&lt;a href=&#34;#cb5-124&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; with one dimension&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-125&#34;&gt;&lt;a href=&#34;#cb5-125&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train vector of length n representing n observations at points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-126&#34;&gt;&lt;a href=&#34;#cb5-126&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; X_train&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-127&#34;&gt;&lt;a href=&#34;#cb5-127&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param true_function function representing the objective function (in real&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-128&#34;&gt;&lt;a href=&#34;#cb5-128&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; life, this function is unknown and cannot be plotted)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-129&#34;&gt;&lt;a href=&#34;#cb5-129&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-130&#34;&gt;&lt;a href=&#34;#cb5-130&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return ggplot2 plot&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-131&#34;&gt;&lt;a href=&#34;#cb5-131&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gp_1d_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(mu, sigma, X_pred, X_train, y_train, true_function) {&lt;/span&gt;
&lt;span id=&#34;cb5-132&#34;&gt;&lt;a href=&#34;#cb5-132&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-133&#34;&gt;&lt;a href=&#34;#cb5-133&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;m =&lt;/span&gt; mu,&lt;/span&gt;
&lt;span id=&#34;cb5-134&#34;&gt;&lt;a href=&#34;#cb5-134&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;uncertainty =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.96&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sqrt&lt;/span&gt;(sigma),&lt;/span&gt;
&lt;span id=&#34;cb5-135&#34;&gt;&lt;a href=&#34;#cb5-135&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;upper =&lt;/span&gt; m &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; uncertainty,&lt;/span&gt;
&lt;span id=&#34;cb5-136&#34;&gt;&lt;a href=&#34;#cb5-136&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;lower =&lt;/span&gt; m &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; uncertainty,&lt;/span&gt;
&lt;span id=&#34;cb5-137&#34;&gt;&lt;a href=&#34;#cb5-137&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb5-138&#34;&gt;&lt;a href=&#34;#cb5-138&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;f =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;true_function&lt;/span&gt;(X_pred)&lt;/span&gt;
&lt;span id=&#34;cb5-139&#34;&gt;&lt;a href=&#34;#cb5-139&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-140&#34;&gt;&lt;a href=&#34;#cb5-140&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-141&#34;&gt;&lt;a href=&#34;#cb5-141&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; m, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Mean&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-142&#34;&gt;&lt;a href=&#34;#cb5-142&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_ribbon&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-143&#34;&gt;&lt;a href=&#34;#cb5-143&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;ymin =&lt;/span&gt; lower, &lt;span class=&#34;at&#34;&gt;ymax =&lt;/span&gt; upper, &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb5-144&#34;&gt;&lt;a href=&#34;#cb5-144&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-145&#34;&gt;&lt;a href=&#34;#cb5-145&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-146&#34;&gt;&lt;a href=&#34;#cb5-146&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-147&#34;&gt;&lt;a href=&#34;#cb5-147&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_train, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y_train),&lt;/span&gt;
&lt;span id=&#34;cb5-148&#34;&gt;&lt;a href=&#34;#cb5-148&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y, &lt;span class=&#34;at&#34;&gt;shape =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Training point&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb5-149&#34;&gt;&lt;a href=&#34;#cb5-149&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#fb8500&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-150&#34;&gt;&lt;a href=&#34;#cb5-150&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;size =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-151&#34;&gt;&lt;a href=&#34;#cb5-151&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-152&#34;&gt;&lt;a href=&#34;#cb5-152&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;mapping =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; f, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;True function&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-153&#34;&gt;&lt;a href=&#34;#cb5-153&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_shape_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;Training point&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;+&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-154&#34;&gt;&lt;a href=&#34;#cb5-154&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_fill_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#219ebc&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-155&#34;&gt;&lt;a href=&#34;#cb5-155&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;shape =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-156&#34;&gt;&lt;a href=&#34;#cb5-156&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-157&#34;&gt;&lt;a href=&#34;#cb5-157&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-158&#34;&gt;&lt;a href=&#34;#cb5-158&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;y&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-159&#34;&gt;&lt;a href=&#34;#cb5-159&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-160&#34;&gt;&lt;a href=&#34;#cb5-160&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-161&#34;&gt;&lt;a href=&#34;#cb5-161&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-162&#34;&gt;&lt;a href=&#34;#cb5-162&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-163&#34;&gt;&lt;a href=&#34;#cb5-163&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;panel.grid =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;(), &lt;span class=&#34;at&#34;&gt;axis.text.x =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;())&lt;/span&gt;
&lt;span id=&#34;cb5-164&#34;&gt;&lt;a href=&#34;#cb5-164&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb5-165&#34;&gt;&lt;a href=&#34;#cb5-165&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-166&#34;&gt;&lt;a href=&#34;#cb5-166&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Plot of Acquisition Function with Surrogate in One Dimension&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-167&#34;&gt;&lt;a href=&#34;#cb5-167&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-168&#34;&gt;&lt;a href=&#34;#cb5-168&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @X_pred matrix of dimensions (m X 1) representing m prediction points with &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-169&#34;&gt;&lt;a href=&#34;#cb5-169&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; one dimension.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-170&#34;&gt;&lt;a href=&#34;#cb5-170&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @acquisition_function vector of length m representing the acquisition&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-171&#34;&gt;&lt;a href=&#34;#cb5-171&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; function evaluated at the m points of X_pred&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-172&#34;&gt;&lt;a href=&#34;#cb5-172&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param uncertainty_plot the plot of a surrogate model in one dimension&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-173&#34;&gt;&lt;a href=&#34;#cb5-173&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param xt1 scalar, the point, x, that optimises the acquisition function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-174&#34;&gt;&lt;a href=&#34;#cb5-174&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param label character, label for the acquisition function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-175&#34;&gt;&lt;a href=&#34;#cb5-175&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param title character, a title for the plot&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-176&#34;&gt;&lt;a href=&#34;#cb5-176&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-177&#34;&gt;&lt;a href=&#34;#cb5-177&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return ggplot2 plot&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-178&#34;&gt;&lt;a href=&#34;#cb5-178&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;acquisition_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X_pred,&lt;/span&gt;
&lt;span id=&#34;cb5-179&#34;&gt;&lt;a href=&#34;#cb5-179&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             acquisition_function,&lt;/span&gt;
&lt;span id=&#34;cb5-180&#34;&gt;&lt;a href=&#34;#cb5-180&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             uncertainty_plot,&lt;/span&gt;
&lt;span id=&#34;cb5-181&#34;&gt;&lt;a href=&#34;#cb5-181&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             xt1,&lt;/span&gt;
&lt;span id=&#34;cb5-182&#34;&gt;&lt;a href=&#34;#cb5-182&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;label =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;EI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-183&#34;&gt;&lt;a href=&#34;#cb5-183&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb5-184&#34;&gt;&lt;a href=&#34;#cb5-184&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-185&#34;&gt;&lt;a href=&#34;#cb5-185&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb5-186&#34;&gt;&lt;a href=&#34;#cb5-186&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;a =&lt;/span&gt; acquisition_function&lt;/span&gt;
&lt;span id=&#34;cb5-187&#34;&gt;&lt;a href=&#34;#cb5-187&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-188&#34;&gt;&lt;a href=&#34;#cb5-188&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-189&#34;&gt;&lt;a href=&#34;#cb5-189&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; a, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; label)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-190&#34;&gt;&lt;a href=&#34;#cb5-190&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_vline&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;xintercept =&lt;/span&gt; xt1, &lt;span class=&#34;at&#34;&gt;linetype =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-191&#34;&gt;&lt;a href=&#34;#cb5-191&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-192&#34;&gt;&lt;a href=&#34;#cb5-192&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; label, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-193&#34;&gt;&lt;a href=&#34;#cb5-193&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;panel.grid =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;())&lt;/span&gt;
&lt;span id=&#34;cb5-194&#34;&gt;&lt;a href=&#34;#cb5-194&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p2 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; uncertainty_plot &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-195&#34;&gt;&lt;a href=&#34;#cb5-195&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_vline&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;xintercept =&lt;/span&gt; xt1, &lt;span class=&#34;at&#34;&gt;linetype =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-196&#34;&gt;&lt;a href=&#34;#cb5-196&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; title)&lt;/span&gt;
&lt;span id=&#34;cb5-197&#34;&gt;&lt;a href=&#34;#cb5-197&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  aligned_plots &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; cowplot&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;align_plots&lt;/span&gt;(p2, p1 , &lt;span class=&#34;at&#34;&gt;align =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;v&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-198&#34;&gt;&lt;a href=&#34;#cb5-198&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  cowplot&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;plot_grid&lt;/span&gt;(aligned_plots[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]], aligned_plots[[&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;]], &lt;span class=&#34;at&#34;&gt;ncol =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-199&#34;&gt;&lt;a href=&#34;#cb5-199&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb5-200&#34;&gt;&lt;a href=&#34;#cb5-200&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-201&#34;&gt;&lt;a href=&#34;#cb5-201&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gpr&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-202&#34;&gt;&lt;a href=&#34;#cb5-202&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;kernel =&lt;/span&gt; rbf_kernel,&lt;/span&gt;
&lt;span id=&#34;cb5-203&#34;&gt;&lt;a href=&#34;#cb5-203&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb5-204&#34;&gt;&lt;a href=&#34;#cb5-204&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_train,&lt;/span&gt;
&lt;span id=&#34;cb5-205&#34;&gt;&lt;a href=&#34;#cb5-205&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; noise,&lt;/span&gt;
&lt;span id=&#34;cb5-206&#34;&gt;&lt;a href=&#34;#cb5-206&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-207&#34;&gt;&lt;a href=&#34;#cb5-207&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-208&#34;&gt;&lt;a href=&#34;#cb5-208&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-209&#34;&gt;&lt;a href=&#34;#cb5-209&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post_pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp&lt;/span&gt;(X_pred)&lt;/span&gt;
&lt;span id=&#34;cb5-210&#34;&gt;&lt;a href=&#34;#cb5-210&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu&lt;/span&gt;
&lt;span id=&#34;cb5-211&#34;&gt;&lt;a href=&#34;#cb5-211&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma&lt;/span&gt;
&lt;span id=&#34;cb5-212&#34;&gt;&lt;a href=&#34;#cb5-212&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma, &lt;span class=&#34;at&#34;&gt;y_best =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;min&lt;/span&gt;(y_train))&lt;/span&gt;
&lt;span id=&#34;cb5-213&#34;&gt;&lt;a href=&#34;#cb5-213&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gp_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp_1d_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-214&#34;&gt;&lt;a href=&#34;#cb5-214&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu,&lt;/span&gt;
&lt;span id=&#34;cb5-215&#34;&gt;&lt;a href=&#34;#cb5-215&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma,&lt;/span&gt;
&lt;span id=&#34;cb5-216&#34;&gt;&lt;a href=&#34;#cb5-216&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb5-217&#34;&gt;&lt;a href=&#34;#cb5-217&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb5-218&#34;&gt;&lt;a href=&#34;#cb5-218&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_train,&lt;/span&gt;
&lt;span id=&#34;cb5-219&#34;&gt;&lt;a href=&#34;#cb5-219&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;true_function =&lt;/span&gt; objective_function&lt;/span&gt;
&lt;span id=&#34;cb5-220&#34;&gt;&lt;a href=&#34;#cb5-220&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-221&#34;&gt;&lt;a href=&#34;#cb5-221&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-222&#34;&gt;&lt;a href=&#34;#cb5-222&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb5-223&#34;&gt;&lt;a href=&#34;#cb5-223&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;acquisition_function =&lt;/span&gt; ei,&lt;/span&gt;
&lt;span id=&#34;cb5-224&#34;&gt;&lt;a href=&#34;#cb5-224&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;uncertainty_plot =&lt;/span&gt; gp_plot,&lt;/span&gt;
&lt;span id=&#34;cb5-225&#34;&gt;&lt;a href=&#34;#cb5-225&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;xt1 =&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei)],&lt;/span&gt;
&lt;span id=&#34;cb5-226&#34;&gt;&lt;a href=&#34;#cb5-226&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;label =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;EI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-227&#34;&gt;&lt;a href=&#34;#cb5-227&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Gaussian Process Surrogate&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-228&#34;&gt;&lt;a href=&#34;#cb5-228&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The dashed line indicates the next sampling point, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}_{t+1}\)&lt;/span&gt;, as suggested by the acquisition function.&lt;/p&gt;
&lt;p&gt;Now let’s look at some alternative surrogate models.&lt;/p&gt;
&lt;h2 id=&#34;ensembles-as-surrogate-models&#34; class=&#34;anchored&#34;&gt;Ensembles as Surrogate Models&lt;/h2&gt;
&lt;p&gt;A single deterministic model will not work as a surrogate for Bayesian optimisation, as it does not offer a measure of uncertainty. Fortunately there is a way for us to use our favourite machine learning models for Bayesian optimisation. If we collect an ensemble of models, we can use the mean and standard deviation of the predictions as estimates of &lt;span class=&#34;math inline&#34;&gt;\(\mu(\mathbf{x})\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma(\mathbf{x})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;There are a few ways in which we could build an ensemble, and they all work, as long as the distribution of predictions is approximately Gaussian. For instance, if we had a lot of training data, we could do bagging and train several models on different subsets of the training data and use those as an ensemble. We could also use a stack of different models as an ensemble.&lt;/p&gt;
&lt;p&gt;While Bayesian optimisation problems rarely come with a lot of training data, such a situation represents a case where an ensemble might be preferred over a GP, as GPs are difficult to scale for large data sets.&lt;/p&gt;
&lt;p&gt;Another situation where an ensemble might be preferred over a GP is the case where data is very high dimensional. In that case, we can include models with explicit dimensionality reduction in the ensemble to fit the data without introducing too many parameters.&lt;/p&gt;
&lt;h4 id=&#34;example-a-neural-network-ensemble&#34; class=&#34;anchored&#34;&gt;Example: A Neural Network Ensemble&lt;/h4&gt;
&lt;p&gt;As a demonstration of an ensemble used as a surrogate model in the case of our running example, we will fit neural networks. We fit a simple two-layer NN with a random number of nodes in each. Rather than fitting different models, we use 50 different initialisations of the same architecture to create an ensemble.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;bind_cols&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-2&#34;&gt;&lt;a href=&#34;#cb6-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(y_train, &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;y&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb6-3&#34;&gt;&lt;a href=&#34;#cb6-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(X_train, &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;x&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb6-4&#34;&gt;&lt;a href=&#34;#cb6-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb6-5&#34;&gt;&lt;a href=&#34;#cb6-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(X_pred, &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;x&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb6-6&#34;&gt;&lt;a href=&#34;#cb6-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;preds &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;50&lt;/span&gt;, &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(i) {&lt;/span&gt;
&lt;span id=&#34;cb6-7&#34;&gt;&lt;a href=&#34;#cb6-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  m &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; neuralnet&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;neuralnet&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-8&#34;&gt;&lt;a href=&#34;#cb6-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    y &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; .,&lt;/span&gt;
&lt;span id=&#34;cb6-9&#34;&gt;&lt;a href=&#34;#cb6-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; train,&lt;/span&gt;
&lt;span id=&#34;cb6-10&#34;&gt;&lt;a href=&#34;#cb6-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;hidden =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;sample&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;fu&#34;&gt;sample&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)),&lt;/span&gt;
&lt;span id=&#34;cb6-11&#34;&gt;&lt;a href=&#34;#cb6-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;linear.output =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;TRUE&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-12&#34;&gt;&lt;a href=&#34;#cb6-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;threshold =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.0001&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-13&#34;&gt;&lt;a href=&#34;#cb6-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;stepmax =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e6&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-14&#34;&gt;&lt;a href=&#34;#cb6-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb6-15&#34;&gt;&lt;a href=&#34;#cb6-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;predict&lt;/span&gt;(m, pred)&lt;/span&gt;
&lt;span id=&#34;cb6-16&#34;&gt;&lt;a href=&#34;#cb6-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-17&#34;&gt;&lt;a href=&#34;#cb6-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;do.call&lt;/span&gt;(cbind, .) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-18&#34;&gt;&lt;a href=&#34;#cb6-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;mean =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;apply&lt;/span&gt;(., &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, mean), &lt;span class=&#34;at&#34;&gt;sd =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;apply&lt;/span&gt;(., &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, sd))&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Note the assumption that the ensemble predictions follow a Gaussian distribution. Depending on the models and ensemble set up, this assumption might be difficult to satisfy, but it is required for calculating the Expected Improvement acquisition function.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb7&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb7-1&#34;&gt;&lt;a href=&#34;#cb7-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei_nn_ens &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb7-2&#34;&gt;&lt;a href=&#34;#cb7-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; preds&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mean,&lt;/span&gt;
&lt;span id=&#34;cb7-3&#34;&gt;&lt;a href=&#34;#cb7-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; preds&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sd,&lt;/span&gt;
&lt;span id=&#34;cb7-4&#34;&gt;&lt;a href=&#34;#cb7-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_best =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;min&lt;/span&gt;(y_train)&lt;/span&gt;
&lt;span id=&#34;cb7-5&#34;&gt;&lt;a href=&#34;#cb7-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb7-6&#34;&gt;&lt;a href=&#34;#cb7-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ens_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp_1d_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb7-7&#34;&gt;&lt;a href=&#34;#cb7-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; preds&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mean,&lt;/span&gt;
&lt;span id=&#34;cb7-8&#34;&gt;&lt;a href=&#34;#cb7-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; preds&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sd,&lt;/span&gt;
&lt;span id=&#34;cb7-9&#34;&gt;&lt;a href=&#34;#cb7-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb7-10&#34;&gt;&lt;a href=&#34;#cb7-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb7-11&#34;&gt;&lt;a href=&#34;#cb7-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_train,&lt;/span&gt;
&lt;span id=&#34;cb7-12&#34;&gt;&lt;a href=&#34;#cb7-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;true_function =&lt;/span&gt; objective_function&lt;/span&gt;
&lt;span id=&#34;cb7-13&#34;&gt;&lt;a href=&#34;#cb7-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb7-14&#34;&gt;&lt;a href=&#34;#cb7-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb7-15&#34;&gt;&lt;a href=&#34;#cb7-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb7-16&#34;&gt;&lt;a href=&#34;#cb7-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;acquisition_function =&lt;/span&gt; ei_nn_ens,&lt;/span&gt;
&lt;span id=&#34;cb7-17&#34;&gt;&lt;a href=&#34;#cb7-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;uncertainty_plot =&lt;/span&gt; ens_plot,&lt;/span&gt;
&lt;span id=&#34;cb7-18&#34;&gt;&lt;a href=&#34;#cb7-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;xt1 =&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei_nn_ens)],&lt;/span&gt;
&lt;span id=&#34;cb7-19&#34;&gt;&lt;a href=&#34;#cb7-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;label =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;EI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-20&#34;&gt;&lt;a href=&#34;#cb7-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Neural Network Ensemble Surrogate&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-21&#34;&gt;&lt;a href=&#34;#cb7-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The acquisition function evaluated on the ensemble suggests that the next sampling point should be all the way to the right side of search space, as marked by the dashed line. There is another good candidate near the middle though.&lt;/p&gt;
&lt;p&gt;An ensemble of NNs is probably not the right choice of surrogate function in this particular case, where a Gaussian process is much more effective. It does work, however, and demonstrates how we might apply deterministic models to accomplish Bayesian optimisation.&lt;/p&gt;
&lt;p&gt;If we really like Neural Networks, but would like to extend the ‘Bayesian’ part to the surrogate as well, we do have an option: Bayesian Neural Networks.&lt;/p&gt;
&lt;h2 id=&#34;bayesian-neural-networks-as-surrogate-models&#34; class=&#34;anchored&#34;&gt;Bayesian Neural Networks as Surrogate Models&lt;/h2&gt;
&lt;p&gt;Bayesian neural networks (BNNs) are neural networks with weights and biases that are distributions over parameters rather than deterministic point estimates. BNNs can be an attractive alternative to GPs, as they have the dimensionality reduction capabilities of regular neural networks combined with the probabilistic approach to regression that works so well for GPs. However, as we shall see in a moment, BNNs are not a complete walk in the park.&lt;/p&gt;
&lt;p&gt;In order to calculate an acquisition function like Expected Improvement, we need a way to estimate the mean and standard deviation functions. Doing so for a BNN is more challenging than for a GP, as BNNs do not have closed-form expressions for the predictive distribution.&lt;/p&gt;
&lt;p&gt;Instead, we have to condition the BNN on our training data and then sample from the resulting predictive posterior. There are a few ways to do this and conditioning BNNs is a subject all on its own and not our objective here. For now, we will condition our BNN using Hamiltonian Monte Carlo (HMC) in Stan.&lt;/p&gt;
&lt;h4 id=&#34;example-a-bayesian-neural-network-in-stan&#34; class=&#34;anchored&#34;&gt;Example: A Bayesian Neural Network in Stan&lt;/h4&gt;
&lt;p&gt;To build a BNN, or any Bayesian model for that matter, we need to specify a likelihood function as well as priors for any parameters.&lt;/p&gt;
&lt;p&gt;We will assume a Gaussian likelihood, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, i.e.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y \sim \mathcal{N}(\mu, \sigma|\mathbf{X}, \theta)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is the, possibly known, noise of observations and &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the Neural Network function of our training data, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu = {\sf NN}(\mathbf{X}, \theta)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; representing the weights and bias parameters of the NN.&lt;/p&gt;
&lt;p&gt;For this example, we will use a NN with a single hidden layer before the output layer.&lt;/p&gt;
&lt;p&gt;Next we need to specify priors for the weights and biases. Since we have no knowledge of what constitutes good values, we will just use a wide normal prior&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\theta = \{\mathbf{w}_{hidden}, \mathbf{b}_{hidden}, \mathbf{x}_{output}, b_{output}\} \sim \mathcal{N}(0, 3)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The full model specification in Stan is &lt;a href=&#34;https://github.com/AnHosu/bayes-opt/blob/34f9f02cd39f8b5ea198a246179b0e3fc0eef383/06-surrogate-alternatives/bnn.stan&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now we can try to condition the model on our training data. This essentially means collecting samples from the posterior distribution of NNs with this particular architecture.&lt;/p&gt;
&lt;p&gt;While conditioning the model, we also sample posterior predictions by generating a forward pass of the model for a grid of inputs.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb8&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb8-1&#34;&gt;&lt;a href=&#34;#cb8-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Compile the model&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-2&#34;&gt;&lt;a href=&#34;#cb8-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;model &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rstan&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;stan_model&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;bnn.stan&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb8-3&#34;&gt;&lt;a href=&#34;#cb8-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Prepare the data&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-4&#34;&gt;&lt;a href=&#34;#cb8-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;data &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb8-5&#34;&gt;&lt;a href=&#34;#cb8-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;N =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]],&lt;/span&gt;
&lt;span id=&#34;cb8-6&#34;&gt;&lt;a href=&#34;#cb8-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;D =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;]],&lt;/span&gt;
&lt;span id=&#34;cb8-7&#34;&gt;&lt;a href=&#34;#cb8-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb8-8&#34;&gt;&lt;a href=&#34;#cb8-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;as.vector&lt;/span&gt;(y_train),&lt;/span&gt;
&lt;span id=&#34;cb8-9&#34;&gt;&lt;a href=&#34;#cb8-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;M =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]],&lt;/span&gt;
&lt;span id=&#34;cb8-10&#34;&gt;&lt;a href=&#34;#cb8-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb8-11&#34;&gt;&lt;a href=&#34;#cb8-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; noise,&lt;/span&gt;
&lt;span id=&#34;cb8-12&#34;&gt;&lt;a href=&#34;#cb8-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;n_hidden =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-13&#34;&gt;&lt;a href=&#34;#cb8-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb8-14&#34;&gt;&lt;a href=&#34;#cb8-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Fit the model using HMC sampling&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-15&#34;&gt;&lt;a href=&#34;#cb8-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;fit &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rstan&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sampling&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb8-16&#34;&gt;&lt;a href=&#34;#cb8-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;object =&lt;/span&gt; model,&lt;/span&gt;
&lt;span id=&#34;cb8-17&#34;&gt;&lt;a href=&#34;#cb8-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; data,&lt;/span&gt;
&lt;span id=&#34;cb8-18&#34;&gt;&lt;a href=&#34;#cb8-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;chains =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb8-19&#34;&gt;&lt;a href=&#34;#cb8-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;cores =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb8-20&#34;&gt;&lt;a href=&#34;#cb8-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;iter =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;16000&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb8-21&#34;&gt;&lt;a href=&#34;#cb8-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;warmup =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;8000&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb8-22&#34;&gt;&lt;a href=&#34;#cb8-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;seed =&lt;/span&gt; seed,&lt;/span&gt;
&lt;span id=&#34;cb8-23&#34;&gt;&lt;a href=&#34;#cb8-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;control =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;adapt_delta =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.99&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb8-24&#34;&gt;&lt;a href=&#34;#cb8-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb8-25&#34;&gt;&lt;a href=&#34;#cb8-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Summarize the results&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-26&#34;&gt;&lt;a href=&#34;#cb8-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rstan&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;summary&lt;/span&gt;(fit, &lt;span class=&#34;at&#34;&gt;pars =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;y_pred&#34;&lt;/span&gt;)&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;summary &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-27&#34;&gt;&lt;a href=&#34;#cb8-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;()&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We can use the mean and standard deviation of the posterior predictions to calculate the Expected Improvement acquisition function.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb9&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb9-1&#34;&gt;&lt;a href=&#34;#cb9-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei_bnn &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb9-2&#34;&gt;&lt;a href=&#34;#cb9-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; y_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mean,&lt;/span&gt;
&lt;span id=&#34;cb9-3&#34;&gt;&lt;a href=&#34;#cb9-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; y_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sd,&lt;/span&gt;
&lt;span id=&#34;cb9-4&#34;&gt;&lt;a href=&#34;#cb9-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_best =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;min&lt;/span&gt;(y_train)&lt;/span&gt;
&lt;span id=&#34;cb9-5&#34;&gt;&lt;a href=&#34;#cb9-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb9-6&#34;&gt;&lt;a href=&#34;#cb9-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# We should actually use the samples to generate the ribbons on the uncertainty&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb9-7&#34;&gt;&lt;a href=&#34;#cb9-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#  plot, but this method makes for a prettier plot.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb9-8&#34;&gt;&lt;a href=&#34;#cb9-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;bnn_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp_1d_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb9-9&#34;&gt;&lt;a href=&#34;#cb9-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; y_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mean,&lt;/span&gt;
&lt;span id=&#34;cb9-10&#34;&gt;&lt;a href=&#34;#cb9-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; y_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sd,&lt;/span&gt;
&lt;span id=&#34;cb9-11&#34;&gt;&lt;a href=&#34;#cb9-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb9-12&#34;&gt;&lt;a href=&#34;#cb9-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb9-13&#34;&gt;&lt;a href=&#34;#cb9-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_train,&lt;/span&gt;
&lt;span id=&#34;cb9-14&#34;&gt;&lt;a href=&#34;#cb9-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;true_function =&lt;/span&gt; objective_function&lt;/span&gt;
&lt;span id=&#34;cb9-15&#34;&gt;&lt;a href=&#34;#cb9-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb9-16&#34;&gt;&lt;a href=&#34;#cb9-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb9-17&#34;&gt;&lt;a href=&#34;#cb9-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb9-18&#34;&gt;&lt;a href=&#34;#cb9-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;acquisition_function =&lt;/span&gt; ei_bnn,&lt;/span&gt;
&lt;span id=&#34;cb9-19&#34;&gt;&lt;a href=&#34;#cb9-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;uncertainty_plot =&lt;/span&gt; bnn_plot,&lt;/span&gt;
&lt;span id=&#34;cb9-20&#34;&gt;&lt;a href=&#34;#cb9-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;xt1 =&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei_bnn)],&lt;/span&gt;
&lt;span id=&#34;cb9-21&#34;&gt;&lt;a href=&#34;#cb9-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;label =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;EI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb9-22&#34;&gt;&lt;a href=&#34;#cb9-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Bayesian Neural Network Surrogate&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb9-23&#34;&gt;&lt;a href=&#34;#cb9-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/bnn_plot-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The acquisition function evaluated on the BNN surrogate suggests that the next sampling point should be all the way to the right side of search space, as marked by the dashed line. There is another good candidate near the middle though. This is very similar to the ensemble surrogate above.&lt;/p&gt;
&lt;p&gt;This example demonstrated how to use a BNN as a surrogate model and how to calculate Expected Improvement to select a new sampling point. In a real-world case, we should probably not use Stan and HMC to work with BNNs, as the posterior is extremely difficult to sample. This boils down to the fact that any two units in a layer are interchangeable, so the sampler has to navigate multiple equivalent areas of the posterior. Even the simple example above took a very long time to get working. A better choice would probably be to use specialised NN libraries like Pytorch to build a BNN.&lt;/p&gt;
&lt;h2 id=&#34;bespoke-bayesian-models-as-surrogates&#34; class=&#34;anchored&#34;&gt;Bespoke Bayesian Models as Surrogates&lt;/h2&gt;
&lt;p&gt;In the precious section, we discussed how to build a Bayesian Neural Network using Hamiltonian Monte Carlo (HMC). While it did work, it is not what Stan was built for. Stan was built for applying HMC to bespoke models. In this case, bespoke means models that are uniquely tailored to the underlying generative process of the data.&lt;/p&gt;
&lt;p&gt;When using a GP, we are somewhat limited in the types of objective functions we can model. By combining kernels, we can do a lot to tweak the type of functions a GP surrogate can model, but even then the resulting kernel parameters might be hard to interpret. If we happen to have some prior knowledge about the generative structure of the objective function, then we might be able to leverage that to create a surrogate that is parametrised in an interpretable way. In the context of Bayesian optimisation, it is not often the case that we have such intimate knowledge of the objective process that generated the data. We typically also want to prioritise actual optimisation over obtaining interpretable process knowledge, which is why we apply a general purpose model like a GP.&lt;/p&gt;
&lt;p&gt;If, however, we have knowledge of the generative process and we can turn that knowledge into a bespoke probabilistic model, then we have a very powerful tool for optimisation and interpretation.&lt;/p&gt;
&lt;h4 id=&#34;example-a-bespoke-model-in-stan&#34; class=&#34;anchored&#34;&gt;Example: A Bespoke Model in Stan&lt;/h4&gt;
&lt;p&gt;To demonstrate how to use a bespoke model as a surrogate for Bayesian optimisation, we are going to build one for our running example.&lt;/p&gt;
&lt;p&gt;Building a bespoke model requires some prior, possibly incomplete, knowledge of the process that generated the data. So in this case, we imagine that we know the general form of the objective function, but we have no idea about the value of the constants.&lt;/p&gt;
&lt;p&gt;The model has two general components: a likelihood function as well as priors for any parameters. Let’s start with the likelihood.&lt;/p&gt;
&lt;p&gt;For the likelihood, we assume observations with Gaussian noise&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y \sim \mathcal{N}(\mu, \sigma|\mathbf{X},\alpha,\beta)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is the, possibly known, noise of observations and &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is a function of our training data, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu = \mathbf{X}\sin(\mathbf{X}\alpha) + \beta\mathbf{X}^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; being unknown parameters of the model.&lt;/p&gt;
&lt;p&gt;To complete the model we need priors for &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt;. Without any knowledge of these parameters, this is an impossible task. We also do not have enough data to use very wide priors. This demonstrates the fact that we need fairly extensive knowledge to create a bespoke model.&lt;/p&gt;
&lt;p&gt;To make sure we are not stuck at this point, we will give the parameters some wide priors that somewhat overlap with the truth:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\alpha \sim \mathcal{N}(10,2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\beta \sim \mathcal{N}(2,2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The full model specification in Stan is &lt;a href=&#34;https://github.com/AnHosu/bayes-opt/blob/34f9f02cd39f8b5ea198a246179b0e3fc0eef383/06-surrogate-alternatives/bespoke.stan&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now we can try to condition our model on the training data. While conditioning the model, we also sample posterior predictions on a grid of inputs.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb10&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb10-1&#34;&gt;&lt;a href=&#34;#cb10-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Compile the model&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-2&#34;&gt;&lt;a href=&#34;#cb10-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;model &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rstan&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;stan_model&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;bespoke.stan&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb10-3&#34;&gt;&lt;a href=&#34;#cb10-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Prepare the data&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-4&#34;&gt;&lt;a href=&#34;#cb10-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;data &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb10-5&#34;&gt;&lt;a href=&#34;#cb10-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;N =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]],&lt;/span&gt;
&lt;span id=&#34;cb10-6&#34;&gt;&lt;a href=&#34;#cb10-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;as.vector&lt;/span&gt;(X_train),&lt;/span&gt;
&lt;span id=&#34;cb10-7&#34;&gt;&lt;a href=&#34;#cb10-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;as.vector&lt;/span&gt;(y_train),&lt;/span&gt;
&lt;span id=&#34;cb10-8&#34;&gt;&lt;a href=&#34;#cb10-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;M =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]],&lt;/span&gt;
&lt;span id=&#34;cb10-9&#34;&gt;&lt;a href=&#34;#cb10-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;as.vector&lt;/span&gt;(X_pred),&lt;/span&gt;
&lt;span id=&#34;cb10-10&#34;&gt;&lt;a href=&#34;#cb10-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma_rate =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-11&#34;&gt;&lt;a href=&#34;#cb10-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb10-12&#34;&gt;&lt;a href=&#34;#cb10-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Fit the model using HMC sampling&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-13&#34;&gt;&lt;a href=&#34;#cb10-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;fit &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rstan&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sampling&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb10-14&#34;&gt;&lt;a href=&#34;#cb10-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;object =&lt;/span&gt; model,&lt;/span&gt;
&lt;span id=&#34;cb10-15&#34;&gt;&lt;a href=&#34;#cb10-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; data,&lt;/span&gt;
&lt;span id=&#34;cb10-16&#34;&gt;&lt;a href=&#34;#cb10-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;chains =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb10-17&#34;&gt;&lt;a href=&#34;#cb10-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;cores =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb10-18&#34;&gt;&lt;a href=&#34;#cb10-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;iter =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;10000&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb10-19&#34;&gt;&lt;a href=&#34;#cb10-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;warmup =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4000&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb10-20&#34;&gt;&lt;a href=&#34;#cb10-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;seed =&lt;/span&gt; seed,&lt;/span&gt;
&lt;span id=&#34;cb10-21&#34;&gt;&lt;a href=&#34;#cb10-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;control =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;adapt_delta =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.99&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb10-22&#34;&gt;&lt;a href=&#34;#cb10-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb10-23&#34;&gt;&lt;a href=&#34;#cb10-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Summarize the results&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-24&#34;&gt;&lt;a href=&#34;#cb10-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rstan&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;summary&lt;/span&gt;(fit, &lt;span class=&#34;at&#34;&gt;pars =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;y_pred&#34;&lt;/span&gt;)&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;summary &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-25&#34;&gt;&lt;a href=&#34;#cb10-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;()&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We can use the mean and standard deviation of the posterior predictions to calculate the Expected Improvement acquisition function.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb11&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb11-1&#34;&gt;&lt;a href=&#34;#cb11-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei_besp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb11-2&#34;&gt;&lt;a href=&#34;#cb11-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; y_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mean,&lt;/span&gt;
&lt;span id=&#34;cb11-3&#34;&gt;&lt;a href=&#34;#cb11-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; y_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sd,&lt;/span&gt;
&lt;span id=&#34;cb11-4&#34;&gt;&lt;a href=&#34;#cb11-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_best =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;min&lt;/span&gt;(y_train)&lt;/span&gt;
&lt;span id=&#34;cb11-5&#34;&gt;&lt;a href=&#34;#cb11-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb11-6&#34;&gt;&lt;a href=&#34;#cb11-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;besp_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp_1d_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb11-7&#34;&gt;&lt;a href=&#34;#cb11-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; y_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mean,&lt;/span&gt;
&lt;span id=&#34;cb11-8&#34;&gt;&lt;a href=&#34;#cb11-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; y_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sd,&lt;/span&gt;
&lt;span id=&#34;cb11-9&#34;&gt;&lt;a href=&#34;#cb11-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb11-10&#34;&gt;&lt;a href=&#34;#cb11-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb11-11&#34;&gt;&lt;a href=&#34;#cb11-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_train,&lt;/span&gt;
&lt;span id=&#34;cb11-12&#34;&gt;&lt;a href=&#34;#cb11-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;true_function =&lt;/span&gt; objective_function&lt;/span&gt;
&lt;span id=&#34;cb11-13&#34;&gt;&lt;a href=&#34;#cb11-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb11-14&#34;&gt;&lt;a href=&#34;#cb11-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb11-15&#34;&gt;&lt;a href=&#34;#cb11-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb11-16&#34;&gt;&lt;a href=&#34;#cb11-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;acquisition_function =&lt;/span&gt; ei_besp,&lt;/span&gt;
&lt;span id=&#34;cb11-17&#34;&gt;&lt;a href=&#34;#cb11-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;uncertainty_plot =&lt;/span&gt; besp_plot,&lt;/span&gt;
&lt;span id=&#34;cb11-18&#34;&gt;&lt;a href=&#34;#cb11-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;xt1 =&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei_besp)],&lt;/span&gt;
&lt;span id=&#34;cb11-19&#34;&gt;&lt;a href=&#34;#cb11-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;label =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;EI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb11-20&#34;&gt;&lt;a href=&#34;#cb11-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Bespoke Model Surrogate&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-21&#34;&gt;&lt;a href=&#34;#cb11-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/bespoke_plot-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The acquisition function evaluated on the bespoke surrogate suggests that the next sampling point should be all the way to the right side of search space, as marked by the dashed line.&lt;/p&gt;
&lt;p&gt;This is not our best surrogate so far, but since the model has the same functional structure as the objective function, we expect that we would quickly converge to an interpretable model.&lt;/p&gt;
&lt;p&gt;This example demonstrated how to use a bespoke Bayesian model as a surrogate and how to calculate Expected Improvement to select a new sampling point. In a real-world case, we need to have extensive knowledge of the objective function to use this type of surrogate, but it is a powerful tool to create interpretable models.&lt;/p&gt;
&lt;h2 id=&#34;students-t-processes-as-surrogate-models&#34; class=&#34;anchored&#34;&gt;Student’s t Processes as Surrogate Models&lt;/h2&gt;
&lt;p&gt;While GPs are excellent general-purpose surrogate models, they come with the limitation that they expect observational noise to have a Gaussian distribution. This means that GPs might not be compatible with observations from processes that are prone to outliers or otherwise cause noise with a heavy-tailed distribution &lt;span class=&#34;citation&#34; data-cites=&#34;garnett_bayesoptbook_2023&#34;&gt;[1]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A Student’s t process (TP) can be viewed as a generalisation of a GP. It maintains many of the attractive features of GPs, such as a closed form for marginal and conditional distributions, and the ability to specify a covariance function directly, while offering additional advantages over GPs &lt;span class=&#34;citation&#34; data-cites=&#34;Shah2014&#34;&gt;[2]&lt;/span&gt;. One such advantage of the TP is its ability to model observations with heavy-tailed noise. In practice, this means that TPs can be robust to outliers or unexpected events that would disproportionately affect a GP &lt;span class=&#34;citation&#34; data-cites=&#34;Tracey2018&#34;&gt;[3]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A TP does not solve all problems, as there will exist cases where the observational noise is not compatible with neither a GP nor a TP. However, by applying a TP as surrogate model for Bayesian optimisation, we might better capture uncertainty when we have few data points or have extreme variations in data. This property can be particularly valuable when the noise in the data is not well-behaved or when the objective process is prone to abrupt, unpredictable changes.&lt;/p&gt;
&lt;h4 id=&#34;implementing-a-students-t-process&#34; class=&#34;anchored&#34;&gt;Implementing a Student’s t Process&lt;/h4&gt;
&lt;p&gt;The multivariate Student’s t distribution is parametrised by a mean function, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, a shape parameter, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\Sigma}\)&lt;/span&gt;, which is related to the covariance matrix, and the degrees of freedom, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To implement a TP, we need two things: an expression for the negative log likelihood, so we can optimise hyperparameters of the process, and an expression for the posterior predictive distribution parameters, so we can generate predictions. Once we have the TP, we then need an acquisition function. Fortunately, a closed form for Expected Improvement also exists for TPs.&lt;/p&gt;
&lt;p&gt;Since the focus of this post is the application of surrogate models, we will just quickly review the expressions for these components. This does mean that we will be making some tacit assumptions. For a comprehensive treatment of TPs, see &lt;span class=&#34;citation&#34; data-cites=&#34;Shah2014&#34;&gt;[2]&lt;/span&gt;, &lt;span class=&#34;citation&#34; data-cites=&#34;Tang2017&#34;&gt;[4]&lt;/span&gt;, and &lt;span class=&#34;citation&#34; data-cites=&#34;Tracey2018&#34;&gt;[3]&lt;/span&gt;.&lt;/p&gt;
&lt;h5 id=&#34;covariance-matrix-in-students-t-processes&#34; class=&#34;anchored&#34;&gt;Covariance Matrix in Student’s t Processes&lt;/h5&gt;
&lt;p&gt;GPs are parametrised directly by a covariance matrix, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{K}\)&lt;/span&gt;, which is built from evaluation of pairs of input vectors:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[K_{ij} = k(\mathbf{x}_i,\mathbf{x}_j)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is a &lt;a href=&#34;.../kernels-r&#34;&gt;kernel function&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;TPs are a little bit different. Specifically, TPs are parametrised by a shape parameter, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\Sigma}\)&lt;/span&gt;, which is a scaled covariance matrix &lt;span class=&#34;citation&#34; data-cites=&#34;Tracey2018&#34;&gt;[3]&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathbf{\Sigma} = \frac{\nu}{(\nu - 2)}\mathbf{K}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When calculating the log likelihood and posterior covariance of a GP, we often add noise to the diagonal of the covariance matrix to represent noise in observations. This same trick is not possible for TPs.&lt;/p&gt;
&lt;p&gt;To account for observational noise in a TP, we instead add noise within the kernel function, as if we were adding a white noise kernel with a fixed parameter. This is not equivalent to the GP way of accounting for the noise, since it happens before the scaling mentioned above, but for infinite data or infinite &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; prior, the two are equivalent &lt;span class=&#34;citation&#34; data-cites=&#34;Shah2014&#34;&gt;[2]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In the definitions below, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\Sigma}\)&lt;/span&gt; represents the scaled covariance matrix, possibly with added noise using this trick, and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{K}\)&lt;/span&gt; represents the regular covariance matrix.&lt;/p&gt;
&lt;h5 id=&#34;posterior-predictive-multivariate-students-t&#34; class=&#34;anchored&#34;&gt;Posterior Predictive Multivariate Student’s t&lt;/h5&gt;
&lt;p&gt;Given a set of training data, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_t, \mathbf{y}_t\)&lt;/span&gt;, and set of points on which to make predictions, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{X}_p\)&lt;/span&gt;, the mean of the posterior predictive distribution is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathbf{\mu}_{p|t} = \mathbf{K}_{tp}^T \mathbf{K}_{tt}^{-1} \mathbf{y}_t\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\Sigma}_{tp}\)&lt;/span&gt; is the covariance matrix between training and prediction points and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\Sigma}_{tt}\)&lt;/span&gt; is the covariance matrix between training points. We have also assumed a zero mean function &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\mu} = \mathbf{0}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The covariance matrix of the posterior predictive distribution is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathbf{\Sigma}_{p|t} = \frac{\nu_{prior}}{\nu_{prior} - 2}\frac{\nu_{prior} - \mathbf{y}_t^T\mathbf{K}_{tt}^{-1}\mathbf{y}_t - 2}{\nu_{prior} + n_t - 2 }(\mathbf{K}_{pp} - \mathbf{K}_{tp}^T \mathbf{K}_{tt}^{-1} \mathbf{K}_{tp})\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{K}_{pp}\)&lt;/span&gt; is the covariance matrix between prediction points, &lt;span class=&#34;math inline&#34;&gt;\(n_t\)&lt;/span&gt; is the number of training observations, and where we once again assume &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\mu} = \mathbf{0}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Finally, we need the expression for posterior degrees of freedom. We could be conservative and set &lt;span class=&#34;math inline&#34;&gt;\(\nu_{post} = n_{t}\)&lt;/span&gt;, but we will go with the following more lenient expression:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\nu_{post} = \nu_{prior} + n_{t}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The formulas can be implemented directly to calculate each posterior parameter&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb12&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb12-1&#34;&gt;&lt;a href=&#34;#cb12-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Get Parameters of the Posterior Student&#39;s t Process&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-2&#34;&gt;&lt;a href=&#34;#cb12-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-3&#34;&gt;&lt;a href=&#34;#cb12-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function used for the Student&#39;s t process&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-4&#34;&gt;&lt;a href=&#34;#cb12-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_pred matrix (m, d) of prediction points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-5&#34;&gt;&lt;a href=&#34;#cb12-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-6&#34;&gt;&lt;a href=&#34;#cb12-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-7&#34;&gt;&lt;a href=&#34;#cb12-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param nu scalar, prior degrees of freedom. Note that nu + n must be greater&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-8&#34;&gt;&lt;a href=&#34;#cb12-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; than 2.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-9&#34;&gt;&lt;a href=&#34;#cb12-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise. The noise will be added to the&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-10&#34;&gt;&lt;a href=&#34;#cb12-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; covariance matrix for observations, as if it were a white noise kernel.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-11&#34;&gt;&lt;a href=&#34;#cb12-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param ... named parameters for the kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-12&#34;&gt;&lt;a href=&#34;#cb12-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-13&#34;&gt;&lt;a href=&#34;#cb12-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return list of mean (mu), covariance (sigma), and degrees of freedom (nu)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-14&#34;&gt;&lt;a href=&#34;#cb12-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; for a posterior multivariate Student&#39;s t distribution&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-15&#34;&gt;&lt;a href=&#34;#cb12-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;posterior_t &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel,&lt;/span&gt;
&lt;span id=&#34;cb12-16&#34;&gt;&lt;a href=&#34;#cb12-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                        X_pred,&lt;/span&gt;
&lt;span id=&#34;cb12-17&#34;&gt;&lt;a href=&#34;#cb12-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                        X_train,&lt;/span&gt;
&lt;span id=&#34;cb12-18&#34;&gt;&lt;a href=&#34;#cb12-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                        y_train,&lt;/span&gt;
&lt;span id=&#34;cb12-19&#34;&gt;&lt;a href=&#34;#cb12-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                        nu,&lt;/span&gt;
&lt;span id=&#34;cb12-20&#34;&gt;&lt;a href=&#34;#cb12-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                        &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt;, ...) {&lt;/span&gt;
&lt;span id=&#34;cb12-21&#34;&gt;&lt;a href=&#34;#cb12-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X_pred), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb12-22&#34;&gt;&lt;a href=&#34;#cb12-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X_train), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb12-23&#34;&gt;&lt;a href=&#34;#cb12-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(y_train))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(y_train) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(y_train), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb12-24&#34;&gt;&lt;a href=&#34;#cb12-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  n_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]]&lt;/span&gt;
&lt;span id=&#34;cb12-25&#34;&gt;&lt;a href=&#34;#cb12-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (nu &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; n_train &lt;span class=&#34;sc&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb12-26&#34;&gt;&lt;a href=&#34;#cb12-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb12-27&#34;&gt;&lt;a href=&#34;#cb12-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;st&#34;&gt;&#34;The prior degrees of freedom plus the number of training points &#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb12-28&#34;&gt;&lt;a href=&#34;#cb12-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;st&#34;&gt;&#34;must be greater than 2.&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-29&#34;&gt;&lt;a href=&#34;#cb12-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb12-30&#34;&gt;&lt;a href=&#34;#cb12-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb12-31&#34;&gt;&lt;a href=&#34;#cb12-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_train, X_train, ...) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;
&lt;span id=&#34;cb12-32&#34;&gt;&lt;a href=&#34;#cb12-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_s &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_train, X_pred, ...)&lt;/span&gt;
&lt;span id=&#34;cb12-33&#34;&gt;&lt;a href=&#34;#cb12-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_ss &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_pred, X_pred, ...) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;
&lt;span id=&#34;cb12-34&#34;&gt;&lt;a href=&#34;#cb12-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_inv &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;solve&lt;/span&gt;(K)&lt;/span&gt;
&lt;span id=&#34;cb12-35&#34;&gt;&lt;a href=&#34;#cb12-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(K_s) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_inv) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; y_train&lt;/span&gt;
&lt;span id=&#34;cb12-36&#34;&gt;&lt;a href=&#34;#cb12-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_tilde &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; K_ss &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(K_s) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_inv) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_s&lt;/span&gt;
&lt;span id=&#34;cb12-37&#34;&gt;&lt;a href=&#34;#cb12-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  scale &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; ((&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(y_train) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_inv) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; y_train &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; nu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; (nu &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; n_train &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb12-38&#34;&gt;&lt;a href=&#34;#cb12-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; K_tilde &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;as.vector&lt;/span&gt;(scale)&lt;/span&gt;
&lt;span id=&#34;cb12-39&#34;&gt;&lt;a href=&#34;#cb12-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; (nu &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; (nu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)), &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; n_train &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; nu)&lt;/span&gt;
&lt;span id=&#34;cb12-40&#34;&gt;&lt;a href=&#34;#cb12-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h5 id=&#34;log-likelihood-for-a-students-t-process&#34; class=&#34;anchored&#34;&gt;Log Likelihood for a Student’s t Process&lt;/h5&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\Sigma}\)&lt;/span&gt; is calculated using a kernel function with parameters, &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;. Analogous to Gaussian process regression, we find good values for these parameters by minimising the negative log likelihood in what is called Student’s t process regression.&lt;/p&gt;
&lt;p&gt;The log likelihood likelihood function for a TP is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned} \log p(\mathbf{y}_t \mid \mathbf{X}_t, \theta) =\,&amp;amp; \log\Gamma\left(\frac{\nu_{prior} + d}{2}\right) \\\ &amp;amp;- \log\Gamma\left(\frac{\nu_{prior}}{2}\right) \\\ &amp;amp;- \frac{1}{2}\log\det (\mathbf{\Sigma}_{tt}) \\\ &amp;amp;- \frac{1}{2}(\nu_{prior}+d)\log\left(1+\frac{\mathbf{y}_t^T (\mathbf{\Sigma}_{tt})^{-1} \mathbf{y}_t}{\nu_{prior}}\right) \\\ &amp;amp;- \frac{1}{2}d \log(\nu_{prior}\pi) \end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(\nu_{prior}\)&lt;/span&gt; is the prior degrees of freedom, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the number of dimensions of the distribution, and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{\Sigma}_{tt}\)&lt;/span&gt; is the scaled covariance matrix between training points &lt;span class=&#34;citation&#34; data-cites=&#34;Rasmussen:2006&#34;&gt;[5]&lt;/span&gt; &lt;span class=&#34;citation&#34; data-cites=&#34;Tracey2018&#34;&gt;[3]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Despite being in the logarithmic domain, the log likelihood is still numerically challenged. To create a robust implementation we build an algorithm inspired by the one presented for GPs in chapter 2 of &lt;span class=&#34;citation&#34; data-cites=&#34;Rasmussen:2006&#34;&gt;[5]&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb13&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb13-1&#34;&gt;&lt;a href=&#34;#cb13-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Student&#39;s t Negative log-Likelihood of a Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-2&#34;&gt;&lt;a href=&#34;#cb13-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-3&#34;&gt;&lt;a href=&#34;#cb13-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-4&#34;&gt;&lt;a href=&#34;#cb13-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-5&#34;&gt;&lt;a href=&#34;#cb13-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-6&#34;&gt;&lt;a href=&#34;#cb13-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param nu scalar, degrees of freedom&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-7&#34;&gt;&lt;a href=&#34;#cb13-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-8&#34;&gt;&lt;a href=&#34;#cb13-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-9&#34;&gt;&lt;a href=&#34;#cb13-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return function with kernel parameters as input and negative log likelihood&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-10&#34;&gt;&lt;a href=&#34;#cb13-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; as output&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-11&#34;&gt;&lt;a href=&#34;#cb13-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;nll_t &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, X_train, y_train, nu, noise) {&lt;/span&gt;
&lt;span id=&#34;cb13-12&#34;&gt;&lt;a href=&#34;#cb13-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(params) {&lt;/span&gt;
&lt;span id=&#34;cb13-13&#34;&gt;&lt;a href=&#34;#cb13-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    n &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]]&lt;/span&gt;
&lt;span id=&#34;cb13-14&#34;&gt;&lt;a href=&#34;#cb13-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    d &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;]]&lt;/span&gt;
&lt;span id=&#34;cb13-15&#34;&gt;&lt;a href=&#34;#cb13-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    L &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(kernel, &lt;span class=&#34;at&#34;&gt;X1 =&lt;/span&gt; X_train, &lt;span class=&#34;at&#34;&gt;X2 =&lt;/span&gt; X_train, &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;params) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-16&#34;&gt;&lt;a href=&#34;#cb13-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(noise&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(n)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-17&#34;&gt;&lt;a href=&#34;#cb13-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;multiply_by&lt;/span&gt;(nu &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; (nu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-18&#34;&gt;&lt;a href=&#34;#cb13-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;chol&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb13-19&#34;&gt;&lt;a href=&#34;#cb13-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    logdet &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;sum&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;log&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(L)))&lt;/span&gt;
&lt;span id=&#34;cb13-20&#34;&gt;&lt;a href=&#34;#cb13-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    a &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;backsolve&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;r =&lt;/span&gt; L, &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;forwardsolve&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(L), &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; y_train))&lt;/span&gt;
&lt;span id=&#34;cb13-21&#34;&gt;&lt;a href=&#34;#cb13-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    beta &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(y_train) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; a&lt;/span&gt;
&lt;span id=&#34;cb13-22&#34;&gt;&lt;a href=&#34;#cb13-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    (d &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;log&lt;/span&gt;(nu &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; pi) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; logdet &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; (nu &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; d) &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;log&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; beta &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; nu)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-23&#34;&gt;&lt;a href=&#34;#cb13-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;multiply_by&lt;/span&gt;(&lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-24&#34;&gt;&lt;a href=&#34;#cb13-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;lgamma&lt;/span&gt;(nu &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;lgamma&lt;/span&gt;((nu &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; d) &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb13-25&#34;&gt;&lt;a href=&#34;#cb13-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb13-26&#34;&gt;&lt;a href=&#34;#cb13-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h5 id=&#34;students-t-process-regression&#34; class=&#34;anchored&#34;&gt;Student’s t Process Regression&lt;/h5&gt;
&lt;p&gt;We are now ready to implement regression with TPs. For a kernel with parameters &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, we apply an optimiser to find the parameter values, &lt;span class=&#34;math inline&#34;&gt;\(\theta^+\)&lt;/span&gt;, that minimise the negative log likelihood&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\theta^+ = \arg\min_{\theta}(-\log p(\mathbf{y}_t \mid \mathbf{X}_t, \theta))\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We then condition the resulting TP on our training data and create an expression for the predictive posterior.&lt;/p&gt;
&lt;p&gt;Minimising the negative log likelihood for a TP can be somewhat tricky. In the following implementation, the optimiser is restarted multiple times to reduce the risk of getting stuck in a local minimum. While this method will work for the simple examples below, more robust approaches are needed for real life problems with higher dimensionality, more complex kernels, or more observations.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb14&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb14-1&#34;&gt;&lt;a href=&#34;#cb14-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Student&#39;s t Process Regression&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-2&#34;&gt;&lt;a href=&#34;#cb14-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-3&#34;&gt;&lt;a href=&#34;#cb14-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-4&#34;&gt;&lt;a href=&#34;#cb14-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-5&#34;&gt;&lt;a href=&#34;#cb14-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-6&#34;&gt;&lt;a href=&#34;#cb14-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param nu initial degrees of freedom&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-7&#34;&gt;&lt;a href=&#34;#cb14-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-8&#34;&gt;&lt;a href=&#34;#cb14-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param ... parameters of the kernel function with initial guesses. Due to the&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-9&#34;&gt;&lt;a href=&#34;#cb14-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; optimiser used, all parameters must be given and the order unfortunately&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-10&#34;&gt;&lt;a href=&#34;#cb14-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; matters&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-11&#34;&gt;&lt;a href=&#34;#cb14-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-12&#34;&gt;&lt;a href=&#34;#cb14-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return function that takes a matrix of prediction points as input and&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-13&#34;&gt;&lt;a href=&#34;#cb14-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; returns the posterior predictive distribution for the output&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-14&#34;&gt;&lt;a href=&#34;#cb14-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tpr &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, X_train, y_train, &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt;, ...) {&lt;/span&gt;
&lt;span id=&#34;cb14-15&#34;&gt;&lt;a href=&#34;#cb14-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (nu &lt;span class=&#34;sc&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;) &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;nu must be &amp;gt; 2&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb14-16&#34;&gt;&lt;a href=&#34;#cb14-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  kernel_nll &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;nll_t&lt;/span&gt;(kernel, X_train, y_train, nu, noise)&lt;/span&gt;
&lt;span id=&#34;cb14-17&#34;&gt;&lt;a href=&#34;#cb14-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  param &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(...)&lt;/span&gt;
&lt;span id=&#34;cb14-18&#34;&gt;&lt;a href=&#34;#cb14-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;co&#34;&gt;# We do multiple restarts of the optimiser to avoid getting stuck in local&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-19&#34;&gt;&lt;a href=&#34;#cb14-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;co&#34;&gt;#  minima.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-20&#34;&gt;&lt;a href=&#34;#cb14-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  opt_params &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;50&lt;/span&gt;, &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(i) {&lt;/span&gt;
&lt;span id=&#34;cb14-21&#34;&gt;&lt;a href=&#34;#cb14-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;optim&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;par =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rexp&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(param), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;at&#34;&gt;fn =&lt;/span&gt; kernel_nll, &lt;span class=&#34;at&#34;&gt;method =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;BFGS&#34;&lt;/span&gt;)&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;par&lt;/span&gt;
&lt;span id=&#34;cb14-22&#34;&gt;&lt;a href=&#34;#cb14-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  })&lt;/span&gt;
&lt;span id=&#34;cb14-23&#34;&gt;&lt;a href=&#34;#cb14-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  nll_vals &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map_dbl&lt;/span&gt;(opt_params, kernel_nll)&lt;/span&gt;
&lt;span id=&#34;cb14-24&#34;&gt;&lt;a href=&#34;#cb14-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  opt_param &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; opt_params[[&lt;span class=&#34;fu&#34;&gt;which.min&lt;/span&gt;(nll_vals)]]&lt;/span&gt;
&lt;span id=&#34;cb14-25&#34;&gt;&lt;a href=&#34;#cb14-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X_pred) {&lt;/span&gt;
&lt;span id=&#34;cb14-26&#34;&gt;&lt;a href=&#34;#cb14-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-27&#34;&gt;&lt;a href=&#34;#cb14-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      posterior_t,&lt;/span&gt;
&lt;span id=&#34;cb14-28&#34;&gt;&lt;a href=&#34;#cb14-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;kernel =&lt;/span&gt; kernel,&lt;/span&gt;
&lt;span id=&#34;cb14-29&#34;&gt;&lt;a href=&#34;#cb14-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb14-30&#34;&gt;&lt;a href=&#34;#cb14-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb14-31&#34;&gt;&lt;a href=&#34;#cb14-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_train,&lt;/span&gt;
&lt;span id=&#34;cb14-32&#34;&gt;&lt;a href=&#34;#cb14-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; nu,&lt;/span&gt;
&lt;span id=&#34;cb14-33&#34;&gt;&lt;a href=&#34;#cb14-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; noise,&lt;/span&gt;
&lt;span id=&#34;cb14-34&#34;&gt;&lt;a href=&#34;#cb14-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;opt_param&lt;/span&gt;
&lt;span id=&#34;cb14-35&#34;&gt;&lt;a href=&#34;#cb14-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb14-36&#34;&gt;&lt;a href=&#34;#cb14-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-37&#34;&gt;&lt;a href=&#34;#cb14-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu,&lt;/span&gt;
&lt;span id=&#34;cb14-38&#34;&gt;&lt;a href=&#34;#cb14-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma),&lt;/span&gt;
&lt;span id=&#34;cb14-39&#34;&gt;&lt;a href=&#34;#cb14-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;Sigma =&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma,&lt;/span&gt;
&lt;span id=&#34;cb14-40&#34;&gt;&lt;a href=&#34;#cb14-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;nu,&lt;/span&gt;
&lt;span id=&#34;cb14-41&#34;&gt;&lt;a href=&#34;#cb14-41&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;parameters =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;set_names&lt;/span&gt;(opt_param, &lt;span class=&#34;fu&#34;&gt;names&lt;/span&gt;(param))&lt;/span&gt;
&lt;span id=&#34;cb14-42&#34;&gt;&lt;a href=&#34;#cb14-42&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb14-43&#34;&gt;&lt;a href=&#34;#cb14-43&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb14-44&#34;&gt;&lt;a href=&#34;#cb14-44&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h5 id=&#34;expected-improvement-for-a-students-t-process&#34; class=&#34;anchored&#34;&gt;Expected Improvement for a Student’s t Process&lt;/h5&gt;
&lt;p&gt;Now that we have an expression for the posterior predictive of a TP, the only component missing for Bayesian optimisation is an acquisition function.&lt;/p&gt;
&lt;p&gt;When using a TP surrogate model, Expected Improvement can be calculated using the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}a_{EI}(\mathbf{x}) =\,&amp;amp; (y_{min} - \mu(\mathbf{x}) - \xi) \Lambda_{\nu_{post}}(Z) \\ &amp;amp;+\, \sigma(\mathbf{x})\frac{\nu_{post}}{\nu_{post}-1}(1+\frac{Z^2}{\nu_{post}})\lambda_{\nu_{post}}(Z)\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Z = \frac{y_{min} - \mu(\mathbf{x}) - \xi}{\sigma(\mathbf{x})}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu(\mathbf{x})\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma(\mathbf{x})\)&lt;/span&gt; are the posterior predictive mean and scale parameters of the TP at &lt;span class=&#34;math inline&#34;&gt;\(\mathbf{x}\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(\nu_{post}\)&lt;/span&gt; is the posterior degrees of freedom. &lt;span class=&#34;math inline&#34;&gt;\(\Lambda_{\nu_{post}}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\lambda_{\nu_{post}}\)&lt;/span&gt; are the standard Student’s t cumulative distribution function and probability density function with &lt;span class=&#34;math inline&#34;&gt;\(\nu_{post}\)&lt;/span&gt; degrees of freedom, respectively. &lt;span class=&#34;math inline&#34;&gt;\(y_{min}\)&lt;/span&gt; is the best observation seen so far &lt;span class=&#34;citation&#34; data-cites=&#34;Shah2014&#34;&gt;[2]&lt;/span&gt; &lt;span class=&#34;citation&#34; data-cites=&#34;Tracey2018&#34;&gt;[3]&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(\xi\)&lt;/span&gt; is a trade-off parameter that balances exploration and exploitation.&lt;/p&gt;
&lt;p&gt;We implement these formulas along with a nice plot.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;p&gt;&lt;/p&gt;&lt;details&gt;
&lt;summary&gt;Show the code&lt;/summary&gt;&lt;p&gt;&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb15&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb15-1&#34;&gt;&lt;a href=&#34;#cb15-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Density Function of Location-Scale Student&#39;s t Distribution&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-2&#34;&gt;&lt;a href=&#34;#cb15-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-3&#34;&gt;&lt;a href=&#34;#cb15-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param x vector of quantiles&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-4&#34;&gt;&lt;a href=&#34;#cb15-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param mu mean&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-5&#34;&gt;&lt;a href=&#34;#cb15-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma standard deviation&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-6&#34;&gt;&lt;a href=&#34;#cb15-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param nu degrees of freedom&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-7&#34;&gt;&lt;a href=&#34;#cb15-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-8&#34;&gt;&lt;a href=&#34;#cb15-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return density&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-9&#34;&gt;&lt;a href=&#34;#cb15-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;dst &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(x, &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb15-10&#34;&gt;&lt;a href=&#34;#cb15-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; sigma &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dt&lt;/span&gt;((x &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; mu) &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; sigma, nu)&lt;/span&gt;
&lt;span id=&#34;cb15-11&#34;&gt;&lt;a href=&#34;#cb15-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb15-12&#34;&gt;&lt;a href=&#34;#cb15-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-13&#34;&gt;&lt;a href=&#34;#cb15-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Distribution Function of Location-Scale Student&#39;s t Distribution&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-14&#34;&gt;&lt;a href=&#34;#cb15-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-15&#34;&gt;&lt;a href=&#34;#cb15-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param q vector of quantiles&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-16&#34;&gt;&lt;a href=&#34;#cb15-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param mu mean&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-17&#34;&gt;&lt;a href=&#34;#cb15-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma standard deviation&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-18&#34;&gt;&lt;a href=&#34;#cb15-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param nu degrees of freedom&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-19&#34;&gt;&lt;a href=&#34;#cb15-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-20&#34;&gt;&lt;a href=&#34;#cb15-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return distribution&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-21&#34;&gt;&lt;a href=&#34;#cb15-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;pst &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(q, &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)  &lt;span class=&#34;fu&#34;&gt;pt&lt;/span&gt;((q &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; mu) &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; sigma, nu)&lt;/span&gt;
&lt;span id=&#34;cb15-22&#34;&gt;&lt;a href=&#34;#cb15-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-23&#34;&gt;&lt;a href=&#34;#cb15-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Quantile Function of Location-Scale Student&#39;s t Distribution&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-24&#34;&gt;&lt;a href=&#34;#cb15-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-25&#34;&gt;&lt;a href=&#34;#cb15-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param p vector of probabilities&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-26&#34;&gt;&lt;a href=&#34;#cb15-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param mu mean&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-27&#34;&gt;&lt;a href=&#34;#cb15-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma standard deviation&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-28&#34;&gt;&lt;a href=&#34;#cb15-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param nu degrees of freedom&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-29&#34;&gt;&lt;a href=&#34;#cb15-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-30&#34;&gt;&lt;a href=&#34;#cb15-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return distribution&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-31&#34;&gt;&lt;a href=&#34;#cb15-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;qst &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(p, &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)  &lt;span class=&#34;fu&#34;&gt;qt&lt;/span&gt;(p, nu) &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; sigma &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; mu&lt;/span&gt;
&lt;span id=&#34;cb15-32&#34;&gt;&lt;a href=&#34;#cb15-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-33&#34;&gt;&lt;a href=&#34;#cb15-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Expected Improvement Acquisition Function for a Student&#39;s t Surrogate&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-34&#34;&gt;&lt;a href=&#34;#cb15-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-35&#34;&gt;&lt;a href=&#34;#cb15-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param mu vector of length m. Mean of a Student&#39;s t process at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-36&#34;&gt;&lt;a href=&#34;#cb15-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma vector of length m. The diagonal of the covariance matrix of a&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-37&#34;&gt;&lt;a href=&#34;#cb15-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Student&#39;s t process evaluated at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-38&#34;&gt;&lt;a href=&#34;#cb15-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param nu scalar, degrees of freedom.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-39&#34;&gt;&lt;a href=&#34;#cb15-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_best scalar. Best mean prediction so far on observed points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-40&#34;&gt;&lt;a href=&#34;#cb15-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param xi scalar, exploration/exploitation trade off&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-41&#34;&gt;&lt;a href=&#34;#cb15-41&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param task one of &#34;max&#34; or &#34;min&#34;, indicating the optimisation problem&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-42&#34;&gt;&lt;a href=&#34;#cb15-42&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-43&#34;&gt;&lt;a href=&#34;#cb15-43&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return EI, vector of length m&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-44&#34;&gt;&lt;a href=&#34;#cb15-44&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;expected_improvement_t &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(mu,&lt;/span&gt;
&lt;span id=&#34;cb15-45&#34;&gt;&lt;a href=&#34;#cb15-45&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                   sigma,&lt;/span&gt;
&lt;span id=&#34;cb15-46&#34;&gt;&lt;a href=&#34;#cb15-46&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                   nu,&lt;/span&gt;
&lt;span id=&#34;cb15-47&#34;&gt;&lt;a href=&#34;#cb15-47&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                   y_best,&lt;/span&gt;
&lt;span id=&#34;cb15-48&#34;&gt;&lt;a href=&#34;#cb15-48&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                   &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.01&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb15-49&#34;&gt;&lt;a href=&#34;#cb15-49&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                   &lt;span class=&#34;at&#34;&gt;task =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;min&#34;&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb15-50&#34;&gt;&lt;a href=&#34;#cb15-50&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (task &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;min&#34;&lt;/span&gt;) imp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; y_best &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; xi&lt;/span&gt;
&lt;span id=&#34;cb15-51&#34;&gt;&lt;a href=&#34;#cb15-51&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (task &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;max&#34;&lt;/span&gt;) imp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; y_best &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; xi&lt;/span&gt;
&lt;span id=&#34;cb15-52&#34;&gt;&lt;a href=&#34;#cb15-52&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(imp)) &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#39;task must be &#34;min&#34; or &#34;max&#34;&#39;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb15-53&#34;&gt;&lt;a href=&#34;#cb15-53&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  Z &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; imp &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; sigma&lt;/span&gt;
&lt;span id=&#34;cb15-54&#34;&gt;&lt;a href=&#34;#cb15-54&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  scaled_sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; sigma &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; (&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; (Z&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt;(nu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb15-55&#34;&gt;&lt;a href=&#34;#cb15-55&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; imp &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;pst&lt;/span&gt;(Z, &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; nu) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; scaled_sigma &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dst&lt;/span&gt;(Z, &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; nu)&lt;/span&gt;
&lt;span id=&#34;cb15-56&#34;&gt;&lt;a href=&#34;#cb15-56&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei[sigma &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.0&lt;/span&gt;] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-57&#34;&gt;&lt;a href=&#34;#cb15-57&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei&lt;/span&gt;
&lt;span id=&#34;cb15-58&#34;&gt;&lt;a href=&#34;#cb15-58&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb15-59&#34;&gt;&lt;a href=&#34;#cb15-59&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-60&#34;&gt;&lt;a href=&#34;#cb15-60&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param mu vector of length m. Mean of a Student&#39;s t process at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-61&#34;&gt;&lt;a href=&#34;#cb15-61&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma vector of length m. The diagonal of the covariance matrix of a&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-62&#34;&gt;&lt;a href=&#34;#cb15-62&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Student&#39;s t process evaluated at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-63&#34;&gt;&lt;a href=&#34;#cb15-63&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param nu scalar, degrees of freedom.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-64&#34;&gt;&lt;a href=&#34;#cb15-64&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_pred matrix of dimensions (m X 1) representing m prediction points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-65&#34;&gt;&lt;a href=&#34;#cb15-65&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; with one dimension.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-66&#34;&gt;&lt;a href=&#34;#cb15-66&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix of dimensions (n X 1) representing n training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-67&#34;&gt;&lt;a href=&#34;#cb15-67&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; with one dimension&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-68&#34;&gt;&lt;a href=&#34;#cb15-68&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train vector of length n representing n observations at points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-69&#34;&gt;&lt;a href=&#34;#cb15-69&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; X_train&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-70&#34;&gt;&lt;a href=&#34;#cb15-70&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param true_function function representing the objective function (in real&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-71&#34;&gt;&lt;a href=&#34;#cb15-71&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; life, this function is unknown and cannot be plotted)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-72&#34;&gt;&lt;a href=&#34;#cb15-72&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-73&#34;&gt;&lt;a href=&#34;#cb15-73&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return ggplot2 plot&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-74&#34;&gt;&lt;a href=&#34;#cb15-74&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tp_1d_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(mu,&lt;/span&gt;
&lt;span id=&#34;cb15-75&#34;&gt;&lt;a href=&#34;#cb15-75&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                       sigma,&lt;/span&gt;
&lt;span id=&#34;cb15-76&#34;&gt;&lt;a href=&#34;#cb15-76&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                       nu,&lt;/span&gt;
&lt;span id=&#34;cb15-77&#34;&gt;&lt;a href=&#34;#cb15-77&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                       X_pred,&lt;/span&gt;
&lt;span id=&#34;cb15-78&#34;&gt;&lt;a href=&#34;#cb15-78&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                       X_train,&lt;/span&gt;
&lt;span id=&#34;cb15-79&#34;&gt;&lt;a href=&#34;#cb15-79&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                       y_train,&lt;/span&gt;
&lt;span id=&#34;cb15-80&#34;&gt;&lt;a href=&#34;#cb15-80&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                       true_function) {&lt;/span&gt;
&lt;span id=&#34;cb15-81&#34;&gt;&lt;a href=&#34;#cb15-81&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb15-82&#34;&gt;&lt;a href=&#34;#cb15-82&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb15-83&#34;&gt;&lt;a href=&#34;#cb15-83&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu,&lt;/span&gt;
&lt;span id=&#34;cb15-84&#34;&gt;&lt;a href=&#34;#cb15-84&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma,&lt;/span&gt;
&lt;span id=&#34;cb15-85&#34;&gt;&lt;a href=&#34;#cb15-85&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;upper =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;qst&lt;/span&gt;(&lt;span class=&#34;fl&#34;&gt;0.945&lt;/span&gt;, mu, sigma, nu),&lt;/span&gt;
&lt;span id=&#34;cb15-86&#34;&gt;&lt;a href=&#34;#cb15-86&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;lower =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;qst&lt;/span&gt;(&lt;span class=&#34;fl&#34;&gt;0.055&lt;/span&gt;, mu, sigma, nu),&lt;/span&gt;
&lt;span id=&#34;cb15-87&#34;&gt;&lt;a href=&#34;#cb15-87&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;f =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;true_function&lt;/span&gt;(X_pred)&lt;/span&gt;
&lt;span id=&#34;cb15-88&#34;&gt;&lt;a href=&#34;#cb15-88&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-89&#34;&gt;&lt;a href=&#34;#cb15-89&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-90&#34;&gt;&lt;a href=&#34;#cb15-90&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; mu, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Mean&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-91&#34;&gt;&lt;a href=&#34;#cb15-91&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_ribbon&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb15-92&#34;&gt;&lt;a href=&#34;#cb15-92&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;ymin =&lt;/span&gt; lower, &lt;span class=&#34;at&#34;&gt;ymax =&lt;/span&gt; upper, &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb15-93&#34;&gt;&lt;a href=&#34;#cb15-93&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-94&#34;&gt;&lt;a href=&#34;#cb15-94&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-95&#34;&gt;&lt;a href=&#34;#cb15-95&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb15-96&#34;&gt;&lt;a href=&#34;#cb15-96&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_train, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y_train),&lt;/span&gt;
&lt;span id=&#34;cb15-97&#34;&gt;&lt;a href=&#34;#cb15-97&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y, &lt;span class=&#34;at&#34;&gt;shape =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Training point&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb15-98&#34;&gt;&lt;a href=&#34;#cb15-98&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#fb8500&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb15-99&#34;&gt;&lt;a href=&#34;#cb15-99&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;size =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-100&#34;&gt;&lt;a href=&#34;#cb15-100&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-101&#34;&gt;&lt;a href=&#34;#cb15-101&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;mapping =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; f, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;True function&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-102&#34;&gt;&lt;a href=&#34;#cb15-102&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_shape_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;Training point&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;+&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-103&#34;&gt;&lt;a href=&#34;#cb15-103&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_fill_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#219ebc&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-104&#34;&gt;&lt;a href=&#34;#cb15-104&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;shape =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-105&#34;&gt;&lt;a href=&#34;#cb15-105&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-106&#34;&gt;&lt;a href=&#34;#cb15-106&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb15-107&#34;&gt;&lt;a href=&#34;#cb15-107&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;y&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb15-108&#34;&gt;&lt;a href=&#34;#cb15-108&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb15-109&#34;&gt;&lt;a href=&#34;#cb15-109&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb15-110&#34;&gt;&lt;a href=&#34;#cb15-110&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-111&#34;&gt;&lt;a href=&#34;#cb15-111&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb15-112&#34;&gt;&lt;a href=&#34;#cb15-112&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;panel.grid =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;(), &lt;span class=&#34;at&#34;&gt;axis.text.x =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;())&lt;/span&gt;
&lt;span id=&#34;cb15-113&#34;&gt;&lt;a href=&#34;#cb15-113&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;h4 id=&#34;applying-a-students-t-process&#34; class=&#34;anchored&#34;&gt;Applying a Student’s t Process&lt;/h4&gt;
&lt;p&gt;Now we are finally ready to apply a TP to our running example.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb16&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb16-1&#34;&gt;&lt;a href=&#34;#cb16-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;tpr&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb16-2&#34;&gt;&lt;a href=&#34;#cb16-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;kernel =&lt;/span&gt; rbf_kernel,&lt;/span&gt;
&lt;span id=&#34;cb16-3&#34;&gt;&lt;a href=&#34;#cb16-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb16-4&#34;&gt;&lt;a href=&#34;#cb16-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_train,&lt;/span&gt;
&lt;span id=&#34;cb16-5&#34;&gt;&lt;a href=&#34;#cb16-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb16-6&#34;&gt;&lt;a href=&#34;#cb16-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; noise,&lt;/span&gt;
&lt;span id=&#34;cb16-7&#34;&gt;&lt;a href=&#34;#cb16-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb16-8&#34;&gt;&lt;a href=&#34;#cb16-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-9&#34;&gt;&lt;a href=&#34;#cb16-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb16-10&#34;&gt;&lt;a href=&#34;#cb16-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post_pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;tp&lt;/span&gt;(X_pred)&lt;/span&gt;
&lt;span id=&#34;cb16-11&#34;&gt;&lt;a href=&#34;#cb16-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu&lt;/span&gt;
&lt;span id=&#34;cb16-12&#34;&gt;&lt;a href=&#34;#cb16-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma&lt;/span&gt;
&lt;span id=&#34;cb16-13&#34;&gt;&lt;a href=&#34;#cb16-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;nu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;nu&lt;/span&gt;
&lt;span id=&#34;cb16-14&#34;&gt;&lt;a href=&#34;#cb16-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei_t &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement_t&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb16-15&#34;&gt;&lt;a href=&#34;#cb16-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu,&lt;/span&gt;
&lt;span id=&#34;cb16-16&#34;&gt;&lt;a href=&#34;#cb16-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma,&lt;/span&gt;
&lt;span id=&#34;cb16-17&#34;&gt;&lt;a href=&#34;#cb16-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; nu,&lt;/span&gt;
&lt;span id=&#34;cb16-18&#34;&gt;&lt;a href=&#34;#cb16-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_best =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;min&lt;/span&gt;(y_train)&lt;/span&gt;
&lt;span id=&#34;cb16-19&#34;&gt;&lt;a href=&#34;#cb16-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb16-20&#34;&gt;&lt;a href=&#34;#cb16-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tp_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;tp_1d_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb16-21&#34;&gt;&lt;a href=&#34;#cb16-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu,&lt;/span&gt;
&lt;span id=&#34;cb16-22&#34;&gt;&lt;a href=&#34;#cb16-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma,&lt;/span&gt;
&lt;span id=&#34;cb16-23&#34;&gt;&lt;a href=&#34;#cb16-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; nu,&lt;/span&gt;
&lt;span id=&#34;cb16-24&#34;&gt;&lt;a href=&#34;#cb16-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb16-25&#34;&gt;&lt;a href=&#34;#cb16-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb16-26&#34;&gt;&lt;a href=&#34;#cb16-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_train,&lt;/span&gt;
&lt;span id=&#34;cb16-27&#34;&gt;&lt;a href=&#34;#cb16-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;true_function =&lt;/span&gt; objective_function&lt;/span&gt;
&lt;span id=&#34;cb16-28&#34;&gt;&lt;a href=&#34;#cb16-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb16-29&#34;&gt;&lt;a href=&#34;#cb16-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb16-30&#34;&gt;&lt;a href=&#34;#cb16-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb16-31&#34;&gt;&lt;a href=&#34;#cb16-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;acquisition_function =&lt;/span&gt; ei_t,&lt;/span&gt;
&lt;span id=&#34;cb16-32&#34;&gt;&lt;a href=&#34;#cb16-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;uncertainty_plot =&lt;/span&gt; tp_plot,&lt;/span&gt;
&lt;span id=&#34;cb16-33&#34;&gt;&lt;a href=&#34;#cb16-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;xt1 =&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei_t)],&lt;/span&gt;
&lt;span id=&#34;cb16-34&#34;&gt;&lt;a href=&#34;#cb16-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;label =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;EI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb16-35&#34;&gt;&lt;a href=&#34;#cb16-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Student&#39;s t Process Surrogate&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-36&#34;&gt;&lt;a href=&#34;#cb16-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The acquisition function evaluated on the TP suggests that the next sampling point should be just to the left of the middle, as marked by the dashed line. This pattern is very similar to the one obtained with a GP, demonstrating that the performance of TPs can be very similar to GPs.&lt;/p&gt;
&lt;p&gt;However, the power of TPs lies in resilience to outliers. To demonstrate this, we attempt to apply our TP tp an additional example with much more heavy-tailed non-Gaussian noise.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb17&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb17-1&#34;&gt;&lt;a href=&#34;#cb17-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_extra &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-2&#34;&gt;&lt;a href=&#34;#cb17-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;noise_extra &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.25&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-3&#34;&gt;&lt;a href=&#34;#cb17-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_extra_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;runif&lt;/span&gt;(n_extra), n_extra, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb17-4&#34;&gt;&lt;a href=&#34;#cb17-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Observations with heavy-tailed noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-5&#34;&gt;&lt;a href=&#34;#cb17-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_extra_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;objective_function&lt;/span&gt;(X_extra_train) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-6&#34;&gt;&lt;a href=&#34;#cb17-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(n_extra, &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, noise_extra) &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;sqrt&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rchisq&lt;/span&gt;(n_extra, &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;)))&lt;/span&gt;
&lt;span id=&#34;cb17-7&#34;&gt;&lt;a href=&#34;#cb17-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;tpr&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb17-8&#34;&gt;&lt;a href=&#34;#cb17-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;kernel =&lt;/span&gt; rbf_kernel,&lt;/span&gt;
&lt;span id=&#34;cb17-9&#34;&gt;&lt;a href=&#34;#cb17-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_extra_train,&lt;/span&gt;
&lt;span id=&#34;cb17-10&#34;&gt;&lt;a href=&#34;#cb17-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_extra_train,&lt;/span&gt;
&lt;span id=&#34;cb17-11&#34;&gt;&lt;a href=&#34;#cb17-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb17-12&#34;&gt;&lt;a href=&#34;#cb17-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; noise_extra,&lt;/span&gt;
&lt;span id=&#34;cb17-13&#34;&gt;&lt;a href=&#34;#cb17-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb17-14&#34;&gt;&lt;a href=&#34;#cb17-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-15&#34;&gt;&lt;a href=&#34;#cb17-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb17-16&#34;&gt;&lt;a href=&#34;#cb17-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post_pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;tp&lt;/span&gt;(X_pred)&lt;/span&gt;
&lt;span id=&#34;cb17-17&#34;&gt;&lt;a href=&#34;#cb17-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu&lt;/span&gt;
&lt;span id=&#34;cb17-18&#34;&gt;&lt;a href=&#34;#cb17-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma&lt;/span&gt;
&lt;span id=&#34;cb17-19&#34;&gt;&lt;a href=&#34;#cb17-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;nu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;nu&lt;/span&gt;
&lt;span id=&#34;cb17-20&#34;&gt;&lt;a href=&#34;#cb17-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei_t &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement_t&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb17-21&#34;&gt;&lt;a href=&#34;#cb17-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu,&lt;/span&gt;
&lt;span id=&#34;cb17-22&#34;&gt;&lt;a href=&#34;#cb17-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma,&lt;/span&gt;
&lt;span id=&#34;cb17-23&#34;&gt;&lt;a href=&#34;#cb17-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; nu,&lt;/span&gt;
&lt;span id=&#34;cb17-24&#34;&gt;&lt;a href=&#34;#cb17-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_best =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;min&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;tp&lt;/span&gt;(X_extra_train)&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu)&lt;/span&gt;
&lt;span id=&#34;cb17-25&#34;&gt;&lt;a href=&#34;#cb17-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb17-26&#34;&gt;&lt;a href=&#34;#cb17-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tp_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;tp_1d_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb17-27&#34;&gt;&lt;a href=&#34;#cb17-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu,&lt;/span&gt;
&lt;span id=&#34;cb17-28&#34;&gt;&lt;a href=&#34;#cb17-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma,&lt;/span&gt;
&lt;span id=&#34;cb17-29&#34;&gt;&lt;a href=&#34;#cb17-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; nu,&lt;/span&gt;
&lt;span id=&#34;cb17-30&#34;&gt;&lt;a href=&#34;#cb17-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb17-31&#34;&gt;&lt;a href=&#34;#cb17-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_extra_train,&lt;/span&gt;
&lt;span id=&#34;cb17-32&#34;&gt;&lt;a href=&#34;#cb17-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_extra_train,&lt;/span&gt;
&lt;span id=&#34;cb17-33&#34;&gt;&lt;a href=&#34;#cb17-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;true_function =&lt;/span&gt; objective_function&lt;/span&gt;
&lt;span id=&#34;cb17-34&#34;&gt;&lt;a href=&#34;#cb17-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb17-35&#34;&gt;&lt;a href=&#34;#cb17-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb17-36&#34;&gt;&lt;a href=&#34;#cb17-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb17-37&#34;&gt;&lt;a href=&#34;#cb17-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;acquisition_function =&lt;/span&gt; ei_t,&lt;/span&gt;
&lt;span id=&#34;cb17-38&#34;&gt;&lt;a href=&#34;#cb17-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;uncertainty_plot =&lt;/span&gt; tp_plot,&lt;/span&gt;
&lt;span id=&#34;cb17-39&#34;&gt;&lt;a href=&#34;#cb17-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;xt1 =&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei_t)],&lt;/span&gt;
&lt;span id=&#34;cb17-40&#34;&gt;&lt;a href=&#34;#cb17-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;label =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;EI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb17-41&#34;&gt;&lt;a href=&#34;#cb17-41&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Student&#39;s t Process Surrogate, Heavy-Tailed Noise&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-42&#34;&gt;&lt;a href=&#34;#cb17-42&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Despite the extreme noise, the TP manages a decent fit that can be used for Bayesian optimisation.&lt;/p&gt;
&lt;p&gt;This example demonstrated how to use a Student’s t process as a surrogate and how to calculate Expected Improvement to select a new sampling point. In a real-world case, where noise might be heavy-tailed, a TP might succeed where a GP fails. As more training data is gathered, the posterior of a TP converges to a GP. The only trade-off in using TPs is the additional computational complexity and the fact that there are much fewer tools supporting TPs than there are tools implementing GPs.&lt;/p&gt;
&lt;h1 class=&#34;unnumbered&#34; id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body&#34; role=&#34;doc-bibliography&#34;&gt;
&lt;div id=&#34;ref-garnett_bayesoptbook_2023&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[1] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Garnett&lt;/span&gt;, R. (2023). &lt;em&gt;&lt;span&gt;Bayesian Optimization&lt;/span&gt;&lt;/em&gt;. Cambridge University Press.&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Shah2014&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[2] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Shah&lt;/span&gt;, A., &lt;span class=&#34;smallcaps&#34;&gt;Wilson&lt;/span&gt;, A. and &lt;span class=&#34;smallcaps&#34;&gt;Ghahramani&lt;/span&gt;, Z. (2014). &lt;span class=&#34;nocase&#34;&gt;Student-t Processes as Alternatives to Gaussian Processes&lt;/span&gt;. In &lt;em&gt;Proceedings of the seventeenth international conference on artificial intelligence and statistics&lt;/em&gt; Proceedings of machine learning research vol 33, (S. Kaski and J. Corander, ed) pp 877–85. PMLR, Reykjavik, Iceland Available at &lt;a href=&#34;https://proceedings.mlr.press/v33/shah14.html&#34;&gt;https://proceedings.mlr.press/v33/shah14.html&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Tracey2018&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[3] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Tracey&lt;/span&gt;, B. D. and &lt;span class=&#34;smallcaps&#34;&gt;Wolpert&lt;/span&gt;, D. (2018). Upgrading from gaussian processes to student’s-t processes. In &lt;em&gt;2018 &lt;span&gt;AIAA&lt;/span&gt; non-deterministic approaches conference&lt;/em&gt;. American Institute of Aeronautics; Astronautics Available at &lt;a href=&#34;https://doi.org/10.2514%2F6.2018-1659&#34;&gt;https://doi.org/10.2514%2F6.2018-1659&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Tang2017&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[4] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Tang&lt;/span&gt;, Q., &lt;span class=&#34;smallcaps&#34;&gt;Niu&lt;/span&gt;, L., &lt;span class=&#34;smallcaps&#34;&gt;Wang&lt;/span&gt;, Y., &lt;span class=&#34;smallcaps&#34;&gt;Dai&lt;/span&gt;, T., &lt;span class=&#34;smallcaps&#34;&gt;An&lt;/span&gt;, W., &lt;span class=&#34;smallcaps&#34;&gt;Cai&lt;/span&gt;, J. and &lt;span class=&#34;smallcaps&#34;&gt;Xia&lt;/span&gt;, S.-T. (2017). Student-t process regression with student-t likelihood. In &lt;em&gt;Proceedings of the twenty-sixth international joint conference on artificial intelligence, &lt;span&gt;IJCAI-17&lt;/span&gt;&lt;/em&gt; pp 2822–8 Available at &lt;a href=&#34;https://doi.org/10.24963/ijcai.2017/393&#34;&gt;https://doi.org/10.24963/ijcai.2017/393&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Rasmussen:2006&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[5] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Rasmussen&lt;/span&gt;, C. E. and &lt;span class=&#34;smallcaps&#34;&gt;Williams&lt;/span&gt;, C. K. I. (2006). &lt;em&gt;Gaussian processes for machine learning, chapter 2 &amp;amp; 9&lt;/em&gt;. MIT Press.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;license&#34;&gt;License&lt;/h1&gt;
&lt;p&gt;The content of this project itself is licensed under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International license&lt;/a&gt;, and the underlying code is licensed under the &lt;a href=&#34;https://github.com/AnHosu/bayes-opt/blob/6e25a7a4ec88edac9b55dea2b51382d21030a998/LICENSE&#34;&gt;GNU General Public License v3.0 license&lt;/a&gt;.&lt;/p&gt;
&lt;script type=&#34;application/javascript&#34;&gt;
window.document.addEventListener(&#34;DOMContentLoaded&#34;, function (event) {
  const tabsets =  window.document.querySelectorAll(&#34;.panel-tabset-tabby&#34;)
  tabsets.forEach(function(tabset) {
    const tabby = new Tabby(&#39;#&#39; + tabset.id);
  });
  const icon = &#34;&#34;;
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: &#39;right&#39;,
    icon: icon
  };
  anchorJS.add(&#39;.anchored&#39;);
  const clipboard = new window.ClipboardJS(&#39;.code-copy-button&#39;, {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on(&#39;success&#39;, function(e) {
    // button target
    const button = e.trigger;
    // don&#39;t keep focus
    button.blur();
    // flash &#34;checked&#34;
    button.classList.add(&#39;code-copy-button-checked&#39;);
    setTimeout(function() {
      button.classList.remove(&#39;code-copy-button-checked&#39;);
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: &#39;light-border&#39;,
      placement: &#39;bottom-start&#39;
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-noteref&#34;]&#39;);
  for (var i=0; i&lt;noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute(&#39;href&#39;);
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, &#34;&#34;);
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-biblioref&#34;]&#39;);
  for (var i=0; i&lt;bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute(&#39;data-cites&#39;).split(&#39; &#39;);
    tippyHover(ref, function() {
      var popup = window.document.createElement(&#39;div&#39;);
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement(&#39;div&#39;);
        citeDiv.classList.add(&#39;hanging-indent&#39;);
        citeDiv.classList.add(&#39;csl-entry&#39;);
        var biblioDiv = window.document.getElementById(&#39;ref-&#39; + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
&lt;/script&gt;


&lt;/body&gt;&lt;/html&gt;</description>
    </item>
    
    <item>
      <title>Acquisition Functions for Bayesian Optimisation</title>
      <link>/post/acquisition-functions-r/</link>
      <pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate>
      <guid>/post/acquisition-functions-r/</guid>
      <description>
&lt;!DOCTYPE html&gt;
&lt;html xmlns=&#34;http://www.w3.org/1999/xhtml&#34; lang=&#34;&#34; xml:lang=&#34;&#34;&gt;&lt;head&gt;
  &lt;meta charset=&#34;utf-8&#34;&gt;
  &lt;meta name=&#34;generator&#34; content=&#34;quarto-0.2.243&#34;&gt;
  &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0, user-scalable=yes&#34;&gt;
  &lt;title&gt;index&lt;/title&gt;
  &lt;style&gt;
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre &gt; code.sourceCode { white-space: pre; position: relative; }
    pre &gt; code.sourceCode &gt; span { display: inline-block; line-height: 1.25; }
    pre &gt; code.sourceCode &gt; span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode &gt; span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre &gt; code.sourceCode { white-space: pre-wrap; }
    pre &gt; code.sourceCode &gt; span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code &gt; span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code &gt; span &gt; a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre &gt; code.sourceCode &gt; span &gt; a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  &lt;/style&gt;

  &lt;script src=&#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js&#34;&gt;&lt;/script&gt;
  &lt;script&gt;document.addEventListener(&#34;DOMContentLoaded&#34;, function () {
   var mathElements = document.getElementsByClassName(&#34;math&#34;);
   var macros = [];
   for (var i = 0; i &lt; mathElements.length; i++) {
    var texText = mathElements[i].firstChild;
    if (mathElements[i].tagName == &#34;SPAN&#34;) {
     katex.render(texText.data, mathElements[i], {
      displayMode: mathElements[i].classList.contains(&#39;display&#39;),
      throwOnError: false,
      macros: macros,
      fleqn: false
     });
  }}});
  &lt;/script&gt;
  &lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css&#34;&gt;
  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&#34;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&#34;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
  &lt;script src=&#34;index_files/libs/clipboard/clipboard.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tabby.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/popper.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tippy.umd.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/anchor.min.js&#34;&gt;&lt;/script&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/tippy.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/light-border.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-html.min.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-syntax-highlighting.css&#34; rel=&#34;stylesheet&#34;&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;&lt;a href=&#34;../bayesian-opt-r/&#34;&gt;Bayesian optimisation&lt;/a&gt; is a powerful optimisation technique for black-box functions and processes with expensive evaluations. It is popular for hyperparameter tuning and model selection in machine learning, but has many real-world applications as well. One of the key components of Bayesian optimisation is the acquisition function, which guides the search process by balancing exploration and exploitation of the search space. In this post, we will dive into the role of acquisition functions in Bayesian optimisation and discuss some popular examples.&lt;/p&gt;
&lt;p&gt;Along with the discussion are implementations of each acquisition function in R, using only base R and the Tidyverse.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(ggplot2)&lt;/span&gt;
&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(magrittr)&lt;/span&gt;
&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;set.seed&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;4444&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;acquisition-functions-in-bayesian-optimisation&#34; class=&#34;anchored&#34;&gt;Acquisition Functions in Bayesian Optimisation&lt;/h2&gt;
&lt;p&gt;Bayesian optimisation is an iterative process. It combines a probabilistic surrogate model, often a Gaussian Process (GP), with an acquisition function to select the next point to evaluate in an expensive objective function or process, &lt;span class=&#34;math inline&#34;&gt;f&lt;/span&gt;. The surrogate model captures our current understanding and uncertainty of the objective function, while the acquisition function helps balance the trade-off between exploring new regions of input space and exploiting regions with high predicted performance.&lt;/p&gt;
&lt;p&gt;Mathematically, the acquisition function, &lt;span class=&#34;math inline&#34;&gt;a(\mathbf{x})&lt;/span&gt;, assigns a value to each point in the search space &lt;span class=&#34;math inline&#34;&gt;\mathbf{x} \in \mathcal{X}&lt;/span&gt;. The next point to evaluate, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{t+1}&lt;/span&gt;, is chosen by maximising or minimising the acquisition function, depending on the optimisation task and acquisition function at hand, i.e.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{x}_{t+1} = \arg\min_{\mathbf{x} \in \mathcal{X}} a(\mathbf{x})&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{x}_{t+1} = \arg\max_{\mathbf{x} \in \mathcal{X}} a(\mathbf{x})&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The acquisition function takes into account both the mean &lt;span class=&#34;math inline&#34;&gt;\mu(\mathbf{x})&lt;/span&gt; and the variance &lt;span class=&#34;math inline&#34;&gt;\sigma^2(\mathbf{x})&lt;/span&gt; of the surrogate model’s prediction, to balance exploration and exploitation. Roughly speaking, areas with extreme values of &lt;span class=&#34;math inline&#34;&gt;\mu(\mathbf{x})&lt;/span&gt; correspond to areas we might exploit to get good performing samples, while areas with high values of &lt;span class=&#34;math inline&#34;&gt;\sigma^2(\mathbf{x})&lt;/span&gt; correspond to with high uncertainty that we might consider for exploration.&lt;/p&gt;
&lt;h4 id=&#34;notation&#34; class=&#34;anchored&#34;&gt;Notation&lt;/h4&gt;
&lt;p&gt;The notation used in this post is as follows&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;a(\mathbf{x})&lt;/span&gt; is an acquisition function of a point &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; in the search space &lt;span class=&#34;math inline&#34;&gt;\mathcal{X}&lt;/span&gt;. While the search space often contains multiple feature dimensions &lt;span class=&#34;math inline&#34;&gt;\mathcal{X} \in \mathbb{R}^n&lt;/span&gt;, here the example will be in one dimension.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;f(\mathbf{x})&lt;/span&gt; is the value of true objective function, &lt;span class=&#34;math inline&#34;&gt;f&lt;/span&gt;, at &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt;. It is this function that we aim to optimise. However, the function is not directly available and it is expensive to evaluate so we use a surrogate model to approximate it.&lt;/p&gt;
&lt;p&gt;In most applications, the observations of the objective function are noisy, &lt;span class=&#34;math inline&#34;&gt;y = f(\mathbf{x}) + \epsilon&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\epsilon&lt;/span&gt; is Gaussian noise. So we will use &lt;span class=&#34;math inline&#34;&gt;\mathbf{y}&lt;/span&gt; to indicate observations.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;f(\mathbf{x}^+)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;f_{\min}&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;f_{\max}&lt;/span&gt; all represent the best observed value of the objective function so far. If the observations are noisy, the corresponding notation is &lt;span class=&#34;math inline&#34;&gt;y^+&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;y_{\min}&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;y_{\max}&lt;/span&gt;. For most examples of acquisition functions, this post focuses on minimisation problems, where the best observed value is &lt;span class=&#34;math inline&#34;&gt;y_{\min}&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\mathcal{D}&lt;/span&gt; is a set of training observations &lt;span class=&#34;math inline&#34;&gt;(\mathbf{X}_{train}, \mathbf{y}_{train})&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\mu(\mathbf{x})&lt;/span&gt; represents the mean prediction of the surrogate model at point &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\sigma(\mathbf{x})&lt;/span&gt; represents the standard deviation (uncertainty) of the surrogate model’s prediction at point &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt;. For a GP, this is an entry in the diagonal of the posterior covariance matrix.&lt;/p&gt;
&lt;h4 id=&#34;an-example-problem&#34; class=&#34;anchored&#34;&gt;An Example Problem&lt;/h4&gt;
&lt;p&gt;For the demonstration of acquisition functions, we need a toy problem. We will use a simple objective function without noise and a single dimension.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;objective_function &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(x) {&lt;/span&gt;
&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;sin&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;12&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; x) &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; x &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; x&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;), &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb2-5&#34;&gt;&lt;a href=&#34;#cb2-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;objective_function&lt;/span&gt;(X_pred)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This function has two minima and two maxima in the search space &lt;span class=&#34;math inline&#34;&gt;\mathcal{X} = [0,1]&lt;/span&gt;, so it will not be too easy to maximise or minimise.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;p&gt;&lt;/p&gt;&lt;details&gt;
&lt;summary&gt;Show the code&lt;/summary&gt;&lt;p&gt;&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_pred, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y_pred)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;x&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;f(x)&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Objective Function&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We will approximate the the objective function with a Gaussian process surrogate model that utilises the RBF kernel. See the &lt;a href=&#34;../bayesian-opt-r/&#34;&gt;Bayesian optimisation post&lt;/a&gt; for details.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;p&gt;&lt;/p&gt;&lt;details&gt;
&lt;summary&gt;Show the code&lt;/summary&gt;&lt;p&gt;&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; RBF Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-4&#34;&gt;&lt;a href=&#34;#cb4-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-5&#34;&gt;&lt;a href=&#34;#cb4-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param l length scale&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-6&#34;&gt;&lt;a href=&#34;#cb4-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma_f scale parameter &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-7&#34;&gt;&lt;a href=&#34;#cb4-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-8&#34;&gt;&lt;a href=&#34;#cb4-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-9&#34;&gt;&lt;a href=&#34;#cb4-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;rbf_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb4-10&#34;&gt;&lt;a href=&#34;#cb4-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb4-11&#34;&gt;&lt;a href=&#34;#cb4-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb4-12&#34;&gt;&lt;a href=&#34;#cb4-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sqdist &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;(X1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(X2))) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-13&#34;&gt;&lt;a href=&#34;#cb4-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X1&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-14&#34;&gt;&lt;a href=&#34;#cb4-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X2&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb4-15&#34;&gt;&lt;a href=&#34;#cb4-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma_f&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;exp&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; l&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; sqdist)&lt;/span&gt;
&lt;span id=&#34;cb4-16&#34;&gt;&lt;a href=&#34;#cb4-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb4-17&#34;&gt;&lt;a href=&#34;#cb4-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-18&#34;&gt;&lt;a href=&#34;#cb4-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Random Samples from a Multivariate Gaussian&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-19&#34;&gt;&lt;a href=&#34;#cb4-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-20&#34;&gt;&lt;a href=&#34;#cb4-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; This implementation is similar to MASS::mvrnorm, but uses chlosky&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-21&#34;&gt;&lt;a href=&#34;#cb4-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; decomposition instead. This should be more stable but is less efficient than&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-22&#34;&gt;&lt;a href=&#34;#cb4-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; the MASS implementation, which recycles the eigen decomposition for the&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-23&#34;&gt;&lt;a href=&#34;#cb4-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; sampling part.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-24&#34;&gt;&lt;a href=&#34;#cb4-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-25&#34;&gt;&lt;a href=&#34;#cb4-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param n number of samples to sample&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-26&#34;&gt;&lt;a href=&#34;#cb4-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param mu the mean of each input dimension&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-27&#34;&gt;&lt;a href=&#34;#cb4-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma the covariance matrix&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-28&#34;&gt;&lt;a href=&#34;#cb4-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param epsilon numerical tolerance added to the diagonal of the covariance&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-29&#34;&gt;&lt;a href=&#34;#cb4-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;  matrix. This is necessary for the Cholesky decomposition, in some cases.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-30&#34;&gt;&lt;a href=&#34;#cb4-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-31&#34;&gt;&lt;a href=&#34;#cb4-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return numerical vector of n samples&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-32&#34;&gt;&lt;a href=&#34;#cb4-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;rmvnorm &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;n =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, mu, sigma, &lt;span class=&#34;at&#34;&gt;epsilon =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-6&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb4-33&#34;&gt;&lt;a href=&#34;#cb4-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    p &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(mu)&lt;/span&gt;
&lt;span id=&#34;cb4-34&#34;&gt;&lt;a href=&#34;#cb4-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;all&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(sigma) &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(p, p))) &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;incompatible dimensions of arguments&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb4-35&#34;&gt;&lt;a href=&#34;#cb4-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ev &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;eigen&lt;/span&gt;(sigma, &lt;span class=&#34;at&#34;&gt;symmetric =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;TRUE&lt;/span&gt;)&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;values&lt;/span&gt;
&lt;span id=&#34;cb4-36&#34;&gt;&lt;a href=&#34;#cb4-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;all&lt;/span&gt;(ev &lt;span class=&#34;sc&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;epsilon&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;abs&lt;/span&gt;(ev[1L]))) {&lt;/span&gt;
&lt;span id=&#34;cb4-37&#34;&gt;&lt;a href=&#34;#cb4-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;The covariance matrix (sigma) is not positive definite&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb4-38&#34;&gt;&lt;a href=&#34;#cb4-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    }&lt;/span&gt;
&lt;span id=&#34;cb4-39&#34;&gt;&lt;a href=&#34;#cb4-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    cholesky &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;chol&lt;/span&gt;(sigma &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(p)&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;epsilon)&lt;/span&gt;
&lt;span id=&#34;cb4-40&#34;&gt;&lt;a href=&#34;#cb4-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    sample &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(p&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;n, &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb4-41&#34;&gt;&lt;a href=&#34;#cb4-41&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(sample) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(n, p)&lt;/span&gt;
&lt;span id=&#34;cb4-42&#34;&gt;&lt;a href=&#34;#cb4-42&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(sample &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; cholesky, &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, mu, &lt;span class=&#34;at&#34;&gt;FUN =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb4-43&#34;&gt;&lt;a href=&#34;#cb4-43&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb4-44&#34;&gt;&lt;a href=&#34;#cb4-44&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-45&#34;&gt;&lt;a href=&#34;#cb4-45&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Get Parameters of the Posterior Gaussian Process&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-46&#34;&gt;&lt;a href=&#34;#cb4-46&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-47&#34;&gt;&lt;a href=&#34;#cb4-47&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function used for the Gaussian process&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-48&#34;&gt;&lt;a href=&#34;#cb4-48&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_pred matrix (m, d) of prediction points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-49&#34;&gt;&lt;a href=&#34;#cb4-49&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-50&#34;&gt;&lt;a href=&#34;#cb4-50&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-51&#34;&gt;&lt;a href=&#34;#cb4-51&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-52&#34;&gt;&lt;a href=&#34;#cb4-52&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param ... named parameters for the kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-53&#34;&gt;&lt;a href=&#34;#cb4-53&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-54&#34;&gt;&lt;a href=&#34;#cb4-54&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return list of mean (mu) and covariance (sigma) for the Gaussian&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-55&#34;&gt;&lt;a href=&#34;#cb4-55&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;posterior &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, X_pred, X_train, y_train, &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt;, ...) {&lt;/span&gt;
&lt;span id=&#34;cb4-56&#34;&gt;&lt;a href=&#34;#cb4-56&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X_pred), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb4-57&#34;&gt;&lt;a href=&#34;#cb4-57&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X_train), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb4-58&#34;&gt;&lt;a href=&#34;#cb4-58&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(y_train))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(y_train) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(y_train), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb4-59&#34;&gt;&lt;a href=&#34;#cb4-59&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_train, X_train, ...) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;
&lt;span id=&#34;cb4-60&#34;&gt;&lt;a href=&#34;#cb4-60&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_s &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_train, X_pred, ...)&lt;/span&gt;
&lt;span id=&#34;cb4-61&#34;&gt;&lt;a href=&#34;#cb4-61&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_ss &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_pred, X_pred, ...) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;
&lt;span id=&#34;cb4-62&#34;&gt;&lt;a href=&#34;#cb4-62&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_inv &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;solve&lt;/span&gt;(K)&lt;/span&gt;
&lt;span id=&#34;cb4-63&#34;&gt;&lt;a href=&#34;#cb4-63&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(K_s) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_inv) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; y_train&lt;/span&gt;
&lt;span id=&#34;cb4-64&#34;&gt;&lt;a href=&#34;#cb4-64&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; K_ss &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(K_s) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_inv) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_s&lt;/span&gt;
&lt;span id=&#34;cb4-65&#34;&gt;&lt;a href=&#34;#cb4-65&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma)&lt;/span&gt;
&lt;span id=&#34;cb4-66&#34;&gt;&lt;a href=&#34;#cb4-66&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb4-67&#34;&gt;&lt;a href=&#34;#cb4-67&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-68&#34;&gt;&lt;a href=&#34;#cb4-68&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Negative log-Likelihood of a Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-69&#34;&gt;&lt;a href=&#34;#cb4-69&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-70&#34;&gt;&lt;a href=&#34;#cb4-70&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-71&#34;&gt;&lt;a href=&#34;#cb4-71&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-72&#34;&gt;&lt;a href=&#34;#cb4-72&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-73&#34;&gt;&lt;a href=&#34;#cb4-73&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-74&#34;&gt;&lt;a href=&#34;#cb4-74&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-75&#34;&gt;&lt;a href=&#34;#cb4-75&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return function with kernel parameters as input and negative log likelihood&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-76&#34;&gt;&lt;a href=&#34;#cb4-76&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; as output&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-77&#34;&gt;&lt;a href=&#34;#cb4-77&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;nll &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, X_train, y_train, noise) {&lt;/span&gt;
&lt;span id=&#34;cb4-78&#34;&gt;&lt;a href=&#34;#cb4-78&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(params) {&lt;/span&gt;
&lt;span id=&#34;cb4-79&#34;&gt;&lt;a href=&#34;#cb4-79&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    n &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]]&lt;/span&gt;
&lt;span id=&#34;cb4-80&#34;&gt;&lt;a href=&#34;#cb4-80&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    K &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(kernel, &lt;span class=&#34;at&#34;&gt;X1 =&lt;/span&gt; X_train, &lt;span class=&#34;at&#34;&gt;X2 =&lt;/span&gt; X_train, &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;params)&lt;/span&gt;
&lt;span id=&#34;cb4-81&#34;&gt;&lt;a href=&#34;#cb4-81&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    L &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;chol&lt;/span&gt;(K &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(n))&lt;/span&gt;
&lt;span id=&#34;cb4-82&#34;&gt;&lt;a href=&#34;#cb4-82&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    a &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;backsolve&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;r =&lt;/span&gt; L, &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;forwardsolve&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(L), &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; y_train))&lt;/span&gt;
&lt;span id=&#34;cb4-83&#34;&gt;&lt;a href=&#34;#cb4-83&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(y_train)&lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt;a &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;sum&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;log&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(L))) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;n&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;log&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;pi)&lt;/span&gt;
&lt;span id=&#34;cb4-84&#34;&gt;&lt;a href=&#34;#cb4-84&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb4-85&#34;&gt;&lt;a href=&#34;#cb4-85&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb4-86&#34;&gt;&lt;a href=&#34;#cb4-86&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-87&#34;&gt;&lt;a href=&#34;#cb4-87&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Gaussian Process Regression&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-88&#34;&gt;&lt;a href=&#34;#cb4-88&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-89&#34;&gt;&lt;a href=&#34;#cb4-89&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-90&#34;&gt;&lt;a href=&#34;#cb4-90&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-91&#34;&gt;&lt;a href=&#34;#cb4-91&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-92&#34;&gt;&lt;a href=&#34;#cb4-92&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-93&#34;&gt;&lt;a href=&#34;#cb4-93&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param ... parameters of the kernel function with initial guesses. Due to the&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-94&#34;&gt;&lt;a href=&#34;#cb4-94&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; optimiser used, all parameters must be given and the order unfortunately&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-95&#34;&gt;&lt;a href=&#34;#cb4-95&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; matters&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-96&#34;&gt;&lt;a href=&#34;#cb4-96&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-97&#34;&gt;&lt;a href=&#34;#cb4-97&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return function that takes a matrix of prediction points as input and&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-98&#34;&gt;&lt;a href=&#34;#cb4-98&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; returns the posterior predictive distribution for the output&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-99&#34;&gt;&lt;a href=&#34;#cb4-99&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gpr &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, X_train, y_train, &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt;, ...) {&lt;/span&gt;
&lt;span id=&#34;cb4-100&#34;&gt;&lt;a href=&#34;#cb4-100&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  kernel_nll &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;nll&lt;/span&gt;(kernel, X_train, y_train, noise)&lt;/span&gt;
&lt;span id=&#34;cb4-101&#34;&gt;&lt;a href=&#34;#cb4-101&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  param &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(...)&lt;/span&gt;
&lt;span id=&#34;cb4-102&#34;&gt;&lt;a href=&#34;#cb4-102&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  opt &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;optim&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;par =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(param)), &lt;span class=&#34;at&#34;&gt;fn =&lt;/span&gt; kernel_nll)&lt;/span&gt;
&lt;span id=&#34;cb4-103&#34;&gt;&lt;a href=&#34;#cb4-103&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  opt_param &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; opt&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;par&lt;/span&gt;
&lt;span id=&#34;cb4-104&#34;&gt;&lt;a href=&#34;#cb4-104&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X_pred) {&lt;/span&gt;
&lt;span id=&#34;cb4-105&#34;&gt;&lt;a href=&#34;#cb4-105&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb4-106&#34;&gt;&lt;a href=&#34;#cb4-106&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      posterior,&lt;/span&gt;
&lt;span id=&#34;cb4-107&#34;&gt;&lt;a href=&#34;#cb4-107&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;kernel =&lt;/span&gt; kernel,&lt;/span&gt;
&lt;span id=&#34;cb4-108&#34;&gt;&lt;a href=&#34;#cb4-108&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb4-109&#34;&gt;&lt;a href=&#34;#cb4-109&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb4-110&#34;&gt;&lt;a href=&#34;#cb4-110&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_train,&lt;/span&gt;
&lt;span id=&#34;cb4-111&#34;&gt;&lt;a href=&#34;#cb4-111&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; noise,&lt;/span&gt;
&lt;span id=&#34;cb4-112&#34;&gt;&lt;a href=&#34;#cb4-112&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;opt_param&lt;/span&gt;
&lt;span id=&#34;cb4-113&#34;&gt;&lt;a href=&#34;#cb4-113&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb4-114&#34;&gt;&lt;a href=&#34;#cb4-114&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb4-115&#34;&gt;&lt;a href=&#34;#cb4-115&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu,&lt;/span&gt;
&lt;span id=&#34;cb4-116&#34;&gt;&lt;a href=&#34;#cb4-116&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma),&lt;/span&gt;
&lt;span id=&#34;cb4-117&#34;&gt;&lt;a href=&#34;#cb4-117&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;Sigma =&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma,&lt;/span&gt;
&lt;span id=&#34;cb4-118&#34;&gt;&lt;a href=&#34;#cb4-118&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;parameters =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;set_names&lt;/span&gt;(opt_param, &lt;span class=&#34;fu&#34;&gt;names&lt;/span&gt;(param))&lt;/span&gt;
&lt;span id=&#34;cb4-119&#34;&gt;&lt;a href=&#34;#cb4-119&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb4-120&#34;&gt;&lt;a href=&#34;#cb4-120&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb4-121&#34;&gt;&lt;a href=&#34;#cb4-121&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;p&gt;The model will receive four training points. We perform Gaussian process regression and condition the Gaussian process on our training data before drawing from the posterior predictive distribution on a grid of &lt;span class=&#34;math inline&#34;&gt;\mathbf{x} \in \mathcal{X}&lt;/span&gt;. The &lt;span class=&#34;math inline&#34;&gt;\mu(\mathbf{x})&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\sigma(\mathbf{x})&lt;/span&gt; of the posterior predictive distribution are needed to calculate some acquisition functions.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fl&#34;&gt;0.1&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.2&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.7&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.75&lt;/span&gt;), &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-2&#34;&gt;&lt;a href=&#34;#cb5-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;objective_function&lt;/span&gt;(X_train)&lt;/span&gt;
&lt;span id=&#34;cb5-3&#34;&gt;&lt;a href=&#34;#cb5-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gpr&lt;/span&gt;(rbf_kernel, X_train, y_train, &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-4&#34;&gt;&lt;a href=&#34;#cb5-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_min &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;min&lt;/span&gt;(y_train)&lt;/span&gt;
&lt;span id=&#34;cb5-5&#34;&gt;&lt;a href=&#34;#cb5-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_max &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;max&lt;/span&gt;(y_train)&lt;/span&gt;
&lt;span id=&#34;cb5-6&#34;&gt;&lt;a href=&#34;#cb5-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post_pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp&lt;/span&gt;(X_pred)&lt;/span&gt;
&lt;span id=&#34;cb5-7&#34;&gt;&lt;a href=&#34;#cb5-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu&lt;/span&gt;
&lt;span id=&#34;cb5-8&#34;&gt;&lt;a href=&#34;#cb5-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here is what the Gaussian process looks like so far.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;p&gt;&lt;/p&gt;&lt;details&gt;
&lt;summary&gt;Show the code&lt;/summary&gt;&lt;p&gt;&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gp_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-2&#34;&gt;&lt;a href=&#34;#cb6-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu,&lt;/span&gt;
&lt;span id=&#34;cb6-3&#34;&gt;&lt;a href=&#34;#cb6-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;uncertainty =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.96&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sqrt&lt;/span&gt;(sigma),&lt;/span&gt;
&lt;span id=&#34;cb6-4&#34;&gt;&lt;a href=&#34;#cb6-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;upper =&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; uncertainty,&lt;/span&gt;
&lt;span id=&#34;cb6-5&#34;&gt;&lt;a href=&#34;#cb6-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;lower =&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; uncertainty,&lt;/span&gt;
&lt;span id=&#34;cb6-6&#34;&gt;&lt;a href=&#34;#cb6-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb6-7&#34;&gt;&lt;a href=&#34;#cb6-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;f =&lt;/span&gt; y_pred&lt;/span&gt;
&lt;span id=&#34;cb6-8&#34;&gt;&lt;a href=&#34;#cb6-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-9&#34;&gt;&lt;a href=&#34;#cb6-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-10&#34;&gt;&lt;a href=&#34;#cb6-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; mu, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Mean&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-11&#34;&gt;&lt;a href=&#34;#cb6-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_ribbon&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-12&#34;&gt;&lt;a href=&#34;#cb6-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;ymin =&lt;/span&gt; lower, &lt;span class=&#34;at&#34;&gt;ymax =&lt;/span&gt; upper, &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb6-13&#34;&gt;&lt;a href=&#34;#cb6-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-14&#34;&gt;&lt;a href=&#34;#cb6-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-15&#34;&gt;&lt;a href=&#34;#cb6-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-16&#34;&gt;&lt;a href=&#34;#cb6-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_train, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y_train),&lt;/span&gt;
&lt;span id=&#34;cb6-17&#34;&gt;&lt;a href=&#34;#cb6-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y, &lt;span class=&#34;at&#34;&gt;shape =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Training point&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb6-18&#34;&gt;&lt;a href=&#34;#cb6-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#fb8500&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-19&#34;&gt;&lt;a href=&#34;#cb6-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;size =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-20&#34;&gt;&lt;a href=&#34;#cb6-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-21&#34;&gt;&lt;a href=&#34;#cb6-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;mapping =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; f, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;True function&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-22&#34;&gt;&lt;a href=&#34;#cb6-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_shape_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;Training point&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;+&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-23&#34;&gt;&lt;a href=&#34;#cb6-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_fill_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#219ebc&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-24&#34;&gt;&lt;a href=&#34;#cb6-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;shape =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-25&#34;&gt;&lt;a href=&#34;#cb6-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-26&#34;&gt;&lt;a href=&#34;#cb6-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-27&#34;&gt;&lt;a href=&#34;#cb6-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;y&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-28&#34;&gt;&lt;a href=&#34;#cb6-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-29&#34;&gt;&lt;a href=&#34;#cb6-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-30&#34;&gt;&lt;a href=&#34;#cb6-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-31&#34;&gt;&lt;a href=&#34;#cb6-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-32&#34;&gt;&lt;a href=&#34;#cb6-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;panel.grid =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;(), &lt;span class=&#34;at&#34;&gt;axis.text.x =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;())&lt;/span&gt;
&lt;span id=&#34;cb6-33&#34;&gt;&lt;a href=&#34;#cb6-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gp_plot&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/details&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Before getting started, we also define a plot to visualise the acquisition function along with the GP.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;p&gt;&lt;/p&gt;&lt;details&gt;
&lt;summary&gt;Show the code&lt;/summary&gt;&lt;p&gt;&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb7&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb7-1&#34;&gt;&lt;a href=&#34;#cb7-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;acquisition_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X_pred,&lt;/span&gt;
&lt;span id=&#34;cb7-2&#34;&gt;&lt;a href=&#34;#cb7-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             acquisition_function,&lt;/span&gt;
&lt;span id=&#34;cb7-3&#34;&gt;&lt;a href=&#34;#cb7-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             gp_plot,&lt;/span&gt;
&lt;span id=&#34;cb7-4&#34;&gt;&lt;a href=&#34;#cb7-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             xt1,&lt;/span&gt;
&lt;span id=&#34;cb7-5&#34;&gt;&lt;a href=&#34;#cb7-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;label =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;EI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-6&#34;&gt;&lt;a href=&#34;#cb7-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb7-7&#34;&gt;&lt;a href=&#34;#cb7-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb7-8&#34;&gt;&lt;a href=&#34;#cb7-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb7-9&#34;&gt;&lt;a href=&#34;#cb7-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;a =&lt;/span&gt; acquisition_function&lt;/span&gt;
&lt;span id=&#34;cb7-10&#34;&gt;&lt;a href=&#34;#cb7-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-11&#34;&gt;&lt;a href=&#34;#cb7-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-12&#34;&gt;&lt;a href=&#34;#cb7-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; a, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; label)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-13&#34;&gt;&lt;a href=&#34;#cb7-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_vline&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;xintercept =&lt;/span&gt; xt1, &lt;span class=&#34;at&#34;&gt;linetype =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-14&#34;&gt;&lt;a href=&#34;#cb7-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-15&#34;&gt;&lt;a href=&#34;#cb7-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; label, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-16&#34;&gt;&lt;a href=&#34;#cb7-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;panel.grid =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;())&lt;/span&gt;
&lt;span id=&#34;cb7-17&#34;&gt;&lt;a href=&#34;#cb7-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p2 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; gp_plot &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-18&#34;&gt;&lt;a href=&#34;#cb7-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_vline&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;xintercept =&lt;/span&gt; xt1, &lt;span class=&#34;at&#34;&gt;linetype =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-19&#34;&gt;&lt;a href=&#34;#cb7-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; title)&lt;/span&gt;
&lt;span id=&#34;cb7-20&#34;&gt;&lt;a href=&#34;#cb7-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  aligned_plots &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; cowplot&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;align_plots&lt;/span&gt;(p2, p1 , &lt;span class=&#34;at&#34;&gt;align =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;v&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb7-21&#34;&gt;&lt;a href=&#34;#cb7-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  cowplot&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;plot_grid&lt;/span&gt;(aligned_plots[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]], aligned_plots[[&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;]], &lt;span class=&#34;at&#34;&gt;ncol =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb7-22&#34;&gt;&lt;a href=&#34;#cb7-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;p&gt;Now we are ready to apply different acquisition functions to help recommend the next point to sample.&lt;/p&gt;
&lt;h2 id=&#34;expected-improvement&#34; class=&#34;anchored&#34;&gt;Expected Improvement&lt;/h2&gt;
&lt;p&gt;The idea behind Expected Improvement (EI) is to search for the point in the search space that has the highest probability of improving the current best solution. EI is defined as the expected value of the improvement over the current best solution, where the improvement is defined as the difference between the function value at the candidate point and the current best value. In other words, EI measures how much better the objective function is expected to be at the candidate point compared to the current best value, weighted by the probability of achieving that improvement.&lt;/p&gt;
&lt;p&gt;Formally, the expected improvement acquisition function for a minimisation problem is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;a_{EI}(\mathbf{x}) = \mathbb{E}\left[\max(0, f_{\min} - f(\mathbf{x}))\right]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; is the candidate point and &lt;span class=&#34;math inline&#34;&gt;f_{\min}&lt;/span&gt; is the current best function value observed so far.&lt;/p&gt;
&lt;p&gt;When using a GP surrogate model conditioned on noisy observations in place of &lt;span class=&#34;math inline&#34;&gt;f&lt;/span&gt;, EI can be calculated using the following formula &lt;span class=&#34;citation&#34; data-cites=&#34;frazier2018tutorial&#34;&gt;[1]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;a_{EI}(\mathbf{x}) = (y_{min} - \mu(\mathbf{x}) - \xi) \Phi(Z) + \sigma(\mathbf{x}) \phi(Z)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;Z = \frac{y_{min} - \mu(\mathbf{x}) - \xi}{\sigma(\mathbf{x})}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\mu(\mathbf{x})&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\sigma(\mathbf{x})&lt;/span&gt; are the mean and standard deviation of the Gaussian process at &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\Phi&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\phi&lt;/span&gt; are the standard normal cumulative distribution function and probability density function, respectively, and &lt;span class=&#34;math inline&#34;&gt;\xi&lt;/span&gt; is a trade-off parameter that balances exploration and exploitation. Higher values of &lt;span class=&#34;math inline&#34;&gt;\xi&lt;/span&gt; lead to more exploration and smaller values to exploitation. &lt;span class=&#34;math inline&#34;&gt;a_{EI}(\mathbf{x}) = 0&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\sigma(\mathbf{x}) = 0&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The formulas can be implemented directly.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb8&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb8-1&#34;&gt;&lt;a href=&#34;#cb8-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Expected Improvement Acquisition Function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-2&#34;&gt;&lt;a href=&#34;#cb8-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-3&#34;&gt;&lt;a href=&#34;#cb8-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @mu vector of length m. Mean of a Gaussian process at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-4&#34;&gt;&lt;a href=&#34;#cb8-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @sigma vector of length m. The diagonal of the covariance matrix of a&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-5&#34;&gt;&lt;a href=&#34;#cb8-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Gaussian process evaluated at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-6&#34;&gt;&lt;a href=&#34;#cb8-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_best scalar. Best mean prediction so far on observed points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-7&#34;&gt;&lt;a href=&#34;#cb8-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param xi scalar, exploration/exploitation trade off&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-8&#34;&gt;&lt;a href=&#34;#cb8-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @task one of &#34;max&#34; or &#34;min&#34;, indicating the optimisation problem&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-9&#34;&gt;&lt;a href=&#34;#cb8-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-10&#34;&gt;&lt;a href=&#34;#cb8-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return EI, vector of length m&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-11&#34;&gt;&lt;a href=&#34;#cb8-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;expected_improvement &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(mu, sigma, y_best, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.01&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;task =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;min&#34;&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb8-12&#34;&gt;&lt;a href=&#34;#cb8-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (task &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;min&#34;&lt;/span&gt;) imp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; y_best &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; xi&lt;/span&gt;
&lt;span id=&#34;cb8-13&#34;&gt;&lt;a href=&#34;#cb8-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (task &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;max&#34;&lt;/span&gt;) imp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; y_best &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; xi&lt;/span&gt;
&lt;span id=&#34;cb8-14&#34;&gt;&lt;a href=&#34;#cb8-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(imp)) &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#39;task must be &#34;min&#34; or &#34;max&#34;&#39;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb8-15&#34;&gt;&lt;a href=&#34;#cb8-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  Z &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; imp &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; sigma&lt;/span&gt;
&lt;span id=&#34;cb8-16&#34;&gt;&lt;a href=&#34;#cb8-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; imp &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;pnorm&lt;/span&gt;(Z) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; sigma &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dnorm&lt;/span&gt;(Z)&lt;/span&gt;
&lt;span id=&#34;cb8-17&#34;&gt;&lt;a href=&#34;#cb8-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei[sigma &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.0&lt;/span&gt;] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-18&#34;&gt;&lt;a href=&#34;#cb8-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei&lt;/span&gt;
&lt;span id=&#34;cb8-19&#34;&gt;&lt;a href=&#34;#cb8-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Let’s see it in action. We calculate EI along a grid and draw it below the GP.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb9&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb9-1&#34;&gt;&lt;a href=&#34;#cb9-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement&lt;/span&gt;(mu, sigma, y_min, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.05&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb9-2&#34;&gt;&lt;a href=&#34;#cb9-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;xt1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei)]&lt;/span&gt;
&lt;span id=&#34;cb9-3&#34;&gt;&lt;a href=&#34;#cb9-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb9-4&#34;&gt;&lt;a href=&#34;#cb9-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_pred,&lt;/span&gt;
&lt;span id=&#34;cb9-5&#34;&gt;&lt;a href=&#34;#cb9-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei,&lt;/span&gt;
&lt;span id=&#34;cb9-6&#34;&gt;&lt;a href=&#34;#cb9-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  gp_plot,&lt;/span&gt;
&lt;span id=&#34;cb9-7&#34;&gt;&lt;a href=&#34;#cb9-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  xt1,&lt;/span&gt;
&lt;span id=&#34;cb9-8&#34;&gt;&lt;a href=&#34;#cb9-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;EI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb9-9&#34;&gt;&lt;a href=&#34;#cb9-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;Expected Improvement (Minimisation)&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb9-10&#34;&gt;&lt;a href=&#34;#cb9-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The next sampling point, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{t+1}&lt;/span&gt;, is the one that maximises the acquisition function, here EI. As marked by the dashed line, this point is close to the right edge, where there is a high mean prediction but also high uncertainty, so it satisfies our need for both exploration and exploitation.&lt;/p&gt;
&lt;p&gt;EI works for maximisation problems as well, by replacing &lt;span class=&#34;math inline&#34;&gt;y_{min} - \mu(\mathbf{x})&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\mu(\mathbf{x}) - y_{max}&lt;/span&gt; in the expressions above.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb10&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb10-1&#34;&gt;&lt;a href=&#34;#cb10-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement&lt;/span&gt;(mu, sigma, y_max, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.05&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;task =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;max&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb10-2&#34;&gt;&lt;a href=&#34;#cb10-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;xt1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei)]&lt;/span&gt;
&lt;span id=&#34;cb10-3&#34;&gt;&lt;a href=&#34;#cb10-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb10-4&#34;&gt;&lt;a href=&#34;#cb10-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_pred,&lt;/span&gt;
&lt;span id=&#34;cb10-5&#34;&gt;&lt;a href=&#34;#cb10-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei,&lt;/span&gt;
&lt;span id=&#34;cb10-6&#34;&gt;&lt;a href=&#34;#cb10-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  gp_plot,&lt;/span&gt;
&lt;span id=&#34;cb10-7&#34;&gt;&lt;a href=&#34;#cb10-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  xt1,&lt;/span&gt;
&lt;span id=&#34;cb10-8&#34;&gt;&lt;a href=&#34;#cb10-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;EI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb10-9&#34;&gt;&lt;a href=&#34;#cb10-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;Expected Improvement (Maximisation)&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-10&#34;&gt;&lt;a href=&#34;#cb10-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The next sampling point, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{t+1}&lt;/span&gt;, is still the one that maximises EI. As marked by the dashed line, this point is close to two sampled points, where we are quite certain that there is improvement to be found.&lt;/p&gt;
&lt;h2 id=&#34;probability-of-improvement&#34; class=&#34;anchored&#34;&gt;Probability of Improvement&lt;/h2&gt;
&lt;p&gt;Probability of improvement (PI) aims to select the point that has the highest probability of improving the current best solution. Like expected improvement, the PI function balances exploration and exploitation by taking into account both the mean and the variance of the surrogate model. A point with a high mean and low variance is likely to be a good candidate for exploitation, while a point with a high variance but lower mean may be more suitable for exploration.&lt;/p&gt;
&lt;p&gt;The PI acquisition function is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;a_{PI}(\mathbf{x}) = P(f(\mathbf{x}) \lt f_{\min} + \xi)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When using a GP surrogate model conditioned on noisy observations in place of &lt;span class=&#34;math inline&#34;&gt;f&lt;/span&gt;, EI can be calculated using the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;a_{\text{PI}}(\mathbf{x}) = \Phi\left(\frac{y_{min} - \mu(\mathbf{x}) - \xi}{\sigma(\mathbf{x})}\right)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\mu(\mathbf{x})&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\sigma(\mathbf{x})&lt;/span&gt; are the mean and standard deviation of the Gaussian process at &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\Phi&lt;/span&gt; is the standard normal cumulative distribution function, and &lt;span class=&#34;math inline&#34;&gt;\xi&lt;/span&gt; is a trade-off parameter that balances exploration and exploitation &lt;span class=&#34;citation&#34; data-cites=&#34;garnett_bayesoptbook_2023&#34;&gt;[2]&lt;/span&gt;. Higher values of &lt;span class=&#34;math inline&#34;&gt;\xi&lt;/span&gt; lead to more exploration and smaller values to exploitation.&lt;/p&gt;
&lt;p&gt;The formula can be implemented directly&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb11&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb11-1&#34;&gt;&lt;a href=&#34;#cb11-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Probability of Improvement Acquisition Function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-2&#34;&gt;&lt;a href=&#34;#cb11-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-3&#34;&gt;&lt;a href=&#34;#cb11-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @mu vector of length m. Mean of a Gaussian process at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-4&#34;&gt;&lt;a href=&#34;#cb11-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @sigma vector of length m. The diagonal of the covariance matrix of a&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-5&#34;&gt;&lt;a href=&#34;#cb11-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Gaussian process evaluated at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-6&#34;&gt;&lt;a href=&#34;#cb11-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_best scalar. Best mean prediction so far on observed points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-7&#34;&gt;&lt;a href=&#34;#cb11-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param xi scalar, exploration/exploitation trade off&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-8&#34;&gt;&lt;a href=&#34;#cb11-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @task one of &#34;max&#34; or &#34;min&#34;, indicating the optimisation problem&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-9&#34;&gt;&lt;a href=&#34;#cb11-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-10&#34;&gt;&lt;a href=&#34;#cb11-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return PI, vector of length m&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-11&#34;&gt;&lt;a href=&#34;#cb11-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;probability_of_improvement &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(mu,&lt;/span&gt;
&lt;span id=&#34;cb11-12&#34;&gt;&lt;a href=&#34;#cb11-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                       sigma,&lt;/span&gt;
&lt;span id=&#34;cb11-13&#34;&gt;&lt;a href=&#34;#cb11-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                       y_best,&lt;/span&gt;
&lt;span id=&#34;cb11-14&#34;&gt;&lt;a href=&#34;#cb11-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                       &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.01&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb11-15&#34;&gt;&lt;a href=&#34;#cb11-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                       &lt;span class=&#34;at&#34;&gt;task =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;min&#34;&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb11-16&#34;&gt;&lt;a href=&#34;#cb11-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (task &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;min&#34;&lt;/span&gt;) imp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; y_best &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; xi&lt;/span&gt;
&lt;span id=&#34;cb11-17&#34;&gt;&lt;a href=&#34;#cb11-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (task &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;max&#34;&lt;/span&gt;) imp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; y_best &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; xi&lt;/span&gt;
&lt;span id=&#34;cb11-18&#34;&gt;&lt;a href=&#34;#cb11-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;pnorm&lt;/span&gt;(imp &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; sigma)&lt;/span&gt;
&lt;span id=&#34;cb11-19&#34;&gt;&lt;a href=&#34;#cb11-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Let’s see it in action. We calculate PI along a grid and draw it below the GP.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb12&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb12-1&#34;&gt;&lt;a href=&#34;#cb12-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;pi &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;probability_of_improvement&lt;/span&gt;(mu, sigma, y_min, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb12-2&#34;&gt;&lt;a href=&#34;#cb12-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;xt1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(pi)]&lt;/span&gt;
&lt;span id=&#34;cb12-3&#34;&gt;&lt;a href=&#34;#cb12-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb12-4&#34;&gt;&lt;a href=&#34;#cb12-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_pred,&lt;/span&gt;
&lt;span id=&#34;cb12-5&#34;&gt;&lt;a href=&#34;#cb12-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  pi,&lt;/span&gt;
&lt;span id=&#34;cb12-6&#34;&gt;&lt;a href=&#34;#cb12-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  gp_plot,&lt;/span&gt;
&lt;span id=&#34;cb12-7&#34;&gt;&lt;a href=&#34;#cb12-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  xt1,&lt;/span&gt;
&lt;span id=&#34;cb12-8&#34;&gt;&lt;a href=&#34;#cb12-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;PI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb12-9&#34;&gt;&lt;a href=&#34;#cb12-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;Probability of Improvement (Minimisation)&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-10&#34;&gt;&lt;a href=&#34;#cb12-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The next sampling point, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{t+1}&lt;/span&gt;, is the one that maximises the acquisition function, here PI. As marked by the dashed line, this is close to the right edge, where there is a low mean prediction but also high uncertainty, so it satisfies our need for both exploration and exploitation. There are a few other good contenders in the spaces between training points though.&lt;/p&gt;
&lt;p&gt;PI works for maximisation problems as well, by replacing &lt;span class=&#34;math inline&#34;&gt;y_{min} - \mu(\mathbf{x})&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\mu(\mathbf{x}) - y_{max}&lt;/span&gt; in the expression above.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb13&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb13-1&#34;&gt;&lt;a href=&#34;#cb13-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;pi &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;probability_of_improvement&lt;/span&gt;(mu, sigma, y_max, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;task =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;max&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb13-2&#34;&gt;&lt;a href=&#34;#cb13-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;xt1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(pi)]&lt;/span&gt;
&lt;span id=&#34;cb13-3&#34;&gt;&lt;a href=&#34;#cb13-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-4&#34;&gt;&lt;a href=&#34;#cb13-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_pred,&lt;/span&gt;
&lt;span id=&#34;cb13-5&#34;&gt;&lt;a href=&#34;#cb13-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  pi,&lt;/span&gt;
&lt;span id=&#34;cb13-6&#34;&gt;&lt;a href=&#34;#cb13-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  gp_plot,&lt;/span&gt;
&lt;span id=&#34;cb13-7&#34;&gt;&lt;a href=&#34;#cb13-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  xt1,&lt;/span&gt;
&lt;span id=&#34;cb13-8&#34;&gt;&lt;a href=&#34;#cb13-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;PI&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb13-9&#34;&gt;&lt;a href=&#34;#cb13-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;Probability of Improvement (Maximisation)&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-10&#34;&gt;&lt;a href=&#34;#cb13-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The next sampling point, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{t+1}&lt;/span&gt;, is still the one that maximises PI. As marked by the dashed line, this is in an area of high uncertainty.&lt;/p&gt;
&lt;h2 id=&#34;lower-upper-confidence-bound&#34; class=&#34;anchored&#34;&gt;Lower &amp;amp; Upper Confidence Bound&lt;/h2&gt;
&lt;p&gt;The Lower Confidence Bound (LCB) and Upper Confidence Bound (UCB) acquisition functions are fairly simple acquisition functions. They balance exploration and exploitation by combining the mean and the weighted standard deviation predictions of the surrogate model. LCB is used for minimisation problems and UCP is applied for maximisation problems.&lt;/p&gt;
&lt;p&gt;The LCB function is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;a_{LCB}(\mathbf{x}) = \mu(\mathbf{x}) - \kappa \sigma(\mathbf{x})&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and UCB as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;a_{UCB}(\mathbf{x}) = \mu(\mathbf{x}) + \kappa \sigma(\mathbf{x})&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\mu(\mathbf{x})&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\sigma(\mathbf{x})&lt;/span&gt; are the mean and standard deviation of the Gaussian process at &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\kappa&lt;/span&gt; is a tunable parameter that controls the balance between exploration and exploitation. Higher values of &lt;span class=&#34;math inline&#34;&gt;\kappa&lt;/span&gt; promote more exploration, while lower values emphasise exploitation.&lt;/p&gt;
&lt;p&gt;With the mean term explicitly controlling exploitation and the weighed standard deviation term explicitly controlling exploration, UCB and LCB arguably represent the simplest acquisition function one could implement. This does not mean that UCB or LCB are worse than EI or PI, however. When the surrogate model is a GP, this simpler acquisition function might have similar performance to EI, for appropriate choices of &lt;span class=&#34;math inline&#34;&gt;\kappa&lt;/span&gt; &lt;span class=&#34;citation&#34; data-cites=&#34;Srinivas_2012&#34;&gt;[3]&lt;/span&gt; &lt;span class=&#34;citation&#34; data-cites=&#34;garnett_bayesoptbook_2023&#34;&gt;[2]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The acquisition functions are straightforward to implement, given &lt;span class=&#34;math inline&#34;&gt;\mu&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\sigma&lt;/span&gt;:&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb14&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb14-1&#34;&gt;&lt;a href=&#34;#cb14-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Upper and Lower Confidence Bound Acquisition Function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-2&#34;&gt;&lt;a href=&#34;#cb14-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-3&#34;&gt;&lt;a href=&#34;#cb14-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @mu vector of length m. Mean of a Gaussian process at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-4&#34;&gt;&lt;a href=&#34;#cb14-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @sigma vector of length m. The diagonal of the covariance matrix of a&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-5&#34;&gt;&lt;a href=&#34;#cb14-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Gaussian process evaluated at m points.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-6&#34;&gt;&lt;a href=&#34;#cb14-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kappa scalar, exploration/exploitation trade off&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-7&#34;&gt;&lt;a href=&#34;#cb14-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @task one of &#34;max&#34; or &#34;min&#34;, indicating the optimisation problem&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-8&#34;&gt;&lt;a href=&#34;#cb14-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-9&#34;&gt;&lt;a href=&#34;#cb14-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return CB, vector of length m&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-10&#34;&gt;&lt;a href=&#34;#cb14-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;confidence_bound &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(mu, sigma, kappa, &lt;span class=&#34;at&#34;&gt;task =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;min&#34;&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb14-11&#34;&gt;&lt;a href=&#34;#cb14-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (task &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;min&#34;&lt;/span&gt;) &lt;span class=&#34;fu&#34;&gt;return&lt;/span&gt;(mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; kappa &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; sigma)&lt;/span&gt;
&lt;span id=&#34;cb14-12&#34;&gt;&lt;a href=&#34;#cb14-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (task &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;max&#34;&lt;/span&gt;) &lt;span class=&#34;fu&#34;&gt;return&lt;/span&gt;(mu &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; kappa &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; sigma)&lt;/span&gt;
&lt;span id=&#34;cb14-13&#34;&gt;&lt;a href=&#34;#cb14-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Let’s see it in action. We calculate LCB along a grid and draw it below the GP.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb15&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb15-1&#34;&gt;&lt;a href=&#34;#cb15-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;lcb &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;confidence_bound&lt;/span&gt;(mu, sigma, &lt;span class=&#34;at&#34;&gt;kappa =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;min&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb15-2&#34;&gt;&lt;a href=&#34;#cb15-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;xt1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.min&lt;/span&gt;(lcb)]&lt;/span&gt;
&lt;span id=&#34;cb15-3&#34;&gt;&lt;a href=&#34;#cb15-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(X_pred, lcb, gp_plot, xt1, &lt;span class=&#34;st&#34;&gt;&#34;LCB&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;Lower Confidence Bound&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;As marked by the dashed line, LCB tells us that the next point to sample, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{t+1}&lt;/span&gt;, is all the way at the right edge of search space.&lt;/p&gt;
&lt;p&gt;We can do the same for UCB&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb16&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb16-1&#34;&gt;&lt;a href=&#34;#cb16-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ucb &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;confidence_bound&lt;/span&gt;(mu, sigma, &lt;span class=&#34;at&#34;&gt;kappa =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;max&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb16-2&#34;&gt;&lt;a href=&#34;#cb16-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;xt1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ucb)]&lt;/span&gt;
&lt;span id=&#34;cb16-3&#34;&gt;&lt;a href=&#34;#cb16-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(X_pred, ucb, gp_plot, xt1, &lt;span class=&#34;st&#34;&gt;&#34;UCB&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;Upper Confidence Bound&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;As marked by the dashed line, UCB tells us that the next point to sample, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{t+1}&lt;/span&gt;, is close to two known points, where we are fairly certain that there is improvement to be found.&lt;/p&gt;
&lt;h2 id=&#34;thompson-sampling&#34; class=&#34;anchored&#34;&gt;Thompson Sampling&lt;/h2&gt;
&lt;p&gt;A Gaussian process represents a distribution over functions. At this point in Bayesian optimisation, the GP has been conditioned on training data, &lt;span class=&#34;math inline&#34;&gt;\mathcal{D}&lt;/span&gt;, and it acts as a surrogate for the objective function. This means that we have a distribution of functions which summarise our knowledge and uncertainty about the objective function.&lt;/p&gt;
&lt;p&gt;We can take that a step further and consider the posterior distribution, &lt;span class=&#34;math inline&#34;&gt;p(\mathbf{x}&#39;|\mathcal{D})&lt;/span&gt;, of points, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&#39;&lt;/span&gt;, that optimise the the functions drawn from the GP. A point drawn from that distribution would be a good candidate for our next evaluation of the objective function&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{x}_{t+1} \sim p(\mathbf{x}&#39;|\mathcal{D})&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is the core idea of Thompson Sampling. Thompson sampling addresses the exploration versus exploitation dilemma by directly making use of our posterior beliefs and the fact that the GP is just a distribution of functions &lt;span class=&#34;citation&#34; data-cites=&#34;garnett_bayesoptbook_2023&#34;&gt;[2]&lt;/span&gt;. Notice also that no additional parameters are needed for this method.&lt;/p&gt;
&lt;p&gt;To do Thompson sampling in practice, we sample a function from the GP&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;a_{ts}(\mathbf{x}) \sim p(y | \mathcal{D})&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is not an acquisition function in the same way that Expected Improvement or Confidence Bound are, but we can use it in exactly the same way to suggest the next point&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{x}_{t+1} \in \arg\min\limits_{\mathbf{x} = \mathcal{X}}(a_{ts}(\mathbf{x}))&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for a minimisation problem, or&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{x}_{t+1} \in \arg\max\limits_{\mathbf{x} = \mathcal{X}}(a_{ts}(\mathbf{x}))&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for a maximisation problem.&lt;/p&gt;
&lt;p&gt;Given the posterior predictive distribution, Thompson sampling is straightforward to implement. Let’s see it in action!&lt;/p&gt;
&lt;p&gt;We draw a random sample function and find its minimum and maximum&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb17&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb17-1&#34;&gt;&lt;a href=&#34;#cb17-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ts &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;as.vector&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;rmvnorm&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu, post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;Sigma))&lt;/span&gt;
&lt;span id=&#34;cb17-2&#34;&gt;&lt;a href=&#34;#cb17-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;xt1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.min&lt;/span&gt;(ts)]&lt;/span&gt;
&lt;span id=&#34;cb17-3&#34;&gt;&lt;a href=&#34;#cb17-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb17-4&#34;&gt;&lt;a href=&#34;#cb17-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_pred,&lt;/span&gt;
&lt;span id=&#34;cb17-5&#34;&gt;&lt;a href=&#34;#cb17-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ts,&lt;/span&gt;
&lt;span id=&#34;cb17-6&#34;&gt;&lt;a href=&#34;#cb17-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  gp_plot,&lt;/span&gt;
&lt;span id=&#34;cb17-7&#34;&gt;&lt;a href=&#34;#cb17-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  xt1,&lt;/span&gt;
&lt;span id=&#34;cb17-8&#34;&gt;&lt;a href=&#34;#cb17-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;Sample&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb17-9&#34;&gt;&lt;a href=&#34;#cb17-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;Thompson Sampling (Minimisation)&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-10&#34;&gt;&lt;a href=&#34;#cb17-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb18&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb18-1&#34;&gt;&lt;a href=&#34;#cb18-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;xt1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ts)]&lt;/span&gt;
&lt;span id=&#34;cb18-2&#34;&gt;&lt;a href=&#34;#cb18-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb18-3&#34;&gt;&lt;a href=&#34;#cb18-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_pred,&lt;/span&gt;
&lt;span id=&#34;cb18-4&#34;&gt;&lt;a href=&#34;#cb18-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ts,&lt;/span&gt;
&lt;span id=&#34;cb18-5&#34;&gt;&lt;a href=&#34;#cb18-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  gp_plot,&lt;/span&gt;
&lt;span id=&#34;cb18-6&#34;&gt;&lt;a href=&#34;#cb18-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  xt1,&lt;/span&gt;
&lt;span id=&#34;cb18-7&#34;&gt;&lt;a href=&#34;#cb18-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;Sample&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb18-8&#34;&gt;&lt;a href=&#34;#cb18-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;Thompson Sampling (Maximisation)&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-9&#34;&gt;&lt;a href=&#34;#cb18-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The dashed line indicates the next sampling point, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{t+1}&lt;/span&gt;, for a minimisation and maximisation task, respectively. For the minimisation problem, we are suggested a point that corresponds to exploitation and for the maximisation problem we are suggested a point that corresponds to exploration. It is this stochastic behaviour that, over a sequence of experiments, will give us a natural balance between exploration and exploitation.&lt;/p&gt;
&lt;h2 id=&#34;knowledge-gradient&#34; class=&#34;anchored&#34;&gt;Knowledge Gradient&lt;/h2&gt;
&lt;p&gt;The Knowledge Gradient (KG) is an acquisition function that makes extensive use of the posterior distribution to suggest a sampling point. KG is simulated rather than calculated and the rationale behind it takes a bit of set up.&lt;/p&gt;
&lt;p&gt;Imagine that we are at the end of our sequential experimentation. We have collected a set of observations &lt;span class=&#34;math inline&#34;&gt;\mathcal{D} = (\mathbf{X},\mathbf{y})&lt;/span&gt; and we are about to recommend our final set point, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}^*&lt;/span&gt;, which hopefully is close the global optimum of the objective function.&lt;/p&gt;
&lt;p&gt;In most real world cases, we are risk averse and would opt to select a point that we have already tested, i.e.&amp;nbsp;&lt;span class=&#34;math inline&#34;&gt;\mathbf{x}^* \in \mathbf{X}&lt;/span&gt;. Imagine, however, that we were not risk averse and just wanted to report the point in search space with the best expected outcome given the data so far, then we might recommend&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{x}^* = \arg\min\limits_{\mathbf{x} \in \mathcal{X}}\mu(\mathbf{x})&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We also define &lt;span class=&#34;math inline&#34;&gt;\mu^* = \mu(\mathbf{x}^*)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;At this point, imagine that we are suddenly allowed to test just one more point. Given that we have decided to recommend the point that optimises the posterior mean at the end of our experimental sequence, the next point, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{t+1}&lt;/span&gt;, we choose to evaluate in the the objective function should be the point that maximises the increase in the optimum posterior mean.&lt;/p&gt;
&lt;p&gt;Let’s say we pick any point, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{t+1} \in \mathcal{X}&lt;/span&gt;, to be our next point. That would result in the observation &lt;span class=&#34;math inline&#34;&gt;y_{t+1}&lt;/span&gt; and eventually a recommended final point, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}^*_{t+1}&lt;/span&gt; with mean &lt;span class=&#34;math inline&#34;&gt;\mu^*_{t+1}&lt;/span&gt;. The decrease in posterior mean, &lt;span class=&#34;math inline&#34;&gt;\mu^* - \mu^*_{t+1}&lt;/span&gt;, would be an excellent estimator of improvement in choosing &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{t+1}&lt;/span&gt; as the next sampling point.&lt;/p&gt;
&lt;p&gt;However, we cannot calculate &lt;span class=&#34;math inline&#34;&gt;\mu^* - \mu^*_{t+1}&lt;/span&gt; without actually collecting the sample &lt;span class=&#34;math inline&#34;&gt;y_{t+1}&lt;/span&gt;. Instead we could estimate the expected value, given just the observations so far:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;a_{KG}(\mathbf{x}) = \mathbb{E}_{p(y|\mathcal{D})}[\mu^* - \mu^*_{t+1}]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is the definition of the Knowledge Gradient for a minimisation problem &lt;span class=&#34;citation&#34; data-cites=&#34;frazier2018tutorial&#34;&gt;[1]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For a maximisation problem, the definition is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;a_{KG}(\mathbf{x}) = \mathbb{E}_{p(y|\mathcal{D})}[\mu^*_{t+1} - \mu^*]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\mu^* = \max(\mu(\mathbf{x}))&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To calculate KG in practice, we need a way to estimate &lt;span class=&#34;math inline&#34;&gt;\mu^*_{t+1}&lt;/span&gt; as a function of existing observations and we need a way to integrate over &lt;span class=&#34;math inline&#34;&gt;p(y|\mathcal{D})&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To address the latter for a proposed point, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_{sim}&lt;/span&gt;, we take the following steps&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;We draw a sample &lt;span class=&#34;math inline&#34;&gt;y_{sim} \sim p(y|\mathbf{x}_{sim},\mathcal{D})&lt;/span&gt;-&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We then create an augmented dataset &lt;span class=&#34;math inline&#34;&gt;\mathcal{D}^+ = (\{\mathbf{X},\mathbf{x}_{sim}\}, \{\mathbf{y},y_{sim}\})&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We condition the surrogate model on the augmented dataset.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finally, we compute the optimum of the new posterior mean. This is an estimate of &lt;span class=&#34;math inline&#34;&gt;\mu^*_{t+1}&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We cannot integrate this estimate over &lt;span class=&#34;math inline&#34;&gt;p(y_{sim}|\mathcal{D})&lt;/span&gt;, but we can draw &lt;span class=&#34;math inline&#34;&gt;M&lt;/span&gt; samples, compute &lt;span class=&#34;math inline&#34;&gt;\mu^*_{t+1}&lt;/span&gt; for each of them and calculate the mean difference:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;a_{KG}(\mathbf{x}) \approx \frac{1}{M}\sum_{j=1}^M \mu^* - \mu^*_{t+1,j}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As &lt;span class=&#34;math inline&#34;&gt;M&lt;/span&gt; approaches infinity, the estimate should converge to the true KG. Since we need a large amount of samples and need to repeat the process for each candidate &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt;, a good sampler is needed to estimate KG.&lt;/p&gt;
&lt;p&gt;For our simple one-dimensional example, we can brute force it without worrying too much about optimising the calculation. For an example with more dimensions or for a smoother estimate of KG, a proper MCMC sampling would be needed.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb19&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb19-1&#34;&gt;&lt;a href=&#34;#cb19-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;mu_min &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;min&lt;/span&gt;(mu)&lt;/span&gt;
&lt;span id=&#34;cb19-2&#34;&gt;&lt;a href=&#34;#cb19-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;mu_max &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;max&lt;/span&gt;(mu)&lt;/span&gt;
&lt;span id=&#34;cb19-3&#34;&gt;&lt;a href=&#34;#cb19-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# for each candidate point&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-4&#34;&gt;&lt;a href=&#34;#cb19-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;kg &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x_sim =&lt;/span&gt; X_pred) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-5&#34;&gt;&lt;a href=&#34;#cb19-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb19-6&#34;&gt;&lt;a href=&#34;#cb19-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;co&#34;&gt;# Calculate the posterior predictive distribution for y at x_sim&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-7&#34;&gt;&lt;a href=&#34;#cb19-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;post =&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map&lt;/span&gt;(x_sim, gp),&lt;/span&gt;
&lt;span id=&#34;cb19-8&#34;&gt;&lt;a href=&#34;#cb19-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;co&#34;&gt;# Draw M = 100 samples of y_sim from the posterior predictive distribution&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-9&#34;&gt;&lt;a href=&#34;#cb19-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;y_sim =&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map&lt;/span&gt;(post, &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(p) {&lt;/span&gt;
&lt;span id=&#34;cb19-10&#34;&gt;&lt;a href=&#34;#cb19-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(rmvnorm, &lt;span class=&#34;at&#34;&gt;n =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; p&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; p&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;Sigma)&lt;/span&gt;
&lt;span id=&#34;cb19-11&#34;&gt;&lt;a href=&#34;#cb19-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    })&lt;/span&gt;
&lt;span id=&#34;cb19-12&#34;&gt;&lt;a href=&#34;#cb19-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-13&#34;&gt;&lt;a href=&#34;#cb19-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tidyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;unnest_longer&lt;/span&gt;(y_sim) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-14&#34;&gt;&lt;a href=&#34;#cb19-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb19-15&#34;&gt;&lt;a href=&#34;#cb19-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;co&#34;&gt;# For each pair of (x_sim, y_sim)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-16&#34;&gt;&lt;a href=&#34;#cb19-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;co&#34;&gt;# augment dataset with x_sim, y_sim and get the posterior mean&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-17&#34;&gt;&lt;a href=&#34;#cb19-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mu_sim =&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map2&lt;/span&gt;(x_sim, y_sim, &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(xs, ys) {&lt;/span&gt;
&lt;span id=&#34;cb19-18&#34;&gt;&lt;a href=&#34;#cb19-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb19-19&#34;&gt;&lt;a href=&#34;#cb19-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        posterior,&lt;/span&gt;
&lt;span id=&#34;cb19-20&#34;&gt;&lt;a href=&#34;#cb19-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;at&#34;&gt;kernel =&lt;/span&gt; rbf_kernel,&lt;/span&gt;
&lt;span id=&#34;cb19-21&#34;&gt;&lt;a href=&#34;#cb19-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb19-22&#34;&gt;&lt;a href=&#34;#cb19-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rbind&lt;/span&gt;(X_train, xs),&lt;/span&gt;
&lt;span id=&#34;cb19-23&#34;&gt;&lt;a href=&#34;#cb19-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rbind&lt;/span&gt;(y_train, ys),&lt;/span&gt;
&lt;span id=&#34;cb19-24&#34;&gt;&lt;a href=&#34;#cb19-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;parameters&lt;/span&gt;
&lt;span id=&#34;cb19-25&#34;&gt;&lt;a href=&#34;#cb19-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      )&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu&lt;/span&gt;
&lt;span id=&#34;cb19-26&#34;&gt;&lt;a href=&#34;#cb19-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    }),&lt;/span&gt;
&lt;span id=&#34;cb19-27&#34;&gt;&lt;a href=&#34;#cb19-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;co&#34;&gt;# Calculate the estimator&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-28&#34;&gt;&lt;a href=&#34;#cb19-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mu_min_sim =&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map_dbl&lt;/span&gt;(mu_sim, min),&lt;/span&gt;
&lt;span id=&#34;cb19-29&#34;&gt;&lt;a href=&#34;#cb19-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mu_max_sim =&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map_dbl&lt;/span&gt;(mu_sim, max),&lt;/span&gt;
&lt;span id=&#34;cb19-30&#34;&gt;&lt;a href=&#34;#cb19-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mu_diff_min =&lt;/span&gt; mu_min &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; mu_min_sim,&lt;/span&gt;
&lt;span id=&#34;cb19-31&#34;&gt;&lt;a href=&#34;#cb19-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mu_diff_max =&lt;/span&gt; mu_max_sim &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; mu_max&lt;/span&gt;
&lt;span id=&#34;cb19-32&#34;&gt;&lt;a href=&#34;#cb19-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-33&#34;&gt;&lt;a href=&#34;#cb19-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;group_by&lt;/span&gt;(x_sim) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-34&#34;&gt;&lt;a href=&#34;#cb19-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;summarise&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;kg_min =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;mean&lt;/span&gt;(mu_diff_min), &lt;span class=&#34;at&#34;&gt;kg_max =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;mean&lt;/span&gt;(mu_diff_max)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-35&#34;&gt;&lt;a href=&#34;#cb19-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;arrange&lt;/span&gt;(x_sim)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here is KG for the minimisation case. Notice that the estimate is very rough. More samples would have made the estimate smoother. The dashed line shows where we would sample next, according to KG.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb20&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb20-1&#34;&gt;&lt;a href=&#34;#cb20-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb20-2&#34;&gt;&lt;a href=&#34;#cb20-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_pred,&lt;/span&gt;
&lt;span id=&#34;cb20-3&#34;&gt;&lt;a href=&#34;#cb20-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  kg&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;kg_min,&lt;/span&gt;
&lt;span id=&#34;cb20-4&#34;&gt;&lt;a href=&#34;#cb20-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  gp_plot,&lt;/span&gt;
&lt;span id=&#34;cb20-5&#34;&gt;&lt;a href=&#34;#cb20-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(kg&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;kg_min)],&lt;/span&gt;
&lt;span id=&#34;cb20-6&#34;&gt;&lt;a href=&#34;#cb20-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;KG&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb20-7&#34;&gt;&lt;a href=&#34;#cb20-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;Knowledge Gradient (minimisation)&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-8&#34;&gt;&lt;a href=&#34;#cb20-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here is KG for the maximisation case. Notice that the estimate is very rough. The dashed line shows where we would sample next, according to KG.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb21&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb21-1&#34;&gt;&lt;a href=&#34;#cb21-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;acquisition_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb21-2&#34;&gt;&lt;a href=&#34;#cb21-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_pred,&lt;/span&gt;
&lt;span id=&#34;cb21-3&#34;&gt;&lt;a href=&#34;#cb21-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  kg&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;kg_max,&lt;/span&gt;
&lt;span id=&#34;cb21-4&#34;&gt;&lt;a href=&#34;#cb21-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  gp_plot,&lt;/span&gt;
&lt;span id=&#34;cb21-5&#34;&gt;&lt;a href=&#34;#cb21-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_pred[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(kg&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;kg_max)],&lt;/span&gt;
&lt;span id=&#34;cb21-6&#34;&gt;&lt;a href=&#34;#cb21-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;KG&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb21-7&#34;&gt;&lt;a href=&#34;#cb21-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;st&#34;&gt;&#34;Knowledge Gradient (maximisation)&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb21-8&#34;&gt;&lt;a href=&#34;#cb21-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 class=&#34;unnumbered&#34; id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body&#34; role=&#34;doc-bibliography&#34;&gt;
&lt;div id=&#34;ref-frazier2018tutorial&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[1] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Frazier&lt;/span&gt;, P. I. (2018). A tutorial on bayesian optimization. Available at &lt;a href=&#34;https://arxiv.org/abs/1807.02811&#34;&gt;https://arxiv.org/abs/1807.02811&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-garnett_bayesoptbook_2023&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[2] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Garnett&lt;/span&gt;, R. (2023). &lt;em&gt;&lt;span&gt;Bayesian Optimization&lt;/span&gt;&lt;/em&gt;. Cambridge University Press.&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Srinivas_2012&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[3] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Srinivas&lt;/span&gt;, N., &lt;span class=&#34;smallcaps&#34;&gt;Krause&lt;/span&gt;, A., &lt;span class=&#34;smallcaps&#34;&gt;Kakade&lt;/span&gt;, S. M. and &lt;span class=&#34;smallcaps&#34;&gt;Seeger&lt;/span&gt;, M. W. (2012). Information-theoretic regret bounds for gaussian process optimization in the bandit setting. &lt;em&gt;&lt;span&gt;IEEE&lt;/span&gt; Transactions on Information Theory&lt;/em&gt; &lt;strong&gt;58&lt;/strong&gt; 3250–65 Available at &lt;a href=&#34;https://doi.org/10.1109%2Ftit.2011.2182033&#34;&gt;https://doi.org/10.1109%2Ftit.2011.2182033&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;license&#34;&gt;License&lt;/h1&gt;
&lt;p&gt;The content of this project itself is licensed under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International license&lt;/a&gt;, and the underlying code is licensed under the &lt;a href=&#34;https://github.com/AnHosu/bespoke-bayesian-biochem/blob/main/LICENSE&#34;&gt;GNU General Public License v3.0 license&lt;/a&gt;.&lt;/p&gt;
&lt;script type=&#34;application/javascript&#34;&gt;
window.document.addEventListener(&#34;DOMContentLoaded&#34;, function (event) {
  const tabsets =  window.document.querySelectorAll(&#34;.panel-tabset-tabby&#34;)
  tabsets.forEach(function(tabset) {
    const tabby = new Tabby(&#39;#&#39; + tabset.id);
  });
  const icon = &#34;&#34;;
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: &#39;right&#39;,
    icon: icon
  };
  anchorJS.add(&#39;.anchored&#39;);
  const clipboard = new window.ClipboardJS(&#39;.code-copy-button&#39;, {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on(&#39;success&#39;, function(e) {
    // button target
    const button = e.trigger;
    // don&#39;t keep focus
    button.blur();
    // flash &#34;checked&#34;
    button.classList.add(&#39;code-copy-button-checked&#39;);
    setTimeout(function() {
      button.classList.remove(&#39;code-copy-button-checked&#39;);
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: &#39;light-border&#39;,
      placement: &#39;bottom-start&#39;
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-noteref&#34;]&#39;);
  for (var i=0; i&lt;noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute(&#39;href&#39;);
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, &#34;&#34;);
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-biblioref&#34;]&#39;);
  for (var i=0; i&lt;bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute(&#39;data-cites&#39;).split(&#39; &#39;);
    tippyHover(ref, function() {
      var popup = window.document.createElement(&#39;div&#39;);
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement(&#39;div&#39;);
        citeDiv.classList.add(&#39;hanging-indent&#39;);
        citeDiv.classList.add(&#39;csl-entry&#39;);
        var biblioDiv = window.document.getElementById(&#39;ref-&#39; + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
&lt;/script&gt;


&lt;/body&gt;&lt;/html&gt;</description>
    </item>
    
    <item>
      <title>Kernels for Gaussian Processes</title>
      <link>/post/kernels-r/</link>
      <pubDate>Sun, 16 Apr 2023 00:00:00 +0000</pubDate>
      <guid>/post/kernels-r/</guid>
      <description>&lt;!DOCTYPE html&gt;
&lt;html xmlns=&#34;http://www.w3.org/1999/xhtml&#34; lang=&#34;&#34; xml:lang=&#34;&#34;&gt;&lt;head&gt;
  &lt;meta charset=&#34;utf-8&#34;&gt;
  &lt;meta name=&#34;generator&#34; content=&#34;quarto-0.2.243&#34;&gt;
  &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0, user-scalable=yes&#34;&gt;
  &lt;title&gt;index&lt;/title&gt;
  &lt;style&gt;
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre &gt; code.sourceCode { white-space: pre; position: relative; }
    pre &gt; code.sourceCode &gt; span { display: inline-block; line-height: 1.25; }
    pre &gt; code.sourceCode &gt; span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode &gt; span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre &gt; code.sourceCode { white-space: pre-wrap; }
    pre &gt; code.sourceCode &gt; span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code &gt; span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code &gt; span &gt; a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre &gt; code.sourceCode &gt; span &gt; a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  &lt;/style&gt;

  &lt;script src=&#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js&#34;&gt;&lt;/script&gt;
  &lt;script&gt;document.addEventListener(&#34;DOMContentLoaded&#34;, function () {
   var mathElements = document.getElementsByClassName(&#34;math&#34;);
   var macros = [];
   for (var i = 0; i &lt; mathElements.length; i++) {
    var texText = mathElements[i].firstChild;
    if (mathElements[i].tagName == &#34;SPAN&#34;) {
     katex.render(texText.data, mathElements[i], {
      displayMode: mathElements[i].classList.contains(&#39;display&#39;),
      throwOnError: false,
      macros: macros,
      fleqn: false
     });
  }}});
  &lt;/script&gt;
  &lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css&#34;&gt;
  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&#34;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&#34;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
  &lt;script src=&#34;index_files/libs/clipboard/clipboard.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tabby.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/popper.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tippy.umd.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/anchor.min.js&#34;&gt;&lt;/script&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/tippy.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/light-border.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-html.min.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-syntax-highlighting.css&#34; rel=&#34;stylesheet&#34;&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;This post takes an extensive look at kernels and discusses the rationales, utility, and limitations of some popular kernels, focusing primarily on their application in Gaussian processes and Bayesian optimisation. Along with the discussion are implementations of the kernels in base R.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(ggplot2)&lt;/span&gt;
&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(magrittr)&lt;/span&gt;
&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;set.seed&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;4444&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Kernels, also known as covariance functions, are central to Gaussian processes and other machine learning methods where they provide the main means of implementing prior knowledge about the modelled process.&lt;/p&gt;
&lt;p&gt;Intuitively, kernels quantify how similar two points are, given just their position in input space. The kernel function determines the smoothness and complexity of the resulting Gaussian process model, and it controls how much weight is given to different regions of the input space. Different types of kernel functions can be used to model different types of data, such as periodic or spatial data.&lt;/p&gt;
&lt;p&gt;Bayesian optimisation extensively employs Gaussian processes, so kernels provide the means to define a bespoke prior distribution over the objective function or process being optimised. There are a plethora of kernels available, and for successful implementations of Bayesian optimisation, selecting the right one is essential but difficult.&lt;/p&gt;
&lt;h2 id=&#34;applying-kernels-in-gaussian-processes&#34; class=&#34;anchored&#34;&gt;Applying Kernels in Gaussian Processes&lt;/h2&gt;
&lt;p&gt;Formally, a kernel function &lt;span class=&#34;math inline&#34;&gt;k(\mathbf{x},\mathbf{x&#39;})&lt;/span&gt; takes two input vectors, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\mathbf{x&#39;}&lt;/span&gt;, and returns a real-valued scalar that represents a similarity measure between the inputs.&lt;/p&gt;
&lt;p&gt;A kernel function must be positive semi-definite (PSD). This means that the kernel matrix, &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}&lt;/span&gt;, constructed from any set of &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; input row vectors &lt;span class=&#34;math inline&#34;&gt;{\mathbf{x}_1, \ldots, \mathbf{x}_n}&lt;/span&gt;, must be PSD. The entries of the kernel matrix are defined as &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}_{i,j} = k(\mathbf{x}_i, \mathbf{x}_j)&lt;/span&gt;, for all combinations of &lt;span class=&#34;math inline&#34;&gt;i, j \in (1, \ldots, n)&lt;/span&gt;. The PSD property ensures that the kernel matrix can be applied as the covariance matrix in a Gaussian process.&lt;/p&gt;
&lt;p&gt;In the context of a Gaussian process that should approximate an objective function, a good kernel function should be flexible enough to capture the underlying structure of the data, but not so flexible that it overfits the data. The choice of kernel function and its hyperparameters can have a significant impact on the performance of the Gaussian process and its application in Bayesian optimisation, so it is important to choose carefully and experiment with different options.&lt;/p&gt;
&lt;p&gt;However, without knowing the virtues, pitfalls, and assumptions of a kernel, it is difficult to assess its quality for a given problem. In the following sections, a selection of kernels and their virtues are discussed.&lt;/p&gt;
&lt;p&gt;To demonstrate the kernels, two plots are defined. The first plot simply draws the kernel function as a function of Euclidean distance.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;p&gt;&lt;/p&gt;&lt;details&gt;
&lt;summary&gt;Show the code&lt;/summary&gt;&lt;p&gt;&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;plot_kernel_value &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, ...) {&lt;/span&gt;
&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;X1 =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;by =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.05&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;X2 =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1)),&lt;/span&gt;
&lt;span id=&#34;cb2-5&#34;&gt;&lt;a href=&#34;#cb2-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;kv =&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map2_dbl&lt;/span&gt;(X1, X2, kernel, ...)&lt;/span&gt;
&lt;span id=&#34;cb2-6&#34;&gt;&lt;a href=&#34;#cb2-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-7&#34;&gt;&lt;a href=&#34;#cb2-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X1, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; kv)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-8&#34;&gt;&lt;a href=&#34;#cb2-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-9&#34;&gt;&lt;a href=&#34;#cb2-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Euclidean distance&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;kernel value&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb2-10&#34;&gt;&lt;a href=&#34;#cb2-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb2-11&#34;&gt;&lt;a href=&#34;#cb2-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;p&gt;The next plot samples from the Gaussian process that uses the kernel function to calculate its covariance matrix. This essentially translates to sampling random functions from the Gaussian process. See the post on &lt;a href=&#34;../bayesian-opt-r&#34;&gt;Bayesian optimisation&lt;/a&gt; for details.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;p&gt;&lt;/p&gt;&lt;details&gt;
&lt;summary&gt;Show the code&lt;/summary&gt;&lt;p&gt;&lt;/p&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Random Samples from a Multivariate Gaussian&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; This implementation is similar to MASS::mvrnorm, but uses chlosky&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; decomposition instead. This should be more stable but is less efficient than&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-5&#34;&gt;&lt;a href=&#34;#cb3-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; the MASS implementation, which recycles the eigen decomposition for the&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-6&#34;&gt;&lt;a href=&#34;#cb3-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; sampling part.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-7&#34;&gt;&lt;a href=&#34;#cb3-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-8&#34;&gt;&lt;a href=&#34;#cb3-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param n number of samples to sample&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-9&#34;&gt;&lt;a href=&#34;#cb3-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param mu the mean of each input dimension&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-10&#34;&gt;&lt;a href=&#34;#cb3-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma the covariance matrix&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-11&#34;&gt;&lt;a href=&#34;#cb3-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param epsilon numerical tolerance added to the diagonal of the covariance&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-12&#34;&gt;&lt;a href=&#34;#cb3-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;  matrix. This is necessary for the Cholesky decomposition, in some cases.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-13&#34;&gt;&lt;a href=&#34;#cb3-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-14&#34;&gt;&lt;a href=&#34;#cb3-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return numerical vector of n samples&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-15&#34;&gt;&lt;a href=&#34;#cb3-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;rmvnorm &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;n =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, mu, sigma, &lt;span class=&#34;at&#34;&gt;epsilon =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-6&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb3-16&#34;&gt;&lt;a href=&#34;#cb3-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    p &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(mu)&lt;/span&gt;
&lt;span id=&#34;cb3-17&#34;&gt;&lt;a href=&#34;#cb3-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;all&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(sigma) &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(p, p))) &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;incompatible dimensions of arguments&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb3-18&#34;&gt;&lt;a href=&#34;#cb3-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ev &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;eigen&lt;/span&gt;(sigma, &lt;span class=&#34;at&#34;&gt;symmetric =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;TRUE&lt;/span&gt;)&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;values&lt;/span&gt;
&lt;span id=&#34;cb3-19&#34;&gt;&lt;a href=&#34;#cb3-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;all&lt;/span&gt;(ev &lt;span class=&#34;sc&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;epsilon &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;abs&lt;/span&gt;(ev[1L]))) {&lt;/span&gt;
&lt;span id=&#34;cb3-20&#34;&gt;&lt;a href=&#34;#cb3-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;The covariance matrix (sigma) is not positive definite&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb3-21&#34;&gt;&lt;a href=&#34;#cb3-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    }&lt;/span&gt;
&lt;span id=&#34;cb3-22&#34;&gt;&lt;a href=&#34;#cb3-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    cholesky &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;chol&lt;/span&gt;(sigma &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(p) &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; epsilon)&lt;/span&gt;
&lt;span id=&#34;cb3-23&#34;&gt;&lt;a href=&#34;#cb3-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    sample &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(p&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;n, &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb3-24&#34;&gt;&lt;a href=&#34;#cb3-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(sample) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(n, p)&lt;/span&gt;
&lt;span id=&#34;cb3-25&#34;&gt;&lt;a href=&#34;#cb3-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(sample &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; cholesky, &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, mu, &lt;span class=&#34;at&#34;&gt;FUN =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb3-26&#34;&gt;&lt;a href=&#34;#cb3-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb3-27&#34;&gt;&lt;a href=&#34;#cb3-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-28&#34;&gt;&lt;a href=&#34;#cb3-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;plot_gp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, ...) {&lt;/span&gt;
&lt;span id=&#34;cb3-29&#34;&gt;&lt;a href=&#34;#cb3-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  n_samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-30&#34;&gt;&lt;a href=&#34;#cb3-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_predict &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;), &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb3-31&#34;&gt;&lt;a href=&#34;#cb3-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;times =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X_predict))&lt;/span&gt;
&lt;span id=&#34;cb3-32&#34;&gt;&lt;a href=&#34;#cb3-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(kernel, &lt;span class=&#34;at&#34;&gt;X1 =&lt;/span&gt; X_predict, &lt;span class=&#34;at&#34;&gt;X2 =&lt;/span&gt; X_predict, ...)&lt;/span&gt;
&lt;span id=&#34;cb3-33&#34;&gt;&lt;a href=&#34;#cb3-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rmvnorm&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;n =&lt;/span&gt; n_samples, mu, sigma)&lt;/span&gt;
&lt;span id=&#34;cb3-34&#34;&gt;&lt;a href=&#34;#cb3-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb3-35&#34;&gt;&lt;a href=&#34;#cb3-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(samples),&lt;/span&gt;
&lt;span id=&#34;cb3-36&#34;&gt;&lt;a href=&#34;#cb3-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;paste&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;sample&#34;&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, n_samples))&lt;/span&gt;
&lt;span id=&#34;cb3-37&#34;&gt;&lt;a href=&#34;#cb3-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-38&#34;&gt;&lt;a href=&#34;#cb3-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb3-39&#34;&gt;&lt;a href=&#34;#cb3-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_predict,&lt;/span&gt;
&lt;span id=&#34;cb3-40&#34;&gt;&lt;a href=&#34;#cb3-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;uncertainty =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.6&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sqrt&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(sigma)),&lt;/span&gt;
&lt;span id=&#34;cb3-41&#34;&gt;&lt;a href=&#34;#cb3-41&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu,&lt;/span&gt;
&lt;span id=&#34;cb3-42&#34;&gt;&lt;a href=&#34;#cb3-42&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;lower =&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; uncertainty,&lt;/span&gt;
&lt;span id=&#34;cb3-43&#34;&gt;&lt;a href=&#34;#cb3-43&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;upper =&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; uncertainty&lt;/span&gt;
&lt;span id=&#34;cb3-44&#34;&gt;&lt;a href=&#34;#cb3-44&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-45&#34;&gt;&lt;a href=&#34;#cb3-45&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-46&#34;&gt;&lt;a href=&#34;#cb3-46&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_ribbon&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb3-47&#34;&gt;&lt;a href=&#34;#cb3-47&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;ymin =&lt;/span&gt; lower, &lt;span class=&#34;at&#34;&gt;ymax =&lt;/span&gt; upper, &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb3-48&#34;&gt;&lt;a href=&#34;#cb3-48&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-49&#34;&gt;&lt;a href=&#34;#cb3-49&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-50&#34;&gt;&lt;a href=&#34;#cb3-50&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; mu, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Mean&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-51&#34;&gt;&lt;a href=&#34;#cb3-51&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-52&#34;&gt;&lt;a href=&#34;#cb3-52&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb3-53&#34;&gt;&lt;a href=&#34;#cb3-53&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;y&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb3-54&#34;&gt;&lt;a href=&#34;#cb3-54&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;x&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb3-55&#34;&gt;&lt;a href=&#34;#cb3-55&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb3-56&#34;&gt;&lt;a href=&#34;#cb3-56&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-57&#34;&gt;&lt;a href=&#34;#cb3-57&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-58&#34;&gt;&lt;a href=&#34;#cb3-58&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;panel.grid =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;())&lt;/span&gt;
&lt;span id=&#34;cb3-59&#34;&gt;&lt;a href=&#34;#cb3-59&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;Reduce&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb3-60&#34;&gt;&lt;a href=&#34;#cb3-60&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb3-61&#34;&gt;&lt;a href=&#34;#cb3-61&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;init =&lt;/span&gt; p,&lt;/span&gt;
&lt;span id=&#34;cb3-62&#34;&gt;&lt;a href=&#34;#cb3-62&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;lapply&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;paste&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;sample&#34;&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, n_samples)), &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(s) {&lt;/span&gt;
&lt;span id=&#34;cb3-63&#34;&gt;&lt;a href=&#34;#cb3-63&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; .data[[s]], &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; s), &lt;span class=&#34;at&#34;&gt;linetype =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb3-64&#34;&gt;&lt;a href=&#34;#cb3-64&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    })&lt;/span&gt;
&lt;span id=&#34;cb3-65&#34;&gt;&lt;a href=&#34;#cb3-65&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-66&#34;&gt;&lt;a href=&#34;#cb3-66&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_colour_brewer&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;palette =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;YlGnBu&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-67&#34;&gt;&lt;a href=&#34;#cb3-67&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_fill_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#219ebc&#34;&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb3-68&#34;&gt;&lt;a href=&#34;#cb3-68&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;h2 id=&#34;stationary-kernels&#34; class=&#34;anchored&#34;&gt;Stationary Kernels&lt;/h2&gt;
&lt;p&gt;Stationary kernels are a class of kernel functions that are invariant to translations in input space. Mathematically, a kernel function is stationary if it depends only on the difference between its arguments, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}-\mathbf{x&#39;}&lt;/span&gt;, and not on their absolute values. Formally, a kernel function &lt;span class=&#34;math inline&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;})&lt;/span&gt; is stationary if and only if:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;}) = k(\mathbf{x} + a, \mathbf{x&#39;} + a)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for all inputs &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\mathbf{x&#39;}&lt;/span&gt; and all &lt;span class=&#34;math inline&#34;&gt;a&lt;/span&gt;.&lt;/p&gt;
&lt;h3 id=&#34;rbf-kernel&#34; class=&#34;anchored&#34;&gt;RBF Kernel&lt;/h3&gt;
&lt;p&gt;The Radial Basis Function (RBF) kernel is also known as the Squared Exponential kernel or the Gaussian kernel. It is a popular choice in Gaussian processes because of its simplicity and interpretability. The RBF kernel is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;}) = \sigma^2 \exp\left(-\frac{\lVert \mathbf{x} - \mathbf{x&#39;}\rVert^2}{2l^2}\right)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\lVert \mathbf{x} - \mathbf{x&#39;}\rVert^2&lt;/span&gt; is the squared Euclidean distance between the two vectors. &lt;span class=&#34;math inline&#34;&gt;\sigma^2&lt;/span&gt; is a variance parameter that simply scales the kernel. More interestingly, the length scale parameter, &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt;, controls the smoothness and the range of influence of the kernel. It determines how quickly the similarity between two input points decreases as their distance increases.&lt;/p&gt;
&lt;p&gt;Intuitively, small length scales mean that two points have to be very close to have any correlation. This results in very flexible functions that do not expect much correlation between data points. For a large length scale, however, points that are far apart are still expected to behave in a similar way. This results in very smooth functions that expect similar output values across the entire feature space.&lt;/p&gt;
&lt;p&gt;The flexibility and interpretability of the length scale parameter makes the RBF kernel a good starting point, when exploring Gaussian processes.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; RBF Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Isotropic RBF kernel function generalised to two sets of n and m observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-4&#34;&gt;&lt;a href=&#34;#cb4-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; of d features.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-5&#34;&gt;&lt;a href=&#34;#cb4-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-6&#34;&gt;&lt;a href=&#34;#cb4-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-7&#34;&gt;&lt;a href=&#34;#cb4-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-8&#34;&gt;&lt;a href=&#34;#cb4-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma scale parameter, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-9&#34;&gt;&lt;a href=&#34;#cb4-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param l length scale, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-10&#34;&gt;&lt;a href=&#34;#cb4-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-11&#34;&gt;&lt;a href=&#34;#cb4-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return kernel matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-12&#34;&gt;&lt;a href=&#34;#cb4-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;rbf_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb4-13&#34;&gt;&lt;a href=&#34;#cb4-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb4-14&#34;&gt;&lt;a href=&#34;#cb4-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb4-15&#34;&gt;&lt;a href=&#34;#cb4-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sqdist &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;(X1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(X2))) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-16&#34;&gt;&lt;a href=&#34;#cb4-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X1&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-17&#34;&gt;&lt;a href=&#34;#cb4-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X2&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb4-18&#34;&gt;&lt;a href=&#34;#cb4-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;exp&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; l&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; sqdist)&lt;/span&gt;
&lt;span id=&#34;cb4-19&#34;&gt;&lt;a href=&#34;#cb4-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here is an example of how the covariance between two vectors tapers off, as their Euclidean distance increases.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_kernel_value&lt;/span&gt;(rbf_kernel)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Random functions pulled from a Gaussian process that employs the RBF kernel are quite flexible.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_gp&lt;/span&gt;(rbf_kernel)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;rq-kernel&#34; class=&#34;anchored&#34;&gt;RQ Kernel&lt;/h4&gt;
&lt;p&gt;The Rational Quadratic (RQ) kernel is a generalisation of the RBF kernel in the sense that it can be interpreted as an infinite sum of RBF kernels with different length scales. The RQ kernel is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;}) = \sigma^2\left(1 + \frac{\Vert x - x&#39;\Vert^2}{2\alpha \ell^2}\right)^{-\alpha}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\lVert \mathbf{x} - \mathbf{x&#39;}\rVert^2&lt;/span&gt; is the squared Euclidean distance between the two vectors. &lt;span class=&#34;math inline&#34;&gt;\sigma^2&lt;/span&gt; is a variance parameter that simply scales the kernel. The length scale parameter, &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt;, determines how quickly the similarity between two input points decreases as their distance increases, just like for the RBF kernel. The mixture parameter, &lt;span class=&#34;math inline&#34;&gt;\alpha&lt;/span&gt;, can be viewed as controlling how much local variation the kernel allows. When drawing functions from a Gaussian process that employs the RQ kernel, small values of &lt;span class=&#34;math inline&#34;&gt;\alpha&lt;/span&gt; will yield functions with more local variation while still displaying the overall length scaling defined by &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt;. On the other hand, larger values of &lt;span class=&#34;math inline&#34;&gt;\alpha&lt;/span&gt; will yield functions with less local variation. In fact as &lt;span class=&#34;math inline&#34;&gt;\alpha \to \infty&lt;/span&gt; the RQ kernel converges to the RBF kernel with the same &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since the RQ Kernel can model functions with a mixture of different length scales, it is useful for problems where the function may have both local and global variations. However, the RQ kernel needs tuning of two hyperparameters, &lt;span class=&#34;math inline&#34;&gt;\alpha&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt;, which in turn requires more data. The addition of &lt;span class=&#34;math inline&#34;&gt;\alpha&lt;/span&gt; also arguably decreases the interpretability of &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The added flexibility compared to the RBF kernel without too much added complexity, makes the RQ kernel a good alternative, when exploring Gaussian processes.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb7&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb7-1&#34;&gt;&lt;a href=&#34;#cb7-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; RQ Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-2&#34;&gt;&lt;a href=&#34;#cb7-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-3&#34;&gt;&lt;a href=&#34;#cb7-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Isotropic RQ kernel function generalised to two sets of n and m observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-4&#34;&gt;&lt;a href=&#34;#cb7-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; of d features.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-5&#34;&gt;&lt;a href=&#34;#cb7-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-6&#34;&gt;&lt;a href=&#34;#cb7-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-7&#34;&gt;&lt;a href=&#34;#cb7-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-8&#34;&gt;&lt;a href=&#34;#cb7-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma scale parameter, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-9&#34;&gt;&lt;a href=&#34;#cb7-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param l length scale, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-10&#34;&gt;&lt;a href=&#34;#cb7-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param alpha mixture parameter, positive scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-11&#34;&gt;&lt;a href=&#34;#cb7-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-12&#34;&gt;&lt;a href=&#34;#cb7-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return kernel matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-13&#34;&gt;&lt;a href=&#34;#cb7-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;rq_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb7-14&#34;&gt;&lt;a href=&#34;#cb7-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb7-15&#34;&gt;&lt;a href=&#34;#cb7-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb7-16&#34;&gt;&lt;a href=&#34;#cb7-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sqdist &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;(X1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(X2))) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-17&#34;&gt;&lt;a href=&#34;#cb7-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X1&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-18&#34;&gt;&lt;a href=&#34;#cb7-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X2&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb7-19&#34;&gt;&lt;a href=&#34;#cb7-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; (&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; sqdist &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; (&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; alpha &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; l&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;))&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;alpha)&lt;/span&gt;
&lt;span id=&#34;cb7-20&#34;&gt;&lt;a href=&#34;#cb7-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here is an example of how the covariance between two vectors tapers off, as their Euclidean distance increases.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb8&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb8-1&#34;&gt;&lt;a href=&#34;#cb8-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_kernel_value&lt;/span&gt;(rq_kernel, &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The emphasis on local variation yields functions which are much more flexible.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb9&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb9-1&#34;&gt;&lt;a href=&#34;#cb9-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_gp&lt;/span&gt;(rq_kernel, &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;exponential-kernel&#34; class=&#34;anchored&#34;&gt;Exponential Kernel&lt;/h4&gt;
&lt;p&gt;The RBF and RQ kernels represent smooth kernels, i.e.&amp;nbsp;kernels that are differentiable and, when applied in Gaussian processes, yield functions that are less prone to abrupt changes. The exponential kernel, on the other hand, is not differentiable. The exponential kernel is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;}) = \sigma^2 \exp\left(-\frac{\lVert \mathbf{x} - \mathbf{x&#39;}\rVert}{l}\right)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\lVert \mathbf{x} - \mathbf{x&#39;}\rVert&lt;/span&gt; is the Euclidean distance between the two vectors. &lt;span class=&#34;math inline&#34;&gt;\sigma^2&lt;/span&gt; is a variance parameter that simply scales the kernel. The length scale parameter, &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt;, determines how quickly the similarity between two input points decreases as their distance increases, just like for the RBF kernel.&lt;/p&gt;
&lt;p&gt;When applied in Gaussian processes, the exponential kernel yields functions that are much less smooth compared to the RBF kernel. This is useful when trying to model functions that exhibit abrupt changes.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb10&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb10-1&#34;&gt;&lt;a href=&#34;#cb10-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Exponential Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-2&#34;&gt;&lt;a href=&#34;#cb10-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-3&#34;&gt;&lt;a href=&#34;#cb10-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Isotropic exponential kernel function generalised to two sets of n and m&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-4&#34;&gt;&lt;a href=&#34;#cb10-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; observations of d features.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-5&#34;&gt;&lt;a href=&#34;#cb10-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-6&#34;&gt;&lt;a href=&#34;#cb10-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-7&#34;&gt;&lt;a href=&#34;#cb10-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-8&#34;&gt;&lt;a href=&#34;#cb10-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma scale parameter, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-9&#34;&gt;&lt;a href=&#34;#cb10-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param l length scale, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-10&#34;&gt;&lt;a href=&#34;#cb10-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-11&#34;&gt;&lt;a href=&#34;#cb10-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return kernel matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-12&#34;&gt;&lt;a href=&#34;#cb10-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;exponential_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb10-13&#34;&gt;&lt;a href=&#34;#cb10-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb10-14&#34;&gt;&lt;a href=&#34;#cb10-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb10-15&#34;&gt;&lt;a href=&#34;#cb10-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  distance &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;(X1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(X2))) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-16&#34;&gt;&lt;a href=&#34;#cb10-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X1&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-17&#34;&gt;&lt;a href=&#34;#cb10-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X2&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-18&#34;&gt;&lt;a href=&#34;#cb10-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sqrt&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb10-19&#34;&gt;&lt;a href=&#34;#cb10-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;exp&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;distance &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; l)&lt;/span&gt;
&lt;span id=&#34;cb10-20&#34;&gt;&lt;a href=&#34;#cb10-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here is an example of of the covariance tapers off between two vectors, as their Euclidean distance increases. Notice the abrupt decline in covariance.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb11&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb11-1&#34;&gt;&lt;a href=&#34;#cb11-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_kernel_value&lt;/span&gt;(exponential_kernel, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The Gaussian process yields functions which are prone to abrupt changes and thus look very rough.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb12&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb12-1&#34;&gt;&lt;a href=&#34;#cb12-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_gp&lt;/span&gt;(exponential_kernel, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;matérn-kernel&#34; class=&#34;anchored&#34;&gt;Matérn Kernel&lt;/h4&gt;
&lt;p&gt;The Matérn kernel is a flexible and versatile stationary kernel that can model a wide range of functions. The Matérn kernel is given by:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x},\mathbf{x&#39;}) = \sigma^2\frac{2^{1-\nu}}{\Gamma(\nu)}\left(\frac{\sqrt{2\nu}\lVert\mathbf{x}-\mathbf{x&#39;}\rVert}{l}\right)^{\nu} K_{\nu}\left(\frac{\sqrt{2\nu}\lVert\mathbf{x}-\mathbf{x&#39;}\rVert}{l}\right)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\sigma^2&lt;/span&gt; is a variance parameter that scales the kernel, &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt; is the length scale parameter, &lt;span class=&#34;math inline&#34;&gt;\nu&lt;/span&gt; is the smoothness parameter, &lt;span class=&#34;math inline&#34;&gt;\lVert\mathbf{x}-\mathbf{x&#39;}\rVert&lt;/span&gt; is the Euclidean distance between the two vectors, &lt;span class=&#34;math inline&#34;&gt;\Gamma(\cdot)&lt;/span&gt; is the gamma function, and &lt;span class=&#34;math inline&#34;&gt;K_{\nu}(\cdot)&lt;/span&gt; is a modified Bessel function of the second kind with order &lt;span class=&#34;math inline&#34;&gt;\nu&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The RBF kernel yields smooth functions when applied in a Gaussian process, and the exponential kernel yields rugged functions. The Matérn kernel is a generalisation of the RBF kernel, where the parameter &lt;span class=&#34;math inline&#34;&gt;\nu&lt;/span&gt; controls the differentiability, and thus smoothness, of the kernel. In fact, setting &lt;span class=&#34;math inline&#34;&gt;\nu = 0.5&lt;/span&gt; results in the exponential kernel and, as &lt;span class=&#34;math inline&#34;&gt;\nu \to \infty&lt;/span&gt;, the Matérn kernel converges to the RBF kernel.&lt;/p&gt;
&lt;p&gt;The Matérn kernel is a popular choice for Gaussian processes, as it only makes very weak assumptions about the function being modelled. The length scale and smoothness parameters allow for modelling smooth functions with long-range covariance as well as functions with abrupt changes. The downside is that the kernel is very flexible and it takes data and effort to avoid overfitting.&lt;/p&gt;
&lt;p&gt;Base R includes functions for the gamma function as well as a Bessel function of the second kind with given order, so it can be implemented without the need for additional libraries.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb13&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb13-1&#34;&gt;&lt;a href=&#34;#cb13-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Matérn Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-2&#34;&gt;&lt;a href=&#34;#cb13-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-3&#34;&gt;&lt;a href=&#34;#cb13-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Isotropic Matérn kernel function generalised to two sets of n and m&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-4&#34;&gt;&lt;a href=&#34;#cb13-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; observations of d features.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-5&#34;&gt;&lt;a href=&#34;#cb13-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-6&#34;&gt;&lt;a href=&#34;#cb13-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-7&#34;&gt;&lt;a href=&#34;#cb13-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-8&#34;&gt;&lt;a href=&#34;#cb13-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma scale parameter, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-9&#34;&gt;&lt;a href=&#34;#cb13-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param l length scale, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-10&#34;&gt;&lt;a href=&#34;#cb13-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param nu smoothness parameter, positive scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-11&#34;&gt;&lt;a href=&#34;#cb13-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-12&#34;&gt;&lt;a href=&#34;#cb13-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return kernel matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-13&#34;&gt;&lt;a href=&#34;#cb13-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;matern_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;2.5&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb13-14&#34;&gt;&lt;a href=&#34;#cb13-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb13-15&#34;&gt;&lt;a href=&#34;#cb13-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb13-16&#34;&gt;&lt;a href=&#34;#cb13-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  distance &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;(X1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(X2))) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-17&#34;&gt;&lt;a href=&#34;#cb13-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X1&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-18&#34;&gt;&lt;a href=&#34;#cb13-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X2&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-19&#34;&gt;&lt;a href=&#34;#cb13-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sqrt&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb13-20&#34;&gt;&lt;a href=&#34;#cb13-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  term &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;sqrt&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; nu) &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; distance &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; l&lt;/span&gt;
&lt;span id=&#34;cb13-21&#34;&gt;&lt;a href=&#34;#cb13-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; sigma &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; (&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; nu) &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gamma&lt;/span&gt;(nu)) &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; (term&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;nu) &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;besselK&lt;/span&gt;(term, nu)&lt;/span&gt;
&lt;span id=&#34;cb13-22&#34;&gt;&lt;a href=&#34;#cb13-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K[distance &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-23&#34;&gt;&lt;a href=&#34;#cb13-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K&lt;/span&gt;
&lt;span id=&#34;cb13-24&#34;&gt;&lt;a href=&#34;#cb13-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The kernel value looks like the RBF kernel or the exponential kernel, depending on the smoothness parameter&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb14&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb14-1&#34;&gt;&lt;a href=&#34;#cb14-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_kernel_value&lt;/span&gt;(matern_kernel, &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The Matérn kernel can yield functions that strike a balance between smoothness and flexibility&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb15&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb15-1&#34;&gt;&lt;a href=&#34;#cb15-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_gp&lt;/span&gt;(matern_kernel, &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.5&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;periodic-kernels&#34; class=&#34;anchored&#34;&gt;Periodic Kernels&lt;/h2&gt;
&lt;p&gt;Periodic kernels are a class of kernel functions that exhibit periodicity. Formally, a periodic kernel function &lt;span class=&#34;math inline&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;})&lt;/span&gt; is periodic if and only if:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;}) = k(\mathbf{x}, \mathbf{x&#39;}+n\omega)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for all inputs &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\mathbf{x&#39;}&lt;/span&gt; and all integers &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\omega&lt;/span&gt; is the period of the kernel.&lt;/p&gt;
&lt;h4 id=&#34;the-basic-periodic-kernel&#34; class=&#34;anchored&#34;&gt;The Basic Periodic Kernel&lt;/h4&gt;
&lt;p&gt;The basic periodic kernel is a simple periodic kernel that can be used to model functions that exhibit periodic behaviour, i.e., functions that repeat their values in regular intervals. This is especially useful when dealing with time series data or spatial data that exhibit cyclical patterns. The kernel is derived from the RBF kernel with a transformation of the input to a periodic domain &lt;span class=&#34;citation&#34; data-cites=&#34;MacKay:1998&#34;&gt;[1]&lt;/span&gt;. Consequently, the basic periodic kernel resembles the RBF kernel but with an additional trigonometric term that introduces periodicity. The definition is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;}) = \exp \left( -\frac{2 \sin^2\left(\pi \frac{\lVert\mathbf{x}-\mathbf{x&#39;}\rVert}{\omega}\right)}{l^2} \right)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\lVert\mathbf{x}-\mathbf{x&#39;}\rVert&lt;/span&gt; is the Euclidean distance between the two vectors, &lt;span class=&#34;math inline&#34;&gt;\omega&lt;/span&gt; is the period, and &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt; is the length scale.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb16&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb16-1&#34;&gt;&lt;a href=&#34;#cb16-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Basic Periodic Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-2&#34;&gt;&lt;a href=&#34;#cb16-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-3&#34;&gt;&lt;a href=&#34;#cb16-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Isotropic basic periodic kernel function generalised to two sets of n and m&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-4&#34;&gt;&lt;a href=&#34;#cb16-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; observations of d features.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-5&#34;&gt;&lt;a href=&#34;#cb16-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-6&#34;&gt;&lt;a href=&#34;#cb16-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-7&#34;&gt;&lt;a href=&#34;#cb16-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-8&#34;&gt;&lt;a href=&#34;#cb16-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma scale parameter, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-9&#34;&gt;&lt;a href=&#34;#cb16-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param l length scale, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-10&#34;&gt;&lt;a href=&#34;#cb16-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param omega period parameter, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-11&#34;&gt;&lt;a href=&#34;#cb16-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-12&#34;&gt;&lt;a href=&#34;#cb16-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return kernel matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-13&#34;&gt;&lt;a href=&#34;#cb16-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;periodic_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;omega =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb16-14&#34;&gt;&lt;a href=&#34;#cb16-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb16-15&#34;&gt;&lt;a href=&#34;#cb16-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb16-16&#34;&gt;&lt;a href=&#34;#cb16-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  distance &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;(X1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(X2))) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-17&#34;&gt;&lt;a href=&#34;#cb16-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X1&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-18&#34;&gt;&lt;a href=&#34;#cb16-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X2&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-19&#34;&gt;&lt;a href=&#34;#cb16-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sqrt&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb16-20&#34;&gt;&lt;a href=&#34;#cb16-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;exp&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;sin&lt;/span&gt;(pi &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; distance &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; omega)&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; l&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb16-21&#34;&gt;&lt;a href=&#34;#cb16-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Plotting the basic periodic kernel function results in a periodic pattern with peaks and valleys, where the peaks occur when the inputs are multiples of the period, &lt;span class=&#34;math inline&#34;&gt;\omega&lt;/span&gt; apart. The covariance between input points is highest when the points are separated by multiples of the period length and decreases as the distance between the points deviates from multiples of the period.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb17&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb17-1&#34;&gt;&lt;a href=&#34;#cb17-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_kernel_value&lt;/span&gt;(periodic_kernel, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;omega =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.5&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Sampled functions from a Gaussian process that utilises the basic periodic kernel exhibit periodic behaviour. Such functions, when plotted, appear as smooth, oscillating curves that repeat their patterns over regular intervals.&lt;/p&gt;
&lt;p&gt;The properties of the basic periodic kernel, i.e.&amp;nbsp;the period &lt;span class=&#34;math inline&#34;&gt;\omega&lt;/span&gt; and the length scale &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt;, determine the characteristics of the sampled functions.&lt;/p&gt;
&lt;p&gt;The period, &lt;span class=&#34;math inline&#34;&gt;\omega&lt;/span&gt; controls the distance between repetitions of the pattern in the sampled functions. A smaller period length will result in more frequent repetitions, while a larger period length will cause the repetitions to be spaced further apart.&lt;/p&gt;
&lt;p&gt;The length scale, &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt;, determines how smooth or wiggly the sampled functions are, just like it does for the RBF kernel. A smaller length scale will produce more wiggly functions, while a larger length scale will yield smoother functions with fewer oscillations within each period.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb18&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb18-1&#34;&gt;&lt;a href=&#34;#cb18-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_gp&lt;/span&gt;(periodic_kernel, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;omega =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The basic periodic kernel alone cannot capture trends or non-periodic variations in the data, but can be combined with other kernels to create a very powerful model for objective functions with periodicity.&lt;/p&gt;
&lt;p&gt;However, compared to simpler kernels, the basic periodic kernel has an additional hyperparameter, the period parameter &lt;span class=&#34;math inline&#34;&gt;\omega&lt;/span&gt;, that needs to be tuned. The choice of period can have a significant impact on the model performance, and finding an appropriate value can be challenging. As with any periodic kernel, applying the basic periodic kernel comes with the assumption that the underlying objective function being modelled exhibits periodic behaviour. If the assumption does not hold true, applying this kernel could be detrimental.&lt;/p&gt;
&lt;h4 id=&#34;locally-periodic-kernel&#34; class=&#34;anchored&#34;&gt;Locally Periodic Kernel&lt;/h4&gt;
&lt;p&gt;An example of the basic periodic kernel working in tandem with a non-periodic kernel is the locally periodic kernel, which is the product of the basic periodic kernel and the RBF kernel.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;}) = \sigma^2\exp \left( -\frac{2 \sin^2\left(\pi \frac{\lVert\mathbf{x}-\mathbf{x&#39;}\rVert}{\omega}\right)}{l_p^2} \right) \exp \left( -\frac{\lVert\mathbf{x}-\mathbf{x&#39;}\rVert^2}{2 l_v^2} \right)&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb19&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb19-1&#34;&gt;&lt;a href=&#34;#cb19-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Locally Periodic Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-2&#34;&gt;&lt;a href=&#34;#cb19-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-3&#34;&gt;&lt;a href=&#34;#cb19-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Isotropic locally periodic kernel function generalised to two sets of n and m&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-4&#34;&gt;&lt;a href=&#34;#cb19-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; observations of d features.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-5&#34;&gt;&lt;a href=&#34;#cb19-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-6&#34;&gt;&lt;a href=&#34;#cb19-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-7&#34;&gt;&lt;a href=&#34;#cb19-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-8&#34;&gt;&lt;a href=&#34;#cb19-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma scale parameter, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-9&#34;&gt;&lt;a href=&#34;#cb19-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param l_period length scale for periodicity, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-10&#34;&gt;&lt;a href=&#34;#cb19-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param l_var length scale for stationary variance, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-11&#34;&gt;&lt;a href=&#34;#cb19-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param omega period parameter, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-12&#34;&gt;&lt;a href=&#34;#cb19-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-13&#34;&gt;&lt;a href=&#34;#cb19-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return kernel matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-14&#34;&gt;&lt;a href=&#34;#cb19-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;locally_periodic_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1,&lt;/span&gt;
&lt;span id=&#34;cb19-15&#34;&gt;&lt;a href=&#34;#cb19-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                    X2,&lt;/span&gt;
&lt;span id=&#34;cb19-16&#34;&gt;&lt;a href=&#34;#cb19-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                    &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb19-17&#34;&gt;&lt;a href=&#34;#cb19-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                    &lt;span class=&#34;at&#34;&gt;l_period =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb19-18&#34;&gt;&lt;a href=&#34;#cb19-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                    &lt;span class=&#34;at&#34;&gt;l_var =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb19-19&#34;&gt;&lt;a href=&#34;#cb19-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                                    &lt;span class=&#34;at&#34;&gt;omega =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb19-20&#34;&gt;&lt;a href=&#34;#cb19-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;periodic_kernel&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; l_period, &lt;span class=&#34;at&#34;&gt;omega =&lt;/span&gt; omega, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma) &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-21&#34;&gt;&lt;a href=&#34;#cb19-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;rbf_kernel&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; l_period, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb19-22&#34;&gt;&lt;a href=&#34;#cb19-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Plotting the locally periodic kernel results a series of peaks, reflecting the periodic behaviour captured by the periodic kernel. The peaks are highest when the Euclidean distance between the input vectors is a multiple of the period length. The periodic effect is dampened over longer distances due to the length scaling of the RBF kernel.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb20&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb20-1&#34;&gt;&lt;a href=&#34;#cb20-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_kernel_value&lt;/span&gt;(locally_periodic_kernel, &lt;span class=&#34;at&#34;&gt;omega =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Sample functions from a Gaussian process that utilises the locally periodic kernel exhibit both periodic behaviour and local variations. The functions appear as smooth, oscillating curves that repeat their patterns over regular intervals, but with varying amplitude and local changes.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb21&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb21-1&#34;&gt;&lt;a href=&#34;#cb21-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_gp&lt;/span&gt;(locally_periodic_kernel, &lt;span class=&#34;at&#34;&gt;omega =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The locally periodic kernel could be combined with other non-periodic kernels like the Matérn kernel to create even more complex dynamics. However, applying a periodic kernel comes with the assumption that the underlying objective function being modelled exhibits periodic behaviour. If the assumption does not hold true, applying a periodic kernel could be detrimental.&lt;/p&gt;
&lt;h2 id=&#34;non-stationary-kernels&#34; class=&#34;anchored&#34;&gt;Non-stationary Kernels&lt;/h2&gt;
&lt;p&gt;Unlike stationary kernels, non-stationary kernels can depend on the absolute values of their inputs.&lt;/p&gt;
&lt;p&gt;Non-stationary kernels are often used when the underlying function being modelled exhibits varying behaviour or has different characteristics in different regions of feature space. For example, if the function being modelled changes rapidly in some regions and slowly in others, a non-stationary kernel may be more appropriate than a stationary kernel.&lt;/p&gt;
&lt;h3 id=&#34;linear-kernel&#34; class=&#34;anchored&#34;&gt;Linear Kernel&lt;/h3&gt;
&lt;p&gt;The linear kernel, also known as the dot product kernel, is a simple non-stationary kernel function. It is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt; k(\mathbf{x}, \mathbf{x&#39;}) = \mathbf{x}^T \mathbf{x&#39;} + \sigma^2 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\sigma&lt;/span&gt; is a constant. When &lt;span class=&#34;math inline&#34;&gt;sigma = 0&lt;/span&gt; the kernel is called homogeneous and inhomogeneous otherwise.&lt;/p&gt;
&lt;p&gt;The linear kernel can be applied in cases when linear behaviour is expected. If the value of the modelled function is expected to grow as a function of the distance from an origin, a linear kernel might be appropriate.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb22&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb22-1&#34;&gt;&lt;a href=&#34;#cb22-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Linear Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb22-2&#34;&gt;&lt;a href=&#34;#cb22-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb22-3&#34;&gt;&lt;a href=&#34;#cb22-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Linear kernel function generalised to two sets of n and m observations of d&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb22-4&#34;&gt;&lt;a href=&#34;#cb22-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; features.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb22-5&#34;&gt;&lt;a href=&#34;#cb22-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb22-6&#34;&gt;&lt;a href=&#34;#cb22-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb22-7&#34;&gt;&lt;a href=&#34;#cb22-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb22-8&#34;&gt;&lt;a href=&#34;#cb22-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma homogeneity parameter, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb22-9&#34;&gt;&lt;a href=&#34;#cb22-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb22-10&#34;&gt;&lt;a href=&#34;#cb22-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return kernel matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb22-11&#34;&gt;&lt;a href=&#34;#cb22-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;linear_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb22-12&#34;&gt;&lt;a href=&#34;#cb22-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb22-13&#34;&gt;&lt;a href=&#34;#cb22-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb22-14&#34;&gt;&lt;a href=&#34;#cb22-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; X1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(X2)&lt;/span&gt;
&lt;span id=&#34;cb22-15&#34;&gt;&lt;a href=&#34;#cb22-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Sampled functions from a Gaussian process that utilises the linear kernel exhibit linear behaviour. These sampled functions, appear as straight lines with varying slopes and intercepts. Indeed, applying a Gaussian process with a linear kernel to data is equivalent to doing Bayesian linear regression.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb23&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb23-1&#34;&gt;&lt;a href=&#34;#cb23-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_gp&lt;/span&gt;(linear_kernel)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Since this kernel captures linear patterns in the data, the sampled functions will always be straight lines and will not be able to model other types of variation. However, it can be combined with other kernels to increase its utility.&lt;/p&gt;
&lt;h4 id=&#34;polynomial-kernel&#34; class=&#34;anchored&#34;&gt;Polynomial Kernel&lt;/h4&gt;
&lt;p&gt;The polynomial kernel is a generalisation of the linear kernel and is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt; K(\mathbf{x}, \mathbf{x&#39;}) = (\mathbf{x}^T \mathbf{x&#39;} + \sigma^2)^{\nu} &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\sigma&lt;/span&gt; is a constant that determines the shape of the kernel function and &lt;span class=&#34;math inline&#34;&gt;\nu&lt;/span&gt;, a positive integer, is the degree of the polynomial. When &lt;span class=&#34;math inline&#34;&gt;sigma = 0&lt;/span&gt; the kernel is called homogeneous and inhomogeneous otherwise.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb24&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb24-1&#34;&gt;&lt;a href=&#34;#cb24-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Polynomial Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb24-2&#34;&gt;&lt;a href=&#34;#cb24-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb24-3&#34;&gt;&lt;a href=&#34;#cb24-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Polynomial kernel function generalised to two sets of n and m observations of&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb24-4&#34;&gt;&lt;a href=&#34;#cb24-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; d features.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb24-5&#34;&gt;&lt;a href=&#34;#cb24-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb24-6&#34;&gt;&lt;a href=&#34;#cb24-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb24-7&#34;&gt;&lt;a href=&#34;#cb24-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb24-8&#34;&gt;&lt;a href=&#34;#cb24-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma homogeneity parameter, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb24-9&#34;&gt;&lt;a href=&#34;#cb24-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param nu degree parameter, positive integer&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb24-10&#34;&gt;&lt;a href=&#34;#cb24-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb24-11&#34;&gt;&lt;a href=&#34;#cb24-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return kernel matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb24-12&#34;&gt;&lt;a href=&#34;#cb24-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;polynomial_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb24-13&#34;&gt;&lt;a href=&#34;#cb24-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb24-14&#34;&gt;&lt;a href=&#34;#cb24-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb24-15&#34;&gt;&lt;a href=&#34;#cb24-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  (sigma &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; X1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(X2))&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;nu&lt;/span&gt;
&lt;span id=&#34;cb24-16&#34;&gt;&lt;a href=&#34;#cb24-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Sampled functions from a Gaussian process that utilises the polynomial kernel will exhibit polynomial behaviour. The functions appear as smooth curves with varying shapes, depending on the degree and the parameters of the polynomial kernel. When &lt;span class=&#34;math inline&#34;&gt;\nu = 2&lt;/span&gt;, the functions are parabolas.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb25&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb25-1&#34;&gt;&lt;a href=&#34;#cb25-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_gp&lt;/span&gt;(polynomial_kernel, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;nu =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Applying a Gaussian process with the polynomial kernel corresponds to doing Bayesian polynomial regression. This means that the kernel can be applied to model non-linear relationships, but it will also be subject to the same constraints and overfitting challenges of regular polynomial regression.&lt;/p&gt;
&lt;h2 id=&#34;other-kernels&#34; class=&#34;anchored&#34;&gt;Other Kernels&lt;/h2&gt;
&lt;h4 id=&#34;constant-kernel&#34; class=&#34;anchored&#34;&gt;Constant Kernel&lt;/h4&gt;
&lt;p&gt;The constant kernel, also known as the bias kernel, is a simple kernel defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;}) = c&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;c&lt;/span&gt; is a constant value.&lt;/p&gt;
&lt;p&gt;The constant kernel is characterised by its simplicity, as it assumes a constant value, meaning the output is the same for all input points. The constant kernel can be combined with other kernels to model more complex relationships between data points. In Gaussian process regression, this kernel can capture constant offsets in the function being modelled.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb26&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb26-1&#34;&gt;&lt;a href=&#34;#cb26-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Constant Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb26-2&#34;&gt;&lt;a href=&#34;#cb26-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb26-3&#34;&gt;&lt;a href=&#34;#cb26-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Constant kernel function generalised to two sets of n and m observations of d&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb26-4&#34;&gt;&lt;a href=&#34;#cb26-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; features.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb26-5&#34;&gt;&lt;a href=&#34;#cb26-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb26-6&#34;&gt;&lt;a href=&#34;#cb26-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb26-7&#34;&gt;&lt;a href=&#34;#cb26-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb26-8&#34;&gt;&lt;a href=&#34;#cb26-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param c kernel value, scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb26-9&#34;&gt;&lt;a href=&#34;#cb26-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb26-10&#34;&gt;&lt;a href=&#34;#cb26-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return kernel matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb26-11&#34;&gt;&lt;a href=&#34;#cb26-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;constant_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;c =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb26-12&#34;&gt;&lt;a href=&#34;#cb26-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb26-13&#34;&gt;&lt;a href=&#34;#cb26-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb26-14&#34;&gt;&lt;a href=&#34;#cb26-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(c, &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]], &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;
&lt;span id=&#34;cb26-15&#34;&gt;&lt;a href=&#34;#cb26-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The constant kernel function is just a flat, two-dimensional surface parallel to the input space. The height of the surface is equal to the constant value &lt;span class=&#34;math inline&#34;&gt;c&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb27&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb27-1&#34;&gt;&lt;a href=&#34;#cb27-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_kernel_value&lt;/span&gt;(constant_kernel)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Sampled functions from a Gaussian process that utilises the constant kernel are just constant functions. The functions are flat, horizontal lines parallel to the x-axis. There is still variance - each function has a different constant value, determined by the variance specified by the kernel. If the Gaussian process has a zero mean function, the sampled functions will be horizontal lines with y-values centred around zero, and their heights will be determined by the constant kernel value according to &lt;span class=&#34;math inline&#34;&gt;y = \beta&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\beta \sim \mathcal{N}(0, c^2)&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb28&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb28-1&#34;&gt;&lt;a href=&#34;#cb28-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_gp&lt;/span&gt;(constant_kernel)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;white-noise-kernel&#34; class=&#34;anchored&#34;&gt;White Noise Kernel&lt;/h4&gt;
&lt;p&gt;The white noise kernel is also known as the Kronecker Delta Kernel because its definition utilises the Kronecker delta function:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;}) = \sigma^2\delta_{\mathbf{x}, \mathbf{x&#39;}}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In other words, when the input vectors are exactly the same there is noise, &lt;span class=&#34;math inline&#34;&gt;\sigma&lt;/span&gt;, otherwise the kernel is zero.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb29&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb29-1&#34;&gt;&lt;a href=&#34;#cb29-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; White Noise Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-2&#34;&gt;&lt;a href=&#34;#cb29-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-3&#34;&gt;&lt;a href=&#34;#cb29-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; White noise kernel function generalised to two sets of n and m observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-4&#34;&gt;&lt;a href=&#34;#cb29-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; of d features.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-5&#34;&gt;&lt;a href=&#34;#cb29-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-6&#34;&gt;&lt;a href=&#34;#cb29-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-7&#34;&gt;&lt;a href=&#34;#cb29-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-8&#34;&gt;&lt;a href=&#34;#cb29-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma noise parameter, positive scalar&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-9&#34;&gt;&lt;a href=&#34;#cb29-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-10&#34;&gt;&lt;a href=&#34;#cb29-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return kernel matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-11&#34;&gt;&lt;a href=&#34;#cb29-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;white_noise_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb29-12&#34;&gt;&lt;a href=&#34;#cb29-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb29-13&#34;&gt;&lt;a href=&#34;#cb29-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb29-14&#34;&gt;&lt;a href=&#34;#cb29-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  k &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]], &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;
&lt;span id=&#34;cb29-15&#34;&gt;&lt;a href=&#34;#cb29-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(k) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-16&#34;&gt;&lt;a href=&#34;#cb29-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  k &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; sigma&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-17&#34;&gt;&lt;a href=&#34;#cb29-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Samples pulled from a Gaussian processes that utilises just the white noise kernel are nothing but white noise.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb30&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb30-1&#34;&gt;&lt;a href=&#34;#cb30-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_gp&lt;/span&gt;(white_noise_kernel)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The white noise kernel alone cannot capture the underlying signal of the function being modelled. However, it can be used in combination with other kernels. Specifically, the white noise kernel models the case where observations have white, i.e.&amp;nbsp;Gaussian, noise but the magnitude of the noise is unknown.&lt;/p&gt;
&lt;h2 id=&#34;anisotropic-kernels&#34; class=&#34;anchored&#34;&gt;Anisotropic Kernels&lt;/h2&gt;
&lt;p&gt;Anisotropic kernels allow for different length scales in different dimensions of feature space. This is in opposition to the isotropic kernels described above, with a single length scale across all dimensions. Intuitively, the anisotropic kernel is stretched or compressed in certain directions compared to its isotropic counterpart. This property can be useful when the input variables have different units or scales.&lt;/p&gt;
&lt;p&gt;The anisotropy of a kernel is controlled by several length scale parameters, which specify the length scaling along each dimension in feature space. The use of anisotropic kernels can improve the predictive accuracy of Gaussian process models when the input variables have different levels of variability or when the correlations between variables vary in different directions. However, anisotropic kernels also increase the complexity of the model because of the added parameters.&lt;/p&gt;
&lt;p&gt;Formally, an anisotropic kernel can be constructed from an isotropic stationary kernel by substituting the distance part of the definition, i.e.&amp;nbsp;&lt;span class=&#34;math inline&#34;&gt;\lVert\mathbf{x}-\mathbf{x&#39;}\rVert^2/l^2&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;(\mathbf{x}-\mathbf{x&#39;})\mathbf{M}(\mathbf{x}-\mathbf{x&#39;})^T&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\mathbf{M}&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;(D×D)&lt;/span&gt; matrix. There are different options for constructing &lt;span class=&#34;math inline&#34;&gt;\mathbf{M}&lt;/span&gt;. A diagonal matrix &lt;span class=&#34;math inline&#34;&gt;\mathbf{M} = l^{-2}\mathbf{I}&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt; is a scalar, would correspond to the isotropic kernel. A diagonal matrix &lt;span class=&#34;math inline&#34;&gt;\mathbf{M} = \mathrm{diag}(\mathbf{l})^{-2}&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\mathbf{l}&lt;/span&gt; is a vector of length &lt;span class=&#34;math inline&#34;&gt;D&lt;/span&gt; of length scales, would correspond to different length scales for each dimension. There are other options for &lt;span class=&#34;math inline&#34;&gt;\mathbf{M}&lt;/span&gt; as well. See chapter 5 of &lt;span class=&#34;citation&#34; data-cites=&#34;Rasmussen:2006&#34;&gt;[2]&lt;/span&gt;.&lt;/p&gt;
&lt;h4 id=&#34;anisotropic-rbf-kernel&#34; class=&#34;anchored&#34;&gt;Anisotropic RBF Kernel&lt;/h4&gt;
&lt;p&gt;The anisotropic RBF kernel expands the isotropic RBF kernel to allow for individual length scaling of input dimensions. It is defined by&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;}) = \sigma^2 \exp\left(-\frac{1}{2}(\mathbf{x}-\mathbf{x&#39;})\mathbf{M}(\mathbf{x}-\mathbf{x&#39;})^T\right)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\sigma^2&lt;/span&gt; is a variance parameter that simply scales the kernel and &lt;span class=&#34;math inline&#34;&gt;\mathbf{M}&lt;/span&gt; is a &lt;span class=&#34;math inline&#34;&gt;(D×D)&lt;/span&gt; matrix that controls the length scaling of the &lt;span class=&#34;math inline&#34;&gt;D&lt;/span&gt; input dimensions. &lt;span class=&#34;math inline&#34;&gt;\mathbf{M}&lt;/span&gt; is often constructed from a length scale scalar, &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt;, or length scale vector &lt;span class=&#34;math inline&#34;&gt;\mathbf{l}&lt;/span&gt;, see examples below.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb31&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb31-1&#34;&gt;&lt;a href=&#34;#cb31-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Anisotropic RBF Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-2&#34;&gt;&lt;a href=&#34;#cb31-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-3&#34;&gt;&lt;a href=&#34;#cb31-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-4&#34;&gt;&lt;a href=&#34;#cb31-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-5&#34;&gt;&lt;a href=&#34;#cb31-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma scale parameter &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-6&#34;&gt;&lt;a href=&#34;#cb31-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param l length scale. &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-7&#34;&gt;&lt;a href=&#34;#cb31-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; A vector of size 1 yields the isotropic kernel.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-8&#34;&gt;&lt;a href=&#34;#cb31-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; A vector of size d yields the anisotropic kernel with individual length&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-9&#34;&gt;&lt;a href=&#34;#cb31-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; scales for each dimension.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-10&#34;&gt;&lt;a href=&#34;#cb31-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; A matrix of size (d, d) allows for fine-grained control of length scaling.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-11&#34;&gt;&lt;a href=&#34;#cb31-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-12&#34;&gt;&lt;a href=&#34;#cb31-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-13&#34;&gt;&lt;a href=&#34;#cb31-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;anisotropic_rbf_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb31-14&#34;&gt;&lt;a href=&#34;#cb31-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb31-15&#34;&gt;&lt;a href=&#34;#cb31-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb31-16&#34;&gt;&lt;a href=&#34;#cb31-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  d &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1)[[&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;]]&lt;/span&gt;
&lt;span id=&#34;cb31-17&#34;&gt;&lt;a href=&#34;#cb31-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(l)) &lt;span class=&#34;sc&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(l) &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) M &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(d) &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; l&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb31-18&#34;&gt;&lt;a href=&#34;#cb31-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(l)) &lt;span class=&#34;sc&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(l) &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; d) M &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(l&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb31-19&#34;&gt;&lt;a href=&#34;#cb31-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(l)) &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(l)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]] &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; d &lt;span class=&#34;sc&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(l)[[&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;]] &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; d) M &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; l&lt;/span&gt;
&lt;span id=&#34;cb31-20&#34;&gt;&lt;a href=&#34;#cb31-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(M)) &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;Dimensions of length scale are not compatible.&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb31-21&#34;&gt;&lt;a href=&#34;#cb31-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  lX1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; M&lt;/span&gt;
&lt;span id=&#34;cb31-22&#34;&gt;&lt;a href=&#34;#cb31-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  lX2 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X2 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; M&lt;/span&gt;
&lt;span id=&#34;cb31-23&#34;&gt;&lt;a href=&#34;#cb31-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sqdist &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;(lX1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(lX2))) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-24&#34;&gt;&lt;a href=&#34;#cb31-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(lX1&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb31-25&#34;&gt;&lt;a href=&#34;#cb31-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(lX2&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb31-26&#34;&gt;&lt;a href=&#34;#cb31-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;exp&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; sqdist)&lt;/span&gt;
&lt;span id=&#34;cb31-27&#34;&gt;&lt;a href=&#34;#cb31-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;When &lt;span class=&#34;math inline&#34;&gt;\mathbf{M}&lt;/span&gt; is a diagonal matrix&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{M} = l^{-2}\mathbf{I}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt; is a length scale scalar, the kernel is isotropic and the kernel response is exactly identical to the one described above for the RBF kernel.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb32&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb32-1&#34;&gt;&lt;a href=&#34;#cb32-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# A scalar l actually yields the isotropic RBF kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb32-2&#34;&gt;&lt;a href=&#34;#cb32-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;plot_kernel_value&lt;/span&gt;(anisotropic_rbf_kernel, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The scaling is the same in all dimensions. Here is an example in 2D&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb33&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb33-1&#34;&gt;&lt;a href=&#34;#cb33-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Prepare a 2D grid&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb33-2&#34;&gt;&lt;a href=&#34;#cb33-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;as.matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;expand.grid&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;d1 =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.1&lt;/span&gt;), &lt;span class=&#34;at&#34;&gt;d2 =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.1&lt;/span&gt;)))&lt;/span&gt;
&lt;span id=&#34;cb33-3&#34;&gt;&lt;a href=&#34;#cb33-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X2 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1)[[&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;]])&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb34&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb34-1&#34;&gt;&lt;a href=&#34;#cb34-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;K &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;anisotropic_rbf_kernel&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb34-2&#34;&gt;&lt;a href=&#34;#cb34-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(X1) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb34-3&#34;&gt;&lt;a href=&#34;#cb34-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;k =&lt;/span&gt; K) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb34-4&#34;&gt;&lt;a href=&#34;#cb34-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb34-5&#34;&gt;&lt;a href=&#34;#cb34-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_contour_filled&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; d1, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; d2, &lt;span class=&#34;at&#34;&gt;z =&lt;/span&gt; k), &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.8&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb34-6&#34;&gt;&lt;a href=&#34;#cb34-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb34-7&#34;&gt;&lt;a href=&#34;#cb34-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Distance in 1st dimension&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb34-8&#34;&gt;&lt;a href=&#34;#cb34-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Distance in 2nd dimension&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb34-9&#34;&gt;&lt;a href=&#34;#cb34-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Kernel value&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb34-10&#34;&gt;&lt;a href=&#34;#cb34-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb34-11&#34;&gt;&lt;a href=&#34;#cb34-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;()&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-33-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;When &lt;span class=&#34;math inline&#34;&gt;\mathbf{M}&lt;/span&gt; is a diagonal matrix&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{M} = \mathrm{diag}(\mathbf{l})^{-2}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\mathbf{l}&lt;/span&gt; is a length scale vector, the kernel is anisotropic and has a separate length scale for each dimension. This effectively stretches or compresses each dimension. Here is an example in 2D of differing length scales&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb35&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb35-1&#34;&gt;&lt;a href=&#34;#cb35-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;K &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;anisotropic_rbf_kernel&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fl&#34;&gt;2.5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb35-2&#34;&gt;&lt;a href=&#34;#cb35-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(X1) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb35-3&#34;&gt;&lt;a href=&#34;#cb35-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;k =&lt;/span&gt; K) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb35-4&#34;&gt;&lt;a href=&#34;#cb35-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb35-5&#34;&gt;&lt;a href=&#34;#cb35-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_contour_filled&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; d1, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; d2, &lt;span class=&#34;at&#34;&gt;z =&lt;/span&gt; k), &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.8&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb35-6&#34;&gt;&lt;a href=&#34;#cb35-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb35-7&#34;&gt;&lt;a href=&#34;#cb35-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Distance in 1st dimension&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb35-8&#34;&gt;&lt;a href=&#34;#cb35-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Distance in 2nd dimension&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb35-9&#34;&gt;&lt;a href=&#34;#cb35-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Kernel value&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb35-10&#34;&gt;&lt;a href=&#34;#cb35-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb35-11&#34;&gt;&lt;a href=&#34;#cb35-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;()&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-34-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Since the first dimension has a larger length scale than the second dimension, the kernel value gets stretched in the first dimension.&lt;/p&gt;
&lt;p&gt;When the length scales of the anisotropic kernel are fitted rather than given, they can sometimes be used for determining feature relevance. An infinitely large length scale corresponds to a dimension with no variation and thus an irrelevant feature. On the other hand, a smaller length scale could indicate a feature with large variation and influence on the model. The inverse of the length scale is thus sometimes used to indicate feature relevance and the process is known as Automatic Relevance Determination (ARD). However, context is important for proper interpretation of fitted length scales. Specifically, the length scales also depend on the unit of each feature and tend to be biased towards non-linear features &lt;span class=&#34;citation&#34; data-cites=&#34;Piironen:2016&#34;&gt;[3]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;When &lt;span class=&#34;math inline&#34;&gt;\mathbf{M}&lt;/span&gt; has non-zero values outside the diagonal, the kernel is stretched and rotated. Here is an example of a rotated kernel&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb36&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb36-1&#34;&gt;&lt;a href=&#34;#cb36-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;K &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;anisotropic_rbf_kernel&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;), &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb36-2&#34;&gt;&lt;a href=&#34;#cb36-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(X1) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb36-3&#34;&gt;&lt;a href=&#34;#cb36-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;k =&lt;/span&gt; K) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb36-4&#34;&gt;&lt;a href=&#34;#cb36-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb36-5&#34;&gt;&lt;a href=&#34;#cb36-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_contour_filled&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; d1, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; d2, &lt;span class=&#34;at&#34;&gt;z =&lt;/span&gt; k), &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.8&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb36-6&#34;&gt;&lt;a href=&#34;#cb36-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb36-7&#34;&gt;&lt;a href=&#34;#cb36-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Distance in 1st dimension&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb36-8&#34;&gt;&lt;a href=&#34;#cb36-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Distance in 2nd dimension&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb36-9&#34;&gt;&lt;a href=&#34;#cb36-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Kernel value&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb36-10&#34;&gt;&lt;a href=&#34;#cb36-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb36-11&#34;&gt;&lt;a href=&#34;#cb36-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;()&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-35-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This property can be used to create a rotation that effectively reduces the dimensionality of the input features.&lt;/p&gt;
&lt;h2 id=&#34;combining-kernels&#34; class=&#34;anchored&#34;&gt;Combining Kernels&lt;/h2&gt;
&lt;p&gt;Kernels can be combined to create new kernels with more flexibility or sophisticated dynamics. The successful application of Gaussian processes relies on choosing a kernel that can model the target function and combining different types of kernels provides a major means of creating a good kernel for the Gaussian process.&lt;/p&gt;
&lt;p&gt;There are two main ways kernels are combined: combining multiple kernels on each feature or using different kernels for different features.&lt;/p&gt;
&lt;h4 id=&#34;creating-new-kernels-from-existing-kernels&#34; class=&#34;anchored&#34;&gt;Creating new kernels from existing kernels&lt;/h4&gt;
&lt;p&gt;A new kernel can be created from existing kernels in multiple ways.&lt;/p&gt;
&lt;h5 id=&#34;summation&#34; class=&#34;anchored&#34;&gt;Summation&lt;/h5&gt;
&lt;p&gt;Two or more kernels can be added together to create a new kernel that captures the features of both. Two kernels &lt;span class=&#34;math inline&#34;&gt;k_1(\mathbf{x},\mathbf{x&#39;})&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;k_2(\mathbf{x},\mathbf{x&#39;})&lt;/span&gt;, can be combined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k_{sum}(\mathbf{x},\mathbf{x&#39;}) = k_1(\mathbf{x},\mathbf{x&#39;}) + k_2(\mathbf{x},\mathbf{x&#39;})&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The resulting kernel will assign high covariance to pairs of points that are similar in &lt;em&gt;either&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;k_1&lt;/span&gt; &lt;em&gt;or&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;k_2&lt;/span&gt;. I.e. the inputs &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\mathbf{x&#39;}&lt;/span&gt; only need to have a high covariance according to one kernel to return a high covariance for the combined kernel, when the kernels are added together.&lt;/p&gt;
&lt;h5 id=&#34;product&#34; class=&#34;anchored&#34;&gt;Product&lt;/h5&gt;
&lt;p&gt;Two or more kernels can be multiplied together to create a new kernel that captures the features of both. Two kernels &lt;span class=&#34;math inline&#34;&gt;K_1(\mathbf{x},\mathbf{x&#39;})&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;K_2(\mathbf{x},\mathbf{x&#39;})&lt;/span&gt;, can be combined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;K_{sum}(\mathbf{x},\mathbf{x&#39;}) = K_1(\mathbf{x},\mathbf{x&#39;})K_2(\mathbf{x},\mathbf{x&#39;})&lt;/span&gt; The resulting kernel will assign high values to pairs of points that are similar in &lt;em&gt;both&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;k_1&lt;/span&gt; &lt;em&gt;and&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;k_2&lt;/span&gt;. I.e. the inputs &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\mathbf{x&#39;}&lt;/span&gt; need to have a high covariance according to both kernels to return a high covariance for the combined kernel, when the kernels are multiplied. The locally periodic kernel, as described above, is an example of a periodic kernel combined with a stationary kernel by multiplication.&lt;/p&gt;
&lt;p&gt;As a consequence of this rule, any kernel can also be raised to a power of a positive integer and still be a valid kernel. For instance, the polynomial kernel can be viewed as the product of &lt;span class=&#34;math inline&#34;&gt;\nu&lt;/span&gt; linear kernels.&lt;/p&gt;
&lt;h5 id=&#34;other-methods&#34; class=&#34;anchored&#34;&gt;Other Methods&lt;/h5&gt;
&lt;p&gt;The sum and product rules can also be combined. Along with the fact that the constant kernel is a valid kernel, one can effectively create a weighed sum of kernels.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k_{sum}(\mathbf{x},\mathbf{x&#39;}) = w_1k_1(\mathbf{x},\mathbf{x&#39;}) + w_2k_2(\mathbf{x},\mathbf{x&#39;})&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;w_1&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;w_2&lt;/span&gt; are weights.&lt;/p&gt;
&lt;p&gt;Two or more kernels can also be combined through convolution and yield a valid kernel &lt;span class=&#34;citation&#34; data-cites=&#34;Rasmussen:2006&#34;&gt;[2]&lt;/span&gt;.&lt;/p&gt;
&lt;h4 id=&#34;different-kernels-for-different-dimensions&#34; class=&#34;anchored&#34;&gt;Different Kernels for Different Dimensions&lt;/h4&gt;
&lt;p&gt;Using different kernels across different dimensions is often the right thing to, as it allows for a more accurate representation of prior knowledge of the modelled process.&lt;/p&gt;
&lt;p&gt;Specifically, when the input features have different properties or units, different kernels might be appropriate. For example, a dimension representing time might benefit from a periodic kernel and another another representing temperature might best be represented with a stationary kernel. Using a separate kernel for each dimension can help capture the distinct behaviours and scales of the two features. It is also easy to imagine a real-world problem where the gathered data includes a mix of different data types, such as continuous, discrete, or categorical. By applying the right type of kernel to each type of feature, all features can be included in the same Gaussian process.&lt;/p&gt;
&lt;p&gt;Imagine the situation where there are two different types of features, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_a&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}_b&lt;/span&gt;. These could be a set of continuous features and a set of categorical features. On the first set of features, one kernel is applied, i.e., &lt;span class=&#34;math inline&#34;&gt;k_a(\mathbf{x}_a,\mathbf{x&#39;}_a)&lt;/span&gt;. On the other set of features another kernel is applied, i.e., &lt;span class=&#34;math inline&#34;&gt;k_b(\mathbf{x}_b,\mathbf{x&#39;}_b)&lt;/span&gt;. The two kernel values can be combined by multiplication&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}_a, \mathbf{x}_b, \mathbf{x&#39;}_a, \mathbf{x&#39;}_b) = k_a(\mathbf{x}_b,\mathbf{x&#39;}_b)k_b(\mathbf{x}_b,\mathbf{x&#39;}_b)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This scales to many feature sets, so it is possible to have a separate kernel for each feature.&lt;/p&gt;
&lt;h1 class=&#34;unnumbered&#34; id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body&#34; role=&#34;doc-bibliography&#34;&gt;
&lt;div id=&#34;ref-MacKay:1998&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[1] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;MacKay&lt;/span&gt;, D. J. C. (1998). Introduction to gaussian processes. Available at &lt;a href=&#34;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.1927&amp;amp;rep=rep1&amp;amp;type=pdf&#34;&gt;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.1927&amp;amp;rep=rep1&amp;amp;type=pdf&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Rasmussen:2006&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[2] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Rasmussen&lt;/span&gt;, C. E. and &lt;span class=&#34;smallcaps&#34;&gt;Williams&lt;/span&gt;, C. K. I. (2006). &lt;em&gt;Gaussian processes for machine learning, chapters 4 &amp;amp; 5&lt;/em&gt;. MIT Press.&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Piironen:2016&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[3] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Piironen&lt;/span&gt;, J. and &lt;span class=&#34;smallcaps&#34;&gt;Vehtari&lt;/span&gt;, A. (2016). Projection predictive model selection for gaussian processes. In &lt;em&gt;2016 &lt;span&gt;IEEE&lt;/span&gt; 26th international workshop on machine learning for signal processing (&lt;span&gt;MLSP&lt;/span&gt;)&lt;/em&gt;. &lt;span&gt;IEEE&lt;/span&gt; Available at &lt;a href=&#34;https://doi.org/10.1109%2Fmlsp.2016.7738829&#34;&gt;https://doi.org/10.1109%2Fmlsp.2016.7738829&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;license&#34;&gt;License&lt;/h1&gt;
&lt;p&gt;The content of this project itself is licensed under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International license&lt;/a&gt;, and the underlying code is licensed under the &lt;a href=&#34;https://github.com/AnHosu/bespoke-bayesian-biochem/blob/main/LICENSE&#34;&gt;GNU General Public License v3.0 license&lt;/a&gt;.&lt;/p&gt;
&lt;script type=&#34;application/javascript&#34;&gt;
window.document.addEventListener(&#34;DOMContentLoaded&#34;, function (event) {
  const tabsets =  window.document.querySelectorAll(&#34;.panel-tabset-tabby&#34;)
  tabsets.forEach(function(tabset) {
    const tabby = new Tabby(&#39;#&#39; + tabset.id);
  });
  const icon = &#34;&#34;;
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: &#39;right&#39;,
    icon: icon
  };
  anchorJS.add(&#39;.anchored&#39;);
  const clipboard = new window.ClipboardJS(&#39;.code-copy-button&#39;, {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on(&#39;success&#39;, function(e) {
    // button target
    const button = e.trigger;
    // don&#39;t keep focus
    button.blur();
    // flash &#34;checked&#34;
    button.classList.add(&#39;code-copy-button-checked&#39;);
    setTimeout(function() {
      button.classList.remove(&#39;code-copy-button-checked&#39;);
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: &#39;light-border&#39;,
      placement: &#39;bottom-start&#39;
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-noteref&#34;]&#39;);
  for (var i=0; i&lt;noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute(&#39;href&#39;);
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, &#34;&#34;);
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-biblioref&#34;]&#39;);
  for (var i=0; i&lt;bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute(&#39;data-cites&#39;).split(&#39; &#39;);
    tippyHover(ref, function() {
      var popup = window.document.createElement(&#39;div&#39;);
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement(&#39;div&#39;);
        citeDiv.classList.add(&#39;hanging-indent&#39;);
        citeDiv.classList.add(&#39;csl-entry&#39;);
        var biblioDiv = window.document.getElementById(&#39;ref-&#39; + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
&lt;/script&gt;


&lt;/body&gt;&lt;/html&gt;</description>
    </item>
    
    <item>
      <title>Bespoke Bayesian Model for Batch Effects in High Throughput Biochemical Assays</title>
      <link>/post/bespoke-biochem-three/</link>
      <pubDate>Sun, 19 Mar 2023 00:00:00 +0000</pubDate>
      <guid>/post/bespoke-biochem-three/</guid>
      <description>&lt;!DOCTYPE html&gt;
&lt;html xmlns=&#34;http://www.w3.org/1999/xhtml&#34; lang=&#34;&#34; xml:lang=&#34;&#34;&gt;&lt;head&gt;
  &lt;meta charset=&#34;utf-8&#34;&gt;
  &lt;meta name=&#34;generator&#34; content=&#34;quarto-0.2.243&#34;&gt;
  &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0, user-scalable=yes&#34;&gt;
  &lt;meta name=&#34;author&#34; content=&#34;Anders Ellegaard&#34;&gt;
  &lt;meta name=&#34;dcterms.date&#34; content=&#34;2023-03-19&#34;&gt;
  &lt;title&gt;batch-effects&lt;/title&gt;
  &lt;style&gt;
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre &gt; code.sourceCode { white-space: pre; position: relative; }
    pre &gt; code.sourceCode &gt; span { display: inline-block; line-height: 1.25; }
    pre &gt; code.sourceCode &gt; span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode &gt; span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre &gt; code.sourceCode { white-space: pre-wrap; }
    pre &gt; code.sourceCode &gt; span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code &gt; span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code &gt; span &gt; a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre &gt; code.sourceCode &gt; span &gt; a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  &lt;/style&gt;

  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&#34;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&#34;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
  &lt;script src=&#34;index_files/libs/clipboard/clipboard.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tabby.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/popper.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tippy.umd.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/anchor.min.js&#34;&gt;&lt;/script&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/tippy.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/light-border.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-html.min.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-syntax-highlighting.css&#34; rel=&#34;stylesheet&#34;&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;In previous studies, we built bespoke Bayesian models to fit observations from a &lt;a href=&#34;../bespoke-biochem-one&#34;&gt;biochemical assay&lt;/a&gt; with kinetics that could be represented by the Hill equation. Then we scaled that up to a &lt;a href=&#34;../bespoke-biochem-two&#34;&gt;screening experiment&lt;/a&gt;. In those studies, our main goal was to achieve good fits for kinetic parameters.&lt;/p&gt;
&lt;p&gt;In this study, we extend the screening experiment to account for variance outside the kinetics of the tissue response. This can be used to account for batch variation, as is demonstrated here, but could also be used to account for other covariates of interest.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(ggplot2)&lt;/span&gt;
&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(magrittr)&lt;/span&gt;
&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb1-4&#34;&gt;&lt;a href=&#34;#cb1-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;colour &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb1-5&#34;&gt;&lt;a href=&#34;#cb1-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;orange_dark =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#fb8500&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb1-6&#34;&gt;&lt;a href=&#34;#cb1-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;orange_light =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#ffb703&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb1-7&#34;&gt;&lt;a href=&#34;#cb1-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;blue_dark =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#023047&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb1-8&#34;&gt;&lt;a href=&#34;#cb1-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;azure =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#219ebc&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb1-9&#34;&gt;&lt;a href=&#34;#cb1-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;blue_light =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#8ecae6&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb1-10&#34;&gt;&lt;a href=&#34;#cb1-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb1-11&#34;&gt;&lt;a href=&#34;#cb1-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;seed &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4444&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb1-12&#34;&gt;&lt;a href=&#34;#cb1-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;set.seed&lt;/span&gt;(seed)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;generative-model&#34;&gt;Generative Model&lt;/h1&gt;
&lt;p&gt;As as always the case in a Bayesian modelling workflow, we start by considering the process that generated the data. Along the way, we will generate simulations from the generative process.&lt;/p&gt;
&lt;p&gt;The process in this case is going to be similar to the screening experiment of the previous post, but we are imagining a scenario where we perform the screening experiment in four batches. We want to combine and compare results from the four batches, but we also realise that the conditions might vary slightly between each batch, so we need some way to account for that.&lt;/p&gt;
&lt;p&gt;Each tested compound is expected to follow a dose-response curve as described by the Hill equation.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;hill_function &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(log_conc, bottom, top, log_IC50, nH) {&lt;/span&gt;
&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  top &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; (bottom &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; top)&lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;((log_IC50 &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; log_conc)&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;nH))&lt;/span&gt;
&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In our assay, we test each compound at different concentrations and observe the corresponding response. We expect that this response is noisy&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;assay_response &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(log_conc, bottom, top, log_IC50, nH, sigma) {&lt;/span&gt;
&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  noise &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(log_conc), &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, sigma)&lt;/span&gt;
&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;hill_function&lt;/span&gt;(log_conc, bottom, top, log_IC50, nH) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise&lt;/span&gt;
&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb3-5&#34;&gt;&lt;a href=&#34;#cb3-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-6&#34;&gt;&lt;a href=&#34;#cb3-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;screening_experiment &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(parameters, log_conc) {&lt;/span&gt;
&lt;span id=&#34;cb3-7&#34;&gt;&lt;a href=&#34;#cb3-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  parameters &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb3-8&#34;&gt;&lt;a href=&#34;#cb3-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    tidyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;expand_grid&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;log_conc =&lt;/span&gt; log_conc) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-9&#34;&gt;&lt;a href=&#34;#cb3-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb3-10&#34;&gt;&lt;a href=&#34;#cb3-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;response =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;assay_response&lt;/span&gt;(log_conc, bottom, top, log_IC50, nH, sigma)&lt;/span&gt;
&lt;span id=&#34;cb3-11&#34;&gt;&lt;a href=&#34;#cb3-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb3-12&#34;&gt;&lt;a href=&#34;#cb3-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now we can define some parameters for the experiment. It is these parameters that we should be able to recover with the Bayesian model later.&lt;/p&gt;
&lt;p&gt;We imagine an experiment of four batches with 50 compounds each. The compounds are randomly assigned to batches, so there is no correlation between batch and compound parameters. However, the batches are expected to have different levels of noise in the observations.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_batch_size &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;50&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_batches &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_compounds &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; n_batches &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; n_batch_size&lt;/span&gt;
&lt;span id=&#34;cb4-4&#34;&gt;&lt;a href=&#34;#cb4-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-5&#34;&gt;&lt;a href=&#34;#cb4-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;true_parameters &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb4-6&#34;&gt;&lt;a href=&#34;#cb4-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;compound =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, n_compounds),&lt;/span&gt;
&lt;span id=&#34;cb4-7&#34;&gt;&lt;a href=&#34;#cb4-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;batch =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;n_batches, &lt;span class=&#34;at&#34;&gt;each =&lt;/span&gt; n_batch_size),&lt;/span&gt;
&lt;span id=&#34;cb4-8&#34;&gt;&lt;a href=&#34;#cb4-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;bottom =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rlnorm&lt;/span&gt;(n_compounds, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;0.25&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.125&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb4-9&#34;&gt;&lt;a href=&#34;#cb4-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;log_IC50 =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(n_compounds, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;1.5&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rexp&lt;/span&gt;(n_compounds, &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb4-10&#34;&gt;&lt;a href=&#34;#cb4-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;top =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.02&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb4-11&#34;&gt;&lt;a href=&#34;#cb4-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;nH =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.99&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb4-12&#34;&gt;&lt;a href=&#34;#cb4-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rep&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;fl&#34;&gt;0.05&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.4&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; n_batches), &lt;span class=&#34;at&#34;&gt;each =&lt;/span&gt; n_batch_size)&lt;/span&gt;
&lt;span id=&#34;cb4-13&#34;&gt;&lt;a href=&#34;#cb4-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Let’s plot a few curves just to make sure that we have got the generative process right.&lt;/p&gt;
&lt;div class=&#34;cell&#34; data-fig.dim=&#34;[8,4]&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;true_curves &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;pmap&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-2&#34;&gt;&lt;a href=&#34;#cb5-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sample_n&lt;/span&gt;(true_parameters, &lt;span class=&#34;at&#34;&gt;size =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb5-3&#34;&gt;&lt;a href=&#34;#cb5-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;geom_function&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-4&#34;&gt;&lt;a href=&#34;#cb5-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;fun =&lt;/span&gt; hill_function,&lt;/span&gt;
&lt;span id=&#34;cb5-5&#34;&gt;&lt;a href=&#34;#cb5-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;args =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-6&#34;&gt;&lt;a href=&#34;#cb5-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;top =&lt;/span&gt; ..&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-7&#34;&gt;&lt;a href=&#34;#cb5-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;bottom =&lt;/span&gt; ..&lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-8&#34;&gt;&lt;a href=&#34;#cb5-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;nH =&lt;/span&gt; ..&lt;span class=&#34;dv&#34;&gt;6&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-9&#34;&gt;&lt;a href=&#34;#cb5-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;log_IC50 =&lt;/span&gt; ..&lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-10&#34;&gt;&lt;a href=&#34;#cb5-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ),&lt;/span&gt;
&lt;span id=&#34;cb5-11&#34;&gt;&lt;a href=&#34;#cb5-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;blue_dark,&lt;/span&gt;
&lt;span id=&#34;cb5-12&#34;&gt;&lt;a href=&#34;#cb5-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-13&#34;&gt;&lt;a href=&#34;#cb5-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb5-14&#34;&gt;&lt;a href=&#34;#cb5-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-15&#34;&gt;&lt;a href=&#34;#cb5-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-16&#34;&gt;&lt;a href=&#34;#cb5-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;p &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-17&#34;&gt;&lt;a href=&#34;#cb5-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;xlim&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;9&lt;/span&gt;, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-18&#34;&gt;&lt;a href=&#34;#cb5-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-19&#34;&gt;&lt;a href=&#34;#cb5-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb5-20&#34;&gt;&lt;a href=&#34;#cb5-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Ligand concentration [M]&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-21&#34;&gt;&lt;a href=&#34;#cb5-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;True tissue response&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb5-22&#34;&gt;&lt;a href=&#34;#cb5-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Sample True Tissue Responses&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-23&#34;&gt;&lt;a href=&#34;#cb5-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb5-24&#34;&gt;&lt;a href=&#34;#cb5-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-25&#34;&gt;&lt;a href=&#34;#cb5-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;Reduce&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;, true_curves, &lt;span class=&#34;at&#34;&gt;init =&lt;/span&gt; p)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/generative_model-1.png&#34; style=&#34;width:90.0%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;bespoke-bayesian-model&#34;&gt;Bespoke Bayesian Model&lt;/h1&gt;
&lt;p&gt;Now that we understand the generative process and we have functions to simulate data, we can start considering a Bayesian model. We need to specify two things; a set of relations that describe the generative process and priors for any parameters. If this seems similar to what we did in the previous post, it is because it is. The Bayesian model should reflect the process that generated the data, and the process is only slightly different to what we did before. So let’s get started.&lt;/p&gt;
&lt;h2 id=&#34;likelihood-model&#34; class=&#34;anchored&#34;&gt;Likelihood Model&lt;/h2&gt;
&lt;p&gt;In our screening assay, we will consider &lt;span class=&#34;math inline&#34;&gt;&lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;c&lt;/em&gt;&lt;em&gt;o&lt;/em&gt;&lt;em&gt;m&lt;/em&gt;&lt;em&gt;p&lt;/em&gt;&lt;em&gt;o&lt;/em&gt;&lt;em&gt;u&lt;/em&gt;&lt;em&gt;n&lt;/em&gt;&lt;em&gt;d&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt; compounds &lt;span class=&#34;math inline&#34;&gt;&lt;em&gt;j&lt;/em&gt; = 1, ..., &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;c&lt;/em&gt;&lt;em&gt;o&lt;/em&gt;&lt;em&gt;m&lt;/em&gt;&lt;em&gt;p&lt;/em&gt;&lt;em&gt;o&lt;/em&gt;&lt;em&gt;u&lt;/em&gt;&lt;em&gt;n&lt;/em&gt;&lt;em&gt;d&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;. For each compound, we measure an assay response, &lt;span class=&#34;math inline&#34;&gt;&lt;em&gt;y&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;, for a number, &lt;span class=&#34;math inline&#34;&gt;&lt;em&gt;i&lt;/em&gt; = 1, ..., &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;m&lt;/em&gt;&lt;em&gt;e&lt;/em&gt;&lt;em&gt;a&lt;/em&gt;&lt;em&gt;s&lt;/em&gt;&lt;em&gt;u&lt;/em&gt;&lt;em&gt;r&lt;/em&gt;&lt;em&gt;e&lt;/em&gt;&lt;em&gt;m&lt;/em&gt;&lt;em&gt;e&lt;/em&gt;&lt;em&gt;n&lt;/em&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;, of ligand concentrations &lt;span class=&#34;math inline&#34;&gt;[&lt;em&gt;A&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;]&lt;/span&gt;. We also know that the assay response averages to the tissue response, &lt;span class=&#34;math inline&#34;&gt;&lt;em&gt;μ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;em&gt;j&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;, but that observations are noisy. Previously, we assumed that all observations were made in the same batch, such that they had identically distributed noise. In this study, we imagine that we had to do our screening experiment in batches, &lt;span class=&#34;math inline&#34;&gt;&lt;em&gt;k&lt;/em&gt; = 1, ..., &lt;em&gt;N&lt;/em&gt;&lt;sub&gt;&lt;em&gt;b&lt;/em&gt;&lt;em&gt;a&lt;/em&gt;&lt;em&gt;t&lt;/em&gt;&lt;em&gt;c&lt;/em&gt;&lt;em&gt;h&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;, under slightly different conditions.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;$$y_{ijk} \sim {\sf Normal}(\mu_{ij}, \sigma_k)$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that the noise parameter, &lt;span class=&#34;math inline&#34;&gt;&lt;em&gt;σ&lt;/em&gt;&lt;sub&gt;&lt;em&gt;k&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt;, is the same for some, but not all, compounds.&lt;/p&gt;
&lt;p&gt;The dose-response is the same as always&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;$$\mu_{ij} = top - \frac{bottom_j - top}{1 + 10^{(\log_{10}(IC_{50,j}) - \log_{10}([A_{ij}]))^{n_H}}}$$&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&#34;priors&#34; class=&#34;anchored&#34;&gt;Priors&lt;/h2&gt;
&lt;p&gt;For our priors, we employ the same as in the previous post&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;$$top \sim {\sf Normal}(1, 0.01)$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;$$n_H \sim {\sf LogNormal}(0, 0.5)$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;$$bottom_j \sim {\sf Normal}(0.25, 0.25)$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;$$\log_{10}(IC_{50,j}) \sim {\sf Normal}(-6, 1.5)$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The only prior that is a little different is the batch noise, which is now four parameters. We expect the four parameters to be different but sampled from the same distribution.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;$$\sigma_k \sim {\sf Exp}(10)$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s define a function that we can use to sample compounds from the assumed prior distributions.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;prior_parameters &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;n_compounds =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-2&#34;&gt;&lt;a href=&#34;#cb6-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;bottom_mean =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-3&#34;&gt;&lt;a href=&#34;#cb6-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;bottom_sd =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-4&#34;&gt;&lt;a href=&#34;#cb6-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;top_mean =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-5&#34;&gt;&lt;a href=&#34;#cb6-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;top_sd =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-6&#34;&gt;&lt;a href=&#34;#cb6-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;log_IC50_mean =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-7&#34;&gt;&lt;a href=&#34;#cb6-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;log_IC50_sd =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-8&#34;&gt;&lt;a href=&#34;#cb6-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;nH_meanlog =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-9&#34;&gt;&lt;a href=&#34;#cb6-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;nH_sdlog =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-10&#34;&gt;&lt;a href=&#34;#cb6-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                             &lt;span class=&#34;at&#34;&gt;sigma_rate =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb6-11&#34;&gt;&lt;a href=&#34;#cb6-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-12&#34;&gt;&lt;a href=&#34;#cb6-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;compound =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, n_compounds),&lt;/span&gt;
&lt;span id=&#34;cb6-13&#34;&gt;&lt;a href=&#34;#cb6-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;bottom =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(n_compounds, bottom_mean, bottom_sd),&lt;/span&gt;
&lt;span id=&#34;cb6-14&#34;&gt;&lt;a href=&#34;#cb6-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;log_IC50 =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(n_compounds, log_IC50_mean, log_IC50_sd),&lt;/span&gt;
&lt;span id=&#34;cb6-15&#34;&gt;&lt;a href=&#34;#cb6-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;top =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, top_mean, top_sd),&lt;/span&gt;
&lt;span id=&#34;cb6-16&#34;&gt;&lt;a href=&#34;#cb6-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;nH =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rlnorm&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, nH_meanlog, nH_sdlog),&lt;/span&gt;
&lt;span id=&#34;cb6-17&#34;&gt;&lt;a href=&#34;#cb6-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rexp&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, sigma_rate)&lt;/span&gt;
&lt;span id=&#34;cb6-18&#34;&gt;&lt;a href=&#34;#cb6-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb6-19&#34;&gt;&lt;a href=&#34;#cb6-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Let’s also sample some dose-response curves from our assumed joint prior distribution. Hopefully the curves will be similar to those simulated from the generative model, but with a bit of noise.&lt;/p&gt;
&lt;div class=&#34;cell&#34; data-fig.dim=&#34;[8,4]&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb7&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb7-1&#34;&gt;&lt;a href=&#34;#cb7-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;priors &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb7-2&#34;&gt;&lt;a href=&#34;#cb7-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  bottom_mean &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.25&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-3&#34;&gt;&lt;a href=&#34;#cb7-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  bottom_sd &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.25&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-4&#34;&gt;&lt;a href=&#34;#cb7-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  top_mean &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-5&#34;&gt;&lt;a href=&#34;#cb7-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  top_sd &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.01&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-6&#34;&gt;&lt;a href=&#34;#cb7-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  log_IC50_mean &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;6&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-7&#34;&gt;&lt;a href=&#34;#cb7-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  log_IC50_sd &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.5&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-8&#34;&gt;&lt;a href=&#34;#cb7-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  nH_meanlog &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-9&#34;&gt;&lt;a href=&#34;#cb7-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  nH_sdlog &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-10&#34;&gt;&lt;a href=&#34;#cb7-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma_rate &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-11&#34;&gt;&lt;a href=&#34;#cb7-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb7-12&#34;&gt;&lt;a href=&#34;#cb7-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-13&#34;&gt;&lt;a href=&#34;#cb7-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;replicate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb7-14&#34;&gt;&lt;a href=&#34;#cb7-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-15&#34;&gt;&lt;a href=&#34;#cb7-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb7-16&#34;&gt;&lt;a href=&#34;#cb7-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    prior_parameters,&lt;/span&gt;
&lt;span id=&#34;cb7-17&#34;&gt;&lt;a href=&#34;#cb7-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;n_compounds =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-18&#34;&gt;&lt;a href=&#34;#cb7-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;priors&lt;/span&gt;
&lt;span id=&#34;cb7-19&#34;&gt;&lt;a href=&#34;#cb7-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ),&lt;/span&gt;
&lt;span id=&#34;cb7-20&#34;&gt;&lt;a href=&#34;#cb7-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;simplify =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;FALSE&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-21&#34;&gt;&lt;a href=&#34;#cb7-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-22&#34;&gt;&lt;a href=&#34;#cb7-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;bind_rows&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;.id =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;rep&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-23&#34;&gt;&lt;a href=&#34;#cb7-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;rep =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;paste0&lt;/span&gt;(rep, &lt;span class=&#34;st&#34;&gt;&#34;-&#34;&lt;/span&gt;, compound)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-24&#34;&gt;&lt;a href=&#34;#cb7-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;screening_experiment&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;log_conc =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-25&#34;&gt;&lt;a href=&#34;#cb7-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; log_conc, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; response, &lt;span class=&#34;at&#34;&gt;group =&lt;/span&gt; rep)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-26&#34;&gt;&lt;a href=&#34;#cb7-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;blue_dark, &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-27&#34;&gt;&lt;a href=&#34;#cb7-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-28&#34;&gt;&lt;a href=&#34;#cb7-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb7-29&#34;&gt;&lt;a href=&#34;#cb7-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;log ligand concentration&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-30&#34;&gt;&lt;a href=&#34;#cb7-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;response&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb7-31&#34;&gt;&lt;a href=&#34;#cb7-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Prior Samples&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-32&#34;&gt;&lt;a href=&#34;#cb7-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/prior_predictive_check-1.png&#34; style=&#34;width:90.0%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The sampled dose-responses look reasonable.&lt;/p&gt;
&lt;h2 id=&#34;stan-implementation&#34; class=&#34;anchored&#34;&gt;Stan Implementation&lt;/h2&gt;
&lt;p&gt;The likelihood and priors are relatively straightforward to implement in Stan. Each observation now has two indexes, one linking it to a compound and one linking it to a specific batch.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb8&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb8-1&#34;&gt;&lt;a href=&#34;#cb8-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;writeLines&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;readLines&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;hill_equation_batch_effects.stan&#34;&lt;/span&gt;))&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-stdout&#34;&gt;
&lt;pre&gt;&lt;code&gt;data {
  int&amp;lt;lower=0&amp;gt; N;
  int&amp;lt;lower=0&amp;gt; N_comp;
  int&amp;lt;lower=0&amp;gt; N_batch;
  int&amp;lt;lower=0&amp;gt; comp[N];
  int&amp;lt;lower=0&amp;gt; batch[N];
  vector[N] log_conc;
  vector[N] y;
}

parameters {
  real top;
  vector&amp;lt;upper=top&amp;gt;[N_comp] bottom;
  vector[N_comp] log_IC50;
  real&amp;lt;lower=0&amp;gt; nH;
  real&amp;lt;lower=0&amp;gt; sigma[N_batch];
}

model {
  vector[N] mu;
  bottom ~ normal(0.25, 0.25);
  top ~ normal(1, 0.01);
  log_IC50 ~ normal(-6, 1.5);
  nH ~ normal(1, 0.01);
  sigma ~ exponential(10);
  for ( i in 1:N ) {
    mu[i] = top + (bottom[comp[i]] - top) 
                  / (1 + 10^((log_IC50[comp[i]] - log_conc[i])*nH));
    y[i] ~ normal(mu[i], sigma[batch[i]]);
  }
}

generated quantities {
  vector[N] mu;
  vector[N] y_sampled;
  for ( i in 1:N ) {
    mu[i] = top + (bottom[comp[i]] - top) 
                  / (1 + 10^((log_IC50[comp[i]] - log_conc[i])*nH));
    y_sampled[i] = normal_rng(mu[i], sigma[batch[i]]);
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now we can condition the model on some training data. We simulate some data, compile an input for the Stan model, and sample from the posterior&lt;/p&gt;
&lt;div class=&#34;cell&#34; data-hash=&#34;batch-effects_cache/html/model_conditioning_b0a240f5afad93b029d832eaff1b0e0e&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb10&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb10-1&#34;&gt;&lt;a href=&#34;#cb10-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;assay_window &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;8&lt;/span&gt;, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;6&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb10-2&#34;&gt;&lt;a href=&#34;#cb10-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-3&#34;&gt;&lt;a href=&#34;#cb10-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;observations &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;screening_experiment&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb10-4&#34;&gt;&lt;a href=&#34;#cb10-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;parameters =&lt;/span&gt; true_parameters,&lt;/span&gt;
&lt;span id=&#34;cb10-5&#34;&gt;&lt;a href=&#34;#cb10-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;log_conc =&lt;/span&gt; assay_window&lt;/span&gt;
&lt;span id=&#34;cb10-6&#34;&gt;&lt;a href=&#34;#cb10-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb10-7&#34;&gt;&lt;a href=&#34;#cb10-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-8&#34;&gt;&lt;a href=&#34;#cb10-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;data &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb10-9&#34;&gt;&lt;a href=&#34;#cb10-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;N =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;nrow&lt;/span&gt;(observations),&lt;/span&gt;
&lt;span id=&#34;cb10-10&#34;&gt;&lt;a href=&#34;#cb10-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;N_comp =&lt;/span&gt; n_compounds,&lt;/span&gt;
&lt;span id=&#34;cb10-11&#34;&gt;&lt;a href=&#34;#cb10-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;N_batch =&lt;/span&gt; n_batches,&lt;/span&gt;
&lt;span id=&#34;cb10-12&#34;&gt;&lt;a href=&#34;#cb10-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;comp =&lt;/span&gt; observations&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;compound,&lt;/span&gt;
&lt;span id=&#34;cb10-13&#34;&gt;&lt;a href=&#34;#cb10-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;batch =&lt;/span&gt; observations&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;batch,&lt;/span&gt;
&lt;span id=&#34;cb10-14&#34;&gt;&lt;a href=&#34;#cb10-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;log_conc =&lt;/span&gt; observations&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;log_conc,&lt;/span&gt;
&lt;span id=&#34;cb10-15&#34;&gt;&lt;a href=&#34;#cb10-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; observations&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;response&lt;/span&gt;
&lt;span id=&#34;cb10-16&#34;&gt;&lt;a href=&#34;#cb10-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb10-17&#34;&gt;&lt;a href=&#34;#cb10-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-18&#34;&gt;&lt;a href=&#34;#cb10-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rstan&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;stan_model&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;hill_equation_batch_effects.stan&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-19&#34;&gt;&lt;a href=&#34;#cb10-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  rstan&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sampling&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb10-20&#34;&gt;&lt;a href=&#34;#cb10-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; data,&lt;/span&gt;
&lt;span id=&#34;cb10-21&#34;&gt;&lt;a href=&#34;#cb10-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;chains =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb10-22&#34;&gt;&lt;a href=&#34;#cb10-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;cores =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb10-23&#34;&gt;&lt;a href=&#34;#cb10-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;iter =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4000&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb10-24&#34;&gt;&lt;a href=&#34;#cb10-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;seed =&lt;/span&gt; seed&lt;/span&gt;
&lt;span id=&#34;cb10-25&#34;&gt;&lt;a href=&#34;#cb10-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb10-26&#34;&gt;&lt;a href=&#34;#cb10-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-27&#34;&gt;&lt;a href=&#34;#cb10-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Extract samples from the posterior distribution&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb10-28&#34;&gt;&lt;a href=&#34;#cb10-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;posterior_samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(rstan&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;extract&lt;/span&gt;(post))&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;model-evaluation&#34;&gt;Model Evaluation&lt;/h1&gt;
&lt;p&gt;Before diving into the posterior distribution, we should check to see that we have good quality samples for each parameter&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb11&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb11-1&#34;&gt;&lt;a href=&#34;#cb11-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post_summaries &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rstan&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;summary&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb11-2&#34;&gt;&lt;a href=&#34;#cb11-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  post,&lt;/span&gt;
&lt;span id=&#34;cb11-3&#34;&gt;&lt;a href=&#34;#cb11-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;probs =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-4&#34;&gt;&lt;a href=&#34;#cb11-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;summary&lt;/span&gt;
&lt;span id=&#34;cb11-5&#34;&gt;&lt;a href=&#34;#cb11-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-6&#34;&gt;&lt;a href=&#34;#cb11-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(post_summaries) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-7&#34;&gt;&lt;a href=&#34;#cb11-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;select&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(mean, se_mean, sd)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-8&#34;&gt;&lt;a href=&#34;#cb11-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;parameter =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rownames&lt;/span&gt;(post_summaries), &lt;span class=&#34;at&#34;&gt;.before =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-9&#34;&gt;&lt;a href=&#34;#cb11-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;across&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;parameter, round, &lt;span class=&#34;at&#34;&gt;digits =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-10&#34;&gt;&lt;a href=&#34;#cb11-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;arrange&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;desc&lt;/span&gt;(Rhat)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-11&#34;&gt;&lt;a href=&#34;#cb11-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;slice_head&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;n =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-12&#34;&gt;&lt;a href=&#34;#cb11-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  knitr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;kable&lt;/span&gt;()&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th style=&#34;text-align: left;&#34;&gt;parameter&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;n_eff&lt;/th&gt;
&lt;th style=&#34;text-align: right;&#34;&gt;Rhat&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;bottom[25]&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;308.722&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.009&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;log_IC50[25]&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;389.533&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.006&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;mu[1178]&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;718.568&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.005&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;mu[1179]&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;907.454&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.005&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;log_IC50[197]&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1025.443&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;mu[542]&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1471.156&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;mu[543]&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;2084.679&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;mu[1177]&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;851.739&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;mu[129]&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;2058.746&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.003&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td style=&#34;text-align: left;&#34;&gt;mu[149]&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;668.907&lt;/td&gt;
&lt;td style=&#34;text-align: right;&#34;&gt;1.003&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;&lt;em&gt;R̂&lt;/em&gt; &amp;lt; 1.01&lt;/span&gt; for all parameters and it looks like we have at least a couple hundred effective samples, so we should be ready to look at the posterior distribution.&lt;/p&gt;
&lt;h2 id=&#34;shared-parameters&#34; class=&#34;anchored&#34;&gt;Shared Parameters&lt;/h2&gt;
&lt;p&gt;Let’s start with a look at &lt;span class=&#34;math inline&#34;&gt;&lt;em&gt;n&lt;/em&gt;&lt;sub&gt;&lt;em&gt;H&lt;/em&gt;&lt;/sub&gt;&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;&lt;em&gt;t&lt;/em&gt;&lt;em&gt;o&lt;/em&gt;&lt;em&gt;p&lt;/em&gt;&lt;/span&gt; which are shared parameters among all compounds&lt;/p&gt;
&lt;div class=&#34;cell&#34; data-fig.dim=&#34;[8,4]&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb12&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb12-1&#34;&gt;&lt;a href=&#34;#cb12-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# True parameters of the simulation.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-2&#34;&gt;&lt;a href=&#34;#cb12-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;truth &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; true_parameters &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-3&#34;&gt;&lt;a href=&#34;#cb12-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;slice_head&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;n =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-4&#34;&gt;&lt;a href=&#34;#cb12-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tidyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;pivot_longer&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb12-5&#34;&gt;&lt;a href=&#34;#cb12-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;everything&lt;/span&gt;(),&lt;/span&gt;
&lt;span id=&#34;cb12-6&#34;&gt;&lt;a href=&#34;#cb12-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;names_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;parameter&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb12-7&#34;&gt;&lt;a href=&#34;#cb12-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;values_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;truth&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-8&#34;&gt;&lt;a href=&#34;#cb12-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb12-9&#34;&gt;&lt;a href=&#34;#cb12-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-10&#34;&gt;&lt;a href=&#34;#cb12-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# A number of draws from our priors to match the number of draws we have from&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-11&#34;&gt;&lt;a href=&#34;#cb12-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#  the posterior&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-12&#34;&gt;&lt;a href=&#34;#cb12-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;prior_samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;replicate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb12-13&#34;&gt;&lt;a href=&#34;#cb12-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;nrow&lt;/span&gt;(posterior_samples),&lt;/span&gt;
&lt;span id=&#34;cb12-14&#34;&gt;&lt;a href=&#34;#cb12-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb12-15&#34;&gt;&lt;a href=&#34;#cb12-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    prior_parameters,&lt;/span&gt;
&lt;span id=&#34;cb12-16&#34;&gt;&lt;a href=&#34;#cb12-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;n_compounds =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb12-17&#34;&gt;&lt;a href=&#34;#cb12-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;priors&lt;/span&gt;
&lt;span id=&#34;cb12-18&#34;&gt;&lt;a href=&#34;#cb12-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ),&lt;/span&gt;
&lt;span id=&#34;cb12-19&#34;&gt;&lt;a href=&#34;#cb12-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;simplify =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;FALSE&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-20&#34;&gt;&lt;a href=&#34;#cb12-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb12-21&#34;&gt;&lt;a href=&#34;#cb12-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;bind_rows&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-22&#34;&gt;&lt;a href=&#34;#cb12-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;select&lt;/span&gt;(top, nH) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb12-23&#34;&gt;&lt;a href=&#34;#cb12-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tidyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;pivot_longer&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb12-24&#34;&gt;&lt;a href=&#34;#cb12-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;everything&lt;/span&gt;(),&lt;/span&gt;
&lt;span id=&#34;cb12-25&#34;&gt;&lt;a href=&#34;#cb12-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;names_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;parameter&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb12-26&#34;&gt;&lt;a href=&#34;#cb12-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;values_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;sample&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-27&#34;&gt;&lt;a href=&#34;#cb12-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb12-28&#34;&gt;&lt;a href=&#34;#cb12-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-29&#34;&gt;&lt;a href=&#34;#cb12-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-30&#34;&gt;&lt;a href=&#34;#cb12-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Plot each of the marginal distributions, comparing prior, posterior, and true&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-31&#34;&gt;&lt;a href=&#34;#cb12-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#  simulation parameters&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-32&#34;&gt;&lt;a href=&#34;#cb12-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;posterior_samples &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-33&#34;&gt;&lt;a href=&#34;#cb12-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;select&lt;/span&gt;(top, nH) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-34&#34;&gt;&lt;a href=&#34;#cb12-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tidyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;pivot_longer&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb12-35&#34;&gt;&lt;a href=&#34;#cb12-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;everything&lt;/span&gt;(),&lt;/span&gt;
&lt;span id=&#34;cb12-36&#34;&gt;&lt;a href=&#34;#cb12-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;names_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;parameter&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb12-37&#34;&gt;&lt;a href=&#34;#cb12-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;values_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;sample&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-38&#34;&gt;&lt;a href=&#34;#cb12-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-39&#34;&gt;&lt;a href=&#34;#cb12-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;left_join&lt;/span&gt;(truth, &lt;span class=&#34;at&#34;&gt;by =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;parameter&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-40&#34;&gt;&lt;a href=&#34;#cb12-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-41&#34;&gt;&lt;a href=&#34;#cb12-41&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_histogram&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb12-42&#34;&gt;&lt;a href=&#34;#cb12-42&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; prior_samples,&lt;/span&gt;
&lt;span id=&#34;cb12-43&#34;&gt;&lt;a href=&#34;#cb12-43&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mapping =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; sample, &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Prior&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb12-44&#34;&gt;&lt;a href=&#34;#cb12-44&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;bins =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;50&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb12-45&#34;&gt;&lt;a href=&#34;#cb12-45&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-46&#34;&gt;&lt;a href=&#34;#cb12-46&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-47&#34;&gt;&lt;a href=&#34;#cb12-47&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_histogram&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; sample, &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Posterior&#34;&lt;/span&gt;), &lt;span class=&#34;at&#34;&gt;bins =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;50&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-48&#34;&gt;&lt;a href=&#34;#cb12-48&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_vline&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;xintercept =&lt;/span&gt; truth, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;truth&#34;&lt;/span&gt;), &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-49&#34;&gt;&lt;a href=&#34;#cb12-49&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;facet_wrap&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; parameter, &lt;span class=&#34;at&#34;&gt;scales =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;free&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-50&#34;&gt;&lt;a href=&#34;#cb12-50&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-51&#34;&gt;&lt;a href=&#34;#cb12-51&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;scale_colour_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;truth&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;orange_light)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-52&#34;&gt;&lt;a href=&#34;#cb12-52&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;scale_fill_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb12-53&#34;&gt;&lt;a href=&#34;#cb12-53&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;st&#34;&gt;&#34;Prior&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;azure,&lt;/span&gt;
&lt;span id=&#34;cb12-54&#34;&gt;&lt;a href=&#34;#cb12-54&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;st&#34;&gt;&#34;Posterior&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;blue_dark&lt;/span&gt;
&lt;span id=&#34;cb12-55&#34;&gt;&lt;a href=&#34;#cb12-55&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-56&#34;&gt;&lt;a href=&#34;#cb12-56&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb12-57&#34;&gt;&lt;a href=&#34;#cb12-57&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Posterior sample count&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb12-58&#34;&gt;&lt;a href=&#34;#cb12-58&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb12-59&#34;&gt;&lt;a href=&#34;#cb12-59&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb12-60&#34;&gt;&lt;a href=&#34;#cb12-60&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb12-61&#34;&gt;&lt;a href=&#34;#cb12-61&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Marginal Posterior and Prior Distributions&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-62&#34;&gt;&lt;a href=&#34;#cb12-62&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/posterior_marginals_shared-1.png&#34; style=&#34;width:90.0%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We seem to have recovered the true underlying parameters nicely.&lt;/p&gt;
&lt;p&gt;Next up is the batch noise. We had four batches so there are four noise parameters, and hopefully they look different&lt;/p&gt;
&lt;div class=&#34;cell&#34; data-fig.dim=&#34;[8,4]&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb13&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb13-1&#34;&gt;&lt;a href=&#34;#cb13-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# True parameters of the simulation.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-2&#34;&gt;&lt;a href=&#34;#cb13-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;truth &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; true_parameters &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-3&#34;&gt;&lt;a href=&#34;#cb13-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;select&lt;/span&gt;(batch, sigma) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-4&#34;&gt;&lt;a href=&#34;#cb13-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;distinct&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-5&#34;&gt;&lt;a href=&#34;#cb13-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tidyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;pivot_longer&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-6&#34;&gt;&lt;a href=&#34;#cb13-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;batch,&lt;/span&gt;
&lt;span id=&#34;cb13-7&#34;&gt;&lt;a href=&#34;#cb13-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;names_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;parameter&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb13-8&#34;&gt;&lt;a href=&#34;#cb13-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;values_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;truth&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-9&#34;&gt;&lt;a href=&#34;#cb13-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb13-10&#34;&gt;&lt;a href=&#34;#cb13-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-11&#34;&gt;&lt;a href=&#34;#cb13-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;unpack_matrix &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(data, cols) {&lt;/span&gt;
&lt;span id=&#34;cb13-12&#34;&gt;&lt;a href=&#34;#cb13-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;for&lt;/span&gt; (col &lt;span class=&#34;cf&#34;&gt;in&lt;/span&gt; cols) {&lt;/span&gt;
&lt;span id=&#34;cb13-13&#34;&gt;&lt;a href=&#34;#cb13-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    mat &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; data[[col]]&lt;/span&gt;
&lt;span id=&#34;cb13-14&#34;&gt;&lt;a href=&#34;#cb13-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;for&lt;/span&gt; (i &lt;span class=&#34;cf&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(mat)[[&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;]]) {&lt;/span&gt;
&lt;span id=&#34;cb13-15&#34;&gt;&lt;a href=&#34;#cb13-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      cname &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;paste0&lt;/span&gt;(col, i)&lt;/span&gt;
&lt;span id=&#34;cb13-16&#34;&gt;&lt;a href=&#34;#cb13-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      data &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(data, &lt;span class=&#34;st&#34;&gt;&#34;{cname}&#34;&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;er&#34;&gt;=&lt;/span&gt; mat[,i])&lt;/span&gt;
&lt;span id=&#34;cb13-17&#34;&gt;&lt;a href=&#34;#cb13-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    }&lt;/span&gt;
&lt;span id=&#34;cb13-18&#34;&gt;&lt;a href=&#34;#cb13-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb13-19&#34;&gt;&lt;a href=&#34;#cb13-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;select&lt;/span&gt;(data, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;all_of&lt;/span&gt;(cols))&lt;/span&gt;
&lt;span id=&#34;cb13-20&#34;&gt;&lt;a href=&#34;#cb13-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb13-21&#34;&gt;&lt;a href=&#34;#cb13-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-22&#34;&gt;&lt;a href=&#34;#cb13-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# A number of draws from our priors to match the number of draws we have from&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-23&#34;&gt;&lt;a href=&#34;#cb13-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#  the posterior&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-24&#34;&gt;&lt;a href=&#34;#cb13-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;prior_samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;replicate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-25&#34;&gt;&lt;a href=&#34;#cb13-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;nrow&lt;/span&gt;(posterior_samples),&lt;/span&gt;
&lt;span id=&#34;cb13-26&#34;&gt;&lt;a href=&#34;#cb13-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-27&#34;&gt;&lt;a href=&#34;#cb13-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    prior_parameters,&lt;/span&gt;
&lt;span id=&#34;cb13-28&#34;&gt;&lt;a href=&#34;#cb13-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;n_compounds =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb13-29&#34;&gt;&lt;a href=&#34;#cb13-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;priors&lt;/span&gt;
&lt;span id=&#34;cb13-30&#34;&gt;&lt;a href=&#34;#cb13-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ),&lt;/span&gt;
&lt;span id=&#34;cb13-31&#34;&gt;&lt;a href=&#34;#cb13-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;simplify =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;FALSE&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-32&#34;&gt;&lt;a href=&#34;#cb13-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb13-33&#34;&gt;&lt;a href=&#34;#cb13-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;bind_rows&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-34&#34;&gt;&lt;a href=&#34;#cb13-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;select&lt;/span&gt;(sigma) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb13-35&#34;&gt;&lt;a href=&#34;#cb13-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tidyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;pivot_longer&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-36&#34;&gt;&lt;a href=&#34;#cb13-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;everything&lt;/span&gt;(),&lt;/span&gt;
&lt;span id=&#34;cb13-37&#34;&gt;&lt;a href=&#34;#cb13-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;names_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;parameter&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb13-38&#34;&gt;&lt;a href=&#34;#cb13-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;values_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;sample&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-39&#34;&gt;&lt;a href=&#34;#cb13-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb13-40&#34;&gt;&lt;a href=&#34;#cb13-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-41&#34;&gt;&lt;a href=&#34;#cb13-41&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;# Plot each of the marginal distributions, comparing prior, posterior, and true&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-42&#34;&gt;&lt;a href=&#34;#cb13-42&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#  simulation parameters&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-43&#34;&gt;&lt;a href=&#34;#cb13-43&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;lapply&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;:&lt;/span&gt;n_batches, &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(i) {&lt;/span&gt;
&lt;span id=&#34;cb13-44&#34;&gt;&lt;a href=&#34;#cb13-44&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-45&#34;&gt;&lt;a href=&#34;#cb13-45&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; posterior_samples&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma[,i],&lt;/span&gt;
&lt;span id=&#34;cb13-46&#34;&gt;&lt;a href=&#34;#cb13-46&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;batch =&lt;/span&gt; i&lt;/span&gt;
&lt;span id=&#34;cb13-47&#34;&gt;&lt;a href=&#34;#cb13-47&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb13-48&#34;&gt;&lt;a href=&#34;#cb13-48&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-49&#34;&gt;&lt;a href=&#34;#cb13-49&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;bind_rows&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-50&#34;&gt;&lt;a href=&#34;#cb13-50&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tidyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;pivot_longer&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-51&#34;&gt;&lt;a href=&#34;#cb13-51&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;batch,&lt;/span&gt;
&lt;span id=&#34;cb13-52&#34;&gt;&lt;a href=&#34;#cb13-52&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;names_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;parameter&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb13-53&#34;&gt;&lt;a href=&#34;#cb13-53&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;values_to =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;sample&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-54&#34;&gt;&lt;a href=&#34;#cb13-54&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-55&#34;&gt;&lt;a href=&#34;#cb13-55&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;left_join&lt;/span&gt;(truth, &lt;span class=&#34;at&#34;&gt;by =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;parameter&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;batch&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-56&#34;&gt;&lt;a href=&#34;#cb13-56&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-57&#34;&gt;&lt;a href=&#34;#cb13-57&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_histogram&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-58&#34;&gt;&lt;a href=&#34;#cb13-58&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; prior_samples,&lt;/span&gt;
&lt;span id=&#34;cb13-59&#34;&gt;&lt;a href=&#34;#cb13-59&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mapping =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; sample, &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Prior&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb13-60&#34;&gt;&lt;a href=&#34;#cb13-60&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;bins =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;50&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb13-61&#34;&gt;&lt;a href=&#34;#cb13-61&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-62&#34;&gt;&lt;a href=&#34;#cb13-62&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-63&#34;&gt;&lt;a href=&#34;#cb13-63&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_histogram&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; sample, &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Posterior&#34;&lt;/span&gt;), &lt;span class=&#34;at&#34;&gt;bins =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;50&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-64&#34;&gt;&lt;a href=&#34;#cb13-64&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_vline&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;xintercept =&lt;/span&gt; truth, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;truth&#34;&lt;/span&gt;), &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-65&#34;&gt;&lt;a href=&#34;#cb13-65&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;facet_grid&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;rows =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;vars&lt;/span&gt;(batch), &lt;span class=&#34;at&#34;&gt;cols =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;vars&lt;/span&gt;(parameter), &lt;span class=&#34;at&#34;&gt;scales =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;free&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-66&#34;&gt;&lt;a href=&#34;#cb13-66&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-67&#34;&gt;&lt;a href=&#34;#cb13-67&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;strip.text.y =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_text&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;angle =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-68&#34;&gt;&lt;a href=&#34;#cb13-68&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;scale_colour_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;truth&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;orange_light)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-69&#34;&gt;&lt;a href=&#34;#cb13-69&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;scale_fill_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-70&#34;&gt;&lt;a href=&#34;#cb13-70&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;st&#34;&gt;&#34;Prior&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;azure,&lt;/span&gt;
&lt;span id=&#34;cb13-71&#34;&gt;&lt;a href=&#34;#cb13-71&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;st&#34;&gt;&#34;Posterior&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;blue_dark&lt;/span&gt;
&lt;span id=&#34;cb13-72&#34;&gt;&lt;a href=&#34;#cb13-72&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-73&#34;&gt;&lt;a href=&#34;#cb13-73&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb13-74&#34;&gt;&lt;a href=&#34;#cb13-74&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Posterior sample count&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb13-75&#34;&gt;&lt;a href=&#34;#cb13-75&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb13-76&#34;&gt;&lt;a href=&#34;#cb13-76&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb13-77&#34;&gt;&lt;a href=&#34;#cb13-77&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb13-78&#34;&gt;&lt;a href=&#34;#cb13-78&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Marginal Posterior and Prior Distributions&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-79&#34;&gt;&lt;a href=&#34;#cb13-79&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/posterior_marginals_sigma-1.png&#34; style=&#34;width:90.0%&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Our model has successfully recovered the noise parameter for each batch, even though they are different.&lt;/p&gt;
&lt;h2 id=&#34;posterior-curves&#34; class=&#34;anchored&#34;&gt;Posterior Curves&lt;/h2&gt;
&lt;p&gt;It is cool that we are able to recover different noise levels for each batch. However, it is important that this does not come at the cost of worse dose-response curve fits. So let’s check that we are still able to determine good curve parameters.&lt;/p&gt;
&lt;p&gt;I have deliberately chosen one easy and one challenging curve.&lt;/p&gt;
&lt;div class=&#34;cell&#34; data-fig.dim=&#34;[8,4]&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb14&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb14-1&#34;&gt;&lt;a href=&#34;#cb14-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;example_curves &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;curve =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;180&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb14-2&#34;&gt;&lt;a href=&#34;#cb14-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;example_curves&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;post_pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map&lt;/span&gt;(example_curves&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;curve, &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(i) {&lt;/span&gt;
&lt;span id=&#34;cb14-3&#34;&gt;&lt;a href=&#34;#cb14-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  posterior_samples &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-4&#34;&gt;&lt;a href=&#34;#cb14-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sample_n&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;4000&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&#34;co&#34;&gt;# Ran out of RAM...&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-5&#34;&gt;&lt;a href=&#34;#cb14-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-6&#34;&gt;&lt;a href=&#34;#cb14-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;log_IC50 =&lt;/span&gt; log_IC50[, i],&lt;/span&gt;
&lt;span id=&#34;cb14-7&#34;&gt;&lt;a href=&#34;#cb14-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;bottom =&lt;/span&gt; bottom[, i]&lt;/span&gt;
&lt;span id=&#34;cb14-8&#34;&gt;&lt;a href=&#34;#cb14-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-9&#34;&gt;&lt;a href=&#34;#cb14-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    tidyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;expand_grid&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;log_conc =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;9&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;50&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb14-10&#34;&gt;&lt;a href=&#34;#cb14-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;tissue_response =&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;pmap_dbl&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-11&#34;&gt;&lt;a href=&#34;#cb14-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(log_conc, bottom, top, log_IC50, nH),&lt;/span&gt;
&lt;span id=&#34;cb14-12&#34;&gt;&lt;a href=&#34;#cb14-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      hill_function&lt;/span&gt;
&lt;span id=&#34;cb14-13&#34;&gt;&lt;a href=&#34;#cb14-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-14&#34;&gt;&lt;a href=&#34;#cb14-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;group_by&lt;/span&gt;(log_conc) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-15&#34;&gt;&lt;a href=&#34;#cb14-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;summarise&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-16&#34;&gt;&lt;a href=&#34;#cb14-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;response_mean =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;mean&lt;/span&gt;(tissue_response),&lt;/span&gt;
&lt;span id=&#34;cb14-17&#34;&gt;&lt;a href=&#34;#cb14-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;response_upper =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;quantile&lt;/span&gt;(tissue_response, &lt;span class=&#34;at&#34;&gt;probs =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.945&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb14-18&#34;&gt;&lt;a href=&#34;#cb14-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;response_lower =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;quantile&lt;/span&gt;(tissue_response, &lt;span class=&#34;at&#34;&gt;probs =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.055&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb14-19&#34;&gt;&lt;a href=&#34;#cb14-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-20&#34;&gt;&lt;a href=&#34;#cb14-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-21&#34;&gt;&lt;a href=&#34;#cb14-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_ribbon&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-22&#34;&gt;&lt;a href=&#34;#cb14-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-23&#34;&gt;&lt;a href=&#34;#cb14-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; log_conc,&lt;/span&gt;
&lt;span id=&#34;cb14-24&#34;&gt;&lt;a href=&#34;#cb14-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;at&#34;&gt;ymin =&lt;/span&gt; response_lower,&lt;/span&gt;
&lt;span id=&#34;cb14-25&#34;&gt;&lt;a href=&#34;#cb14-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;at&#34;&gt;ymax =&lt;/span&gt; response_upper,&lt;/span&gt;
&lt;span id=&#34;cb14-26&#34;&gt;&lt;a href=&#34;#cb14-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-27&#34;&gt;&lt;a href=&#34;#cb14-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      ),&lt;/span&gt;
&lt;span id=&#34;cb14-28&#34;&gt;&lt;a href=&#34;#cb14-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-29&#34;&gt;&lt;a href=&#34;#cb14-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-30&#34;&gt;&lt;a href=&#34;#cb14-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-31&#34;&gt;&lt;a href=&#34;#cb14-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; log_conc,&lt;/span&gt;
&lt;span id=&#34;cb14-32&#34;&gt;&lt;a href=&#34;#cb14-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; response_mean,&lt;/span&gt;
&lt;span id=&#34;cb14-33&#34;&gt;&lt;a href=&#34;#cb14-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Posterior mean&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-34&#34;&gt;&lt;a href=&#34;#cb14-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-35&#34;&gt;&lt;a href=&#34;#cb14-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-36&#34;&gt;&lt;a href=&#34;#cb14-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;filter&lt;/span&gt;(observations, compound &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; i),&lt;/span&gt;
&lt;span id=&#34;cb14-37&#34;&gt;&lt;a href=&#34;#cb14-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; log_conc, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; response, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Observations&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb14-38&#34;&gt;&lt;a href=&#34;#cb14-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-39&#34;&gt;&lt;a href=&#34;#cb14-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_function&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-40&#34;&gt;&lt;a href=&#34;#cb14-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;fun =&lt;/span&gt; hill_function,&lt;/span&gt;
&lt;span id=&#34;cb14-41&#34;&gt;&lt;a href=&#34;#cb14-41&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;args =&lt;/span&gt; true_parameters[i, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;,&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;,&lt;span class=&#34;dv&#34;&gt;7&lt;/span&gt;)],&lt;/span&gt;
&lt;span id=&#34;cb14-42&#34;&gt;&lt;a href=&#34;#cb14-42&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;mapping =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;True tissue response&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb14-43&#34;&gt;&lt;a href=&#34;#cb14-43&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-44&#34;&gt;&lt;a href=&#34;#cb14-44&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-45&#34;&gt;&lt;a href=&#34;#cb14-45&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Tissue response&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb14-46&#34;&gt;&lt;a href=&#34;#cb14-46&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Log ligand concentration [M]&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb14-47&#34;&gt;&lt;a href=&#34;#cb14-47&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb14-48&#34;&gt;&lt;a href=&#34;#cb14-48&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb14-49&#34;&gt;&lt;a href=&#34;#cb14-49&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;paste&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;Posterior Predictive for Compound&#34;&lt;/span&gt;, i)&lt;/span&gt;
&lt;span id=&#34;cb14-50&#34;&gt;&lt;a href=&#34;#cb14-50&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-51&#34;&gt;&lt;a href=&#34;#cb14-51&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_fill_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;azure)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-52&#34;&gt;&lt;a href=&#34;#cb14-52&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb14-53&#34;&gt;&lt;a href=&#34;#cb14-53&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;})&lt;/span&gt;
&lt;span id=&#34;cb14-54&#34;&gt;&lt;a href=&#34;#cb14-54&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;example_curves&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;post_pred_coloured &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-55&#34;&gt;&lt;a href=&#34;#cb14-55&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  example_curves&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;post_pred,&lt;/span&gt;
&lt;span id=&#34;cb14-56&#34;&gt;&lt;a href=&#34;#cb14-56&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(p) {&lt;/span&gt;
&lt;span id=&#34;cb14-57&#34;&gt;&lt;a href=&#34;#cb14-57&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    p &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;scale_colour_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb14-58&#34;&gt;&lt;a href=&#34;#cb14-58&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;st&#34;&gt;&#34;Posterior mean&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;blue_dark,&lt;/span&gt;
&lt;span id=&#34;cb14-59&#34;&gt;&lt;a href=&#34;#cb14-59&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;st&#34;&gt;&#34;Observations&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;orange_light,&lt;/span&gt;
&lt;span id=&#34;cb14-60&#34;&gt;&lt;a href=&#34;#cb14-60&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;st&#34;&gt;&#34;True tissue response&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; colour&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;orange_dark&lt;/span&gt;
&lt;span id=&#34;cb14-61&#34;&gt;&lt;a href=&#34;#cb14-61&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ))&lt;/span&gt;
&lt;span id=&#34;cb14-62&#34;&gt;&lt;a href=&#34;#cb14-62&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb14-63&#34;&gt;&lt;a href=&#34;#cb14-63&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;For the well-behaved curve, all looks good and the uncertainty around the key parameters is fairly small.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb15&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb15-1&#34;&gt;&lt;a href=&#34;#cb15-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;example_curves&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;post_pred_coloured[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]]&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Even in the difficult case, we get a decent fit, demonstrating that we can still get good curves even with the addition of additional parameters to account for batch effects.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb16&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb16-1&#34;&gt;&lt;a href=&#34;#cb16-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;example_curves&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;post_pred_coloured[[&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;]]&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;perspective&#34;&gt;Perspective&lt;/h1&gt;
&lt;p&gt;In this post, we extended our model for the dose-response screening experiment to also include batch effects. We demonstrated that batch effects can be recovered without compromising on curve parameter quality.&lt;/p&gt;
&lt;p&gt;Accounting for batch effects is already very useful, but the approach can be expanded to even more useful situations. Imagine, for instance, a case where the model includes expressions that relate either efficacy or potency to known variations among compounds. That way we combine the power of screening assays with the structure of experiments and possibly derive much more information from our hard earned data.&lt;/p&gt;
&lt;script type=&#34;application/javascript&#34;&gt;
window.document.addEventListener(&#34;DOMContentLoaded&#34;, function (event) {
  const tabsets =  window.document.querySelectorAll(&#34;.panel-tabset-tabby&#34;)
  tabsets.forEach(function(tabset) {
    const tabby = new Tabby(&#39;#&#39; + tabset.id);
  });
  const icon = &#34;&#34;;
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: &#39;right&#39;,
    icon: icon
  };
  anchorJS.add(&#39;.anchored&#39;);
  const clipboard = new window.ClipboardJS(&#39;.code-copy-button&#39;, {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on(&#39;success&#39;, function(e) {
    // button target
    const button = e.trigger;
    // don&#39;t keep focus
    button.blur();
    // flash &#34;checked&#34;
    button.classList.add(&#39;code-copy-button-checked&#39;);
    setTimeout(function() {
      button.classList.remove(&#39;code-copy-button-checked&#39;);
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: &#39;light-border&#39;,
      placement: &#39;bottom-start&#39;
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-noteref&#34;]&#39;);
  for (var i=0; i&lt;noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute(&#39;href&#39;);
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, &#34;&#34;);
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-biblioref&#34;]&#39;);
  for (var i=0; i&lt;bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute(&#39;data-cites&#39;).split(&#39; &#39;);
    tippyHover(ref, function() {
      var popup = window.document.createElement(&#39;div&#39;);
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement(&#39;div&#39;);
        citeDiv.classList.add(&#39;hanging-indent&#39;);
        citeDiv.classList.add(&#39;csl-entry&#39;);
        var biblioDiv = window.document.getElementById(&#39;ref-&#39; + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
&lt;/script&gt;


&lt;/body&gt;&lt;/html&gt;</description>
    </item>
    
    <item>
      <title>Bayesian Optimisation from Scratch in R</title>
      <link>/post/bayesian-opt-r/</link>
      <pubDate>Sun, 12 Mar 2023 00:00:00 +0000</pubDate>
      <guid>/post/bayesian-opt-r/</guid>
      <description>&lt;!DOCTYPE html&gt;
&lt;html xmlns=&#34;http://www.w3.org/1999/xhtml&#34; lang=&#34;&#34; xml:lang=&#34;&#34;&gt;&lt;head&gt;
  &lt;meta charset=&#34;utf-8&#34;&gt;
  &lt;meta name=&#34;generator&#34; content=&#34;quarto-0.2.243&#34;&gt;
  &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0, user-scalable=yes&#34;&gt;
  &lt;title&gt;index&lt;/title&gt;
  &lt;style&gt;
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre &gt; code.sourceCode { white-space: pre; position: relative; }
    pre &gt; code.sourceCode &gt; span { display: inline-block; line-height: 1.25; }
    pre &gt; code.sourceCode &gt; span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode &gt; span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre &gt; code.sourceCode { white-space: pre-wrap; }
    pre &gt; code.sourceCode &gt; span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code &gt; span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code &gt; span &gt; a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre &gt; code.sourceCode &gt; span &gt; a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  &lt;/style&gt;

  &lt;script src=&#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.js&#34;&gt;&lt;/script&gt;
  &lt;script&gt;document.addEventListener(&#34;DOMContentLoaded&#34;, function () {
   var mathElements = document.getElementsByClassName(&#34;math&#34;);
   var macros = [];
   for (var i = 0; i &lt; mathElements.length; i++) {
    var texText = mathElements[i].firstChild;
    if (mathElements[i].tagName == &#34;SPAN&#34;) {
     katex.render(texText.data, mathElements[i], {
      displayMode: mathElements[i].classList.contains(&#39;display&#39;),
      throwOnError: false,
      macros: macros,
      fleqn: false
     });
  }}});
  &lt;/script&gt;
  &lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css&#34;&gt;
  &lt;!--[if lt IE 9]&gt;
    &lt;script src=&#34;//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js&#34;&gt;&lt;/script&gt;
  &lt;![endif]--&gt;
  &lt;script src=&#34;index_files/libs/clipboard/clipboard.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tabby.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/popper.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/tippy.umd.min.js&#34;&gt;&lt;/script&gt;
  &lt;script src=&#34;index_files/libs/quarto-html/anchor.min.js&#34;&gt;&lt;/script&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/tippy.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/light-border.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-html.min.css&#34; rel=&#34;stylesheet&#34;&gt;
  &lt;link href=&#34;index_files/libs/quarto-html/quarto-syntax-highlighting.css&#34; rel=&#34;stylesheet&#34;&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;Bayesian optimisation is a powerful technique for optimising expensive functions or processes. In many applications, such as drug discovery, manufacturing, machine learning, or scientific experimentation, the function or process to be optimised may be time consuming or costly to evaluate. Bayesian optimisation provides a framework for sequential experimentation and for finding optima with as few evaluations as possible.&lt;/p&gt;
&lt;p&gt;This post seeks to introduce the core ideas and components of Bayesian optimisation. Along with the introduction are implementations of all the core components of Bayesian optimisation in R. The implementations only use base R and Tidyverse - they are designed to be simple and not necessarily efficient.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb1&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb1-1&#34;&gt;&lt;a href=&#34;#cb1-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(ggplot2)&lt;/span&gt;
&lt;span id=&#34;cb1-2&#34;&gt;&lt;a href=&#34;#cb1-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;library&lt;/span&gt;(magrittr)&lt;/span&gt;
&lt;span id=&#34;cb1-3&#34;&gt;&lt;a href=&#34;#cb1-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;set.seed&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;4444&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The core idea behind Bayesian optimisation is to use a surrogate model to approximate a true objective function or process, and then use this approximation to determine the next experiment to perform. Typically, Gaussian processes or other similar probabilistic models are used as surrogate models.&lt;/p&gt;
&lt;p&gt;The surrogate model is initialised with a few points and an acquisition function is then used to determine the next point to evaluate. The acquisition function balances exploration, ie. searching the regions of covariate space where the uncertainty is high, and exploitation ie. searching the regions where the surrogate model predicts a high value.&lt;/p&gt;
&lt;p&gt;After the next point is evaluated, it is added to the existing data and the surrogate model is updated. The process of selecting the next point to evaluate and updating the surrogate model is repeated until a stopping criterion is met. This could be when subsequent experiments stop yielding significantly different or better results. In real-world applications, a budget might only allow for limited number of experiments.&lt;/p&gt;
&lt;p&gt;Bayesian optimisation has several advantages over other optimisation methods, including its ability to handle expensive functions and processes with a small number of evaluations. It also performs well in cases with noisy or uncertain data. However, while it can be considered a machine learning model, the surrogate model obtained through Bayesian optimisation is not a universally good approximation of the objective function and is not necessarily suitable for cases where extensive inference or interpretation is needed.&lt;/p&gt;
&lt;h2 id=&#34;core-components-of-bayesian-optimisation&#34; class=&#34;anchored&#34;&gt;Core Components of Bayesian Optimisation&lt;/h2&gt;
&lt;p&gt;There are five main components to Bayesian optimisation&lt;/p&gt;
&lt;h5 id=&#34;objective-function&#34; class=&#34;anchored&#34;&gt;Objective Function&lt;/h5&gt;
&lt;p&gt;The objective function is the function or process that needs to be optimised, but which is expensive or time consuming to evaluate. The objective function is typically a black box, meaning that its mathematical form is unknown, and only its inputs and outputs can be observed.&lt;/p&gt;
&lt;h5 id=&#34;surrogate-model&#34; class=&#34;anchored&#34;&gt;Surrogate Model&lt;/h5&gt;
&lt;p&gt;The surrogate is a regression model that is used to approximate the objective function. The most commonly used surrogate model in Bayesian optimisation is a Gaussian process, which is a flexible, non-parametric model that can capture complex, non-linear relationships between the inputs and outputs of the objective function.&lt;/p&gt;
&lt;h5 id=&#34;acquisition-function&#34; class=&#34;anchored&#34;&gt;Acquisition Function&lt;/h5&gt;
&lt;p&gt;The acquisition function is used to determine the next point to evaluate in the search space. The acquisition function balances exploration and exploitation.&lt;/p&gt;
&lt;h5 id=&#34;initial-training-data&#34; class=&#34;anchored&#34;&gt;Initial Training Data&lt;/h5&gt;
&lt;p&gt;Bayesian optimisation requires some initial data to construct the surrogate model. This data can be obtained by evaluating the objective function at a few points in the search space. Given that the total experiment budget is often limited, much consideration often goes into deciding these initial training points.&lt;/p&gt;
&lt;h5 id=&#34;stopping-criterion&#34; class=&#34;anchored&#34;&gt;Stopping Criterion&lt;/h5&gt;
&lt;p&gt;Bayesian optimisation might require a stopping criterion to determine when to stop the search. This could be some measure of convergence, but often the number of experiments or deadlines set the constraints.&lt;/p&gt;
&lt;p&gt;In the following sections, each component is discussed in greater detail, accompanied by implementations in R.&lt;/p&gt;
&lt;h2 id=&#34;objective-function-1&#34; class=&#34;anchored&#34;&gt;Objective Function&lt;/h2&gt;
&lt;p&gt;Bayesian optimisation can be applied to optimise any function or process that can be thought of as a black box function, &lt;span class=&#34;math inline&#34;&gt;f&lt;/span&gt;, that takes as input a set of covariates, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt;, and returns a scalar, &lt;span class=&#34;math inline&#34;&gt;y&lt;/span&gt;. Sometimes the actual readings from such function are noisy, i.e.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;y = f(\mathbf{x}) + \epsilon&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\epsilon&lt;/span&gt; is the noise, often assumed to be Gaussian &lt;span class=&#34;math inline&#34;&gt;\epsilon \sim \mathcal{N}(0, \sigma_{\epsilon}^2)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Some common examples of real world objective functions include&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ML Hyperparameters&lt;/strong&gt;. Machine learning model hyperparameters such as learning rate or regularisation strength are expensive to optimise, since they require retraining the model for each iteration. In the context of Bayesian optimisation, the model hyperparameters would be the input &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; and the model output would be the scalar objective &lt;span class=&#34;math inline&#34;&gt;y&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Design of experiments&lt;/strong&gt;. Optimising the parameters of chemical or biological experiments can save both time and money, or even accelerate the discovery of new drugs or products.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Manufacturing&lt;/strong&gt;. A manufacturing process can often be thought of as have a set of defined inputs (material, flow, settings, etc.) and measurable outputs that should be maximised (eg. product output or yield) or minimised (eg. waste).&lt;/p&gt;
&lt;h3 id=&#34;benchmarking-functions&#34; class=&#34;anchored&#34;&gt;Benchmarking Functions&lt;/h3&gt;
&lt;p&gt;This implementation of Bayesian optimisation mainly explores each component at a high level so there will not be an actual black box process to optimise. Instead, a benchmark function is used to demonstrate the implementation.&lt;/p&gt;
&lt;p&gt;There are many good benchmark functions. One such is the Ackley function. It is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;f(\mathbf{x}) = -a\exp\left(-b\sqrt{\frac{1}{d}\sum_{i=1}^dx_i^2}\right) - \exp\left(\frac{1}{d}\sum_{i=1}^d \cos(c x_i)\right) \\ + a + \exp(1)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;d&lt;/span&gt; is the number of dimensions and &lt;span class=&#34;math inline&#34;&gt;a&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;b&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;c&lt;/span&gt; are constants. The global minimum of the Ackley function is &lt;span class=&#34;math inline&#34;&gt;f(\mathbf{x})=0&lt;/span&gt; at &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}=(0,0,...,0)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For this implementation the constants are set at &lt;span class=&#34;math inline&#34;&gt;a = 20&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;b = 0.2&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;c = 2\pi&lt;/span&gt;, and the function can be applied to a matrix of observations, &lt;span class=&#34;math inline&#34;&gt;\mathbf{X}&lt;/span&gt;, rather than just a single vector of covariates.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb2&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb2-1&#34;&gt;&lt;a href=&#34;#cb2-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ackley &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X) {&lt;/span&gt;
&lt;span id=&#34;cb2-2&#34;&gt;&lt;a href=&#34;#cb2-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X))&lt;/span&gt;
&lt;span id=&#34;cb2-3&#34;&gt;&lt;a href=&#34;#cb2-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  d &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ncol&lt;/span&gt;(X)&lt;/span&gt;
&lt;span id=&#34;cb2-4&#34;&gt;&lt;a href=&#34;#cb2-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  part1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exp&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;0.2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sqrt&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt;d&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X&lt;span class=&#34;sc&#34;&gt;^&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)))&lt;/span&gt;
&lt;span id=&#34;cb2-5&#34;&gt;&lt;a href=&#34;#cb2-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  part2 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exp&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt;d&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;cos&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;pi&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;X)))&lt;/span&gt;
&lt;span id=&#34;cb2-6&#34;&gt;&lt;a href=&#34;#cb2-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  part1 &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; part2 &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;20&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;exp&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb2-7&#34;&gt;&lt;a href=&#34;#cb2-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;surrogate-model-gaussian-process-regression&#34; class=&#34;anchored&#34;&gt;Surrogate Model: Gaussian Process Regression&lt;/h2&gt;
&lt;p&gt;This section explores the virtues Gaussian processes and how they can be applied as surrogate models for Bayesian optimisation. This is the largest and most complex part of Bayesian optimisation, and the discussions and implementations will only take a brief glance at some of the considerations.&lt;/p&gt;
&lt;p&gt;A Gaussian process (GP) is a probabilistic model that defines a distribution over functions. A GP model assumes that a function can be represented as a collection of random variables with a multivariate Gaussian distribution. Intuitively, the GP assumes that data points with high correlation among the covariates have similar values of the output variable(s).&lt;/p&gt;
&lt;p&gt;Formally, a GP is defined by a mean function and a covariance function, also called a kernel function.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;p(f | \mathbf{X}) = \mathcal{N}(f | \mathbf{\mu}, \mathbf{\Sigma})&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;f&lt;/span&gt; is the objective function and &lt;span class=&#34;math inline&#34;&gt;\mathbf{X}&lt;/span&gt; is a set of observations for the covariates of &lt;span class=&#34;math inline&#34;&gt;f&lt;/span&gt;. The mean function, &lt;span class=&#34;math inline&#34;&gt;\mathbf{\mu}&lt;/span&gt;, specifies the expected value of the function at each point in the covariate space, while the covariance matrix, &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}&lt;/span&gt;, specifies how the function values at any two points in the covariate space are correlated. The covariance matrix is calculated using a kernel function and, in practice, the choice of kernel function is important for obtaining good and interpretable results with Bayesian optimisation. The mean function is of much lesser consequence and is often set to &lt;span class=&#34;math inline&#34;&gt;\mathbf{\mu} = \mathbf{0}&lt;/span&gt;.&lt;/p&gt;
&lt;h3 id=&#34;kernels&#34; class=&#34;anchored&#34;&gt;Kernels&lt;/h3&gt;
&lt;p&gt;The choice of kernel function reflects prior beliefs about smoothness, periodicity, and other properties of the objective function. Intuitively, the kernel is a function that specifies the similarity between pairs of vectors of covariates. In other words, the kernel should quantify how similar two data points are, given just the input.&lt;/p&gt;
&lt;p&gt;Formally, a kernel function &lt;span class=&#34;math inline&#34;&gt;k(\mathbf{x}, \mathbf{x&#39;})&lt;/span&gt; takes two input vectors &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\mathbf{x&#39;}&lt;/span&gt; and produces a scalar value that quantifies the similarity or covariance between the two vectors.&lt;/p&gt;
&lt;p&gt;The kernel function can be applied to the covariates, &lt;span class=&#34;math inline&#34;&gt;\mathbf{X}&lt;/span&gt;, of a set of observed data points to create a covariance matrix, &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\Sigma_{ij} = k(\mathbf{x}_i, \mathbf{x}_j)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;for all combinations of observations &lt;span class=&#34;math inline&#34;&gt;i&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;j&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Kernels themselves are an entire subject, see the &lt;a href=&#34;../kernels-r&#34;&gt;kernel post&lt;/a&gt; for a thorough discussion of kernels for Gaussian processes and Bayesian optimisation.&lt;/p&gt;
&lt;h4 id=&#34;implementing-the-rbf-kernel&#34; class=&#34;anchored&#34;&gt;Implementing the RBF kernel&lt;/h4&gt;
&lt;p&gt;An example of a commonly used kernel is the Radial Basis Function (RBF) kernel. The RBF kernel is defined as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;k(\mathbf{x}_i, \mathbf{x}_j) = \sigma_f^2 \exp\left(-\frac{1}{2}\frac{\lVert \mathbf{x}_i - \mathbf{x}_j\rVert^2}{l^2}\right)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\sigma_f&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt; are parameters and &lt;span class=&#34;math inline&#34;&gt;\lVert \rVert&lt;/span&gt; is the euclidean distance of the two vectors.&lt;/p&gt;
&lt;p&gt;This implementation can take two vectors or two matrices. For a vector input, it returns the kernel function value. For a matrix inputs, the covariance matrix, &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}&lt;/span&gt;, is returned.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb3&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb3-1&#34;&gt;&lt;a href=&#34;#cb3-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; RBF Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-2&#34;&gt;&lt;a href=&#34;#cb3-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-3&#34;&gt;&lt;a href=&#34;#cb3-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X1 matrix of dimensions (n, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-4&#34;&gt;&lt;a href=&#34;#cb3-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X2 matrix of dimensions (m, d). Vectors are coerced to (1, d).&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-5&#34;&gt;&lt;a href=&#34;#cb3-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param l length scale&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-6&#34;&gt;&lt;a href=&#34;#cb3-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma_f scale parameter &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-7&#34;&gt;&lt;a href=&#34;#cb3-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-8&#34;&gt;&lt;a href=&#34;#cb3-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return matrix of dimensions (n, m)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-9&#34;&gt;&lt;a href=&#34;#cb3-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;rbf_kernel &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X1, X2, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.0&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb3-10&#34;&gt;&lt;a href=&#34;#cb3-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X1) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X1))&lt;/span&gt;
&lt;span id=&#34;cb3-11&#34;&gt;&lt;a href=&#34;#cb3-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X2) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X2))&lt;/span&gt;
&lt;span id=&#34;cb3-12&#34;&gt;&lt;a href=&#34;#cb3-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sqdist &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;(X1 &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(X2))) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-13&#34;&gt;&lt;a href=&#34;#cb3-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;add&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X1&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb3-14&#34;&gt;&lt;a href=&#34;#cb3-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;rowSums&lt;/span&gt;(X2&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;dims =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb3-15&#34;&gt;&lt;a href=&#34;#cb3-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma_f&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;exp&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; l&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; sqdist)&lt;/span&gt;
&lt;span id=&#34;cb3-16&#34;&gt;&lt;a href=&#34;#cb3-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\sigma_f^2&lt;/span&gt; is a variance parameter that simply scales the functions to the magnitude of &lt;span class=&#34;math inline&#34;&gt;f&lt;/span&gt;. More interestingly, the length scale parameter, &lt;span class=&#34;math inline&#34;&gt;l&lt;/span&gt; of the RBF kernel affects the smoothness and flexibility of the functions modelled with a GP that uses this kernel. For a small value of the length scale, the kernel results in very flexible functions, whereas a larger length scale yields very smooth functions.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb4&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb4-1&#34;&gt;&lt;a href=&#34;#cb4-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fl&#34;&gt;0.25&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-2&#34;&gt;&lt;a href=&#34;#cb4-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  tidyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;expand_grid&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x1 =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-3&#34;&gt;&lt;a href=&#34;#cb4-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;k =&lt;/span&gt; purrr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;map2_dbl&lt;/span&gt;(x1, l, &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rbf_kernel&lt;/span&gt;(.x, &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, .y))) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-4&#34;&gt;&lt;a href=&#34;#cb4-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x1, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; k, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;factor&lt;/span&gt;(l))) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-5&#34;&gt;&lt;a href=&#34;#cb4-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-6&#34;&gt;&lt;a href=&#34;#cb4-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-7&#34;&gt;&lt;a href=&#34;#cb4-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb4-8&#34;&gt;&lt;a href=&#34;#cb4-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Euclidian distance of points&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb4-9&#34;&gt;&lt;a href=&#34;#cb4-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Covariance&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb4-10&#34;&gt;&lt;a href=&#34;#cb4-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Length scale&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb4-11&#34;&gt;&lt;a href=&#34;#cb4-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;RBF kernel&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb4-12&#34;&gt;&lt;a href=&#34;#cb4-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The intuition here is that for small length scales two points have to be very close to have any correlation. This results in very flexible functions that do not expect much correlation between data points. For a large length scale, however, points that are far apart are still expected to behave in a similar way. This results in very smooth functions that expect similar output values across the entire covariate space.&lt;/p&gt;
&lt;p&gt;The RBF kernel is a popular choice for Gaussian processes in part because of this interpretability. There are other advantages to the RBF kernel, but it is not necessarily a good default choice for &lt;em&gt;every&lt;/em&gt; problem.&lt;/p&gt;
&lt;h3 id=&#34;gaussian-processes-as-a-distribution-over-functions&#34; class=&#34;anchored&#34;&gt;Gaussian processes as a distribution over functions&lt;/h3&gt;
&lt;p&gt;If the Gaussian process is a distribution over functions, it should be possible to sample random functions from it. And indeed it is! The only thing needed in order to sample from a Gaussian is a function for pulling random numbers from, well, a Gaussian.&lt;/p&gt;
&lt;p&gt;In practice, this amounts to plugging the mean and the covariance (kernel) into a multivariate Gaussian and sampling from it. Of course, a set of points, &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt;, is required to compute &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}&lt;/span&gt;. Note, however, that no outputs, &lt;span class=&#34;math inline&#34;&gt;\mathbf{y}&lt;/span&gt; are needed yet, so a grid for &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; will suffice.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb5&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb5-1&#34;&gt;&lt;a href=&#34;#cb5-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Random Samples from a Multivariate Gaussian&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-2&#34;&gt;&lt;a href=&#34;#cb5-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; &lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-3&#34;&gt;&lt;a href=&#34;#cb5-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; This implementation is similar to MASS::mvrnorm, but uses chlosky&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-4&#34;&gt;&lt;a href=&#34;#cb5-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; decomposition instead. This should be more stable but is less efficient than&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-5&#34;&gt;&lt;a href=&#34;#cb5-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; the MASS implementation, which recycles the eigen decomposition for the&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-6&#34;&gt;&lt;a href=&#34;#cb5-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; sampling part.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-7&#34;&gt;&lt;a href=&#34;#cb5-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-8&#34;&gt;&lt;a href=&#34;#cb5-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param n number of samples to sample&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-9&#34;&gt;&lt;a href=&#34;#cb5-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param mu the mean of each input dimension&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-10&#34;&gt;&lt;a href=&#34;#cb5-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param sigma the covariance matrix&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-11&#34;&gt;&lt;a href=&#34;#cb5-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param epsilon numerical tolerance added to the diagonal of the covariance&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-12&#34;&gt;&lt;a href=&#34;#cb5-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;  matrix. This is necessary for the Cholesky decomposition, in some cases.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-13&#34;&gt;&lt;a href=&#34;#cb5-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-14&#34;&gt;&lt;a href=&#34;#cb5-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return numerical vector of n samples&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb5-15&#34;&gt;&lt;a href=&#34;#cb5-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;rmvnorm &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;n =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, mu, sigma, &lt;span class=&#34;at&#34;&gt;epsilon =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-6&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb5-16&#34;&gt;&lt;a href=&#34;#cb5-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    p &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(mu)&lt;/span&gt;
&lt;span id=&#34;cb5-17&#34;&gt;&lt;a href=&#34;#cb5-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;all&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(sigma) &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(p, p))) &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;incompatible dimensions of arguments&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-18&#34;&gt;&lt;a href=&#34;#cb5-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ev &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;eigen&lt;/span&gt;(sigma, &lt;span class=&#34;at&#34;&gt;symmetric =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;TRUE&lt;/span&gt;)&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;values&lt;/span&gt;
&lt;span id=&#34;cb5-19&#34;&gt;&lt;a href=&#34;#cb5-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;all&lt;/span&gt;(ev &lt;span class=&#34;sc&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;epsilon&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;abs&lt;/span&gt;(ev[1L]))) {&lt;/span&gt;
&lt;span id=&#34;cb5-20&#34;&gt;&lt;a href=&#34;#cb5-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;stop&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;The covariance matrix (sigma) is not positive definite&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-21&#34;&gt;&lt;a href=&#34;#cb5-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    }&lt;/span&gt;
&lt;span id=&#34;cb5-22&#34;&gt;&lt;a href=&#34;#cb5-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    cholesky &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;chol&lt;/span&gt;(sigma &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(p)&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;epsilon)&lt;/span&gt;
&lt;span id=&#34;cb5-23&#34;&gt;&lt;a href=&#34;#cb5-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    sample &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(p&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;n, &lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-24&#34;&gt;&lt;a href=&#34;#cb5-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(sample) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(n, p)&lt;/span&gt;
&lt;span id=&#34;cb5-25&#34;&gt;&lt;a href=&#34;#cb5-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;sweep&lt;/span&gt;(sample &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; cholesky, &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;, mu, &lt;span class=&#34;at&#34;&gt;FUN =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb5-26&#34;&gt;&lt;a href=&#34;#cb5-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;To assist the visualisation, here is a plot for the mean, uncertainty, and some samples of a Gaussian process for the case where there is only one covariate, i.e.&amp;nbsp;&lt;span class=&#34;math inline&#34;&gt;\mathbf{X}&lt;/span&gt; is of shape &lt;span class=&#34;math inline&#34;&gt;(n,1)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; is the number of observations.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb6&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb6-1&#34;&gt;&lt;a href=&#34;#cb6-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gpr_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(samples,&lt;/span&gt;
&lt;span id=&#34;cb6-2&#34;&gt;&lt;a href=&#34;#cb6-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                     mu,&lt;/span&gt;
&lt;span id=&#34;cb6-3&#34;&gt;&lt;a href=&#34;#cb6-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                     sigma,&lt;/span&gt;
&lt;span id=&#34;cb6-4&#34;&gt;&lt;a href=&#34;#cb6-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                     X_pred,&lt;/span&gt;
&lt;span id=&#34;cb6-5&#34;&gt;&lt;a href=&#34;#cb6-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                     &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-6&#34;&gt;&lt;a href=&#34;#cb6-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                     &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-7&#34;&gt;&lt;a href=&#34;#cb6-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                     &lt;span class=&#34;at&#34;&gt;true_function =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb6-8&#34;&gt;&lt;a href=&#34;#cb6-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  n_samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(samples)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]]&lt;/span&gt;
&lt;span id=&#34;cb6-9&#34;&gt;&lt;a href=&#34;#cb6-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-10&#34;&gt;&lt;a href=&#34;#cb6-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(samples),&lt;/span&gt;
&lt;span id=&#34;cb6-11&#34;&gt;&lt;a href=&#34;#cb6-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;paste&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;sample&#34;&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, n_samples))&lt;/span&gt;
&lt;span id=&#34;cb6-12&#34;&gt;&lt;a href=&#34;#cb6-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-13&#34;&gt;&lt;a href=&#34;#cb6-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-14&#34;&gt;&lt;a href=&#34;#cb6-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb6-15&#34;&gt;&lt;a href=&#34;#cb6-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;uncertainty =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.6&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sqrt&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(sigma)),&lt;/span&gt;
&lt;span id=&#34;cb6-16&#34;&gt;&lt;a href=&#34;#cb6-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu,&lt;/span&gt;
&lt;span id=&#34;cb6-17&#34;&gt;&lt;a href=&#34;#cb6-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;lower =&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; uncertainty,&lt;/span&gt;
&lt;span id=&#34;cb6-18&#34;&gt;&lt;a href=&#34;#cb6-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;upper =&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; uncertainty,&lt;/span&gt;
&lt;span id=&#34;cb6-19&#34;&gt;&lt;a href=&#34;#cb6-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;f =&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(true_function)) &lt;span class=&#34;fu&#34;&gt;true_function&lt;/span&gt;(X_pred)&lt;/span&gt;
&lt;span id=&#34;cb6-20&#34;&gt;&lt;a href=&#34;#cb6-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-21&#34;&gt;&lt;a href=&#34;#cb6-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-22&#34;&gt;&lt;a href=&#34;#cb6-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_ribbon&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-23&#34;&gt;&lt;a href=&#34;#cb6-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;ymin =&lt;/span&gt; lower, &lt;span class=&#34;at&#34;&gt;ymax =&lt;/span&gt; upper, &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb6-24&#34;&gt;&lt;a href=&#34;#cb6-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-25&#34;&gt;&lt;a href=&#34;#cb6-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-26&#34;&gt;&lt;a href=&#34;#cb6-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; mu, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Mean&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-27&#34;&gt;&lt;a href=&#34;#cb6-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-28&#34;&gt;&lt;a href=&#34;#cb6-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-29&#34;&gt;&lt;a href=&#34;#cb6-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;y&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-30&#34;&gt;&lt;a href=&#34;#cb6-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;x&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-31&#34;&gt;&lt;a href=&#34;#cb6-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-32&#34;&gt;&lt;a href=&#34;#cb6-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-33&#34;&gt;&lt;a href=&#34;#cb6-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-34&#34;&gt;&lt;a href=&#34;#cb6-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;panel.grid =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;())&lt;/span&gt;
&lt;span id=&#34;cb6-35&#34;&gt;&lt;a href=&#34;#cb6-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;Reduce&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-36&#34;&gt;&lt;a href=&#34;#cb6-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;at&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;st&#34;&gt;`&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-37&#34;&gt;&lt;a href=&#34;#cb6-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;init =&lt;/span&gt; p,&lt;/span&gt;
&lt;span id=&#34;cb6-38&#34;&gt;&lt;a href=&#34;#cb6-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;lapply&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;paste&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;sample&#34;&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, n_samples)), &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(s) {&lt;/span&gt;
&lt;span id=&#34;cb6-39&#34;&gt;&lt;a href=&#34;#cb6-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; .data[[s]], &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; s), &lt;span class=&#34;at&#34;&gt;linetype =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb6-40&#34;&gt;&lt;a href=&#34;#cb6-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    })&lt;/span&gt;
&lt;span id=&#34;cb6-41&#34;&gt;&lt;a href=&#34;#cb6-41&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-42&#34;&gt;&lt;a href=&#34;#cb6-42&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_colour_brewer&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;palette =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;YlGnBu&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-43&#34;&gt;&lt;a href=&#34;#cb6-43&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_fill_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;89% interval&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#219ebc&#34;&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb6-44&#34;&gt;&lt;a href=&#34;#cb6-44&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(X_train) &lt;span class=&#34;sc&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(y_train)) {&lt;/span&gt;
&lt;span id=&#34;cb6-45&#34;&gt;&lt;a href=&#34;#cb6-45&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    p &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; p &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb6-46&#34;&gt;&lt;a href=&#34;#cb6-46&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb6-47&#34;&gt;&lt;a href=&#34;#cb6-47&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_train, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y_train),&lt;/span&gt;
&lt;span id=&#34;cb6-48&#34;&gt;&lt;a href=&#34;#cb6-48&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y, &lt;span class=&#34;at&#34;&gt;shape =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Training point&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb6-49&#34;&gt;&lt;a href=&#34;#cb6-49&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#fb8500&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb6-50&#34;&gt;&lt;a href=&#34;#cb6-50&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;        &lt;span class=&#34;at&#34;&gt;size =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-51&#34;&gt;&lt;a href=&#34;#cb6-51&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-52&#34;&gt;&lt;a href=&#34;#cb6-52&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;scale_shape_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;Training point&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;+&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb6-53&#34;&gt;&lt;a href=&#34;#cb6-53&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;shape =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb6-54&#34;&gt;&lt;a href=&#34;#cb6-54&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb6-55&#34;&gt;&lt;a href=&#34;#cb6-55&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(true_function)) {&lt;/span&gt;
&lt;span id=&#34;cb6-56&#34;&gt;&lt;a href=&#34;#cb6-56&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    p &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; p &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb6-57&#34;&gt;&lt;a href=&#34;#cb6-57&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;mapping =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; f, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;True function&#34;&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb6-58&#34;&gt;&lt;a href=&#34;#cb6-58&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb6-59&#34;&gt;&lt;a href=&#34;#cb6-59&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;return&lt;/span&gt;(p)&lt;/span&gt;
&lt;span id=&#34;cb6-60&#34;&gt;&lt;a href=&#34;#cb6-60&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This bit is at the core of Gaussian processes. Given a set of points, the corresponding &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}&lt;/span&gt; is calculated. Then this are plugged into a multivariate Gaussian to obtain predicted function values. In this case, &lt;span class=&#34;math inline&#34;&gt;\mathbf{\mu}&lt;/span&gt; has just been set to &lt;span class=&#34;math inline&#34;&gt;\mathbf{0}&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb7&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb7-1&#34;&gt;&lt;a href=&#34;#cb7-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb7-2&#34;&gt;&lt;a href=&#34;#cb7-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_predict &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;), &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb7-3&#34;&gt;&lt;a href=&#34;#cb7-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;0&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;times =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X_predict))&lt;/span&gt;
&lt;span id=&#34;cb7-4&#34;&gt;&lt;a href=&#34;#cb7-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rbf_kernel&lt;/span&gt;(X_predict, X_predict, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb7-5&#34;&gt;&lt;a href=&#34;#cb7-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rmvnorm&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;n =&lt;/span&gt; n_samples, mu, sigma)&lt;/span&gt;
&lt;span id=&#34;cb7-6&#34;&gt;&lt;a href=&#34;#cb7-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;gpr_plot&lt;/span&gt;(samples, mu, sigma, X_predict)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;conditioning-the-gaussian-process&#34; class=&#34;anchored&#34;&gt;Conditioning the Gaussian process&lt;/h3&gt;
&lt;p&gt;Until now, the GP has just represented a prior belief for the surrogate functions that might model the objective function. It is not a surrogate model yet.&lt;/p&gt;
&lt;p&gt;In order for the GP to be a useful surrogate model, it should provide posterior predictions for proposed points, given the available training data. I.e. for a set of training data, &lt;span class=&#34;math inline&#34;&gt;\mathbf{X}_t&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\mathbf{y}_t&lt;/span&gt;, as well as a set of proposed points &lt;span class=&#34;math inline&#34;&gt;\mathbf{X}_p&lt;/span&gt;, the GP should yield a posterior predictive distribution for the proposed/predicted outputs &lt;span class=&#34;math inline&#34;&gt;\mathbf{y}_p&lt;/span&gt;. For a GP, the joint distribution of training points and new proposed points is itself a GP. Consequently, it is possible to compute the joint distribution of training data and posterior prediction points directly.&lt;/p&gt;
&lt;p&gt;The mean and covariance of this joint distribution have well defined expressions. Given a set of training data, &lt;span class=&#34;math inline&#34;&gt;\mathbf{X}_t, \mathbf{y}_t&lt;/span&gt;, and set of points on which to make predictions, &lt;span class=&#34;math inline&#34;&gt;\mathbf{X}_p&lt;/span&gt;, the mean of the posterior predictive distribution is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{\mu}_{p|t} = \mathbf{\mu}_p + \mathbf{\Sigma}_{tp}^T \mathbf{\Sigma}_{tt}^{-1} (\mathbf{y}_t - \mathbf{\mu}_t)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}_{tp}&lt;/span&gt; is the covariance matrix between training and prediction points and &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}_{tt}&lt;/span&gt; is the covariance matrix between training points.&lt;/p&gt;
&lt;p&gt;Recall though that often &lt;span class=&#34;math inline&#34;&gt;\mathbf{\mu} = \mathbf{0}&lt;/span&gt;, so the equation will often show up as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{\mu}_{p|t} = \mathbf{\Sigma}_{tp} \mathbf{\Sigma}_{tt}^{-1} \mathbf{y}_t&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is also what is implemented below.&lt;/p&gt;
&lt;p&gt;The covariance matrix of the posterior predictive distribution is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathbf{\Sigma}_{p|t} = \mathbf{\Sigma}_{pp} - \mathbf{\Sigma}_{tp}^T \mathbf{\Sigma}_{tt}^{-1} \mathbf{\Sigma}_{tp}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}_{pp}&lt;/span&gt; is the covariance matrix between prediction points.&lt;/p&gt;
&lt;p&gt;These formulas are straightforward linear algebra and could be implemented directly as such. However, they are somewhat numerically unstable. For greater stability, the implementation below calculates the posterior using the algorithm described in chapter 2 of &lt;span class=&#34;citation&#34; data-cites=&#34;Rasmussen:2006&#34;&gt;[1]&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb8&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb8-1&#34;&gt;&lt;a href=&#34;#cb8-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Get Parameters of the Posterior Gaussian Process&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-2&#34;&gt;&lt;a href=&#34;#cb8-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-3&#34;&gt;&lt;a href=&#34;#cb8-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function used for the Gaussian process&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-4&#34;&gt;&lt;a href=&#34;#cb8-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_pred matrix (m, d) of prediction points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-5&#34;&gt;&lt;a href=&#34;#cb8-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-6&#34;&gt;&lt;a href=&#34;#cb8-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-7&#34;&gt;&lt;a href=&#34;#cb8-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-8&#34;&gt;&lt;a href=&#34;#cb8-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param ... named parameters for the kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-9&#34;&gt;&lt;a href=&#34;#cb8-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-10&#34;&gt;&lt;a href=&#34;#cb8-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return list of mean (mu) and covariance (sigma) for the Gaussian&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb8-11&#34;&gt;&lt;a href=&#34;#cb8-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;posterior &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, X_pred, X_train, y_train, &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt;, ...) {&lt;/span&gt;
&lt;span id=&#34;cb8-12&#34;&gt;&lt;a href=&#34;#cb8-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X_pred), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb8-13&#34;&gt;&lt;a href=&#34;#cb8-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X_train), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb8-14&#34;&gt;&lt;a href=&#34;#cb8-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(y_train))) &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(y_train) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(y_train), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb8-15&#34;&gt;&lt;a href=&#34;#cb8-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_train, X_train, ...) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;
&lt;span id=&#34;cb8-16&#34;&gt;&lt;a href=&#34;#cb8-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_s &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_train, X_pred, ...)&lt;/span&gt;
&lt;span id=&#34;cb8-17&#34;&gt;&lt;a href=&#34;#cb8-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_ss &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;kernel&lt;/span&gt;(X_pred, X_pred, ...) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_pred)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]])&lt;/span&gt;
&lt;span id=&#34;cb8-18&#34;&gt;&lt;a href=&#34;#cb8-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  K_inv &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;solve&lt;/span&gt;(K)&lt;/span&gt;
&lt;span id=&#34;cb8-19&#34;&gt;&lt;a href=&#34;#cb8-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(K_s) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_inv) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; y_train&lt;/span&gt;
&lt;span id=&#34;cb8-20&#34;&gt;&lt;a href=&#34;#cb8-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; K_ss &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; (&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(K_s) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_inv) &lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt; K_s&lt;/span&gt;
&lt;span id=&#34;cb8-21&#34;&gt;&lt;a href=&#34;#cb8-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu, &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; sigma)&lt;/span&gt;
&lt;span id=&#34;cb8-22&#34;&gt;&lt;a href=&#34;#cb8-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;With a way to calculate the posterior, it is possible to condition a Gaussian process on some training data.&lt;/p&gt;
&lt;p&gt;Here is a bit of of training data for a one dimensional example.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb9&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb9-1&#34;&gt;&lt;a href=&#34;#cb9-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;4.33&lt;/span&gt;, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;2.1&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;2.1&lt;/span&gt;), &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb9-2&#34;&gt;&lt;a href=&#34;#cb9-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ackley&lt;/span&gt;(X_train)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The Gaussian process is then conditioned on training data and applied to new proposed points in a single step&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb10&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb10-1&#34;&gt;&lt;a href=&#34;#cb10-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_predict &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;), &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb10-2&#34;&gt;&lt;a href=&#34;#cb10-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;posterior&lt;/span&gt;(rbf_kernel, X_predict, X_train, y_train)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Just like the prior distribution, it is possible to sample random functions from the posterior distribution&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb11&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb11-1&#34;&gt;&lt;a href=&#34;#cb11-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu)&lt;/span&gt;
&lt;span id=&#34;cb11-2&#34;&gt;&lt;a href=&#34;#cb11-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma&lt;/span&gt;
&lt;span id=&#34;cb11-3&#34;&gt;&lt;a href=&#34;#cb11-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb11-4&#34;&gt;&lt;a href=&#34;#cb11-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rmvnorm&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;n =&lt;/span&gt; n_samples, mu, sigma)&lt;/span&gt;
&lt;span id=&#34;cb11-5&#34;&gt;&lt;a href=&#34;#cb11-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;gpr_plot&lt;/span&gt;(samples, mu, sigma, X_predict, X_train, y_train, ackley)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;At this point, the fit is not too great and the sampled functions look nothing like the true function. However, this is only based on three data points and an arbitrary choice of kernel parameters.&lt;/p&gt;
&lt;p&gt;Both things will be handled in due time, but it gets worse before it gets better.&lt;/p&gt;
&lt;h4 id=&#34;a-quick-note-on-noise&#34; class=&#34;anchored&#34;&gt;A Quick Note on Noise&lt;/h4&gt;
&lt;p&gt;Recall that training data might be noisy, i.e.&amp;nbsp;&lt;span class=&#34;math inline&#34;&gt;y = f(\mathbf{x}) + \epsilon&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Noise, too, is a subject all on its own. The key thing to remember is that noise can be accounted for by adding it to the diagonal of &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}_{tt}&lt;/span&gt;. This is already implemented in the function for the posterior above.&lt;/p&gt;
&lt;p&gt;The effect of noisy training data on the posterior is, unsurprisingly, more uncertainty.&lt;/p&gt;
&lt;p&gt;Here a bit of known noise is added to the observations.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb12&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb12-1&#34;&gt;&lt;a href=&#34;#cb12-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;noise &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb12-2&#34;&gt;&lt;a href=&#34;#cb12-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ackley&lt;/span&gt;(X_train) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(X_train))&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;When recreating the plot from above, now using the noisy observations, the most noticeable difference is that the distribution mean no longer passes though each observation.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb13&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb13-1&#34;&gt;&lt;a href=&#34;#cb13-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;posterior&lt;/span&gt;(rbf_kernel, X_predict, X_train, y_train, &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; noise)&lt;/span&gt;
&lt;span id=&#34;cb13-2&#34;&gt;&lt;a href=&#34;#cb13-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu&lt;/span&gt;
&lt;span id=&#34;cb13-3&#34;&gt;&lt;a href=&#34;#cb13-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma&lt;/span&gt;
&lt;span id=&#34;cb13-4&#34;&gt;&lt;a href=&#34;#cb13-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb13-5&#34;&gt;&lt;a href=&#34;#cb13-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rmvnorm&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;n =&lt;/span&gt; n_samples, mu, sigma)&lt;/span&gt;
&lt;span id=&#34;cb13-6&#34;&gt;&lt;a href=&#34;#cb13-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;gpr_plot&lt;/span&gt;(samples, mu, sigma, X_predict, X_train, y_train, ackley)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;gaussian-process-regression&#34; class=&#34;anchored&#34;&gt;Gaussian Process Regression&lt;/h3&gt;
&lt;p&gt;Until now, the kernel parameters have been set at fixed, arbitrary values. This is a waste of good parameters, and it is possible to do something better. The core idea of Gaussian process regression (GPR) is that the kernel parameters can be adapted to fit the training data.&lt;/p&gt;
&lt;p&gt;A common approach to estimating the parameters of a kernel function in GPR is Maximum Likelihood Estimation (MLE).&lt;/p&gt;
&lt;p&gt;The likelihood function for a Gaussian process is given by&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;p(\mathbf{y}_t \mid \mathbf{X}_t, \theta) = \mathcal{N}(\mathbf{y}_t \mid \mathbf{\mu}, \mathbf{\Sigma}_{tt} + \sigma_{\epsilon}^2 \mathbf{I})&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\mathbf{\Sigma}_{tt}&lt;/span&gt; is the covariance matrix computed on training data using some kernel with parameters &lt;span class=&#34;math inline&#34;&gt;\theta&lt;/span&gt;. In the case of the RBF kernel, the parameters to estimate are &lt;span class=&#34;math inline&#34;&gt;\theta = (\sigma_f, l)&lt;/span&gt;. Notice that the noise has been added to the diagonal of the covariance matrix to account for noisy training data.&lt;/p&gt;
&lt;p&gt;The corresponding log likelihood function is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\log p(\mathbf{y}_t \mid \mathbf{X}_t, \theta) = -\frac{1}{2} \left( \log \det (\mathbf{\Sigma}_{tt} + \sigma_{\epsilon}^2 \mathbf{I}) + \mathbf{y}_t^T (\mathbf{\Sigma}_{tt} + \sigma_{\epsilon}^2 \mathbf{I})^{-1} \mathbf{y}_t + n \log(2\pi) \right)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;n&lt;/span&gt; is the number of data points.&lt;/p&gt;
&lt;p&gt;The optimal values of the kernel parameters are the values that maximise the log likelihood or, equivalently, minimise the negative log likelihood.&lt;/p&gt;
&lt;p&gt;To implement Gaussian process regression, two components are needed: the likelihood and an optimiser. Here is an implementation of a negative log likelihood function, for any kernel. The implementation follows Algorithm 2.1 from chapter 2 of &lt;span class=&#34;citation&#34; data-cites=&#34;Rasmussen:2006&#34;&gt;[1]&lt;/span&gt;.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb14&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb14-1&#34;&gt;&lt;a href=&#34;#cb14-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Negative log-Likelihood of a Kernel&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-2&#34;&gt;&lt;a href=&#34;#cb14-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-3&#34;&gt;&lt;a href=&#34;#cb14-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-4&#34;&gt;&lt;a href=&#34;#cb14-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-5&#34;&gt;&lt;a href=&#34;#cb14-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-6&#34;&gt;&lt;a href=&#34;#cb14-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-7&#34;&gt;&lt;a href=&#34;#cb14-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-8&#34;&gt;&lt;a href=&#34;#cb14-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return function with kernel parameters as input and negative log likelihood&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-9&#34;&gt;&lt;a href=&#34;#cb14-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; as output&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb14-10&#34;&gt;&lt;a href=&#34;#cb14-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;nll &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, X_train, y_train, noise) {&lt;/span&gt;
&lt;span id=&#34;cb14-11&#34;&gt;&lt;a href=&#34;#cb14-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(params) {&lt;/span&gt;
&lt;span id=&#34;cb14-12&#34;&gt;&lt;a href=&#34;#cb14-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    n &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(X_train)[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]]&lt;/span&gt;
&lt;span id=&#34;cb14-13&#34;&gt;&lt;a href=&#34;#cb14-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    K &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(kernel, &lt;span class=&#34;at&#34;&gt;X1 =&lt;/span&gt; X_train, &lt;span class=&#34;at&#34;&gt;X2 =&lt;/span&gt; X_train, &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;params)&lt;/span&gt;
&lt;span id=&#34;cb14-14&#34;&gt;&lt;a href=&#34;#cb14-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    L &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;chol&lt;/span&gt;(K &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise&lt;span class=&#34;sc&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(n))&lt;/span&gt;
&lt;span id=&#34;cb14-15&#34;&gt;&lt;a href=&#34;#cb14-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    a &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;backsolve&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;r =&lt;/span&gt; L, &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;forwardsolve&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(L), &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; y_train))&lt;/span&gt;
&lt;span id=&#34;cb14-16&#34;&gt;&lt;a href=&#34;#cb14-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(y_train)&lt;span class=&#34;sc&#34;&gt;%*%&lt;/span&gt;a &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;sum&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;log&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(L))) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;n&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;log&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;pi)&lt;/span&gt;
&lt;span id=&#34;cb14-17&#34;&gt;&lt;a href=&#34;#cb14-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb14-18&#34;&gt;&lt;a href=&#34;#cb14-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;There are many ways to minimise the function. Since there are only two parameters for the RBF kernel, the built in optimiser will do just fine.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb15&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb15-1&#34;&gt;&lt;a href=&#34;#cb15-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;rbf_nll &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;nll&lt;/span&gt;(rbf_kernel, X_train, y_train, noise)&lt;/span&gt;
&lt;span id=&#34;cb15-2&#34;&gt;&lt;a href=&#34;#cb15-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;opt &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;optim&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;par =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;), &lt;span class=&#34;at&#34;&gt;fn =&lt;/span&gt; rbf_nll)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The optimised kernel parameters should improve the GP.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb16&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb16-1&#34;&gt;&lt;a href=&#34;#cb16-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;posterior&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb16-2&#34;&gt;&lt;a href=&#34;#cb16-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  rbf_kernel,&lt;/span&gt;
&lt;span id=&#34;cb16-3&#34;&gt;&lt;a href=&#34;#cb16-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_predict,&lt;/span&gt;
&lt;span id=&#34;cb16-4&#34;&gt;&lt;a href=&#34;#cb16-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_train,&lt;/span&gt;
&lt;span id=&#34;cb16-5&#34;&gt;&lt;a href=&#34;#cb16-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  y_train,&lt;/span&gt;
&lt;span id=&#34;cb16-6&#34;&gt;&lt;a href=&#34;#cb16-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; noise,&lt;/span&gt;
&lt;span id=&#34;cb16-7&#34;&gt;&lt;a href=&#34;#cb16-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; opt&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;par[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]],&lt;/span&gt;
&lt;span id=&#34;cb16-8&#34;&gt;&lt;a href=&#34;#cb16-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; opt&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;par[[&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;]]&lt;/span&gt;
&lt;span id=&#34;cb16-9&#34;&gt;&lt;a href=&#34;#cb16-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;)&lt;/span&gt;
&lt;span id=&#34;cb16-10&#34;&gt;&lt;a href=&#34;#cb16-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;mu &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu&lt;/span&gt;
&lt;span id=&#34;cb16-11&#34;&gt;&lt;a href=&#34;#cb16-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma&lt;/span&gt;
&lt;span id=&#34;cb16-12&#34;&gt;&lt;a href=&#34;#cb16-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;3&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb16-13&#34;&gt;&lt;a href=&#34;#cb16-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;samples &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rmvnorm&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;n =&lt;/span&gt; n_samples, mu, sigma)&lt;/span&gt;
&lt;span id=&#34;cb16-14&#34;&gt;&lt;a href=&#34;#cb16-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;gpr_plot&lt;/span&gt;(samples, mu, sigma, X_predict, X_train, y_train, ackley)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;With that, all the components for creating a GP surrogate model are in place. For future use, they are collected in a single function that performs GPR.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb17&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb17-1&#34;&gt;&lt;a href=&#34;#cb17-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Gaussian Process Regression&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-2&#34;&gt;&lt;a href=&#34;#cb17-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-3&#34;&gt;&lt;a href=&#34;#cb17-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param kernel kernel function&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-4&#34;&gt;&lt;a href=&#34;#cb17-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-5&#34;&gt;&lt;a href=&#34;#cb17-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param y_train column vector (n, d) of training observations&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-6&#34;&gt;&lt;a href=&#34;#cb17-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param noise scalar of observation noise&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-7&#34;&gt;&lt;a href=&#34;#cb17-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param ... parameters of the kernel function with initial guesses. Due to the&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-8&#34;&gt;&lt;a href=&#34;#cb17-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; optimiser used, all parameters must be given and the order unfortunately&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-9&#34;&gt;&lt;a href=&#34;#cb17-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; matters&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-10&#34;&gt;&lt;a href=&#34;#cb17-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-11&#34;&gt;&lt;a href=&#34;#cb17-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return function that takes a matrix of prediction points as input and&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-12&#34;&gt;&lt;a href=&#34;#cb17-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; returns the posterior predictive distribution for the output&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb17-13&#34;&gt;&lt;a href=&#34;#cb17-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gpr &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(kernel, X_train, y_train, &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1e-8&lt;/span&gt;, ...) {&lt;/span&gt;
&lt;span id=&#34;cb17-14&#34;&gt;&lt;a href=&#34;#cb17-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  kernel_nll &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;nll&lt;/span&gt;(kernel, X_train, y_train, noise)&lt;/span&gt;
&lt;span id=&#34;cb17-15&#34;&gt;&lt;a href=&#34;#cb17-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  param &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(...)&lt;/span&gt;
&lt;span id=&#34;cb17-16&#34;&gt;&lt;a href=&#34;#cb17-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  opt &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;optim&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;par =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rep&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(param)), &lt;span class=&#34;at&#34;&gt;fn =&lt;/span&gt; kernel_nll)&lt;/span&gt;
&lt;span id=&#34;cb17-17&#34;&gt;&lt;a href=&#34;#cb17-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  opt_param &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; opt&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;par&lt;/span&gt;
&lt;span id=&#34;cb17-18&#34;&gt;&lt;a href=&#34;#cb17-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(X_pred) {&lt;/span&gt;
&lt;span id=&#34;cb17-19&#34;&gt;&lt;a href=&#34;#cb17-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; rlang&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;exec&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb17-20&#34;&gt;&lt;a href=&#34;#cb17-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      posterior,&lt;/span&gt;
&lt;span id=&#34;cb17-21&#34;&gt;&lt;a href=&#34;#cb17-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;kernel =&lt;/span&gt; kernel,&lt;/span&gt;
&lt;span id=&#34;cb17-22&#34;&gt;&lt;a href=&#34;#cb17-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;X_pred =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb17-23&#34;&gt;&lt;a href=&#34;#cb17-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;X_train =&lt;/span&gt; X_train,&lt;/span&gt;
&lt;span id=&#34;cb17-24&#34;&gt;&lt;a href=&#34;#cb17-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y_train =&lt;/span&gt; y_train,&lt;/span&gt;
&lt;span id=&#34;cb17-25&#34;&gt;&lt;a href=&#34;#cb17-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;noise =&lt;/span&gt; noise,&lt;/span&gt;
&lt;span id=&#34;cb17-26&#34;&gt;&lt;a href=&#34;#cb17-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;sc&#34;&gt;!!!&lt;/span&gt;opt_param&lt;/span&gt;
&lt;span id=&#34;cb17-27&#34;&gt;&lt;a href=&#34;#cb17-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb17-28&#34;&gt;&lt;a href=&#34;#cb17-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;list&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb17-29&#34;&gt;&lt;a href=&#34;#cb17-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu,&lt;/span&gt;
&lt;span id=&#34;cb17-30&#34;&gt;&lt;a href=&#34;#cb17-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;sigma =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;diag&lt;/span&gt;(post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma),&lt;/span&gt;
&lt;span id=&#34;cb17-31&#34;&gt;&lt;a href=&#34;#cb17-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;parameters =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;set_names&lt;/span&gt;(opt_param, &lt;span class=&#34;fu&#34;&gt;names&lt;/span&gt;(param))&lt;/span&gt;
&lt;span id=&#34;cb17-32&#34;&gt;&lt;a href=&#34;#cb17-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    )&lt;/span&gt;
&lt;span id=&#34;cb17-33&#34;&gt;&lt;a href=&#34;#cb17-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb17-34&#34;&gt;&lt;a href=&#34;#cb17-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h4 id=&#34;applying-gp-in-more-dimensions&#34; class=&#34;anchored&#34;&gt;Applying GP in more Dimensions&lt;/h4&gt;
&lt;p&gt;A GP surrogate model is great for problems with many dimensions and relatively few observations. Here is an example in 2D with just 10 training points.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb18&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb18-1&#34;&gt;&lt;a href=&#34;#cb18-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;noise_2d &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-2&#34;&gt;&lt;a href=&#34;#cb18-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_train_2d &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;runif&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;20&lt;/span&gt;, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;), &lt;span class=&#34;dv&#34;&gt;10&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb18-3&#34;&gt;&lt;a href=&#34;#cb18-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_train_2d &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ackley&lt;/span&gt;(X_train_2d) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise_2d &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb18-4&#34;&gt;&lt;a href=&#34;#cb18-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gpr_2d &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gpr&lt;/span&gt;(rbf_kernel, X_train_2d, y_train_2d, noise_2d, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb18-5&#34;&gt;&lt;a href=&#34;#cb18-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_predict_2d &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;as.matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;expand.grid&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb18-6&#34;&gt;&lt;a href=&#34;#cb18-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;,&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;50&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb18-7&#34;&gt;&lt;a href=&#34;#cb18-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;,&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;50&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb18-8&#34;&gt;&lt;a href=&#34;#cb18-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;))&lt;/span&gt;
&lt;span id=&#34;cb18-9&#34;&gt;&lt;a href=&#34;#cb18-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gpr_2d&lt;/span&gt;(X_predict_2d)&lt;/span&gt;
&lt;span id=&#34;cb18-10&#34;&gt;&lt;a href=&#34;#cb18-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(X_predict_2d, &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;x1&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;x2&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-11&#34;&gt;&lt;a href=&#34;#cb18-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-12&#34;&gt;&lt;a href=&#34;#cb18-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x1, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; x2)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-13&#34;&gt;&lt;a href=&#34;#cb18-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_contour_filled&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;z =&lt;/span&gt; y), &lt;span class=&#34;at&#34;&gt;bins =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;8&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-14&#34;&gt;&lt;a href=&#34;#cb18-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb18-15&#34;&gt;&lt;a href=&#34;#cb18-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(X_train_2d, &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;x1&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;x2&#34;&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb18-16&#34;&gt;&lt;a href=&#34;#cb18-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-17&#34;&gt;&lt;a href=&#34;#cb18-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb18-18&#34;&gt;&lt;a href=&#34;#cb18-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Even with just a few training points, some general tendencies of the objective function have been captured and the surrogate model should be useful for Bayesian optimisation.&lt;/p&gt;
&lt;h2 id=&#34;acquisition-function-1&#34; class=&#34;anchored&#34;&gt;Acquisition Function&lt;/h2&gt;
&lt;p&gt;An acquisition function is used to determine the next point at which to evaluate the objective function. The goal of the acquisition function is to balance exploration, i.e.&amp;nbsp;sampling points in unexplored regions, and exploitation, i.e.&amp;nbsp;sampling points that are likely to be optimal. The acquisition function takes into account the posterior predictive distribution of the surrogate model and provides a quantitative measure of the value of evaluating the objective function at a given point. Some common acquisition functions used in Bayesian optimisation include expected improvement, probability of improvement, and upper confidence bound.&lt;/p&gt;
&lt;h3 id=&#34;implementing-expected-improvement&#34; class=&#34;anchored&#34;&gt;Implementing Expected Improvement&lt;/h3&gt;
&lt;p&gt;The basic idea behind Expected Improvement (EI) is to search for the point in the search space that has the highest probability of improving the current best solution. EI is defined as the expected value of the improvement over the current best solution, where the improvement is defined as the difference between the function value at the candidate point and the current best value. In other words, EI measures how much better the objective function is expected to be at the candidate point compared to the current best value, weighted by the probability of achieving that improvement.&lt;/p&gt;
&lt;p&gt;Formally, the expected improvement acquisition function for a minimisation problem is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\mathrm{EI}(\mathbf{x}) = \mathbb{E}\left[\max(0, f_{\min} - f(\mathbf{x}))\right]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt; is the candidate point &lt;span class=&#34;math inline&#34;&gt;f_{\min}&lt;/span&gt; is the current best function value observed so far.&lt;/p&gt;
&lt;p&gt;When using a GP surrogate model in place of &lt;span class=&#34;math inline&#34;&gt;f&lt;/span&gt;, EI can be calculated using the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;EI(\mathbf{x}) = (\mu(\mathbf{x}) - y_{best} - \xi) \Phi(Z) + \sigma(\mathbf{x}) \phi(Z)&lt;/span&gt; with&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;Z = \frac{\mu(\mathbf{x}) - y_{best} - \xi}{\sigma(\mathbf{x})}&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\mu(\mathbf{x})&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\sigma(\mathbf{x})&lt;/span&gt; are the mean and standard deviation of the Gaussian process at &lt;span class=&#34;math inline&#34;&gt;\mathbf{x}&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\Phi&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\phi&lt;/span&gt; are the standard normal cumulative distribution function and probability density function, respectively, and &lt;span class=&#34;math inline&#34;&gt;\xi&lt;/span&gt; is a trade-off parameter that balances exploration and exploitation. Higher values of &lt;span class=&#34;math inline&#34;&gt;\xi&lt;/span&gt; leads to more exploration and smaller values to exploitation. &lt;span class=&#34;math inline&#34;&gt;EI(\mathbf{x}) = 0&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\sigma(\mathbf{x}) = 0&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The formulas can be implemented directly.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb19&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb19-1&#34;&gt;&lt;a href=&#34;#cb19-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; Expected Improvement&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-2&#34;&gt;&lt;a href=&#34;#cb19-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-3&#34;&gt;&lt;a href=&#34;#cb19-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param gp a conditioned Gaussian process&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-4&#34;&gt;&lt;a href=&#34;#cb19-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X matrix (m, d) of points where EI should be evaluated&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-5&#34;&gt;&lt;a href=&#34;#cb19-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param X_train matrix (n, d) of training points&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-6&#34;&gt;&lt;a href=&#34;#cb19-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @param xi scalar, exploration/exploitation trade off&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-7&#34;&gt;&lt;a href=&#34;#cb19-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-8&#34;&gt;&lt;a href=&#34;#cb19-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;co&#34;&gt;#&#39; @return EI, vector of length m&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-9&#34;&gt;&lt;a href=&#34;#cb19-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;expected_improvement &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(gp, X, X_train, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.01&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb19-10&#34;&gt;&lt;a href=&#34;#cb19-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  post_pred &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp&lt;/span&gt;(X)&lt;/span&gt;
&lt;span id=&#34;cb19-11&#34;&gt;&lt;a href=&#34;#cb19-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  post_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp&lt;/span&gt;(X_train)&lt;/span&gt;
&lt;span id=&#34;cb19-12&#34;&gt;&lt;a href=&#34;#cb19-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  min_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;min&lt;/span&gt;(post_train&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu)&lt;/span&gt;
&lt;span id=&#34;cb19-13&#34;&gt;&lt;a href=&#34;#cb19-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  sigma &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma&lt;/span&gt;
&lt;span id=&#34;cb19-14&#34;&gt;&lt;a href=&#34;#cb19-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;dim&lt;/span&gt;(sigma) &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;length&lt;/span&gt;(post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma), &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb19-15&#34;&gt;&lt;a href=&#34;#cb19-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  imp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; min_train &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; post_pred&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; xi&lt;/span&gt;
&lt;span id=&#34;cb19-16&#34;&gt;&lt;a href=&#34;#cb19-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  Z &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; imp &lt;span class=&#34;sc&#34;&gt;/&lt;/span&gt; sigma&lt;/span&gt;
&lt;span id=&#34;cb19-17&#34;&gt;&lt;a href=&#34;#cb19-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; imp &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;pnorm&lt;/span&gt;(Z) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; sigma &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;dnorm&lt;/span&gt;(Z)&lt;/span&gt;
&lt;span id=&#34;cb19-18&#34;&gt;&lt;a href=&#34;#cb19-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei[sigma &lt;span class=&#34;sc&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.0&lt;/span&gt;] &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb19-19&#34;&gt;&lt;a href=&#34;#cb19-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei&lt;/span&gt;
&lt;span id=&#34;cb19-20&#34;&gt;&lt;a href=&#34;#cb19-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;When there is only a single input dimension, EI can be plotted next to the GP.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb20&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb20-1&#34;&gt;&lt;a href=&#34;#cb20-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei_plot &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(mu,&lt;/span&gt;
&lt;span id=&#34;cb20-2&#34;&gt;&lt;a href=&#34;#cb20-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                    sigma,&lt;/span&gt;
&lt;span id=&#34;cb20-3&#34;&gt;&lt;a href=&#34;#cb20-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                    X_pred,&lt;/span&gt;
&lt;span id=&#34;cb20-4&#34;&gt;&lt;a href=&#34;#cb20-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                    X_train,&lt;/span&gt;
&lt;span id=&#34;cb20-5&#34;&gt;&lt;a href=&#34;#cb20-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                    y_train,&lt;/span&gt;
&lt;span id=&#34;cb20-6&#34;&gt;&lt;a href=&#34;#cb20-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                    ei,&lt;/span&gt;
&lt;span id=&#34;cb20-7&#34;&gt;&lt;a href=&#34;#cb20-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                    &lt;span class=&#34;at&#34;&gt;true_function =&lt;/span&gt; &lt;span class=&#34;cn&#34;&gt;NULL&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb20-8&#34;&gt;&lt;a href=&#34;#cb20-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;                    &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;) {&lt;/span&gt;
&lt;span id=&#34;cb20-9&#34;&gt;&lt;a href=&#34;#cb20-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb20-10&#34;&gt;&lt;a href=&#34;#cb20-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mu =&lt;/span&gt; mu,&lt;/span&gt;
&lt;span id=&#34;cb20-11&#34;&gt;&lt;a href=&#34;#cb20-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;uncertainty =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;1.96&lt;/span&gt;&lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;sqrt&lt;/span&gt;(sigma),&lt;/span&gt;
&lt;span id=&#34;cb20-12&#34;&gt;&lt;a href=&#34;#cb20-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;upper =&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; uncertainty,&lt;/span&gt;
&lt;span id=&#34;cb20-13&#34;&gt;&lt;a href=&#34;#cb20-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;lower =&lt;/span&gt; mu &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt; uncertainty,&lt;/span&gt;
&lt;span id=&#34;cb20-14&#34;&gt;&lt;a href=&#34;#cb20-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb20-15&#34;&gt;&lt;a href=&#34;#cb20-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;f =&lt;/span&gt; &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(true_function)) &lt;span class=&#34;fu&#34;&gt;true_function&lt;/span&gt;(X_pred)&lt;/span&gt;
&lt;span id=&#34;cb20-16&#34;&gt;&lt;a href=&#34;#cb20-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-17&#34;&gt;&lt;a href=&#34;#cb20-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-18&#34;&gt;&lt;a href=&#34;#cb20-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; mu, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Mean&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-19&#34;&gt;&lt;a href=&#34;#cb20-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_ribbon&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb20-20&#34;&gt;&lt;a href=&#34;#cb20-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;ymin =&lt;/span&gt; lower, &lt;span class=&#34;at&#34;&gt;ymax =&lt;/span&gt; upper),&lt;/span&gt;
&lt;span id=&#34;cb20-21&#34;&gt;&lt;a href=&#34;#cb20-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#219ebc&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb20-22&#34;&gt;&lt;a href=&#34;#cb20-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;alpha =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-23&#34;&gt;&lt;a href=&#34;#cb20-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-24&#34;&gt;&lt;a href=&#34;#cb20-24&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb20-25&#34;&gt;&lt;a href=&#34;#cb20-25&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_train, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y_train),&lt;/span&gt;
&lt;span id=&#34;cb20-26&#34;&gt;&lt;a href=&#34;#cb20-26&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; y, &lt;span class=&#34;at&#34;&gt;shape =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Training point&#34;&lt;/span&gt;),&lt;/span&gt;
&lt;span id=&#34;cb20-27&#34;&gt;&lt;a href=&#34;#cb20-27&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;#fb8500&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb20-28&#34;&gt;&lt;a href=&#34;#cb20-28&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;size =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-29&#34;&gt;&lt;a href=&#34;#cb20-29&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-30&#34;&gt;&lt;a href=&#34;#cb20-30&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;scale_shape_manual&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;values =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;Training point&#34;&lt;/span&gt; &lt;span class=&#34;ot&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;+&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-31&#34;&gt;&lt;a href=&#34;#cb20-31&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;shape =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-32&#34;&gt;&lt;a href=&#34;#cb20-32&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-33&#34;&gt;&lt;a href=&#34;#cb20-33&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb20-34&#34;&gt;&lt;a href=&#34;#cb20-34&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;y&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb20-35&#34;&gt;&lt;a href=&#34;#cb20-35&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb20-36&#34;&gt;&lt;a href=&#34;#cb20-36&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;,&lt;/span&gt;
&lt;span id=&#34;cb20-37&#34;&gt;&lt;a href=&#34;#cb20-37&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; title&lt;/span&gt;
&lt;span id=&#34;cb20-38&#34;&gt;&lt;a href=&#34;#cb20-38&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-39&#34;&gt;&lt;a href=&#34;#cb20-39&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;panel.grid =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;(), &lt;span class=&#34;at&#34;&gt;axis.text.x =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;())&lt;/span&gt;
&lt;span id=&#34;cb20-40&#34;&gt;&lt;a href=&#34;#cb20-40&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;cf&#34;&gt;if&lt;/span&gt; (&lt;span class=&#34;sc&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;is.null&lt;/span&gt;(true_function)) {&lt;/span&gt;
&lt;span id=&#34;cb20-41&#34;&gt;&lt;a href=&#34;#cb20-41&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    p1 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; p1 &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; &lt;/span&gt;
&lt;span id=&#34;cb20-42&#34;&gt;&lt;a href=&#34;#cb20-42&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;mapping =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; f, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;True function&#34;&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb20-43&#34;&gt;&lt;a href=&#34;#cb20-43&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  }&lt;/span&gt;
&lt;span id=&#34;cb20-44&#34;&gt;&lt;a href=&#34;#cb20-44&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p2 &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb20-45&#34;&gt;&lt;a href=&#34;#cb20-45&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; X_pred,&lt;/span&gt;
&lt;span id=&#34;cb20-46&#34;&gt;&lt;a href=&#34;#cb20-46&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;ei =&lt;/span&gt; ei&lt;/span&gt;
&lt;span id=&#34;cb20-47&#34;&gt;&lt;a href=&#34;#cb20-47&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-48&#34;&gt;&lt;a href=&#34;#cb20-48&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-49&#34;&gt;&lt;a href=&#34;#cb20-49&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_line&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; ei, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;EI&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-50&#34;&gt;&lt;a href=&#34;#cb20-50&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-51&#34;&gt;&lt;a href=&#34;#cb20-51&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;Expected improvement&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb20-52&#34;&gt;&lt;a href=&#34;#cb20-52&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;panel.grid =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;element_blank&lt;/span&gt;())&lt;/span&gt;
&lt;span id=&#34;cb20-53&#34;&gt;&lt;a href=&#34;#cb20-53&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  aligned_plots &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; cowplot&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;align_plots&lt;/span&gt;(p2, p1, &lt;span class=&#34;at&#34;&gt;align =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;v&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb20-54&#34;&gt;&lt;a href=&#34;#cb20-54&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  cowplot&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;plot_grid&lt;/span&gt;(aligned_plots[[&lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;]], aligned_plots[[&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;]], &lt;span class=&#34;at&#34;&gt;ncol =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb20-55&#34;&gt;&lt;a href=&#34;#cb20-55&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&#34;cb20-56&#34;&gt;&lt;a href=&#34;#cb20-56&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;mygpr &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gpr&lt;/span&gt;(rbf_kernel, X_train, y_train, noise, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb20-57&#34;&gt;&lt;a href=&#34;#cb20-57&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement&lt;/span&gt;(mygpr, X_predict, X_train, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb20-58&#34;&gt;&lt;a href=&#34;#cb20-58&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;mygpr&lt;/span&gt;(X_predict)&lt;/span&gt;
&lt;span id=&#34;cb20-59&#34;&gt;&lt;a href=&#34;#cb20-59&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;ei_plot&lt;/span&gt;(post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu, post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma, X_predict, X_train, y_train, ei, ackley)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In this example, there is some expected improvement near the middle of the input range, but the point expected to bring about the highest improvement is at the right edge of the range.&lt;/p&gt;
&lt;h2 id=&#34;initial-training-data-1&#34; class=&#34;anchored&#34;&gt;Initial Training Data&lt;/h2&gt;
&lt;p&gt;Before applying GPR and EI, a few initial training data are needed. Considering that it is expensive to evaluate the objective function, the number of initial training observations should be limited. However, considering that the GP is not great for extrapolation, the number of initial observation should not be too small either.&lt;/p&gt;
&lt;p&gt;In general, the initial training data should be chosen to provide a good representation of the objective function. This means that the data should be chosen to cover the range of each input dimension. The data should also include inputs that are expected to be both good and bad performers.&lt;/p&gt;
&lt;p&gt;There are a few ways to create a set of initial training inputs. One approach is to use a set of random inputs. This is easy to implement, but it risks testing redundant points and it neglects any prior information of the objective function. In place of a completely random design, Latin Hypercube Sampling (LHS) is often used.&lt;/p&gt;
&lt;p&gt;Another approach is to use domain knowledge to select an initial set of inputs. For example, if the function being optimised is a manufacturing process there might be a fixed range of feasible settings and skilled operators might have good ideas for which settings would perform well.&lt;/p&gt;
&lt;p&gt;For the demonstration of Bayesian optimisation with the Ackley function in just a few dimensions, a few random or linearly spaced points will do fine.&lt;/p&gt;
&lt;h2 id=&#34;stopping-criterion-1&#34; class=&#34;anchored&#34;&gt;Stopping Criterion&lt;/h2&gt;
&lt;p&gt;The final component of Bayesian optimisation is a stopping criterion. Depending on the application, a good stopping criterion might be more or less obvious. In settings where a real life process is optimised, time and money are common constraints. In ML or other theoretical applications, a mathematically defined criterion might be preferred.&lt;/p&gt;
&lt;p&gt;Examples of stopping criteria include&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Maximum number of objective function evaluations.&lt;/li&gt;
&lt;li&gt;When the improvement in objective function value falls below a threshold.&lt;/li&gt;
&lt;li&gt;Project time limits or deadlines.&lt;/li&gt;
&lt;li&gt;Accuracy of the surrogate model.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bayesian-optimisation-in-action&#34; class=&#34;anchored&#34;&gt;Bayesian Optimisation in Action&lt;/h2&gt;
&lt;p&gt;With all the components of Bayesian optimisation in place, a demonstration is due.&lt;/p&gt;
&lt;h3 id=&#34;example-in-1d&#34; class=&#34;anchored&#34;&gt;Example in 1D&lt;/h3&gt;
&lt;p&gt;The initial training data is just two points.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb21&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb21-1&#34;&gt;&lt;a href=&#34;#cb21-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_initial &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb21-2&#34;&gt;&lt;a href=&#34;#cb21-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_initial &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;2.5&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;2.1&lt;/span&gt;), n_initial, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb21-3&#34;&gt;&lt;a href=&#34;#cb21-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;noise &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb21-4&#34;&gt;&lt;a href=&#34;#cb21-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_initial &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ackley&lt;/span&gt;(X_initial) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(n_initial)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;A GP is conditioned on the initial training data and expected improvement is calculated along a grid.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb22&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb22-1&#34;&gt;&lt;a href=&#34;#cb22-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gpr&lt;/span&gt;(rbf_kernel, X_initial, y_initial, noise, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb22-2&#34;&gt;&lt;a href=&#34;#cb22-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_predict &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;), &lt;span class=&#34;dv&#34;&gt;100&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb22-3&#34;&gt;&lt;a href=&#34;#cb22-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement&lt;/span&gt;(gp, X_predict, X_initial, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here is what it looks like so far.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb23&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb23-1&#34;&gt;&lt;a href=&#34;#cb23-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp&lt;/span&gt;(X_predict)&lt;/span&gt;
&lt;span id=&#34;cb23-2&#34;&gt;&lt;a href=&#34;#cb23-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;&lt;span class=&#34;fu&#34;&gt;ei_plot&lt;/span&gt;(post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu, post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma, X_predict, X_initial, y_initial, ei, ackley)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;It looks like the point that will yield the most improvement is all the way at the right edge of input space.&lt;/p&gt;
&lt;p&gt;Now this point is added to the training data.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb24&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb24-1&#34;&gt;&lt;a href=&#34;#cb24-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;x &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_predict[[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei)]]&lt;/span&gt;
&lt;span id=&#34;cb24-2&#34;&gt;&lt;a href=&#34;#cb24-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ackley&lt;/span&gt;(x) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb24-3&#34;&gt;&lt;a href=&#34;#cb24-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rbind&lt;/span&gt;(X_initial, &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(x))&lt;/span&gt;
&lt;span id=&#34;cb24-4&#34;&gt;&lt;a href=&#34;#cb24-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(y_initial, &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(y))&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now it is time for the optimisation part. The stopping criterion will be five additional evaluations.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb25&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb25-1&#34;&gt;&lt;a href=&#34;#cb25-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_rounds &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In each round, the GP is conditioned on the training data, the point that maximises EI is found, and that point is evaluated in the objective function.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb26&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb26-1&#34;&gt;&lt;a href=&#34;#cb26-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;plots &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;lapply&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;seq_len&lt;/span&gt;(n_rounds), &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(i) {&lt;/span&gt;
&lt;span id=&#34;cb26-2&#34;&gt;&lt;a href=&#34;#cb26-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  gp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gpr&lt;/span&gt;(rbf_kernel, X_train, y_train, noise, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb26-3&#34;&gt;&lt;a href=&#34;#cb26-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement&lt;/span&gt;(gp, X_predict, X_train, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb26-4&#34;&gt;&lt;a href=&#34;#cb26-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp&lt;/span&gt;(X_predict)&lt;/span&gt;
&lt;span id=&#34;cb26-5&#34;&gt;&lt;a href=&#34;#cb26-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ei_plot&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb26-6&#34;&gt;&lt;a href=&#34;#cb26-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu,&lt;/span&gt;
&lt;span id=&#34;cb26-7&#34;&gt;&lt;a href=&#34;#cb26-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;sigma,&lt;/span&gt;
&lt;span id=&#34;cb26-8&#34;&gt;&lt;a href=&#34;#cb26-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    X_predict,&lt;/span&gt;
&lt;span id=&#34;cb26-9&#34;&gt;&lt;a href=&#34;#cb26-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    X_train,&lt;/span&gt;
&lt;span id=&#34;cb26-10&#34;&gt;&lt;a href=&#34;#cb26-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    y_train,&lt;/span&gt;
&lt;span id=&#34;cb26-11&#34;&gt;&lt;a href=&#34;#cb26-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ei,&lt;/span&gt;
&lt;span id=&#34;cb26-12&#34;&gt;&lt;a href=&#34;#cb26-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ackley,&lt;/span&gt;
&lt;span id=&#34;cb26-13&#34;&gt;&lt;a href=&#34;#cb26-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;paste&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;Round&#34;&lt;/span&gt;, i)&lt;/span&gt;
&lt;span id=&#34;cb26-14&#34;&gt;&lt;a href=&#34;#cb26-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  )&lt;/span&gt;
&lt;span id=&#34;cb26-15&#34;&gt;&lt;a href=&#34;#cb26-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  x &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_predict[[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei)]]&lt;/span&gt;
&lt;span id=&#34;cb26-16&#34;&gt;&lt;a href=&#34;#cb26-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  y &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ackley&lt;/span&gt;(x) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb26-17&#34;&gt;&lt;a href=&#34;#cb26-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rbind&lt;/span&gt;(X_train, &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(x))&lt;/span&gt;
&lt;span id=&#34;cb26-18&#34;&gt;&lt;a href=&#34;#cb26-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  y_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(y_train, &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(y))&lt;/span&gt;
&lt;span id=&#34;cb26-19&#34;&gt;&lt;a href=&#34;#cb26-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p&lt;/span&gt;
&lt;span id=&#34;cb26-20&#34;&gt;&lt;a href=&#34;#cb26-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;})&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;A closer look at each iteration reveals that the global optimum was found in the fourth evaluation of the objective function.&lt;/p&gt;
&lt;div class=&#34;cell quarto-layout-panel&#34;&gt;
&lt;div class=&#34;quarto-layout-row quarto-layout-valign-top&#34;&gt;
&lt;div class=&#34;cell-output-display quarto-layout-cell&#34; style=&#34;flex-basis: 50.0%;justify-content: center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/bo_plots-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;cell-output-display quarto-layout-cell&#34; style=&#34;flex-basis: 50.0%;justify-content: center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/bo_plots-2.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;quarto-layout-row quarto-layout-valign-top&#34;&gt;
&lt;div class=&#34;cell-output-display quarto-layout-cell&#34; style=&#34;flex-basis: 50.0%;justify-content: center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/bo_plots-3.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;cell-output-display quarto-layout-cell&#34; style=&#34;flex-basis: 50.0%;justify-content: center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/bo_plots-4.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;quarto-layout-row quarto-layout-valign-top&#34;&gt;
&lt;div class=&#34;cell-output-display quarto-layout-cell&#34; style=&#34;flex-basis: 100.0%;justify-content: center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/bo_plots-5.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;example-in-2d&#34; class=&#34;anchored&#34;&gt;Example in 2D&lt;/h3&gt;
&lt;p&gt;With two input dimensions the optimisation is a bit harder.&lt;/p&gt;
&lt;p&gt;The initial training data will be four points.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb27&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb27-1&#34;&gt;&lt;a href=&#34;#cb27-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_initial &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;4&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb27-2&#34;&gt;&lt;a href=&#34;#cb27-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_initial &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;2.1&lt;/span&gt;, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;2.1&lt;/span&gt;, &lt;span class=&#34;fl&#34;&gt;4.7&lt;/span&gt;, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;4.7&lt;/span&gt;, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;2.5&lt;/span&gt;, &lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;fl&#34;&gt;2.5&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb27-3&#34;&gt;&lt;a href=&#34;#cb27-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(n_initial, &lt;span class=&#34;dv&#34;&gt;2&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb27-4&#34;&gt;&lt;a href=&#34;#cb27-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;noise &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb27-5&#34;&gt;&lt;a href=&#34;#cb27-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_initial &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ackley&lt;/span&gt;(X_initial) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(n_initial)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;A GP is conditioned on the initial training data and expected improvement is calculated along a grid.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb28&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb28-1&#34;&gt;&lt;a href=&#34;#cb28-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;gp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gpr&lt;/span&gt;(rbf_kernel, X_initial, y_initial, noise, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb28-2&#34;&gt;&lt;a href=&#34;#cb28-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_predict &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;seq&lt;/span&gt;(&lt;span class=&#34;sc&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;dv&#34;&gt;5&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;length.out =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;50&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb28-3&#34;&gt;&lt;a href=&#34;#cb28-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;expand.grid&lt;/span&gt;(.,.) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb28-4&#34;&gt;&lt;a href=&#34;#cb28-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;as.matrix&lt;/span&gt;()&lt;/span&gt;
&lt;span id=&#34;cb28-5&#34;&gt;&lt;a href=&#34;#cb28-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement&lt;/span&gt;(gp, X_predict, X_initial, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here is what it looks like so far.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb29&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb29-1&#34;&gt;&lt;a href=&#34;#cb29-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp&lt;/span&gt;(X_predict)&lt;/span&gt;
&lt;span id=&#34;cb29-2&#34;&gt;&lt;a href=&#34;#cb29-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(X_predict, &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;x1&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;x2&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-3&#34;&gt;&lt;a href=&#34;#cb29-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-4&#34;&gt;&lt;a href=&#34;#cb29-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x1, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; x2)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-5&#34;&gt;&lt;a href=&#34;#cb29-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_contour_filled&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;z =&lt;/span&gt; y), &lt;span class=&#34;at&#34;&gt;bins =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;8&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-6&#34;&gt;&lt;a href=&#34;#cb29-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb29-7&#34;&gt;&lt;a href=&#34;#cb29-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(X_initial, &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;x1&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;x2&#34;&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb29-8&#34;&gt;&lt;a href=&#34;#cb29-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-9&#34;&gt;&lt;a href=&#34;#cb29-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb29-10&#34;&gt;&lt;a href=&#34;#cb29-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb29-11&#34;&gt;&lt;a href=&#34;#cb29-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(X_predict[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei), ]),&lt;/span&gt;
&lt;span id=&#34;cb29-12&#34;&gt;&lt;a href=&#34;#cb29-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;x1&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;x2&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb29-13&#34;&gt;&lt;a href=&#34;#cb29-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ),&lt;/span&gt;
&lt;span id=&#34;cb29-14&#34;&gt;&lt;a href=&#34;#cb29-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;at&#34;&gt;mapping =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;max EI&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb29-15&#34;&gt;&lt;a href=&#34;#cb29-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-16&#34;&gt;&lt;a href=&#34;#cb29-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb29-17&#34;&gt;&lt;a href=&#34;#cb29-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;)&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&#34;cell-output-display&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;It looks like the point that will yield the most improvement is all the way at the corner of input space.&lt;/p&gt;
&lt;p&gt;Now this point is added to the training data.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb30&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb30-1&#34;&gt;&lt;a href=&#34;#cb30-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;x &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_predict[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei), ]&lt;/span&gt;
&lt;span id=&#34;cb30-2&#34;&gt;&lt;a href=&#34;#cb30-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ackley&lt;/span&gt;(x) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb30-3&#34;&gt;&lt;a href=&#34;#cb30-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;X_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rbind&lt;/span&gt;(X_initial, x)&lt;/span&gt;
&lt;span id=&#34;cb30-4&#34;&gt;&lt;a href=&#34;#cb30-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;y_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(y_initial, &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(y))&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Now it is time for the optimisation part. The stopping criterion will be eigth additional evaluations.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb31&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb31-1&#34;&gt;&lt;a href=&#34;#cb31-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;n_rounds &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;8&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In each round, the GP is conditioned on the training data, the point that maximises EI is found, and that point is evaluated in the objective function.&lt;/p&gt;
&lt;div class=&#34;cell&#34;&gt;
&lt;div class=&#34;sourceCode&#34; id=&#34;cb32&#34;&gt;&lt;pre class=&#34;sourceCode r cell-code code-with-copy&#34;&gt;&lt;code class=&#34;sourceCode r&#34;&gt;&lt;span id=&#34;cb32-1&#34;&gt;&lt;a href=&#34;#cb32-1&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;plots &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;lapply&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;seq_len&lt;/span&gt;(n_rounds), &lt;span class=&#34;cf&#34;&gt;function&lt;/span&gt;(i) {&lt;/span&gt;
&lt;span id=&#34;cb32-2&#34;&gt;&lt;a href=&#34;#cb32-2&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  gp &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gpr&lt;/span&gt;(rbf_kernel, X_train, y_train, noise, &lt;span class=&#34;at&#34;&gt;l =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;sigma_f =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb32-3&#34;&gt;&lt;a href=&#34;#cb32-3&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  ei &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;expected_improvement&lt;/span&gt;(gp, X_predict, X_train, &lt;span class=&#34;at&#34;&gt;xi =&lt;/span&gt; &lt;span class=&#34;fl&#34;&gt;0.01&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb32-4&#34;&gt;&lt;a href=&#34;#cb32-4&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  post &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;gp&lt;/span&gt;(X_predict)&lt;/span&gt;
&lt;span id=&#34;cb32-5&#34;&gt;&lt;a href=&#34;#cb32-5&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  x &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; X_predict[&lt;span class=&#34;fu&#34;&gt;which.max&lt;/span&gt;(ei), ]&lt;/span&gt;
&lt;span id=&#34;cb32-6&#34;&gt;&lt;a href=&#34;#cb32-6&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(X_predict, &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;x1&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;x2&#34;&lt;/span&gt;)) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb32-7&#34;&gt;&lt;a href=&#34;#cb32-7&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    dplyr&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;mutate&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; post&lt;span class=&#34;sc&#34;&gt;$&lt;/span&gt;mu) &lt;span class=&#34;sc&#34;&gt;%&amp;gt;%&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb32-8&#34;&gt;&lt;a href=&#34;#cb32-8&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;ggplot&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;x =&lt;/span&gt; x1, &lt;span class=&#34;at&#34;&gt;y =&lt;/span&gt; x2)) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb32-9&#34;&gt;&lt;a href=&#34;#cb32-9&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_contour_filled&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;z =&lt;/span&gt; y), &lt;span class=&#34;at&#34;&gt;bins =&lt;/span&gt; &lt;span class=&#34;dv&#34;&gt;8&lt;/span&gt;) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb32-10&#34;&gt;&lt;a href=&#34;#cb32-10&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb32-11&#34;&gt;&lt;a href=&#34;#cb32-11&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(X_train, &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;x1&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;x2&#34;&lt;/span&gt;))&lt;/span&gt;
&lt;span id=&#34;cb32-12&#34;&gt;&lt;a href=&#34;#cb32-12&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb32-13&#34;&gt;&lt;a href=&#34;#cb32-13&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;geom_point&lt;/span&gt;(&lt;/span&gt;
&lt;span id=&#34;cb32-14&#34;&gt;&lt;a href=&#34;#cb32-14&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;data =&lt;/span&gt; tibble&lt;span class=&#34;sc&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;fu&#34;&gt;as_tibble&lt;/span&gt;(&lt;span class=&#34;fu&#34;&gt;t&lt;/span&gt;(x), &lt;span class=&#34;at&#34;&gt;.name_repair =&lt;/span&gt; &lt;span class=&#34;sc&#34;&gt;~&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;x1&#34;&lt;/span&gt;, &lt;span class=&#34;st&#34;&gt;&#34;x2&#34;&lt;/span&gt;)),&lt;/span&gt;
&lt;span id=&#34;cb32-15&#34;&gt;&lt;a href=&#34;#cb32-15&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;      &lt;span class=&#34;at&#34;&gt;mapping =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;aes&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;max EI&#34;&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb32-16&#34;&gt;&lt;a href=&#34;#cb32-16&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    ) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb32-17&#34;&gt;&lt;a href=&#34;#cb32-17&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;theme_minimal&lt;/span&gt;() &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt;&lt;/span&gt;
&lt;span id=&#34;cb32-18&#34;&gt;&lt;a href=&#34;#cb32-18&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;    &lt;span class=&#34;fu&#34;&gt;labs&lt;/span&gt;(&lt;span class=&#34;at&#34;&gt;fill =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;colour =&lt;/span&gt; &lt;span class=&#34;st&#34;&gt;&#34;&#34;&lt;/span&gt;, &lt;span class=&#34;at&#34;&gt;title =&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;paste&lt;/span&gt;(&lt;span class=&#34;st&#34;&gt;&#34;Round&#34;&lt;/span&gt;, i))&lt;/span&gt;
&lt;span id=&#34;cb32-19&#34;&gt;&lt;a href=&#34;#cb32-19&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  y &lt;span class=&#34;ot&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;ackley&lt;/span&gt;(x) &lt;span class=&#34;sc&#34;&gt;+&lt;/span&gt; noise &lt;span class=&#34;sc&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rnorm&lt;/span&gt;(&lt;span class=&#34;dv&#34;&gt;1&lt;/span&gt;)&lt;/span&gt;
&lt;span id=&#34;cb32-20&#34;&gt;&lt;a href=&#34;#cb32-20&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  X_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;rbind&lt;/span&gt;(X_train, x)&lt;/span&gt;
&lt;span id=&#34;cb32-21&#34;&gt;&lt;a href=&#34;#cb32-21&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  y_train &lt;span class=&#34;ot&#34;&gt;&amp;lt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;fu&#34;&gt;c&lt;/span&gt;(y_train, &lt;span class=&#34;fu&#34;&gt;matrix&lt;/span&gt;(y))&lt;/span&gt;
&lt;span id=&#34;cb32-22&#34;&gt;&lt;a href=&#34;#cb32-22&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;  p&lt;/span&gt;
&lt;span id=&#34;cb32-23&#34;&gt;&lt;a href=&#34;#cb32-23&#34; aria-hidden=&#34;true&#34; tabindex=&#34;-1&#34;&gt;&lt;/a&gt;})&lt;/span&gt;&lt;/code&gt;&lt;button title=&#34;Copy to Clipboard&#34; class=&#34;code-copy-button&#34;&gt;&lt;i class=&#34;bi&#34;&gt;&lt;/i&gt;&lt;/button&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Looking at the last four iterations reveals that, while close, the global optimum has not been found and that many iterations were spent exploring the edges of input space. A few more iterations might have revealed the global optimum. On the other hand, the small budget did reveal a relatively good set of input parameters.&lt;/p&gt;
&lt;div class=&#34;cell quarto-layout-panel&#34;&gt;
&lt;div class=&#34;quarto-layout-row quarto-layout-valign-top&#34;&gt;
&lt;div class=&#34;cell-output-display quarto-layout-cell&#34; style=&#34;flex-basis: 50.0%;justify-content: center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/bo_plots_2d-1.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;cell-output-display quarto-layout-cell&#34; style=&#34;flex-basis: 50.0%;justify-content: center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/bo_plots_2d-2.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;quarto-layout-row quarto-layout-valign-top&#34;&gt;
&lt;div class=&#34;cell-output-display quarto-layout-cell&#34; style=&#34;flex-basis: 50.0%;justify-content: center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/bo_plots_2d-3.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;cell-output-display quarto-layout-cell&#34; style=&#34;flex-basis: 50.0%;justify-content: center;&#34;&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/bo_plots_2d-4.png&#34; width=&#34;672&#34;&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 class=&#34;unnumbered&#34; id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body&#34; role=&#34;doc-bibliography&#34;&gt;
&lt;div id=&#34;ref-Rasmussen:2006&#34; class=&#34;csl-entry&#34; role=&#34;doc-biblioentry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[1] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Rasmussen&lt;/span&gt;, C. E. and &lt;span class=&#34;smallcaps&#34;&gt;Williams&lt;/span&gt;, C. K. I. (2006). &lt;em&gt;Gaussian processes for machine learning&lt;/em&gt;. MIT Press.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;license&#34;&gt;License&lt;/h1&gt;
&lt;p&gt;The content of this project itself is licensed under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International license&lt;/a&gt;, and the underlying code is licensed under the &lt;a href=&#34;https://github.com/AnHosu/bespoke-bayesian-biochem/blob/main/LICENSE&#34;&gt;GNU General Public License v3.0 license&lt;/a&gt;.&lt;/p&gt;
&lt;script type=&#34;application/javascript&#34;&gt;
window.document.addEventListener(&#34;DOMContentLoaded&#34;, function (event) {
  const tabsets =  window.document.querySelectorAll(&#34;.panel-tabset-tabby&#34;)
  tabsets.forEach(function(tabset) {
    const tabby = new Tabby(&#39;#&#39; + tabset.id);
  });
  const icon = &#34;&#34;;
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: &#39;right&#39;,
    icon: icon
  };
  anchorJS.add(&#39;.anchored&#39;);
  const clipboard = new window.ClipboardJS(&#39;.code-copy-button&#39;, {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on(&#39;success&#39;, function(e) {
    // button target
    const button = e.trigger;
    // don&#39;t keep focus
    button.blur();
    // flash &#34;checked&#34;
    button.classList.add(&#39;code-copy-button-checked&#39;);
    setTimeout(function() {
      button.classList.remove(&#39;code-copy-button-checked&#39;);
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: &#39;light-border&#39;,
      placement: &#39;bottom-start&#39;
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-noteref&#34;]&#39;);
  for (var i=0; i&lt;noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute(&#39;href&#39;);
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, &#34;&#34;);
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll(&#39;a[role=&#34;doc-biblioref&#34;]&#39;);
  for (var i=0; i&lt;bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute(&#39;data-cites&#39;).split(&#39; &#39;);
    tippyHover(ref, function() {
      var popup = window.document.createElement(&#39;div&#39;);
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement(&#39;div&#39;);
        citeDiv.classList.add(&#39;hanging-indent&#39;);
        citeDiv.classList.add(&#39;csl-entry&#39;);
        var biblioDiv = window.document.getElementById(&#39;ref-&#39; + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
&lt;/script&gt;


&lt;/body&gt;&lt;/html&gt;</description>
    </item>
    
    <item>
      <title>Bespoke Bayesian Model for Biochemical Assays</title>
      <link>/post/bespoke-biochem-one/</link>
      <pubDate>Sat, 20 Nov 2021 00:00:00 +0000</pubDate>
      <guid>/post/bespoke-biochem-one/</guid>
      <description>
&lt;script src=&#34;../../post/bespoke-biochem-one/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I am on a quest to improve the model fitting I do on biochemical assays. For some time, I have had this feeling that I should be able to extract more information from the data gathered in biochemical assays, in particular assays with a high throughput. I have been using classical machine learning techniques and generic fitting and optimisation functions to interpret data from such assays. While this approach works, it also neglects much of the available domain expertise. Many of the underlying biochemical mechanisms are known and I would like my models to take that into account so I get results that are more directly interpretable in the context of the hypothesis that required the assay in the first place. In other words, I want a bespoke model.&lt;/p&gt;
&lt;p&gt;I will be developing the bespoke model one minimally viable step at a time. In this study, I am building a Bayesian model for biochemical assays where the underlying data generating process is the Hill equation for tissue responses &lt;span class=&#34;citation&#34;&gt;[&lt;a href=&#34;#ref-Neubig597&#34; role=&#34;doc-biblioref&#34;&gt;1&lt;/a&gt;]&lt;/span&gt;. I will then test the model in two simulated example studies.&lt;/p&gt;
&lt;p&gt;I was inspired to write this study after reading the chapter “Generalized Linear Madness” in the book Statistical Rethinking by R. McElreath &lt;span class=&#34;citation&#34;&gt;[&lt;a href=&#34;#ref-McElreath:2016&#34; role=&#34;doc-biblioref&#34;&gt;2&lt;/a&gt;]&lt;/span&gt; and the writings of M. Betancourt &lt;span class=&#34;citation&#34;&gt;[&lt;a href=&#34;#ref-Betancourt:2019&#34; role=&#34;doc-biblioref&#34;&gt;3&lt;/a&gt;]&lt;/span&gt;. For an introduction to bespoke Bayesian models, I highly recommend these resources.&lt;/p&gt;
&lt;p&gt;If you are following along, we will build the Bayesian models in Stan and make use of the Rstan interface to extract posterior samples. For data wrangling and visualisation, we will use the Tidyverse.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(magrittr)

options(mc.cores = parallel::detectCores())

colour &amp;lt;- list(
  orange_dark = &amp;quot;#fb8500&amp;quot;,
  orange_light = &amp;quot;#ffb703&amp;quot;,
  blue_dark = &amp;quot;#023047&amp;quot;,
  azure = &amp;quot;#219ebc&amp;quot;,
  blue_light = &amp;quot;#8ecae6&amp;quot;
)

set.seed(4444)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;contents&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Contents&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#contents&#34;&gt;Contents&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#domain-expertise&#34;&gt;Domain Expertise&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#hill-equation&#34;&gt;Hill Equation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#from-domain-expertise-to-probabilistic-model&#34;&gt;From Domain Expertise to Probabilistic Model&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#a-prior-for-the-hill-coefficient&#34;&gt;A prior for the Hill coefficient&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#a-prior-for-the-maximum-tissue-response&#34;&gt;A prior for the maximum tissue response&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#a-prior-for-the-minimum-tissue-response&#34;&gt;A prior for the minimum tissue response&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#a-prior-for-potency&#34;&gt;A prior for potency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#a-prior-for-experiment-noise&#34;&gt;A prior for experiment noise&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-studies&#34;&gt;Example Studies&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#example-study-1---exploring-kinetics&#34;&gt;Example Study 1 - Exploring Kinetics&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#a-model-for-study-1&#34;&gt;A model for study 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#prior-predictive-check-in-tidyverse&#34;&gt;Prior predictive check in Tidyverse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#building-a-stan-model-for-study-1&#34;&gt;Building a Stan model for study 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-study-1&#34;&gt;Fitting study 1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example-study-2---new-drug&#34;&gt;Example Study 2 - New Drug&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#a-model-for-study-2&#34;&gt;A model for study 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#prior-predictive-check-with-stan&#34;&gt;Prior predictive check with Stan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#building-a-stan-model-for-study-2&#34;&gt;Building a Stan model for study 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-study-2&#34;&gt;Fitting study 2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#assessing-posterior-quality&#34;&gt;Assessing posterior quality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#comparing-to-another-fitting-method&#34;&gt;Comparing to another fitting method&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#next-steps&#34;&gt;Next Steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#license&#34;&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;domain-expertise&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Domain Expertise&lt;/h1&gt;
&lt;p&gt;Before we start coding a model or even looking at any data, let’s formally discuss the biochemical domain experitise.&lt;/p&gt;
&lt;div id=&#34;hill-equation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hill Equation&lt;/h2&gt;
&lt;p&gt;When a ligand, e.g. a drug, is an antagonist to a receptor that causes some tissue response, the strength of that response, &lt;span class=&#34;math inline&#34;&gt;\(\mu_i\)&lt;/span&gt;, declines with increased concentration of that ligand, &lt;span class=&#34;math inline&#34;&gt;\([A_i]\)&lt;/span&gt;. The response is known to follow the Hill Equation &lt;span class=&#34;citation&#34;&gt;[&lt;a href=&#34;#ref-Neubig597&#34; role=&#34;doc-biblioref&#34;&gt;1&lt;/a&gt;]&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu_i = top - \frac{bottom - top}{1 + 10^{(\log_{10}(IC_{50}) - \log_{10}([A_i]))^{n_H}}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When tissue response is plotted against log ligand concentration, the Hill equation is a downwards sloping S-curve where &lt;span class=&#34;math inline&#34;&gt;\(top\)&lt;/span&gt; is the maximum response and &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt; is the minimum response. &lt;span class=&#34;math inline&#34;&gt;\(IC_{50}\)&lt;/span&gt; is the concentration at which the response is halfway between &lt;span class=&#34;math inline&#34;&gt;\(top\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt;. The final parameter, the Hill coefficient &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt;, affects the steepness of the curve and is determined by the underlying kinetics. At &lt;span class=&#34;math inline&#34;&gt;\(n_H = 1\)&lt;/span&gt;, a ligand binding is independent of previously bound ligands. At &lt;span class=&#34;math inline&#34;&gt;\(n_H &amp;lt; 1\)&lt;/span&gt; binding has diminishing returns and at &lt;span class=&#34;math inline&#34;&gt;\(n_H &amp;gt; 1\)&lt;/span&gt; ligands cooperatively bind for increasing returns on tissue response.&lt;/p&gt;
&lt;p&gt;The Hill Equation appears in various forms in literature. Notably, when the ligand is an agonist, the curve has a positive slope and the halfway point is then often named &lt;span class=&#34;math inline&#34;&gt;\(EC_{50}\)&lt;/span&gt;. The logarithm base used could also be any other, but base 10 is a common choice, as 10 times dilutions or other whole-number dilutions are easier to make.&lt;/p&gt;
&lt;p&gt;Let’s plot an example curve&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hill_function &amp;lt;- function(log_conc, bottom, top, log_IC50, nH) {
  top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH))
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bottom &amp;lt;- 0
top &amp;lt;- 1
log_IC50 &amp;lt;- -3
nH &amp;lt;- 1
ggplot() +
  xlim(log_IC50 - 3, log_IC50 + 3) +
  geom_function(
    fun = hill_function,
    args = list(bottom = bottom, top = top, log_IC50 = log_IC50, nH = nH),
    aes(colour = &amp;quot;Tissue response&amp;quot;)
  ) +
  labs(
    x = &amp;quot;log ligand concentration&amp;quot;,
    y = &amp;quot;response&amp;quot;,
    title = &amp;quot;Hill Equation Example&amp;quot;
  ) +
  scale_colour_manual(values = c(&amp;quot;Tissue response&amp;quot; = colour$azure)) +
  theme_minimal() +
  theme(legend.title = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-one/index_files/figure-html/hill_equation-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the real world, we cannot sample the true tissue response exactly. As a proxy for the tissue response, we employ assays that are performed &lt;em&gt;in vitro&lt;/em&gt;. Such assays are sensitive to environmental conditions and, even in the most strictly controlled settings, yield noisy responses. Baring any systematic bias, the assay response, &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; should average to the true tissue response though.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;assay_response &amp;lt;- function(log_conc, bottom, top, log_IC50, nH, sigma) {
  noise &amp;lt;- rnorm(length(log_conc), 0, sigma)
  hill_function(log_conc, bottom, top, log_IC50, nH) + noise
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble::tibble(
  log_conc = seq(log_IC50 -3, log_IC50 + 3, length.out = 5),
  y = assay_response(log_conc, bottom, top, log_IC50, nH, (top - bottom)/20)
) %&amp;gt;% 
  ggplot(aes(log_conc, y)) +
  geom_point(aes(colour = &amp;quot;Noisy assay response&amp;quot;)) +
  geom_function(
    fun = hill_function,
    args = list(bottom = bottom, top = top, log_IC50 = log_IC50, nH = nH),
    aes(colour = &amp;quot;Tissue response&amp;quot;)
  ) +
  scale_colour_manual(values = c(
    &amp;quot;Tissue response&amp;quot; = colour$azure,
    &amp;quot;Noisy assay response&amp;quot; = colour$orange_light
  )) +
  labs(
    x = &amp;quot;log ligand concentration&amp;quot;,
    y = &amp;quot;response&amp;quot;,
    colour = &amp;quot;&amp;quot;
  ) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-one/index_files/figure-html/noisy_assay_response-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;from-domain-expertise-to-probabilistic-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;From Domain Expertise to Probabilistic Model&lt;/h2&gt;
&lt;p&gt;With the basic domain knowledge in place, we are ready to start thinking about the assay in terms of probability distributions.&lt;/p&gt;
&lt;p&gt;The first expression relates our observed assay responses, &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;, to the true underlying tissue response, &lt;span class=&#34;math inline&#34;&gt;\(\mu_i\)&lt;/span&gt;. Given repeat observations, the assay response should average to the tissue response and the variance should be small and finite, so it is not too far a stretch to think of the assay response as a sample from a normal distribution.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim {\sf Normal}(\mu_i, \sigma)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is a parameter that is shared among all observations.&lt;/p&gt;
&lt;p&gt;We already know how the tissue response relates to the ligand concentration, &lt;span class=&#34;math inline&#34;&gt;\([A_i]\)&lt;/span&gt;, the variable of our assay; it is the Hill equation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu_i = top - \frac{bottom - top}{1 + 10^{(\log_{10}(IC_{50}) - \log_{10}([A_i]))^{n_H}}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;These two expressions define our observational model or likelihood function. Next, we need to specify our prior model, and this is where domain expertise comes in handy.&lt;/p&gt;
&lt;p&gt;The prior model needs to have prior assumptions and corresponding distributions for each parameter in the model. The parameters that need priors are &lt;span class=&#34;math inline&#34;&gt;\(IC_{50}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(top\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_i\)&lt;/span&gt; is an unobserved variable - it is a deterministic function of the model parameters and our variable, &lt;span class=&#34;math inline&#34;&gt;\([A_i]\)&lt;/span&gt;, so it does not need a prior.&lt;/p&gt;
&lt;p&gt;The priors will always have to be specific to the assay at hand. In this study, we are not considering a real assay, but will be simulating instead. Even so, we can still discuss general prior strategies for parameters of the model, in the light of our general knowledge about the biochemical processes. Later, when we start simulating, we can lock in specific priors.&lt;/p&gt;
&lt;p&gt;Let’s consider each parameter in turn, starting with &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;a-prior-for-the-hill-coefficient&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A prior for the Hill coefficient&lt;/h3&gt;
&lt;p&gt;The Hill coefficient will in many cases be well known. For instance, if the receptor that causes the tissue response is known to have only one binding site for the ligand, it extremely unlikely that we will observe any cooperative or competitive kinetics.&lt;/p&gt;
&lt;p&gt;When each ligand binds an individual receptor, the binding should be independent, regardless of the nature of the ligand. Hence, in theory, &lt;span class=&#34;math inline&#34;&gt;\(n_H = 1\)&lt;/span&gt; and we can assign a narrow prior, say &lt;span class=&#34;math inline&#34;&gt;\(n_H \sim {\sf Normal}(1, 0.1)\)&lt;/span&gt;. This prior puts 95% of the probability between 0.8 and 1.2. If we were very sure, we could go for an even narrower prior.&lt;/p&gt;
&lt;p&gt;In case we encountered a response with cooperative binding, we would just move the prior distribution a bit above 1. For instance, if we were studying hemoglobin, we could put the prior at &lt;span class=&#34;math inline&#34;&gt;\({\sf Normal}(2.5, 0.5)\)&lt;/span&gt; or thereabouts.&lt;/p&gt;
&lt;p&gt;We know one more thing though. The Hill coefficient cannot be less than zero, as that would change the kinetics of the system. With the narrow prior around &lt;span class=&#34;math inline&#34;&gt;\(n_H = 1\)&lt;/span&gt; it is not really an issue, as there is virtually no probability mass below 0, but for kinetics with diminishing returns, an exponential prior or a half-normal distribution may be preferable.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-prior-for-the-maximum-tissue-response&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A prior for the maximum tissue response&lt;/h3&gt;
&lt;p&gt;When discussing the &lt;span class=&#34;math inline&#34;&gt;\(top\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt; parameters, it is worth discussing assay technique. Even though the assay is performed &lt;em&gt;in vitro&lt;/em&gt;, the subject, e.g. tissue, receptor, or enzyme, is often a biological construct and thus likely to exhibit batch variation. Furthermore, the raw assay reading carries no particular meaning. Instead, we employ controls to get a normalised response. For instance, we might use a bit of buffer as a negative control and assign the corresponding response to 1 and, at the other end, we might use a known strongly binding ligand as a positive control and assign the corresponding response to 0. The raw readings are then normalised between these two controls to yield the assay response, &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Back to the maximum response. In most contexts, the maximum response is not all that interesting compared to the other parameters. We expect the maximum response to be in the vicinity of the negative control, and if we were doing regular curve fitting, we might just fix the maximum response at 1.&lt;/p&gt;
&lt;p&gt;In terms of probabilities, it means that we have very strong prior knowledge about the maximum response. We could allow it to vary a bit, but I assert that is would not offer much utility.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-prior-for-the-minimum-tissue-response&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A prior for the minimum tissue response&lt;/h3&gt;
&lt;p&gt;The minimum response, &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt;, is much more interesting, as it represents the greatest effect a ligand can have on a tissue response. Analogous to the negative control, we set the response of a positive control to 0. However, we cannot necessarily fix the minimum response at this point.&lt;/p&gt;
&lt;p&gt;Imagine an assay where we are testing a chemical compound in the hopes of identifying a new antagonist for the tissue response of interest. If the compound is not a ligand for the receptor, there is no response and &lt;span class=&#34;math inline&#34;&gt;\(bottom = top\)&lt;/span&gt;. On the other hand, if we come across a ligand, then it might elicit a stronger or weaker response than the positive control.&lt;/p&gt;
&lt;p&gt;What does this mean in terms of a prior? It means that screening experiments require a relatively wide prior for the &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt; parameter; we only know that it should be less than &lt;span class=&#34;math inline&#34;&gt;\(top\)&lt;/span&gt; and that it is unlikely to be much smaller than 0. However, if we are studying the kinetics of the system and we have a known strong ligand as positive control, we can choose a much narrower prior around 0.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-prior-for-potency&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A prior for potency&lt;/h3&gt;
&lt;p&gt;Deciding on a prior for &lt;span class=&#34;math inline&#34;&gt;\(IC_{50}\)&lt;/span&gt; is difficult for two reasons. If we are screening new compounds, we might have no idea about the potency of the compound or whether it even has potency at all. Secondly, &lt;span class=&#34;math inline&#34;&gt;\(IC_{50}\)&lt;/span&gt; is a concentration and the tissue response depends on the ligand concentration relative to this concentration. In other words, it is the magnitude of the potency that matters.&lt;/p&gt;
&lt;p&gt;The way to handle this is by thinking of a prior for &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; instead. Units matter, but if we use Molar concentration then &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50}) = -9\)&lt;/span&gt; would correspond to an extremely potent ligand and &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50}) = 0\)&lt;/span&gt; would correspond to extremely low potency.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-prior-for-experiment-noise&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A prior for experiment noise&lt;/h3&gt;
&lt;p&gt;Hopefully, the experiment noise is minimal. Consider &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.1\)&lt;/span&gt;. Since we expect most readings to fall in the range &lt;span class=&#34;math inline&#34;&gt;\([0, 1]\)&lt;/span&gt;, this noise level translates to 95% of assay responses being within +-20% of the tissue response. This might be a lot or it might be what is expected from a biological assay, but the point is that, as long as we normalise the assay responses, this parameter should be easy to reason about. For instance, &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; can never be less than zero, and if it is higher than 0.5, then the assay is more noise than signal.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-studies&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example Studies&lt;/h1&gt;
&lt;p&gt;Let’s move on to some simulated studies&lt;/p&gt;
&lt;div id=&#34;example-study-1---exploring-kinetics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example Study 1 - Exploring Kinetics&lt;/h2&gt;
&lt;p&gt;In this study we are imagining a situation where we are trying to learn more about the kinetics of a tissue response. We are investigating a receptor for which we have a known strongly binding antagonist. We suspect that the receptor has multiple binding sites and that ligand binding is not independent. We also do not know the potency, &lt;span class=&#34;math inline&#34;&gt;\(IC_{50}\)&lt;/span&gt;, of the antagonist, but we know that maximum tissue response is observed at &lt;span class=&#34;math inline&#34;&gt;\([A_i] &amp;gt; 10^{-3}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let’s set some ‘secret’ values for the system and simulate assay readings. Later, we will try to recover these values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;study_1_params &amp;lt;- list(
  bottom = 0,
  top = 1,
  log_IC50 = -5.6,
  nH = 1.4,
  sigma = 0.05
)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;a-model-for-study-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A model for study 1&lt;/h3&gt;
&lt;p&gt;Before performing the experiment, i.e. simulating observations, we should take some time to reflect on our domain expertise and translate it into a bespoke probabilistic model for this particular scenario.&lt;/p&gt;
&lt;p&gt;We know that we will measure an assay response, &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;, for a number of ligand concentrations &lt;span class=&#34;math inline&#34;&gt;\([A_i]\)&lt;/span&gt;. We also know that the assay response averages to the tissue response, &lt;span class=&#34;math inline&#34;&gt;\(\mu_i\)&lt;/span&gt;, but that observations are noisy:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim {\sf Normal}(\mu_i, \sigma)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The tissue response is a deterministic function of four kinetic parameters, as described by the Hill equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu_i = top - \frac{bottom - top}{1 + 10^{(\log_{10}(IC_{50}) - \log_{10}([A_i]))^{n_H}}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(top\)&lt;/span&gt; parameter should, on average, be equal to our negative control, which we fix at 1. Our negative control is just water or buffer, and we have no reason to believe that the maximum tissue response when ligand concentration is infinitely small is any different from the buffer. Thus, our domain expertise tells us to put a very narrow prior on this parameter:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[top \sim {\sf Normal}(1, 0.01)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt; parameter should, on average, be equal to our positive control, which we fix at 0. Our positive control is an extreme concentration of the ligand to be sure that it elicits the minimum tissue response. We have no reason to believe that the minimum tissue response when ligand concentration is infinitely large is any different from the extreme concentration. Thus, our domain expertise tells us to put a very narrow prior on this parameter too:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[bottom \sim {\sf Normal}(0, 0.01)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We do not know much about the Hill coefficient, &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt;, as we have limited experience with the underlying kinetics. We do, however, know that the Hill coefficient should not be less than 0. While &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt; may be more or less than 1, we also know that it is very unlikely that it is orders of magnitude smaller or larger. We can place a wide log-normal prior on this parameter to keep it positive and we can choose distribution parameters such that there is equal probability above and below 1:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n_H \sim {\sf LogNormal}(0, 1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We also do not know much about &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt;, but we consider -9 and -3 fairly extreme values, so we can just use a wide normal prior that keeps the parameter mostly in that range:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\log_{10}(IC_{50}) \sim {\sf Normal}(-6, 1.5)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Finally, we should consider how noisy our observations might be. We have little experience with this assay, so we expect a lot of noise. Let’s say that we expect the assay response to be within 20% above or below the tissue response, in most cases. This roughly translates to an expectation of &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.1\)&lt;/span&gt;. We also know that &lt;span class=&#34;math inline&#34;&gt;\(\sigma &amp;gt; 0\)&lt;/span&gt;, so we can use an exponential prior with an expectation of 0.1, i.e. a rate of 10:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma \sim {\sf Exp}(10)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prior-predictive-check-in-tidyverse&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Prior predictive check in Tidyverse&lt;/h3&gt;
&lt;p&gt;With the model specified, my hands are itching to start fitting. That would be a poor idea, though. Before fitting, we should verify that the model as a whole conforms to our domain knowledge. Even though we have chosen what we think are reasonable priors, it it difficult to get an intuition about how all those priors interact. However, since the model is probabilistic and generative, we can sample predictions from it without fitting anything first. If the distribution of those prior predictions agree with our expectations, then we are good to go.&lt;/p&gt;
&lt;p&gt;For a simple model like this, it is fairly easy to perform such a prior predictive check with Tidyverse and basic R functionality. First we sample parameters from the prior distributions, then we calculate the deterministic variables, and finally draw out the curves.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_samples &amp;lt;- 50
# A function to easily sample prior parameters
study_1_priors &amp;lt;- function(n) {
  tibble::tibble(
    top = rnorm(n, 1, 0.01),
    bottom = rnorm(n, 0, 0.01),
    nH = rlnorm(n, 0, 1),
    log_IC50 = rnorm(n, -6, 1.5),
    sigma = rexp(n, 10)
  )
}
# Draw each corresponding assay response
study_1_prior_pred_samples &amp;lt;- study_1_priors(n_samples) %&amp;gt;%
  dplyr::filter(top &amp;gt; bottom) %&amp;gt;% # This is very unlikely to happen though
  dplyr::mutate(
    tissue_response = purrr::pmap(
      list(top, bottom, nH, log_IC50, sigma),
      ~ geom_function(
        fun = assay_response,
        args = list(
          top = ..1,
          bottom = ..2,
          nH = ..3,
          log_IC50 = ..4,
          sigma = ..5
        ),
        colour = colour$blue_dark,
        alpha = 0.5
      )
    )
  )

p &amp;lt;- ggplot() +
  xlim(-9, -3) +
  theme_minimal() +
  labs(x = &amp;quot;Ligand concentration [M]&amp;quot; , y = &amp;quot;Prior assay response&amp;quot;)
Reduce(`+`, study_1_prior_pred_samples$tissue_response, init = p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-one/index_files/figure-html/prior_pred_check_example_1-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This looks much like the curves we would expect from a real assay. Extreme concentrations have extreme responses and the s-shaped part of the curve is somewhere in between. In some cases, the noise is extreme but that is probably to be expected from an assay where we have little or no experience.&lt;/p&gt;
&lt;p&gt;I initially set the prior for &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt; way too wide, resulting in many extreme responses. That does not comply with domain knowledge, so I shrunk the prior.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;building-a-stan-model-for-study-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Building a Stan model for study 1&lt;/h3&gt;
&lt;p&gt;Now we are almost ready to fit the model. To do so, I have implemented it in Stan. There are other excellent introductions to Stan, see the &lt;a href=&#34;https://mc-stan.org/docs/2_28/stan-users-guide/index.html&#34;&gt;Stan User Guide&lt;/a&gt; or some of the references below.&lt;/p&gt;
&lt;p&gt;Here is the Stan model that corresponds to the model described above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(readLines(&amp;quot;hill_equation_study_1.stan&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;data {
  int&amp;lt;lower=0&amp;gt; N; // Number of observations
  vector[N] log_conc; // Tested concentration on log10 scale
  vector[N] y; // Normalised assay responses
}
parameters {
  real bottom;
  real&amp;lt;lower=bottom&amp;gt; top;
  real log_IC50;
  real&amp;lt;lower=0&amp;gt; nH;
  real&amp;lt;lower=0&amp;gt; sigma;
}
model {
  vector[N] mu;
  bottom ~ normal(0, 0.01);
  top ~ normal(1, 0.01);
  log_IC50 ~ normal(-6, 1.5);
  nH ~ lognormal(0, 1);
  sigma ~ exponential(10);
  for ( i in 1:N) {
    mu[i] = top + (bottom - top)/(1 + 10^((log_IC50 - log_conc[i])*nH));
  }
  y ~ normal(mu, sigma);
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-study-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fitting study 1&lt;/h3&gt;
&lt;p&gt;Now we can simulate some observations and fit the model. To make the simulation realistic, we generate observations in a wide space of ligand concentration, from &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}([A_i]) = -9\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}([A_i]) = -3\)&lt;/span&gt;. To make it a challenge, we will generate just 6 observations.&lt;/p&gt;
&lt;p&gt;Fitting our bespoke Bayesian model amounts to sampling from the posterior distribution. Here I am drawing 1000 samples per chain from the posterior. This is not a large model, so we could easily sample a lot more if we wanted.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_observations &amp;lt;- 6
n_posterior_samples &amp;lt;- 1e3

# Determine the log concentrations at which to simulate
study_1_concentrations &amp;lt;- seq(-9, -3, length.out = n_observations)

# Simulate observations using our &amp;#39;secret&amp;#39; parameters
study_1_observations &amp;lt;- rlang::exec(
  assay_response,
  study_1_concentrations,
  !!!study_1_params
)

# Everything the model needs to know
study_1_data_list &amp;lt;- list(
  N = n_observations,
  log_conc = study_1_concentrations,
  y = study_1_observations
)

# This compiles the model and samples from the posterior
study_1_post &amp;lt;- rstan::stan(
  &amp;quot;hill_equation_study_1.stan&amp;quot;,
  data = study_1_data_list,
  chains = 4,
  iter = n_posterior_samples * 2,
  warmup = n_posterior_samples,
  seed = 4444
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have samples from the posterior distribution. Let’s put them to work!&lt;/p&gt;
&lt;p&gt;Recall that the underlying research question was the kinetics of the tissue response. So more than the actual tissue response, we are interested in the posterior marginal distributions for the Hill coefficient, &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt;, and the potency, &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt;. We can extract samples for the marginal distribution of each of our model parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Extract samples from the posterior distribution
posterior_samples &amp;lt;- rstan::extract(study_1_post) %&amp;gt;% 
  tibble::as_tibble() %&amp;gt;%
  dplyr::select(bottom, top, log_IC50, nH, sigma)

# True parameters of the simulation.
parameter_tibble &amp;lt;- study_1_params %&amp;gt;%
  tibble::as_tibble() %&amp;gt;%
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &amp;quot;parameter&amp;quot;,
    values_to = &amp;quot;truth&amp;quot;
  )

# Plot each of the marginal distributions, comparing prior, posterior, and true
#  simulation parameters
posterior_samples %&amp;gt;%
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &amp;quot;parameter&amp;quot;,
    values_to = &amp;quot;sample&amp;quot;
  ) %&amp;gt;%
  dplyr::left_join(parameter_tibble, by = &amp;quot;parameter&amp;quot;) %&amp;gt;%
  ggplot() +
  geom_histogram(
    data = tidyr::pivot_longer(
      study_1_priors(nrow(posterior_samples)),
      dplyr::everything(),
      names_to = &amp;quot;parameter&amp;quot;,
      values_to = &amp;quot;sample&amp;quot;
    ),
    mapping = aes(x = sample, fill = &amp;quot;Prior&amp;quot;),
    bins = 50,
    alpha = 0.5
  ) +
  geom_histogram(aes(x = sample, fill = &amp;quot;Posterior&amp;quot;), bins = 50, alpha = 0.5) +
  geom_vline(aes(xintercept = truth, colour = &amp;quot;truth&amp;quot;), alpha = 0.5) +
  facet_wrap(~ parameter, scales = &amp;quot;free&amp;quot;) +
  theme_minimal() +
  scale_colour_manual(values = c(&amp;quot;truth&amp;quot; = colour$orange_light)) +
  scale_fill_manual(values = c(
    &amp;quot;Prior&amp;quot; = colour$azure,
    &amp;quot;Posterior&amp;quot; = colour$blue_dark
  )) +
  labs(
    y = &amp;quot;Posterior sample count&amp;quot;,
    x = &amp;quot;&amp;quot;,
    colour = &amp;quot;&amp;quot;,
    fill = &amp;quot;&amp;quot;,
    title = &amp;quot;Marginal Posterior and Prior Distributions&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-one/index_files/figure-html/posterior_marginals_example_1-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are so many exciting things to discuss here. I have opted to plot samples from both the posterior and prior distributions, so we can appreciate how the data worked to update our prior beliefs to posterior distributions.&lt;/p&gt;
&lt;p&gt;The first thing to notice is that the parameters for which we selected very narrow priors, i.e. &lt;span class=&#34;math inline&#34;&gt;\(top\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt;, nothing has changed. The data is not enough to overwhelm the strong priors and the posterior is mostly informed by the prior.&lt;/p&gt;
&lt;p&gt;On the other hand, the data has provided enough information to concentrate the probability density to a much narrower interval for the three remaining parameters. The posterior median for &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; is very close to the truth. &lt;span class=&#34;math inline&#34;&gt;\(nH\)&lt;/span&gt; is a bit more uncertain, but most of the probability is concentrated well above one, which correctly suggests cooperatively binding ligands.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_summaries &amp;lt;- rstan::summary(
  study_1_post,
  pars = c(&amp;quot;bottom&amp;quot;, &amp;quot;top&amp;quot;, &amp;quot;log_IC50&amp;quot;, &amp;quot;nH&amp;quot;, &amp;quot;sigma&amp;quot;),
  probs = c(0.055, 0.5, 0.945)
)$summary

tibble::as_tibble(post_summaries) %&amp;gt;% 
  dplyr::select(c(&amp;quot;5.5%&amp;quot;, &amp;quot;50%&amp;quot;, &amp;quot;94.5%&amp;quot;)) %&amp;gt;%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %&amp;gt;%
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;5.5%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;50%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;94.5%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0170975&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.0010557&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0144481&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;top&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9861742&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0016366&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0170142&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-5.7516723&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-5.5360470&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-5.4050335&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;nH&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9012444&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.6121050&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.1663929&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sigma&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0434627&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0712316&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1351734&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;At this point, we can draw a conclusion for our experiment: Given our model assumptions, data strongly suggests cooperatively binding kinetics with a 89% compatibility interval for &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; at about &lt;span class=&#34;math inline&#34;&gt;\([-5.75, -5.41]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;To improve the result, we could run another experiment using this much narrower range for &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; as a prior and for determining ligand concentrations to test, as that interval is likely to contain the s-shaped part of the Hill curve.&lt;/p&gt;
&lt;p&gt;Speaking of the Hill curve, let’s see what our posterior predictions look like for the tissue response as a function of log ligand concentration.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;study_1_post_pred &amp;lt;- posterior_samples %&amp;gt;%
  tidyr::expand_grid(log_conc = seq(-3, -9, length.out = 50)) %&amp;gt;% 
  dplyr::mutate(tissue_response = purrr::pmap_dbl(
    list(log_conc, bottom, top, log_IC50, nH),
    hill_function
  )) %&amp;gt;%
  dplyr::group_by(log_conc) %&amp;gt;%
  dplyr::summarise(
    response_mean = mean(tissue_response),
    response_upper = quantile(tissue_response, probs = 0.945),
    response_lower = quantile(tissue_response, probs = 0.055)
  ) %&amp;gt;%
  ggplot() +
  geom_ribbon(
    aes(
      x = log_conc,
      ymin = response_lower,
      ymax = response_upper,
      fill = &amp;quot;89% interval&amp;quot;
    ),
    alpha = 0.5
  ) +
  geom_line(aes(x = log_conc, y = response_mean, colour = &amp;quot;Posterior mean&amp;quot;)) +
  geom_point(
    data = tibble::tibble(
      log_conc = study_1_concentrations,
      observations = study_1_observations
    ),
    aes(x = log_conc, y = observations, colour = &amp;quot;Observations&amp;quot;)
  ) +
  geom_function(
    fun = hill_function,
    args = study_1_params[-5],
    mapping = aes(colour = &amp;quot;True tissue response&amp;quot;)
  ) +
  labs(
    y = &amp;quot;Tissue response&amp;quot;,
    x = &amp;quot;Log ligand concentration [M]&amp;quot;,
    colour = &amp;quot;&amp;quot;,
    fill = &amp;quot;&amp;quot;
  ) +
  scale_fill_manual(values = c(&amp;quot;89% interval&amp;quot; = colour$azure)) +
  theme_minimal()
study_1_post_pred +
  scale_colour_manual(values = c(
    &amp;quot;Posterior mean&amp;quot; = colour$blue_dark,
    &amp;quot;Observations&amp;quot; = colour$orange_light,
    &amp;quot;True tissue response&amp;quot; = colour$orange_dark
  ))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-one/index_files/figure-html/posterior_predictive_example_1-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The true tissue response is all contained in the 89% interval for the posterior predicted response, despite noisy observations and despite the fact that 5 out of 6 observations lie outside the s-shaped part of the curve.&lt;/p&gt;
&lt;p&gt;However, it also seems that we got lucky and had an observation very close to the true &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt;. This point quite clearly provides an anchor for the entire model. We might not always be this lucky. In that case, however, the posterior marginal distributions for the kinetic parameters would just be much more informed by the priors, in turn telling us that we should perform more experiments.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-study-2---new-drug&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example Study 2 - New Drug&lt;/h2&gt;
&lt;p&gt;In this study, we imagine that we are developing a new potential drug candidate. As a part of the development process, we have produced a modified version of an endogenous ligand and we are looking to assess its potency, &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt;, and efficacy, which is defined in terms of &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We are able to approximate the tissue response &lt;em&gt;in vitro&lt;/em&gt;, but it involves complex biochemistry, so noisy measurements are to be expected.&lt;/p&gt;
&lt;p&gt;The tissue response to the endogenous ligand is well characterised, so we know that the ligands bind independently, i.e. &lt;span class=&#34;math inline&#34;&gt;\(n_H = 1\)&lt;/span&gt;, and we know that for the endogenous ligand &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50}) = -7.2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let’s set some ‘secret’ values for the system and simulate assay readings. Later, we will try to recover these values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;study_2_params &amp;lt;- list(
  bottom = 0.2,
  top = 1,
  log_IC50 = -7.6,
  nH = 1,
  sigma = 0.1
)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;a-model-for-study-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A model for study 2&lt;/h3&gt;
&lt;p&gt;We are still assuming the same kinetics for the tissue response as in study 1.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim {\sf Normal}(\mu_i, \sigma)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu_i = top - \frac{bottom - top}{1 + 10^{(\log_{10}(IC_{50}) - \log_{10}([A_i]))^{n_H}}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Our assumptions about the &lt;span class=&#34;math inline&#34;&gt;\(top\)&lt;/span&gt; parameter are the same as in study 1.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[top \sim {\sf Normal}(1, 0.01)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In this case, we have produced a variant of the endogenous ligand. The most likely scenario is that our modification causes the ligand to lose efficacy such that the minimum tissue response is somewhere between 0 and 1. However, there is a small chance that our superior design yields a ligand that is more efficacious than the endogenous ligand and thus has a minimum response below 0. Our prior for the &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt; parameter should thus be concentrated between 0 and 1 but with some probability below 0. I have opted for a normal prior.&lt;/p&gt;
&lt;p&gt;Note that this prior puts some probability in the scenario where the &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt; parameter is larger than the &lt;span class=&#34;math inline&#34;&gt;\(top\)&lt;/span&gt; parameter. This is not consistent with our domain knowledge and it is a challenge that we will handle in a moment.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[bottom \sim {\sf Normal}(0.25, 0.25)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Changing the ligand will not change the receptor, so it is extremely unlikely that the Hill coefficient changes.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n_H \sim {\sf Normal}(1, 0.01)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The modified ligand is likely to lose potency, i.e. have a higher &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt;, compared to the endogenous ligand which has &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50}) = -7.2\)&lt;/span&gt;, but we might get lucky and see an increase. This is not much to go on, but it should still allow us to use a narrower prior than in study 1.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\log_{10}(IC_{50}) \sim {\sf Normal}(-6, 0.7)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Noise is expected to be quite severe.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma \sim {\sf Exp}(10)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prior-predictive-check-with-stan&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Prior predictive check with Stan&lt;/h3&gt;
&lt;p&gt;As in the previous study, we should check that the prior predictive distribution conforms to expectations as given by our domain expertise.&lt;/p&gt;
&lt;p&gt;This time I have opted to utilise Stan to sample from the priors. It is a bit of extra work, but it scales well for larger and more complex models.&lt;/p&gt;
&lt;p&gt;One challenge we have, is the constraint that &lt;span class=&#34;math inline&#34;&gt;\(top \ge bottom\)&lt;/span&gt;. A way to handle this could be to discard any samples that violates the constraint and replace them with new samples until the desired number of samples are obtained. I would like something a bit more elegant.&lt;/p&gt;
&lt;p&gt;In Stan, constraints can be set on parameters and, during Monte Carlo sampling from the posterior, those constraints are enforced. However, when we want to use random number generators to sample from the prior distributions, we have to enforce it ourselves. I have implemented a small Stan program to sample from the priors in study 2:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(readLines(&amp;quot;hill_equation_study_2_prior.stan&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;functions {
  // A lower-bounded normal distribution random number generator
  real normal_lower_rng(real mu, real sigma, real lower_bound) {
    // Locate the lower bound
    real p_lower_bound = normal_cdf(lower_bound, mu, sigma);
    // Uniformly sample probabilities in the bounded range
    real u = uniform_rng(p_lower_bound, 1);
    // Transform back to a normal distribution
    real y = mu + sigma * inv_Phi(u);
    return y;
  }
  // An upper-bounded normal distribution random number generator
  real normal_upper_rng(real mu, real sigma, real upper_bound) {
    // Locate the upper bound
    real p_upper_bound = normal_cdf(upper_bound, mu, sigma);
    // Uniformly sample probabilities in the bounded range
    real u = uniform_rng(0, p_upper_bound);
    // Transform back to a normal distribution
    real y = mu + sigma * inv_Phi(u);
    return y;
  }
}
data {
  int&amp;lt;lower=0&amp;gt; N; // Number of samples
  vector[N] log_conc; // Tested concentration on log10 scale
}
generated quantities{
  real&amp;lt;lower = 0&amp;gt; nH = normal_lower_rng(1, 0.01, 0);
  real top = normal_rng(1, 0.01);
  real bottom = normal_upper_rng(0.25, 0.25, top);
  real log_IC50 = normal_rng(-6, 0.7);
  real sigma = exponential_rng(10);
  vector[N] mu;
  vector[N] y;
  for ( i in 1:N) {
    mu[i] = top + (bottom - top)/(1 + 10^((log_IC50 - log_conc[i])*nH));
    y[i] = normal_rng(mu[i], sigma);
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that there is no &lt;code&gt;model&lt;/code&gt; block in the code. This program should not run a Monte Carlo simulation. Rather, it should just pull samples from the prior distributions. This can be accomplished with Stan’s Fixed Parameter mode.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_prior_samples &amp;lt;- 50
log_conc &amp;lt;- seq(-9, -3, length.out = n_prior_samples)

prior &amp;lt;- rstan::stan(
  &amp;quot;hill_equation_study_2_prior.stan&amp;quot;,
  data = list(N = n_prior_samples, log_conc = log_conc),
  algorithm = &amp;quot;Fixed_param&amp;quot;,
  chains = 1,
  iter = 100,
  warmup = 0,
  seed = 4444
)

samples &amp;lt;- rstan::extract(prior)

sample_readings &amp;lt;- lapply(1:100, function(i) {
  tibble::tibble(
  y = samples$y[i,],
  x = log_conc
) %&amp;gt;% 
  geom_line(mapping = aes(x, y), colour = colour$blue_dark, alpha = 0.5)
})
p &amp;lt;- ggplot() + 
  theme_minimal() +
  labs(x = &amp;quot;Ligand concentration [M]&amp;quot; , y = &amp;quot;Prior assay response&amp;quot;)
Reduce(`+`, sample_readings, init = p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-one/index_files/figure-html/prior_2_stan-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We expect most potential curves to reach 50% of their minimum response well above -7.2, corresponding to lost potency. There is, however, still a small chance of increased potency, i.e. a value smaller than -7.2. Likewise for the minimum response, we find it most likely that a modification will cause the minimum response to be somewhere between 0 and 1, yet there is a chance that the minimum response is less than zero.&lt;/p&gt;
&lt;p&gt;All in all, these seem like suitable priors, but we also note that the amount of noise could severely impact conclusions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;building-a-stan-model-for-study-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Building a Stan model for study 2&lt;/h3&gt;
&lt;p&gt;Here is the Stan model that corresponds to the model described above. Note that we do not need to specify our own distribution functions to satisfy constraints. When running the simulation, Stan keeps track of constraints and makes sure that they are satisfied.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(readLines(&amp;quot;hill_equation_study_2_post.stan&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;data {
  int&amp;lt;lower=0&amp;gt; N;
  vector[N] log_conc;
  vector[N] y;
}
parameters {
  real bottom;
  real&amp;lt;lower=bottom&amp;gt; top;
  real log_IC50;
  real&amp;lt;lower=0&amp;gt; nH;
  real&amp;lt;lower=0&amp;gt; sigma;
}
model {
  vector[N] mu;
  bottom ~ normal(0.25, 0.25);
  top ~ normal(1, 0.01);
  log_IC50 ~ normal(-6, 0.7);
  nH ~ normal(1, 0.01);
  sigma ~ exponential(10);
  for ( i in 1:N) {
    mu[i] = top + (bottom - top)/(1 + 10^((log_IC50 - log_conc[i])*nH));
  }
  y ~ normal(mu, sigma);
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-study-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fitting study 2&lt;/h3&gt;
&lt;p&gt;Now we can simulate some observations and fit the model. As we do not expect our modified ligand to stray too far from the curve of the endogenous ligand, we generate observations in a narrow space of ligand concentration, from &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}([A_i]) = -7.5\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}([A_i]) = -4.5\)&lt;/span&gt;. To make it a challenge, we will generate just 6 observations.&lt;/p&gt;
&lt;p&gt;As for study 1, I am drawing 1000 samples per chain from the posterior.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_observations &amp;lt;- 6
n_posterior_samples &amp;lt;- 1e3

# Determine the log concentrations at which to simulate
study_2_concentrations &amp;lt;- seq(-7.5, -4.5, length.out = n_observations)

# Simulate observations using our &amp;#39;secret&amp;#39; parameters
study_2_observations &amp;lt;- rlang::exec(
  assay_response,
  study_2_concentrations,
  !!!study_2_params
)

# Everything the model needs to know
data_list &amp;lt;- list(
  N = n_observations,
  log_conc = study_2_concentrations,
  y = study_2_observations
)

# This compiles the model and samples from the posterior
study_2_post &amp;lt;- rstan::stan(
  &amp;quot;hill_equation_study_2_post.stan&amp;quot;,
  data = data_list,
  chains = 4,
  iter = n_posterior_samples * 2,
  warmup = n_posterior_samples,
  seed = 4444
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The underlying research question for this study was primarily concerned with the &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt; parameters. So more than the actual tissue response, we are interested in the marginal posterior distributions for these two parameters. Let’s start by summarising the marginal posterior distributions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;study_2_priors &amp;lt;- function(n) {
  tibble::tibble(
    top = rnorm(n, 1, 0.01),
    bottom = rnorm(n, 0.25, 0.25),
    nH = rnorm(n, 1, 0.01),
    log_IC50 = rnorm(n, -6, 0.7),
    sigma = rexp(n, 10)
  )
}

# Extract samples from the posterior distribution
posterior_samples &amp;lt;- rstan::extract(study_2_post) %&amp;gt;% 
  tibble::as_tibble() %&amp;gt;%
  dplyr::select(bottom, top, log_IC50, nH, sigma)

# True parameters of the simulation.
parameter_tibble &amp;lt;- study_2_params %&amp;gt;%
  tibble::as_tibble() %&amp;gt;%
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &amp;quot;parameter&amp;quot;,
    values_to = &amp;quot;truth&amp;quot;
  )

# Plot each of the marginal distributions, comparing prior, posterior, and true
#  simulation parameters
posterior_samples %&amp;gt;%
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &amp;quot;parameter&amp;quot;,
    values_to = &amp;quot;sample&amp;quot;
  ) %&amp;gt;%
  dplyr::left_join(parameter_tibble, by = &amp;quot;parameter&amp;quot;) %&amp;gt;%
  ggplot() +
  geom_histogram(
    data = tidyr::pivot_longer(
      study_2_priors(nrow(posterior_samples)),
      dplyr::everything(),
      names_to = &amp;quot;parameter&amp;quot;,
      values_to = &amp;quot;sample&amp;quot;
    ),
    mapping = aes(x = sample, fill = &amp;quot;Prior&amp;quot;),
    bins = 50,
    alpha = 0.5
  ) +
  geom_histogram(aes(x = sample, fill = &amp;quot;Posterior&amp;quot;), bins = 50, alpha = 0.5) +
  geom_vline(aes(xintercept = truth, colour = &amp;quot;truth&amp;quot;), alpha = 0.5) +
  facet_wrap(~ parameter, scales = &amp;quot;free&amp;quot;) +
  theme_minimal() +
  scale_colour_manual(values = c(&amp;quot;truth&amp;quot; = colour$orange_light)) +
  scale_fill_manual(
    values = c(&amp;quot;Prior&amp;quot; = colour$azure, &amp;quot;Posterior&amp;quot; = colour$blue_dark)
  ) +
  labs(
    y = &amp;quot;Posterior sample count&amp;quot;,
    x = &amp;quot;&amp;quot;,
    colour = &amp;quot;&amp;quot;,
    fill = &amp;quot;&amp;quot;,
    title = &amp;quot;Marginal Posterior and Prior Distributions&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-one/index_files/figure-html/posterior_marginals_study_2-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The first thing to notice here is that the posterior probability mass is more concentrated than the prior. However, the marginal posterior distributions for &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt; are still relatively wide. Recall that a difference of one in &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; is an order of magnitude in terms of concentration. Small changes in potency matter a lot if we have to manufacture the compound at one point. So our data did not tell us much about the precise potency and efficacy of this modified ligand.&lt;/p&gt;
&lt;p&gt;On the other hand, the posterior probability mass is mostly at &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50}) &amp;lt; -7.2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(bottom &amp;gt; 0\)&lt;/span&gt;, i.e. we are quite certain that our modified ligand has higher potency than the endogenous ligand but elicits a smaller response. With well defined priors and a small amount of data, we have a perfectly good screening experiment.&lt;/p&gt;
&lt;p&gt;If we were interested in gaining a better understanding of the modified ligand, we could perform more experiments and get those posterior probability masses even more concentrated. We also see that the true noise of the assay is quite high; reducing it might help to better learn the underlying tissue response.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_summaries &amp;lt;- rstan::summary(
  study_2_post,
  pars = c(&amp;quot;bottom&amp;quot;, &amp;quot;top&amp;quot;, &amp;quot;log_IC50&amp;quot;, &amp;quot;nH&amp;quot;, &amp;quot;sigma&amp;quot;),
  probs = c(0.055, 0.5, 0.945)
)$summary

tibble::as_tibble(post_summaries) %&amp;gt;% 
  dplyr::select(c(&amp;quot;5.5%&amp;quot;, &amp;quot;50%&amp;quot;, &amp;quot;94.5%&amp;quot;)) %&amp;gt;%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %&amp;gt;%
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;5.5%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;50%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;94.5%&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0848792&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1544085&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2183073&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;top&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9831631&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9995818&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0156166&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-7.7146376&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-7.4971292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-7.2296555&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;nH&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9842731&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9999304&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0161020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sigma&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0405449&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.0680069&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1388871&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;At this point, we can draw a conclusion for our experiment: Given our model assumptions, data strongly suggests that the modified ligand has higher potency than the endogenous ligand with a 89% credibility interval for &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; at about &lt;span class=&#34;math inline&#34;&gt;\([-8.08, -7.22]\)&lt;/span&gt;. We also conclude that the modified ligand has less efficacy than the endogenous ligand with a 89% credibility interval for &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt; at about &lt;span class=&#34;math inline&#34;&gt;\([0.12, 0.30]\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Before accepting the conclusion, it is a good idea to look at the posterior predictions and compare them to the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples %&amp;gt;%
  tidyr::expand_grid(log_conc = seq(-3, -9, length.out = 50)) %&amp;gt;% 
  dplyr::mutate(tissue_response = purrr::pmap_dbl(
    list(log_conc, bottom, top, log_IC50, nH),
    hill_function
  )) %&amp;gt;%
  dplyr::group_by(log_conc) %&amp;gt;%
  dplyr::summarise(
    response_mean = mean(tissue_response),
    response_upper = quantile(tissue_response, probs = 0.945),
    response_lower = quantile(tissue_response, probs = 0.055)
  ) %&amp;gt;%
  ggplot() +
  geom_ribbon(
    aes(
      x = log_conc,
      ymin = response_lower,
      ymax = response_upper,
      fill = &amp;quot;89% interval&amp;quot;
    ),
    alpha = 0.5
  ) +
  geom_line(aes(x = log_conc, y = response_mean, colour = &amp;quot;Posterior mean&amp;quot;)) +
  geom_point(
    data = tibble::tibble(
      log_conc = study_2_concentrations,
      observations = study_2_observations
    ),
    aes(x = log_conc, y = observations, colour = &amp;quot;Observations&amp;quot;)
  ) +
  geom_function(
    fun = hill_function,
    args = study_2_params[-5],
    mapping = aes(colour = &amp;quot;True tissue response&amp;quot;)
  ) +
  scale_colour_manual(values = c(
    &amp;quot;Posterior mean&amp;quot; = colour$blue_dark,
    &amp;quot;Observations&amp;quot; = colour$orange_light,
    &amp;quot;True tissue response&amp;quot; = colour$orange_dark
  )) +
  labs(
    y = &amp;quot;Tissue response&amp;quot;,
    x = &amp;quot;Log ligand concentration [M]&amp;quot;,
    colour = &amp;quot;&amp;quot;,
    fill = &amp;quot;&amp;quot;
  ) +
  scale_fill_manual(values = c(&amp;quot;89% interval&amp;quot; = colour$azure)) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-one/index_files/figure-html/posterior_predictive_study_2-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The true tissue response is all contained in the 89% interval for the posterior predicted response, despite noisy observations and despite the fact that 4 out of 6 observations lie outside the s-shaped part of the curve.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;assessing-posterior-quality&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Assessing posterior quality&lt;/h2&gt;
&lt;p&gt;During the two studies, I avoided a rather important subject, namely assessing the quality of our posterior estimate. The algorithm that explores and samples from the posterior, Hamiltonian Monte Carlo (HMC), is as much a part of the Bayesian model as priors and as such should enjoy the same deliberate consideration.&lt;/p&gt;
&lt;p&gt;We have observed that the posterior predictive distribution yields reasonable predictions, which gives us a lot of confidence in the model as a whole. In these studies, we could also compare the predictions to the true underlying parameters of the simulations, so we know that the model is at least somewhat right.&lt;/p&gt;
&lt;p&gt;All is not perfectly well, however. In study one, Stan complains that during the HMC run there were divergent transitions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rstan::check_divergences(study_1_post)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;5 of 4000 iterations ended with a divergence (0.125%).
Try increasing &amp;#39;adapt_delta&amp;#39; to remove the divergences.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://mc-stan.org/misc/warnings.html#runtime-warnings&#34;&gt;Stan is noisy&lt;/a&gt; and will complain when something seems wrong in the HMC sampler.&lt;/p&gt;
&lt;p&gt;In this case, it is divergent transitions which usually happens when an iteration ends up in a part of parameter space where the probabilities have large gradients.&lt;/p&gt;
&lt;p&gt;Increasing &lt;code&gt;adapt_delta&lt;/code&gt; as suggested by Stan will help avoid the divergent transitions, but why were they there in the first place? Let’s look at some diagnostic parameters for the posterior in the first study:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_summaries &amp;lt;- rstan::summary(
  study_1_post,
  pars = c(&amp;quot;bottom&amp;quot;, &amp;quot;top&amp;quot;, &amp;quot;log_IC50&amp;quot;, &amp;quot;nH&amp;quot;, &amp;quot;sigma&amp;quot;),
  probs = c(0.055, 0.5, 0.945)
)$summary

tibble::as_tibble(post_summaries) %&amp;gt;% 
  dplyr::select(c(&amp;quot;n_eff&amp;quot;, &amp;quot;Rhat&amp;quot;)) %&amp;gt;%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %&amp;gt;%
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n_eff&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Rhat&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1610.7382&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.002482&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;top&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3738.8936&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.000015&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1401.6208&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.002600&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;nH&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;523.3805&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.012667&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sigma&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1414.4814&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.000310&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;code&gt;n_eff&lt;/code&gt; is an estimate of the number of independent samples from the posterior. &lt;code&gt;Rhat&lt;/code&gt; is a measure of convergence. Values &lt;span class=&#34;math inline&#34;&gt;\(\hat{R} &amp;gt; 1.01\)&lt;/span&gt; indicate that convergence has not entirely been reached.&lt;/p&gt;
&lt;p&gt;According to the diagnostics, the marginal posterior for &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt; has been challenging to estimate. This is not altogether surprising, considering that we only have one good point on the s-shaped part of the curve. There are many combinations of &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt; that would pass though the point equally well and some of them have extreme probability gradients.&lt;/p&gt;
&lt;p&gt;So why does increasing &lt;code&gt;adapt_delta&lt;/code&gt; work? Intuitively, it causes Stan to pick a smaller step size for the HMC sampler. This reduces the chance that the sample ends up in a far off part of parameter space where gradients are extreme. The trade-off is that the posterior might be less efficiently sampled, so for larger models, one might have to do more samples to fully explore the posterior.&lt;/p&gt;
&lt;p&gt;Let’s try running study one with an increased &lt;code&gt;adapt_delta&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;study_1_post_improved &amp;lt;- rstan::stan(
  &amp;quot;hill_equation_study_1.stan&amp;quot;,
  data = study_1_data_list,
  chains = 4,
  iter = n_posterior_samples * 2,
  warmup = n_posterior_samples,
  seed = 4444,
  control = list(adapt_delta = 0.95)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That should improve the situation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rstan::check_divergences(study_1_post_improved)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;0 of 4000 iterations ended with a divergence.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indeed it did!. Let’s also have a look at the diagnostics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_summaries &amp;lt;- rstan::summary(
  study_1_post_improved,
  pars = c(&amp;quot;bottom&amp;quot;, &amp;quot;top&amp;quot;, &amp;quot;log_IC50&amp;quot;, &amp;quot;nH&amp;quot;, &amp;quot;sigma&amp;quot;),
  probs = c(0.055, 0.5, 0.945)
)$summary

tibble::as_tibble(post_summaries) %&amp;gt;% 
  dplyr::select(c(&amp;quot;n_eff&amp;quot;, &amp;quot;Rhat&amp;quot;)) %&amp;gt;%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %&amp;gt;%
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n_eff&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Rhat&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2103.743&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9995628&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;top&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3942.552&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0001219&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1152.528&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0010730&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;nH&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1380.143&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0016422&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sigma&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1375.529&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0041702&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The numbers have improved and we have more faith in the posterior samples. Remember though that having good diagnostics alone does not imply a good model. The diagnostic check should be combined with prior and posterior predictive checks to ensure that the model is reasonable.&lt;/p&gt;
&lt;p&gt;There is so much more to discuss about diagnosing HMC - we have barely scratched the surface here. &lt;code&gt;?rstan::check_hmc_diagnostics&lt;/code&gt; is a great place to start, if you want to learn more.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;comparing-to-another-fitting-method&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Comparing to another fitting method&lt;/h2&gt;
&lt;p&gt;Before wrapping up, I’d like to return to my initial goal, which was to squeeze more information out of the data I get from biochemical assays.&lt;/p&gt;
&lt;p&gt;At this point, all we have done is fit a model to two experiments of six data points each and, despite the assistance from Stan, it has taken more code and more computation than a ‘classic’ fit would have. So was it worth it? Let’s compare.&lt;/p&gt;
&lt;p&gt;Here I am fitting the data from study one using non-linear least squares. To make it fair, I have put in as much information as the optimisation algorithm allows: the initial guess is at the median of the priors we set for study one and the parameters are roughly constrained to the 95% prior interval.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod &amp;lt;- nls(
  y ~ top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH)),
  data = study_1_data_list,
  algorithm = &amp;quot;port&amp;quot;,
  start = list(bottom = 0, top = 1, log_IC50 = -6, nH = 1),
  lower = list(bottom = -0.02, top = 0.98, log_IC50 = -9, nH = 0),
  upper = list(bottom = 0.02, top = 1.02, log_IC50 = -3, nH = 100)
)

study_1_post_pred +
  geom_function(
    fun = hill_function,
    args = mod$m$getPars(),
    mapping = aes(colour = &amp;quot;NLS fit&amp;quot;)
  ) +
  scale_colour_manual(values = c(
    &amp;quot;Posterior mean&amp;quot; = colour$blue_dark,
    &amp;quot;Observations&amp;quot; = colour$orange_light,
    &amp;quot;True tissue response&amp;quot; = colour$orange_dark,
    &amp;quot;NLS fit&amp;quot; = &amp;quot;black&amp;quot;
  ))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-one/index_files/figure-html/posterior_predictive_study_1_improved-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The NLS fit is obviously close to the true tissue response and it took much less code and time to fit. Compared to our Bayesian model, the NLS fit is not bad. In fact, it will be useful in many cases, but there are a few notable differences.&lt;/p&gt;
&lt;p&gt;With the Bayesian model, we get an estimate of the amount of noise in the experiment, in addition to the parameters of the Hill equation. Such an estimate can be very useful for understanding and continuous improvement of the biochemical assays.&lt;/p&gt;
&lt;p&gt;With the Bayesian model, we also get marginal posterior distributions. With a regular fit, we only get a point estimate for each parameter and any uncertainty is lost. We do not always need anything but a point estimate to answer our hypotheses, but the marginal posterior distributions can be useful in future experimental design and as priors for the next experiment.&lt;/p&gt;
&lt;p&gt;Finally there is an added robustness. Biological data has all sorts of weird behaviour. In a situation where the data points are all over the place, due to some unknown external factor, the resulting Bayesian model would show little or no change from the prior model, whereas the NLS model would fail altogether. So with a Bayesian model, we can rely on probabilities to tell us when an experiment is an outlier.&lt;/p&gt;
&lt;p&gt;At the end of the day, the chosen method depends on the downstream application of the parameters and the hypotheses that we are trying to answer with the data. For now, I am keeping both in my toolbox, but I am seeing increased usefulness for the Bayesian approach, especially in screening experiments.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Next Steps&lt;/h1&gt;
&lt;p&gt;In the preceding two study examples, we spent a lot of time fuzzing over just a few data points. In real applications, however, data is often more abundant and more diverse. In particular, I am thinking of screening experiments. In screening experiments, one might test a large number of potential ligands at once, meaning that there is more data but also more behaviour to be captured.&lt;/p&gt;
&lt;p&gt;In my next study, I will be discussing development of a bespoke Bayesian model for high-throughput biochemical screening assays. Stay tuned!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body&#34;&gt;
&lt;div id=&#34;ref-Neubig597&#34; class=&#34;csl-entry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[1] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Neubig&lt;/span&gt;, R. R., &lt;span class=&#34;smallcaps&#34;&gt;Spedding&lt;/span&gt;, M., &lt;span class=&#34;smallcaps&#34;&gt;Kenakin&lt;/span&gt;, T. and &lt;span class=&#34;smallcaps&#34;&gt;Christopoulos&lt;/span&gt;, A. (2003). International union of pharmacology committee on receptor nomenclature and drug classification. XXXVIII. Update on terms and symbols in quantitative pharmacology. &lt;em&gt;Pharmacological Reviews&lt;/em&gt; &lt;strong&gt;55&lt;/strong&gt; 597–606 Available at &lt;a href=&#34;https://pharmrev.aspetjournals.org/content/55/4/597&#34;&gt;https://pharmrev.aspetjournals.org/content/55/4/597&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-McElreath:2016&#34; class=&#34;csl-entry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[2] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;McElreath&lt;/span&gt;, R. (2020). &lt;em&gt;Statistical rethinking: A bayesian course with examples in r and stan&lt;/em&gt;. CRC Press.&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Betancourt:2019&#34; class=&#34;csl-entry&#34;&gt;
&lt;div class=&#34;csl-left-margin&#34;&gt;[3] &lt;/div&gt;&lt;div class=&#34;csl-right-inline&#34;&gt;&lt;span class=&#34;smallcaps&#34;&gt;Betancourt&lt;/span&gt;, M. (2019). Probabilistic modeling and statistical inference. Available at &lt;a href=&#34;https://github.com/betanalpha/knitr_case_studies/tree/master/modeling_and_inference&#34;&gt;https://github.com/betanalpha/knitr_case_studies/tree/master/modeling_and_inference&lt;/a&gt;.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;license&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;License&lt;/h1&gt;
&lt;p&gt;The content of this project itself is licensed under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International license&lt;/a&gt;, and the underlying code is licensed under the &lt;a href=&#34;https://github.com/AnHosu/bespoke-bayesian-biochem/blob/main/LICENSE&#34;&gt;GNU General Public License v3.0 license&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Olympic Athletes over Time - A Tidy Bayesian Data Exploration</title>
      <link>/post/bayesian-olympics/</link>
      <pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate>
      <guid>/post/bayesian-olympics/</guid>
      <description>
&lt;script src=&#34;../../post/bayesian-olympics/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;It is the Olympics and thus the perfect time to look at some Olympic data. This set of data is part of the data provided for &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday&#34;&gt;Tidy Tuesday&lt;/a&gt; 2021-07-27 and was originally scraped by GitHub user &lt;a href=&#34;http://www.randigriffin.com/2018/05/27/olympic-history-1-web-scraping.html&#34;&gt;rgriff23&lt;/a&gt;. It is a really cool set of data and I thought it would be the perfect stage to show off how I like to use R and the Tidyverse for numeric calculations in exploratory Bayesian data analysis.&lt;/p&gt;
&lt;p&gt;Let’s get right into it and load in the data.&lt;/p&gt;
&lt;div id=&#34;data-preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data Preparation&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tt_data &amp;lt;- tidytuesdayR::tt_load(&amp;quot;2021-07-27&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(tt_data$olympics)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 15
##      id name    sex     age height weight team   noc   games   year season city 
##   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;
## 1     1 A Diji… M        24    180     80 China  CHN   1992 …  1992 Summer Barc…
## 2     2 A Lamu… M        23    170     60 China  CHN   2012 …  2012 Summer Lond…
## 3     3 Gunnar… M        24     NA     NA Denma… DEN   1920 …  1920 Summer Antw…
## 4     4 Edgar … M        34     NA     NA Denma… DEN   1900 …  1900 Summer Paris
## 5     5 Christ… F        21    185     82 Nethe… NED   1988 …  1988 Winter Calg…
## 6     5 Christ… F        21    185     82 Nethe… NED   1988 …  1988 Winter Calg…
## # … with 3 more variables: sport &amp;lt;chr&amp;gt;, event &amp;lt;chr&amp;gt;, medal &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data holds statistics about athletes that participated in Olympic Games, both summer and winter, from 1896 to 2016. There are so &lt;a href=&#34;https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results&#34;&gt;many great stories&lt;/a&gt; to be told with such an extensive set of data, but here I have chosen to focus on the height data, as it offers a great opportunity to do some simple exploratory Bayesian data analysis and to do so within the great structure of Tidyverse.&lt;/p&gt;
&lt;p&gt;In order to have a goal to work towards, let’s decide to explore the difference in the height of athletes before and after the 1940s. I’ll clean the data a bit and split it into into those two groups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;olympics_data &amp;lt;- tt_data$olympics %&amp;gt;%
  dplyr::filter(!is.na(height), !is.na(weight), season == &amp;quot;Summer&amp;quot;) %&amp;gt;%
  dplyr::distinct(id, .keep_all = TRUE) %&amp;gt;%
  dplyr::mutate(
    div = dplyr::case_when(
      year &amp;lt; 1940 ~ &amp;quot;before&amp;quot;,
      year &amp;gt; 1950 ~ &amp;quot;after&amp;quot;,
      TRUE ~ NA_character_
    )
  ) %&amp;gt;%
  dplyr::filter(!is.na(div))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-model-and-priors&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data Model and Priors&lt;/h1&gt;
&lt;p&gt;I am assuming that athlete height is normally distributed with mean and standard deviation parameters that can be estimated:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[h_i \sim {\sf Normal}(\mu, \sigma)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Before looking at the data, we should determine some sensible priors. I think that the mean athlete height should be somewhere in the range of 150 to 190 cm, and I think that it is possible, but quite unlikely, to fall outside of this range. This translates to a normal prior centered at 170 cm and a 10 cm standard deviation. That way approximately 95% of the probability falls within the 150 to 190 cm range.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu \sim {\sf Normal}(170, 10)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I expect quite a large standard deviation on athlete height. The Olympic games has sports that favour tall athletes and sports that favour short athletes. I am, however, fairly confident that the majority of heights will fall within 60 cm on either side of the mean height. I’ll go for a flat, uniform, prior. Often it makes sense to use a log-normal prior for the standard deviation but, in this case, I would like to allow less regularisation on larger standard deviations.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma \sim {\sf Uniform}(0, 30)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s simulate some prior samples, to ensure that the priors we have chosen are realistic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_prior_samples &amp;lt;- 1e5
tibble::tibble(
  sample_mu = rnorm(n_prior_samples, 170, 10),
  sample_sigma = runif(n_prior_samples, 0, 30),
  prior_pred = rnorm(n_prior_samples, sample_mu, sample_sigma)
) %&amp;gt;% 
  ggplot(aes(x = prior_pred)) +
    geom_density(fill = &amp;quot;#219ebc&amp;quot;, alpha = 0.5, colour = FALSE) +
    labs(x = &amp;quot;Athlete height&amp;quot;, y = &amp;quot;Prior density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bayesian-olympics/index_files/figure-html/prior_sim-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our prior belief of athlete height puts almost all probability in the range 100 to 250 cm. The priors might be a bit on the weak side, but we should have enough data that this is not too consequential.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-data-analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bayesian Data Analysis&lt;/h1&gt;
&lt;p&gt;Since we only have two parameters, we can simulate the posterior distribution using grid approximation. We will estimate the posterior at 1000 values of mu and sigma, so a total of 10e6 parameter combinations.&lt;/p&gt;
&lt;p&gt;I am going to sample 500 athletes from each group. The grid approximation becomes much slower with more data, but 500 examples from each group should be plenty for the question we are exploring.&lt;/p&gt;
&lt;p&gt;Once the parameter grid is generated, the grid approximation proceeds in four steps that we repeat for each of our two sets of data
1. The likelihood of data given the two parameters is calculated for each point in the parameter grid
2. The prior probability of each parameter is calculated for each point in the grid
3. We find the product of likelihood and prior (the numerator of Bayes’ Theorem)
4. We estimate the posterior probabilities at every point on the grid&lt;/p&gt;
&lt;p&gt;Since we have quite a lot of data, the probabilities are going to be extremely small. In fact, if we try to estimate them directly, we cross the precision boundary of R and everything will just evaluate to 0. Instead we will calculate the log probabilities. This also means that probability products instead become sums.&lt;/p&gt;
&lt;p&gt;This is where I find the Tidyverse tools very useful. Instead of keeping simulations in separate vectors, I can build the grid approximation directly in the data frame (tibble) and keep track of the relationship between the elements of the simulation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_data &amp;lt;- 500
n_per_param &amp;lt;- 1e3
# Sample data
heights_before &amp;lt;- olympics_data %&amp;gt;% 
  dplyr::filter(div == &amp;quot;before&amp;quot;) %&amp;gt;%
  dplyr::slice_sample(n = n_data) %&amp;gt;%
  dplyr::pull(height)
heights_after &amp;lt;- olympics_data %&amp;gt;% 
  dplyr::filter(div == &amp;quot;after&amp;quot;) %&amp;gt;%
  dplyr::slice_sample(n = n_data) %&amp;gt;%
  dplyr::pull(height)
# Build grid approximation
grid &amp;lt;- tibble::tibble(
    # These are the grid, not the priors
    mu = seq(from = 160, to = 190, length.out = n_per_param),
    sigma = seq(from = 5, to = 25, length.out = n_per_param)
  ) %&amp;gt;%
  tidyr::expand(mu, sigma) %&amp;gt;%
  dplyr::mutate(
    # Log-likelihoods
    loglikelihood_before = purrr::map2_dbl(
      mu,
      sigma,
      ~ sum(dnorm(mean = .x, sd = .y, x = heights_before, log = TRUE))
    ),
    loglikelihood_after = purrr::map2_dbl(
      mu,
      sigma,
      ~ sum(dnorm(mean = .x, sd = .y, x = heights_after, log = TRUE))
    ),
    # Prior probabilities
    prior_p_mu = dnorm(mu, mean = 170, sd = 10, log = TRUE),
    prior_p_sigma = dunif(sigma, min = 0, max = 30, log = TRUE),
    # Numerator of Bayes&amp;#39; theorem
    logproduct_before = loglikelihood_before + prior_p_mu + prior_p_sigma,
    logproduct_after = loglikelihood_after + prior_p_mu + prior_p_sigma,
    # Posterior probabilities
    posterior_before = exp(logproduct_before - max(logproduct_before)),
    posterior_after = exp(logproduct_after - max(logproduct_after))
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the posterior calculation, I have chosen to subtract the max log-product from the log-product vector before exponentiating and thus moving from log-probabilities to probabilities. To get samples from the true posterior, we would have had to exponentiate the log-products and then divide each product by the sum of the products (the denominator of Bayes’ Theorem). The log-products are very small (large negative numbers), however, and exponentiating them would cause all of them to evaluate to zero. Instead, I opted to subtract the max log-product, which will bring the log-products much closer to zero and yield a number that can be exponentiated. This does mean that the estimated posterior is not the true posterior, but rather proportional to it. We could try to fix it, but this will work fine for what I intend to do.&lt;/p&gt;
&lt;p&gt;Let’s have a look at the posterior parameter distributions. Since we only have two parameters and since we have everything on a neat grid, we can use ggplot2’s geom_tile to draw a nice contour plot of the joint distribution of the parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(grid, aes(x = mu, y = sigma, fill = posterior_before)) +
  geom_tile() +
  labs(
    x = &amp;quot;Mean athelete height, mu (cm)&amp;quot;,
    y = &amp;quot;Standard deviation of athlete height, sigma (cm)&amp;quot;,
    fill = &amp;quot;&amp;quot;,
    title = &amp;quot;Posterior parameter distribution for athlete heights before 1940&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bayesian-olympics/index_files/figure-html/posterior_params-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(grid, aes(x = mu, y = sigma, fill = posterior_after)) +
  geom_tile() +
  labs(
    x = &amp;quot;Mean athelete height, mu (cm)&amp;quot;,
    y = &amp;quot;Standard deviation of athlete height, sigma (cm)&amp;quot;,
    fill = &amp;quot;&amp;quot;,
    title = &amp;quot;Posterior parameter distribution for athlete heights after 1950&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bayesian-olympics/index_files/figure-html/posterior_params-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is not much going on in these plots, but this is actually great. It means that the data has overwhelmed our relatively weak priors and produced a narrow posterior distribution.&lt;/p&gt;
&lt;p&gt;It looks like there is some difference between the two distributions, but this does not necessarily translate to a difference in athlete height. For that, we need to explore the posterior predictive distributions.&lt;/p&gt;
&lt;p&gt;To produce the posterior predictive distributions, we sample mus and sigmas from the grid with replacement and weighted by the posterior probabilities. Using these sampled parameters, we can simulate samples from the posterior predictive distribution using the random normal generator. We can estimate parameter differences by taking the difference between posterior predictive samples. Again, I like to keep everything aligned in a tibble.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_post_pred_samples &amp;lt;- 1e6
post_pred &amp;lt;- tibble::tibble(
  # Samples of mu
  post_samples_mu_before = grid %&amp;gt;% 
    dplyr::slice_sample(
      n = n_post_pred_samples,
      weight_by = posterior_before,
      replace = TRUE
    ) %&amp;gt;% 
    dplyr::pull(mu),
  post_samples_mu_after = grid %&amp;gt;% 
    dplyr::slice_sample(
      n = n_post_pred_samples,
      weight_by = posterior_after,
      replace = TRUE
    ) %&amp;gt;% 
    dplyr::pull(mu),
  # Samples of sigma
  post_samples_sigma_before = grid %&amp;gt;% 
    dplyr::slice_sample(
      n = n_post_pred_samples,
      weight_by = posterior_before,
      replace = TRUE
    ) %&amp;gt;% 
    dplyr::pull(sigma),
  post_samples_sigma_after = grid %&amp;gt;% 
    dplyr::slice_sample(
      n = n_post_pred_samples,
      weight_by = posterior_after,
      replace = TRUE
    ) %&amp;gt;% 
    dplyr::pull(sigma),
  # Posterior predictive samples
  post_pred_before = rnorm(
    n = n_post_pred_samples,
    mean = post_samples_mu_before,
    sd = post_samples_sigma_before
  ),
  post_pred_after = rnorm(
    n = n_post_pred_samples,
    mean = post_samples_mu_after,
    sd = post_samples_sigma_after
  ),
  # Posterior predictive samples for the difference
  post_pred_diff = post_pred_after - post_pred_before,
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s go ahead and plot the distributions of mean height and the posterior predictive distribution for the difference in height.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(post_pred) +
  geom_density(
    aes(x = post_samples_mu_before, fill = &amp;quot;Before 1940&amp;quot;),
    alpha = 0.5,
    colour = FALSE
  ) +
  geom_density(
    aes(x = post_samples_mu_after, fill = &amp;quot;After 1950&amp;quot;),
    alpha = 0.5,
    colour = FALSE
  ) +
  scale_fill_manual(
    name = &amp;quot;&amp;quot;,
    values = c(&amp;quot;Before 1940&amp;quot; = &amp;quot;#219ebc&amp;quot;, &amp;quot;After 1950&amp;quot; = &amp;quot;#ffb703&amp;quot;)
  ) +
  labs(x = &amp;quot;Mean athlete height (cm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bayesian-olympics/index_files/figure-html/pred_posterior_plots-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(post_pred, aes(x = post_pred_diff)) +
  geom_density(fill = &amp;quot;#023047&amp;quot;, alpha = 0.5, colour = FALSE) +
  labs(x = &amp;quot;Difference in athlete height before 1940 and after 1950 (cm)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bayesian-olympics/index_files/figure-html/pred_posterior_plots-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;While it seems that there are some differences in the distribution of heights before and after the 1940s, the posterior predictive distribution for the difference in heights places the most probability in a broad interval that includes 0. So it does not seem reasonable to conclude that there is a difference. For good measure, let’s calculate the highest probability density interval that includes 89% of the probability:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coda::HPDinterval(coda::as.mcmc(post_pred$post_pred_diff), prob = 0.89)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          lower    upper
## var1 -21.48762 21.55056
## attr(,&amp;quot;Probability&amp;quot;)
## [1] 0.89&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We did not find a difference, but we got to estimate some cool distributions. In practice, grid approximated almost never makes sense to do, but it is a really good example of how I use Tidyverse to alleviate some of the organisational headache when doing numeric calculations for Bayesian statistics and other applications.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bespoke Bayesian Model for High Throughput Biochemical Assays</title>
      <link>/post/bespoke-biochem-two/</link>
      <pubDate>Fri, 23 Apr 2021 00:00:00 +0000</pubDate>
      <guid>/post/bespoke-biochem-two/</guid>
      <description>
&lt;script src=&#34;../../post/bespoke-biochem-two/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I am on a quest to improve the model fitting I do on biochemical assays. For some time, I have had this feeling that I should be able to extract more information from the data gathered in biochemical assays, in particular assays with a high throughput.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;../../project/bespoke-biochem-one&#34;&gt;two previous studies&lt;/a&gt; we built bespoke Bayesian models to fit observations from a biochemical assay with kinetics that could be represented by the Hill equation. In those studies, we fit a single curves one at a time. In this study, we extend the model to capture the additional information available when screening a large number of compounds in parallel.&lt;/p&gt;
&lt;p&gt;We start by setting a seed and some nice colours for plotting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(magrittr)

colour &amp;lt;- list(
  orange_dark = &amp;quot;#fb8500&amp;quot;,
  orange_light = &amp;quot;#ffb703&amp;quot;,
  blue_dark = &amp;quot;#023047&amp;quot;,
  azure = &amp;quot;#219ebc&amp;quot;,
  blue_light = &amp;quot;#8ecae6&amp;quot;
)

set.seed(4444)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;high-troughput-biochemical-experiments&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;High Troughput Biochemical Experiments&lt;/h1&gt;
&lt;p&gt;With Bayesian models, we can take advantage of our domain expertise to produce clear answers to our scientific hypotheses and to quantify uncertainty in data and hypotheses. It does, however, require that we are able to represent our expertise as probabilistic models. So before we dive into the Bayesian engine, let’s discuss our biochemistry knowledge and the data we might get from a high throughput experiment.&lt;/p&gt;
&lt;p&gt;We are considering compounds that are potential ligands to receptors and cause a tissue response according to the Hill equation&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu_{ij} = top - \frac{bottom_j - top}{1 + 10^{(\log_{10}(IC_{50,j}) - \log_{10}([A_i]))^{n_H}}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(\mu_{ij}\)&lt;/span&gt; is the tissue response of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;’th compound at concentration &lt;span class=&#34;math inline&#34;&gt;\([A_i]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The equation looks slightly different from the previous studies because we now have multiple compounds in a screening study. The equation also encodes a few assumptions about such an assay. First of all, we are assuming that the tissue response in the absence of ligand, &lt;span class=&#34;math inline&#34;&gt;\(top\)&lt;/span&gt;, is the same for all tested compounds. Similarly, we are assuming that the kinetics of the tissue response, as represented by the Hill number, &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt;, stays the same for all compounds. For the maximum tissue response, &lt;span class=&#34;math inline&#34;&gt;\(bottom_j\)&lt;/span&gt;, and the concentration at half response, &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50,j})\)&lt;/span&gt;, however, we are assuming that each compound has its own parameter.&lt;/p&gt;
&lt;p&gt;These assumptions might not hold true for every experiment, but if we imagine that we are screening compounds for a good drug candidate and we are looking at the same tissue response for each of them, these assumptions should hold.&lt;/p&gt;
&lt;p&gt;As in previous studies, I opt for synthetic data. This has two advantages; we are forced to consider the underlying process that generates our experiment data and, after we have applied a model, we can compare the output to our known truth. We can code the first part of the generative process with a simple function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hill_function &amp;lt;- function(log_conc, bottom, top, log_IC50, nH) {
  top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, our observations are not perfect and will be subject to some noise. For this study, we are going to assume that all observations were made in the same batch, under the same conditions, and at the same time such that they have identically distributed noise. Specifically, we will give the observations some Gaussian noise.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;assay_response &amp;lt;- function(log_conc, bottom, top, log_IC50, nH, sigma) {
  noise &amp;lt;- rnorm(length(log_conc), 0, sigma)
  hill_function(log_conc, bottom, top, log_IC50, nH) + noise
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we should consider what type of screening we are doing. There are a couple of different options. We could screen a lot of random compounds for activity. While this is a common scenario, it is not too interesting to model, as we expect that the vast majority of tested compounds will have no activity. In this study, as in the previous, we instead imagine the case where we produce a large number of variations on an endogenous ligand, in the hopes that we stumble upon something with more desirable properties like higher potency.&lt;/p&gt;
&lt;p&gt;So we produce 100 modifications to an endogenous ligand which has known parameters &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50}) = -7.2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(bottom = 0\)&lt;/span&gt;. We expect that the modifications might cause us to lose potency, i.e. increase &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt;, and efficacy, i.e. increase &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt;, most of the time. To add a little extra challenge, I am adding compounds that have extremely low &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; corresponding to the case where our modification almost or completely removes potency.&lt;/p&gt;
&lt;p&gt;With this, we have the final part of the generative model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_compounds &amp;lt;- 100

true_parameters &amp;lt;- tibble::tibble(
  compound = seq(1, n_compounds),
  bottom = 1 - rlnorm(n_compounds, -0.25, 0.125),
  log_IC50 = rnorm(n_compounds, -5, 1.5) + rexp(n_compounds, 3),
  top = 1.02,
  nH = 0.99,
  sigma = 0.15
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the generative model in place, we can draw a few of the true curves that we will sample from and estimate in our hypothetical screening experiment.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;true_curves &amp;lt;- purrr::pmap(
  true_parameters,
  ~ geom_function(
    fun = hill_function,
    args = list(
      top = ..4,
      bottom = ..2,
      nH = ..5,
      log_IC50 = ..3
    ),
    colour = colour$blue_dark,
    alpha = 0.5
  )
)

p &amp;lt;- ggplot() +
  xlim(-9, -1) +
  theme_minimal() +
  labs(
    x = &amp;quot;Ligand concentration [M]&amp;quot;,
    y = &amp;quot;True tissue response&amp;quot;,
    title = &amp;quot;Sample True Tissue Responses&amp;quot;
  )

Reduce(`+`, true_curves[1:10], init = p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-two/index_files/figure-html/generative_model-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bespoke-bayesian-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bespoke Bayesian Model&lt;/h1&gt;
&lt;p&gt;Now that we understand the generative process and we have some data, we can start considering a Bayesian model. We need to specify two things; a set of relations that describe the generative process and priors for any parameters. If this seems similar to what we just did in the previous section, it is because it is. The Baysian model should reflect the process that generated the data. So let’s get started.&lt;/p&gt;
&lt;div id=&#34;likelihood-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Likelihood Model&lt;/h2&gt;
&lt;p&gt;In our screening assay, we will consider &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; compounds &lt;span class=&#34;math inline&#34;&gt;\(j = 1, ..., M\)&lt;/span&gt;. For each compound, we measure an assay response, &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}\)&lt;/span&gt;, for a number, &lt;span class=&#34;math inline&#34;&gt;\(i = 1, ..., N\)&lt;/span&gt;, of ligand concentrations &lt;span class=&#34;math inline&#34;&gt;\([A_{ij}]\)&lt;/span&gt;. We also know that the assay response averages to the tissue response, &lt;span class=&#34;math inline&#34;&gt;\(\mu_{ij}\)&lt;/span&gt;, but that observations are noisy:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ij} \sim {\sf Normal}(\mu_{ij}, \sigma)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Note that the noise parameter, &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, is the same for all &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; compounds.&lt;/p&gt;
&lt;p&gt;The tissue response is a deterministic function of four kinetic parameters, as described by the Hill equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mu_{ij} = top - \frac{bottom_j - top}{1 + 10^{(\log_{10}(IC_{50,j}) - \log_{10}([A_{ij}]))^{n_H}}}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;priors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Priors&lt;/h2&gt;
&lt;p&gt;For the minimum response parameter, &lt;span class=&#34;math inline&#34;&gt;\(top\)&lt;/span&gt;, we will specify a narrow prior, as we have no indication that it should be anything other than 1.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[top \sim {\sf Normal}(1, 0.01)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In a real scenario the Hill number, &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt;, will probably be well know before high throughput screening experiments are done. For the purpose of demonstration, however, we will give it a relatively wide prior and hope to learn the true number from our data, in this case.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[n_H \sim {\sf LogNormal}(0, 0.5)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For sigma &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, we put a prior that corresponds to a mean standard deviation that is 10% of the assay window. We also want very high noise to be very unlikely.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma \sim {\sf Exp}(10)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We now have multiple &lt;span class=&#34;math inline&#34;&gt;\(bottom_i\)&lt;/span&gt; parameters to consider.&lt;/p&gt;
&lt;p&gt;We know that the most likely scenario is where our modification causes the ligand to lose efficacy yielding a minimum tissue response somewhere between 0 and 1. However, there is a small chance that our superior design yields a ligand that is more efficacious than the endogenous ligand and thus has a minimum response below 0. Our prior for the &lt;span class=&#34;math inline&#34;&gt;\(bottom\)&lt;/span&gt; parameter should thus be concentrated between 0 and 1 but with some probability below 0. Let’s try a normal prior.&lt;/p&gt;
&lt;p&gt;The question that remains is whether this argument is true for all &lt;span class=&#34;math inline&#34;&gt;\(bottom_i\)&lt;/span&gt;. We are going to assume that it is and use the same prior for all &lt;span class=&#34;math inline&#34;&gt;\(bottom_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[bottom_i \sim {\sf Normal}(0.25, 0.25)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The modified ligand is likely to lose potency, i.e. have a higher &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50,i})\)&lt;/span&gt;, compared to the endogenous ligand which has &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50,i}) = -7.2\)&lt;/span&gt;, but we might get lucky and see an increase. This is not much to go on, but it should still allow us to use a somewhat narrow prior. Again, we will use the same prior for all &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50,i})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We added a bit of an extra challenge, allowing for some compounds to have very high &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50,i})\)&lt;/span&gt;. For now, we are going to pretend that we do not have that knowledge and see what this prior will do for us. In a real world scenario, we never know the true distributions. The best priors arise by applying our scientific experience and logic.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\log_{10}(IC_{50}) \sim {\sf Normal}(-6, 1.5)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;prior-predictive-simulation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Prior Predictive Simulation&lt;/h1&gt;
&lt;p&gt;With the model and priors in place, we should control the sensibility of them with a prior predictive check. So let’s imagine that we perform the screening experiment, sampling the underlying parameters from our prior distributions, and have a look at the hypothetical observations that would arise.&lt;/p&gt;
&lt;p&gt;Let’s go ahead and define a function for sampling our priors and simulating a screening experiment.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prior_parameters &amp;lt;- function(n_compounds = NULL,
                             bottom_mean = NULL,
                             bottom_sd = NULL,
                             top_mean = NULL,
                             top_sd = NULL,
                             log_IC50_mean = NULL,
                             log_IC50_sd = NULL,
                             nH_meanlog = NULL,
                             nH_sdlog = NULL,
                             sigma_rate = NULL) {
  tibble::tibble(
      compound = seq(1, n_compounds),
      bottom = rnorm(n_compounds, bottom_mean, bottom_sd),
      log_IC50 = rnorm(n_compounds, log_IC50_mean, log_IC50_sd),
      top = rnorm(1, top_mean, top_sd),
      nH = rlnorm(1, nH_meanlog, nH_sdlog),
      sigma = rexp(1, sigma_rate)
    )
}

screening_experiment &amp;lt;- function(parameters, log_conc) {
  parameters %&amp;gt;% 
    tidyr::expand_grid(log_conc = log_conc) %&amp;gt;%
    dplyr::mutate(
      response = assay_response(log_conc, bottom, top, log_IC50, nH, sigma)
    )
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can do our prior predictive check by performing a hypothetical experiment with our priors&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;priors &amp;lt;- list(
  bottom_mean &amp;lt;- 0.25,
  bottom_sd &amp;lt;- 0.25,
  top_mean &amp;lt;- 1,
  top_sd &amp;lt;- 0.01,
  log_IC50_mean &amp;lt;- -6,
  log_IC50_sd &amp;lt;- 1.5,
  nH_meanlog &amp;lt;- 0,
  nH_sdlog &amp;lt;- 0.5,
  sigma_rate &amp;lt;- 10
)

replicate(
  10,
  rlang::exec(
    prior_parameters,
    n_compounds = 5,
    !!!priors
  ),
  simplify = FALSE
) %&amp;gt;%
  dplyr::bind_rows(.id = &amp;quot;rep&amp;quot;) %&amp;gt;%
  dplyr::mutate(rep = paste0(rep, &amp;quot;-&amp;quot;, compound)) %&amp;gt;%
  screening_experiment(log_conc = seq(-10, -2, length.out = 100)) %&amp;gt;%
  ggplot(aes(x = log_conc, y = response, group = rep)) +
    geom_line(colour = colour$blue_dark, alpha = 0.5) +
    theme_minimal() +
    labs(
    x = &amp;quot;log ligand concentration&amp;quot;,
    y = &amp;quot;response&amp;quot;,
    title = &amp;quot;Prior Samples&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-two/index_files/figure-html/prior_predictive_check-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our prior understanding of the data generating process predicts a diverse set of curves. One of the things that often surprises me is the large number of seeming outliers, even with conservative estimates for noise. Given variance and enough samples, we are bound to see some weird behaviour.&lt;/p&gt;
&lt;p&gt;I think that these hypothetical samples seem like a fair representation of the samples I expect to get from the assay. If for some reason we thought that the hypothetical samples looked too extreme or did not represent the full range of possible observations, we would have to go back and adjust our priors.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bayesian Model&lt;/h1&gt;
&lt;p&gt;Now it is time for the fun part. First we implement the complete Bayesian model, consisting of our observational model and prior distributions, in Stan.&lt;/p&gt;
&lt;p&gt;The trick here is to define an index variable that keeps track of parameters for individual curves.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeLines(readLines(&amp;quot;hill_equation_screening.stan&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;data {
  int&amp;lt;lower=0&amp;gt; N;
  int&amp;lt;lower=0&amp;gt; M;
  int&amp;lt;lower=0&amp;gt; curve_ind[N];
  vector[N] log_conc;
  vector[N] y;
}

parameters {
  real top;
  vector&amp;lt;upper=top&amp;gt;[M] bottom;
  vector[M] log_IC50;
  real&amp;lt;lower=0&amp;gt; nH;
  real&amp;lt;lower=0&amp;gt; sigma;
  
}

model {
  vector[N] mu;
  bottom ~ normal(0.25, 0.25);
  top ~ normal(1, 0.01);
  log_IC50 ~ normal(-6, 1.5);
  nH ~ normal(1, 0.01);
  sigma ~ exponential(10);
  for ( i in 1:N ) {
    mu[i] = top + (bottom[curve_ind[i]] - top) 
                  / (1 + 10^((log_IC50[curve_ind[i]] - log_conc[i])*nH));
  }
  y ~ normal(mu, sigma);
}

generated quantities {
  vector[N] mu;
  vector[N] y_sampled;
  for ( i in 1:N ) {
    mu[i] = top + (bottom[curve_ind[i]] - top) 
                  / (1 + 10^((log_IC50[curve_ind[i]] - log_conc[i])*nH));
    y_sampled[i] = normal_rng(mu[i], sigma);
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;conditioning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conditioning&lt;/h2&gt;
&lt;p&gt;Next we need some data to condition our model on. So we perform a simulated screening experiment using our true parameters. Recall that we have 100 compounds. In the screening experiment we will sample the tissue response for each compound at 6 different concentrations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;assay_window &amp;lt;- seq(-8, -2, length.out = 6)

observations &amp;lt;- screening_experiment(
  parameters = true_parameters,
  log_conc = assay_window
)

data &amp;lt;- list(
  N = nrow(observations),
  M = max(observations$compound),
  curve_ind = observations$compound,
  log_conc = observations$log_conc,
  y = observations$response
)

post &amp;lt;- rstan::stan_model(&amp;quot;hill_equation_screening.stan&amp;quot;) %&amp;gt;%
  rstan::sampling(
    data = data,
    chains = 4,
    cores = 4,
    seed = 4444
  )

# Extract samples from the posterior distribution
posterior_samples &amp;lt;- rstan::extract(post) %&amp;gt;% tibble::as_tibble()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;examining-the-posterior&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Examining the Posterior&lt;/h1&gt;
&lt;p&gt;Before applying the model, we should do some quality assurance. Since we have simulated data, we can of course compare the posterior distributions to our known truth, and we will definitely do that, in a moment. In real problems, however, the truth is not known and we have to rely on other approaches.&lt;/p&gt;
&lt;p&gt;Here I have three approaches that rely only on the model and the data. None of the approaches will tell us whether the model is a good one, but they will often indicate any problems.&lt;/p&gt;
&lt;div id=&#34;quality-of-the-monte-carlo-simulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quality of the Monte Carlo Simulation&lt;/h2&gt;
&lt;p&gt;The first thing we can do is do a quality check of the Monte Carlo sampling. Stan usually complains when something seems wrong, but we can also check some specific diagnostics.&lt;/p&gt;
&lt;p&gt;I often get divergent transitions when I build multilevel models and they are a signal that there are areas of the model space that are difficult to traverse. Often they can be fixed by increasing the &lt;code&gt;adapt_delta&lt;/code&gt; parameter like we did in a previous study. When that does not work, it is a sign that maybe the model needs to be re-parametrised. For our model in this study, we should not have that problem, though.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rstan::check_divergences(post)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;0 of 4000 iterations ended with a divergence.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When Stan complains about maximum tree depth it is because the Monte Carlo sampler was unable to fully explore some parts of the model space. It is really only an efficiency metric, but a common piece of advise when experiencing tree depth warnings is to use narrower priors. I also often find that I see this warning when I have forgotten to put an explicit prior on a parameter. In this case, we have put a lot of thought into our priors and they should be good.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rstan::check_treedepth(post)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;0 of 4000 iterations saturated the maximum tree depth of 10.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;convergence&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Convergence&lt;/h2&gt;
&lt;p&gt;We should also check check whether each of our parameters have properly converged. Stan provides two metrics for us to review. &lt;span class=&#34;math inline&#34;&gt;\(\hat{R}\)&lt;/span&gt; is a measure of convergence and when &lt;span class=&#34;math inline&#34;&gt;\(\hat{R} &amp;gt; 1.01\)&lt;/span&gt; it is an indication that the posterior samples aren’t quite representative of the true posterior distribution.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(n\_eff\)&lt;/span&gt; is an estimate of the number of true samples our chains represent. If the number of effective samples is low compared to the number of samples we chose to take after warm up, it indicates that it was difficult for the Monte Carlo sampler to figure out that parameter in the grand scheme of things. Sometimes it helps to increase &lt;code&gt;adapt_delta&lt;/code&gt; and do more warm-up samples, but I find that it is also often indicative of data that is very incompatible with the model and its priors. In this study, we ran four chains with 1000 samples after warm-up, so we would like to see at least several hundred effective samples.&lt;/p&gt;
&lt;p&gt;Let’s just have a look at the parameters that proved to be most difficult.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_summaries &amp;lt;- rstan::summary(
  post,
  pars = c(&amp;quot;bottom&amp;quot;, &amp;quot;log_IC50&amp;quot;),
  probs = NULL
)$summary

tibble::as_tibble(post_summaries) %&amp;gt;%
  dplyr::select(-c(mean, se_mean, sd)) %&amp;gt;%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %&amp;gt;%
  dplyr::mutate(dplyr::across(-parameter, round, digits = 3)) %&amp;gt;%
  dplyr::arrange(desc(Rhat)) %&amp;gt;%
  dplyr::slice_head(n = 10) %&amp;gt;%
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n_eff&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Rhat&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50[83]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1177.101&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.003&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[2]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4258.387&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50[2]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4483.525&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50[37]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1349.972&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50[71]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2269.627&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[26]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3953.336&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[32]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6086.841&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[37]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1252.062&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[44]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4487.325&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[71]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4270.506&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.001&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It looks like our parameters have converged nicely.&lt;/p&gt;
&lt;p&gt;Note that some parameters have &lt;span class=&#34;math inline&#34;&gt;\(n\_eff\)&lt;/span&gt; that are quite a bit below the 4000 samples after warm-up. This is not necessarily a cause for concern, but in case it is very low and we want to use the distribution for predictive purposes, it might be a good idea to increase the number of samples after warm-up a bit.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-replication-check&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Replication Check&lt;/h2&gt;
&lt;p&gt;A great sanity check for a model is whether it is able to replicate the data. Our model is fully generative, meaning we can generate hypothetical samples. For a good model, when we generate a number of samples corresponding to the number of data points, the qualitative properties those samples should be similar to those of the original data. Parameters like mean and variance will be very similar, as those are basically the parameters we conditioned on the data, but more qualitative aspects like minimum data point, maximum, or general shape are not a given.&lt;/p&gt;
&lt;p&gt;In the Stan script, I included some generated quantities that are essentially sample observations, so we can compare. We will skip comparing maximum and minimum and just compare the overall shape.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  geom_histogram(
    data = observations,
    mapping = aes(x = response, y = ..density.., fill = &amp;quot;Observed responses&amp;quot;),
    bins = 30,
    alpha = 0.5
  ) +
  geom_histogram(
    data = tibble::tibble(y_sampled = as.vector(posterior_samples$y_sampled)),
    mapping = aes(x = y_sampled, y = ..density.., fill = &amp;quot;Posterior samples&amp;quot;),
    bins = 300,
    alpha = 0.5
  ) +
  theme_minimal() +
  scale_fill_manual(values = list(
    &amp;quot;Observed responses&amp;quot; = colour$azure,
    &amp;quot;Posterior samples&amp;quot; = colour$blue_dark
  )) +
  labs(
    fill = &amp;quot;&amp;quot;,
    y = &amp;quot;Density&amp;quot;,
    x = &amp;quot;Response&amp;quot;,
    title = &amp;quot;Shape Check&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-two/index_files/figure-html/shape_check-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It really looks like out model replicates the data quite nicely. Usually the concerns are whether the tails match; if the data has minimum points that are outside what the model yields or if the samples span a much wider range than the data, it might be cause to rethink the model.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;results&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;p&gt;Our model and the posterior samples seem to be of decent quality, so let’s put them to use.&lt;/p&gt;
&lt;div id=&#34;posterior-marginal-distributions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Posterior Marginal Distributions&lt;/h2&gt;
&lt;p&gt;So our model has 203 parameters, 2 for each of the 100 compounds and 3 parameters that are shared between all of them. Let’s see what we have learned about the three shared parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# True parameters of the simulation.
truth &amp;lt;- true_parameters %&amp;gt;%
  dplyr::slice_head(n = 1) %&amp;gt;%
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &amp;quot;parameter&amp;quot;,
    values_to = &amp;quot;truth&amp;quot;
  )

# A number of draws from our priors to match the number of draws we have from
#  the posterior
prior_samples &amp;lt;- replicate(
  nrow(posterior_samples),
  rlang::exec(
    prior_parameters,
    n_compounds = 1,
    !!!priors
  ),
  simplify = FALSE
) %&amp;gt;% 
  dplyr::bind_rows() %&amp;gt;%
  dplyr::select(top, nH, sigma) %&amp;gt;% 
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &amp;quot;parameter&amp;quot;,
    values_to = &amp;quot;sample&amp;quot;
  )

# Plot each of the marginal distributions, comparing prior, posterior, and true
#  simulation parameters
posterior_samples %&amp;gt;%
  dplyr::select(top, nH, sigma) %&amp;gt;%
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &amp;quot;parameter&amp;quot;,
    values_to = &amp;quot;sample&amp;quot;
  ) %&amp;gt;%
  dplyr::left_join(truth, by = &amp;quot;parameter&amp;quot;) %&amp;gt;%
  ggplot() +
  geom_histogram(
    data = prior_samples,
    mapping = aes(x = sample, fill = &amp;quot;Prior&amp;quot;),
    bins = 50,
    alpha = 0.5
  ) +
  geom_histogram(aes(x = sample, fill = &amp;quot;Posterior&amp;quot;), bins = 50, alpha = 0.5) +
  geom_vline(aes(xintercept = truth, colour = &amp;quot;truth&amp;quot;), alpha = 0.5) +
  facet_wrap(~ parameter, scales = &amp;quot;free&amp;quot;) +
  theme_minimal() +
  scale_colour_manual(values = c(&amp;quot;truth&amp;quot; = colour$orange_light)) +
  scale_fill_manual(values = c(
    &amp;quot;Prior&amp;quot; = colour$azure,
    &amp;quot;Posterior&amp;quot; = colour$blue_dark
  )) +
  labs(
    y = &amp;quot;Posterior sample count&amp;quot;,
    x = &amp;quot;&amp;quot;,
    colour = &amp;quot;&amp;quot;,
    fill = &amp;quot;&amp;quot;,
    title = &amp;quot;Marginal Posterior and Prior Distributions&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-two/index_files/figure-html/posterior_marginals_shared-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And some summary statistics&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_summaries &amp;lt;- rstan::summary(
  post,
  pars = c(&amp;quot;top&amp;quot;, &amp;quot;nH&amp;quot;, &amp;quot;sigma&amp;quot;),
  probs = c(0.055, 0.5, 0.945)
)$summary

tibble::as_tibble(post_summaries) %&amp;gt;%
  dplyr::select(-c(mean, se_mean, sd)) %&amp;gt;%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %&amp;gt;%
  dplyr::mutate(dplyr::across(-parameter, round, digits = 2)) %&amp;gt;%
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;5.5%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;50%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;94.5%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n_eff&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Rhat&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;top&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.03&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.04&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4667.23&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;nH&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.99&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9232.87&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sigma&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.15&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.15&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.16&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2994.32&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;When we fitted the curve for each individual compound, we ended up with posteriors that were very similar to our priors, indicating that the data was insufficient to provide additional information. In this case, however, we share information about the curve shape, sample noise, and the minimum response among all compounds. The pooling of all that information causes us to get very exact estimates for the curve shape and the sample noise. The estimates are even essentially equal to the truth. For the minimum response, our prior is still very informative compared to the data, so the posterior distribution has barely changed.&lt;/p&gt;
&lt;p&gt;These results are quite profound. Even with a relatively wide prior on &lt;span class=&#34;math inline&#34;&gt;\(n_H\)&lt;/span&gt;, corresponding to little knowledge about the kinetics of the response, we were able to estimate those exact kinetics, despite the data being intended for a different purpose. In real problems, we would often be much more sure about that parameter. Similarly, we have a very exact estimate of the experiment noise. If we regularly run such screening experiments this would be a great metric to track over time.&lt;/p&gt;
&lt;p&gt;We cannot look at parameters and curves for each of the compounds, so lets just pick a couple, including one that is difficult to fit. As with the shared parameters, we compare the posterior samples to the prior distribution and our known truth.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;example_compounds &amp;lt;- c(1:5, 93)

# True parameters of the simulation.
truth &amp;lt;- true_parameters %&amp;gt;%
  dplyr::filter(compound %in% example_compounds) %&amp;gt;%
  tidyr::pivot_longer(
    -compound,
    names_to = &amp;quot;parameter&amp;quot;,
    values_to = &amp;quot;truth&amp;quot;
  )

# A number of draws from our priors to match the number of draws we have from
#  the posterior
prior_samples &amp;lt;- replicate(
  nrow(posterior_samples),
  rlang::exec(
    prior_parameters,
    n_compounds = 1,
    !!!priors
  ),
  simplify = FALSE
) %&amp;gt;% 
  dplyr::bind_rows() %&amp;gt;%
  dplyr::select(bottom, log_IC50) %&amp;gt;% 
  tidyr::pivot_longer(
    dplyr::everything(),
    names_to = &amp;quot;parameter&amp;quot;,
    values_to = &amp;quot;sample&amp;quot;
  ) %&amp;gt;%
  tidyr::expand_grid(compound = example_compounds)

# Plot each of the marginal distributions, comparing prior, posterior, and true
#  simulation parameters
lapply(example_compounds, function(i) {
  tibble::tibble(
    bottom = posterior_samples$bottom[,i],
    log_IC50 = posterior_samples$log_IC50[,i],
    compound = i
  )
}) %&amp;gt;% 
  dplyr::bind_rows() %&amp;gt;%
  tidyr::pivot_longer(
    -compound,
    names_to = &amp;quot;parameter&amp;quot;,
    values_to = &amp;quot;sample&amp;quot;
  ) %&amp;gt;%
  dplyr::left_join(truth, by = c(&amp;quot;parameter&amp;quot;, &amp;quot;compound&amp;quot;)) %&amp;gt;%
  ggplot() +
  geom_histogram(
    data = prior_samples,
    mapping = aes(x = sample, fill = &amp;quot;Prior&amp;quot;),
    bins = 50,
    alpha = 0.5
  ) +
  geom_histogram(aes(x = sample, fill = &amp;quot;Posterior&amp;quot;), bins = 50, alpha = 0.5) +
  geom_vline(aes(xintercept = truth, colour = &amp;quot;truth&amp;quot;), alpha = 0.5) +
  facet_grid(rows = vars(compound), cols = vars(parameter), scales = &amp;quot;free&amp;quot;) +
  theme_minimal() +
  theme(strip.text.y = element_text(angle = 0)) +
  scale_colour_manual(values = c(&amp;quot;truth&amp;quot; = colour$orange_light)) +
  scale_fill_manual(values = c(
    &amp;quot;Prior&amp;quot; = colour$azure,
    &amp;quot;Posterior&amp;quot; = colour$blue_dark
  )) +
  labs(
    y = &amp;quot;Posterior sample count&amp;quot;,
    x = &amp;quot;&amp;quot;,
    colour = &amp;quot;&amp;quot;,
    fill = &amp;quot;&amp;quot;,
    title = &amp;quot;Marginal Posterior and Prior Distributions&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-two/index_files/figure-html/posterior_marginals_compounds-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And some summary statistics&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post_summaries &amp;lt;- rstan::summary(
  post,
  pars = c(&amp;quot;bottom&amp;quot;, &amp;quot;log_IC50&amp;quot;),
  probs = c(0.055, 0.5, 0.945)
)$summary

tibble::as_tibble(post_summaries) %&amp;gt;%
  dplyr::select(-c(mean, se_mean, sd)) %&amp;gt;%
  dplyr::mutate(parameter = rownames(post_summaries), .before = 1) %&amp;gt;%
  dplyr::mutate(dplyr::across(-parameter, signif, digits = 4)) %&amp;gt;%
  dplyr::filter(stringr::str_detect(
    parameter,
    paste0(&amp;quot;(\\[&amp;quot;, example_compounds, &amp;quot;\\])&amp;quot;, collapse = &amp;quot;|&amp;quot;)
  )) %&amp;gt;%
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;parameter&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;5.5%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;50%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;94.5%&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;n_eff&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Rhat&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[1]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.26640&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.02345&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2899&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6103.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[2]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.05292&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.30550&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5976&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4258.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[3]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.25210&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.42120&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5831&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5681.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9995&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[4]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.04298&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.18550&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.3221&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6510.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9996&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[5]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-0.14800&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.07444&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2785&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5360.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;bottom[93]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.01054&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.22520&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4813&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1621.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9996&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50[1]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-3.38700&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.84400&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.3980&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4842.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50[2]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-3.26300&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-2.54000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-1.9200&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4484.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50[3]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-5.83300&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-4.93800&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-4.1330&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6467.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9993&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50[4]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-6.41500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-5.83600&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-5.2860&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7889.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9995&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50[5]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-4.60200&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-3.93300&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-3.3400&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5696.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;log_IC50[93]&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-6.41600&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-4.05500&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;-3.4590&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;801.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.0010&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;At first glance, these results may seem unimpressive. Even though the posterior has concentrated compared to our prior, it is still fairly wide. Even the compounds with the narrowest estimate of potency has a 89% interval for &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; spanning more than a unit, corresponding to more than an order of magnitude difference in concentration. That is quite a bit.&lt;/p&gt;
&lt;p&gt;Seen from another perspective though, we only had six data points to estimate each of those two parameters. If we were extremely confident in the resulting estimates that would be very suspicious. The means of the marginal posterior distributions are close to the truth, so we have good estimates for any downstream analysis, but the relatively wide distributions are there to remind us that our estimate is uncertain.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;posterior-predictive&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Posterior Predictive&lt;/h2&gt;
&lt;p&gt;One way to understand how much, or how little, our model has learned from the data is to visualise the posterior predictions along with the original data. Here is a curve where things went rather well&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;example_curves &amp;lt;- tibble::tibble(curve = c(3, 93))
example_curves$post_pred &amp;lt;- purrr::map(example_curves$curve, function(i) {
  posterior_samples %&amp;gt;%
  dplyr::mutate(
    log_IC50 = log_IC50[, i],
    bottom = bottom[, i]
  ) %&amp;gt;%
  tidyr::expand_grid(log_conc = seq(-2, -9, length.out = 50)) %&amp;gt;% 
  dplyr::mutate(tissue_response = purrr::pmap_dbl(
    list(log_conc, bottom, top, log_IC50, nH),
    hill_function
  )) %&amp;gt;%
  dplyr::group_by(log_conc) %&amp;gt;%
  dplyr::summarise(
    response_mean = mean(tissue_response),
    response_upper = quantile(tissue_response, probs = 0.945),
    response_lower = quantile(tissue_response, probs = 0.055)
  ) %&amp;gt;%
  ggplot() +
  geom_ribbon(
    aes(
      x = log_conc,
      ymin = response_lower,
      ymax = response_upper,
      fill = &amp;quot;89% interval&amp;quot;
    ),
    alpha = 0.5
  ) +
  geom_line(aes(x = log_conc, y = response_mean, colour = &amp;quot;Posterior mean&amp;quot;)) +
  geom_point(
    data = dplyr::filter(observations, compound == i),
    aes(x = log_conc, y = response, colour = &amp;quot;Observations&amp;quot;)
  ) +
  geom_function(
    fun = hill_function,
    args = true_parameters[i, -c(1,6)],
    mapping = aes(colour = &amp;quot;True tissue response&amp;quot;)
  ) +
  labs(
    y = &amp;quot;Tissue response&amp;quot;,
    x = &amp;quot;Log ligand concentration [M]&amp;quot;,
    colour = &amp;quot;&amp;quot;,
    fill = &amp;quot;&amp;quot;,
    title = paste(&amp;quot;Posterior Predictive for Compound&amp;quot;, i)
  ) +
  scale_fill_manual(values = c(&amp;quot;89% interval&amp;quot; = colour$azure)) +
  theme_minimal()
})
example_curves$post_pred_coloured &amp;lt;- purrr::map(
  example_curves$post_pred,
  function(p) {
    p + scale_colour_manual(values = c(
      &amp;quot;Posterior mean&amp;quot; = colour$blue_dark,
      &amp;quot;Observations&amp;quot; = colour$orange_light,
      &amp;quot;True tissue response&amp;quot; = colour$orange_dark
    ))
  }
)
example_curves$post_pred_coloured[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-two/index_files/figure-html/posterior_predictive-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our model is very open about its uncertainty. While the posterior mean is a great compromise between the data points, the model also knows that the assay is noisy, and it has used the pooled estimate of that noise across all curves to give us this nice interval for any point prediction. Not also how the model has confidently ruled out one of the points as an outlier. I think this is a lot of information gained from just a few points of data.&lt;/p&gt;
&lt;p&gt;Now let’s have a look at a more difficult case&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;example_curves$post_pred_coloured[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-two/index_files/figure-html/posterior_predictive_2-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This one is difficult because we did not get any good points on the curved part of the tissue response. This makes the estimate for &lt;span class=&#34;math inline&#34;&gt;\(\log_{10}(IC_{50})\)&lt;/span&gt; very uncertain, resulting in the bulge in the middle. Despite all this, the 89% interval nicely contains the true tissue response.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-comparison&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model Comparison&lt;/h2&gt;
&lt;p&gt;Before we wrap up, I want to highlight why I like this approach to modelling my screening assay data in this way by comparing it to a classic model fitting method.&lt;/p&gt;
&lt;p&gt;For the comparison, we will use non-linear least squares to directly fit the Hill equation to the data points for a compound. We cannot put flexible priors on the parameters, but we can set constraints that limit the parameters to a range comparable to that of the priors in our Bayesian model.&lt;/p&gt;
&lt;p&gt;Again let’s start by looking at the case where things go well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;example_curves$model_comp &amp;lt;- purrr::map2(
  example_curves$curve,
  example_curves$post_pred,
  function(curve, p) {
    mod &amp;lt;- nls(
      response ~ top + (bottom - top)/(1 + 10^((log_IC50 - log_conc)*nH)),
      data = dplyr::filter(observations, compound == curve),
      algorithm = &amp;quot;port&amp;quot;,
      start = list(bottom = 0.25, top = 1, log_IC50 = -6, nH = 1),
      lower = list(bottom = -0.3, top = 0.98, log_IC50 = -9, nH = 0),
      upper = list(bottom = 1.0, top = 1.02, log_IC50 = -3, nH = 2)
    )
    
    p +
      geom_function(
        fun = hill_function,
        args = mod$m$getPars(),
        mapping = aes(colour = &amp;quot;NLS fit&amp;quot;)
      ) +
      scale_colour_manual(values = c(
        &amp;quot;Posterior mean&amp;quot; = colour$blue_dark,
        &amp;quot;Observations&amp;quot; = colour$orange_light,
        &amp;quot;True tissue response&amp;quot; = colour$orange_dark,
        &amp;quot;NLS fit&amp;quot; = &amp;quot;black&amp;quot;
      ))
  }
)

example_curves$model_comp[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-two/index_files/figure-html/model_comp-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The least squares model is almost identical to our posterior mean estimate and both are close to the truth. This is not altogether surprising, as we had great data points to fit the model curve on. However, only the Bayesian model comes with an estimate of the uncertainty. With the least squares model, we could easily grow overconfident in the fitted parameters.&lt;/p&gt;
&lt;p&gt;Let’s have a look at the more difficult case.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;example_curves$model_comp[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/bespoke-biochem-two/index_files/figure-html/model_comp_2-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this case, the least squares fit was not really able to find a good foothold in the data, yet it confidently reports the fitted parameters. Granted, our Bayesian model had its troubles too, but at least it reports the extreme uncertainty.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In this study, we built and explored a Bayesian model for understanding large compound screening assays. We showed that we can use our prior knowledge to build a bespoke model and that such a model provides us with more useful information than a conventional least squares model. We experienced that it takes a bit more work to ensure the quality of a Bayesian model, but we tried out a few ways to do so.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Next Steps&lt;/h1&gt;
&lt;p&gt;In the preceding study, we assumed that the compounds were random perturbations on a known endogenous ligand. We also assumed that the observations arose under similar circumstances such that they shared a common noise parameter. These assumptions may hold in some cases, but often we know more about our data than that.&lt;/p&gt;
&lt;p&gt;Maybe the permutations could be described with categories or other labels.&lt;/p&gt;
&lt;p&gt;Maybe we performed our screening assay in batches across multiple days, resulting in a possible batch effect on observation data quality.&lt;/p&gt;
&lt;p&gt;Either of these cases add another layer of complexity, but batch effects and labels are both things we can handle with a bespoke Bayesian model. These are the subjects of a future study. Stay tuned!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;license&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;License&lt;/h1&gt;
&lt;p&gt;The content of this project itself is licensed under the &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0/&#34;&gt;Creative Commons Attribution-ShareAlike 4.0 International license&lt;/a&gt;, and the underlying code is licensed under the &lt;a href=&#34;https://github.com/AnHosu/bespoke-bayesian-biochem/blob/main/LICENSE&#34;&gt;GNU General Public License v3.0 license&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
